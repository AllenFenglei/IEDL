2******there be a lot of information on the internet about and . i want to know how i can extract ( or create ) geometric information from an image . for example , if the image classifier can identify that there be a sphere in the image , how can i generate 3d vertices's and edge from that knowledge ? i want to find all the edge and point on these shapeidentifying geometry in images******identifying geometry in images******Jun 28, 2017******1******CA
2******to perform image recognition you have to find a way to represent an image with certain feature . one of the define characteristic of a good image recognition algorithm be it's ability to detect salient region , that be , region which contain the most information there be a lot of attention on deep learning for content-based image classification at the moment . you can achieve decent result by implement deep learning have three or more layer of cnn's where each layer be responsible for extract one or more feature of the image .******none******Feb 15, 2017******1******CA
-1******wolfram language image identification project launch an image identify site demo which return the top predict tag for the photo . how do it work , briefly ? i mean what type of learn vision technology be use to analyze , recognize and understand the content of an image ?how does wolfram's image identification project work?******how does wolfram's image identification project work?******Aug 18, 2016******1******CA
15******can a convolutional neural network be use for pattern recognition in a problem domain where there be no pre-existing image , say by represent abstract data graphically ? would that always be less efficient ? this developer say current development could go far but not if there's a limit outside image recognition .is the pattern recognition capability of cnns limited to image processing?******is the pattern recognition capability of cnns limited to image processing?******Aug 02, 2016******1******CA
-1******accord to this article , pinterest acquire visualgraph , an image recognition and visual search technology startup . how do pinterest apply visualgraph technology for machine vision , image recognition and visual search in order to classify the image ? in short , how do they predict the image category ? base on what feature ?how does pinterest decipher what's on unmarked pictures and categorize them?******how does pinterest decipher what's on unmarked pictures and categorize them?******Aug 18, 2016******1******CA
3******be convolutional neural network summarily good than pattern recognition in all exist image processing library that don't use cnn's ? or be there still hard outstanding problem in image processing that seem to be beyond their capability ?are convolutional neural networks better than existing image recognition libraries that don't use cnns?******are convolutional neural networks better than existing image recognition libraries that don't use cnns?******Sep 15, 2016******1******CA
1******image recognition can be use to classify image . but i want to find few parameter like height of person , his leg , his hand etc . will cnn helpful for this type of output ?can image recognition used to find height of a person whole, torso, legs etc******can image recognition used to find height of a person whole, torso, legs etc******Oct 05, 2017******1******CA
2******to perform image recognition you have to find a way to represent an image with certain feature . one of the define characteristic of a good image recognition algorithm be it's ability to detect salient region , that be , region which contain the most information there be a lot of attention on deep learning for content-based image classification at the moment . you can achieve decent result by implement deep learning have three or more layer of cnn's where each layer be responsible for extract one or more feature of the image .******none******Feb 15, 2017******1******CA
0******i have hundred of . txt file . i need to get into each one of them and remove certain paragraph that start with specific word but a a whole , be not exactly the same every time . be there an automatic way that can help me clean these part out ? if yes , what be it ? if not , be it easy / quick to create my own ai tool for this job ? assume that i need to get this do very soon , do it take a lot of time to learn how to create an ai tool to get the job do for me ? thanks in advance !automated way to clean lots of .txt files?******automated way to clean lots of .txt files?******Mar 10, 2018******1******CA
1******by default use deepdream technique you can create a dreamlike image out of two different image . be it possible to easily enhance this technique to generate one image out from three ?can deepdream produce a "dream" from 3 images?******can deepdream produce a "dream" from 3 images?******Aug 02, 2016******1******CA
1******everything from facial recognition to the google home be come equip with a . i and it be be widely use , if autonomously connect to the internet , will a . i pose a threat to privacy or will it endanger free will if use for surveillance with facial recognition , like in the movie ' minority report 'will commercialisation and widespread use of a.i in security and surveillance and other household products threaten free will or endanger privacy?******will commercialisation and widespread use of a.i in security and surveillance and other household products threaten free will or endanger privacy?******Apr 21, 2018******1******CA
2******i'm try to identify number and letter in license plate . license plate image be take at different light condtion and convert to gray image . my concern with type of data for training be : gray image : since they be take at different lighthing condition , gray image have different pixel intensity for same number . which mean , i have to get many training data for different light condition to train . edge image : they lack enough pixel information since only edge be white while others ( background ) be black . so i think they will be very weak for translational difference like shear or shift . i want to get some information about which type of image be well for train number in different light condition . i wish to use edge image if they don't differ much since i can prepare edge image right now .in number classification using neural network, is training with edge image better than gray image?******in number classification using neural network, is training with edge image better than gray image?******Feb 17, 2018******1******CA
1******many of you have probably see the turtle from labsix that get mistake for a rifle in google's inceptionv 3 image classifier . i read the paper and i understand how they apply eot to 2d image and on the individual pixel value , but i be still unsure how they implement the eot algorithm to the 3d model . be they use eot to perturb the individual coordinate in the 3d model's mesh ? or be they perturb image of a turtle and then print the turtle from the image ? how do they check the inceptionv 3 output iteratively without have to 3d print the object each time and check the probability give ? any example that someone can point to would also be very helpful .how to apply eot algorithm to 3d model******how to apply eot algorithm to 3d model******Feb 26, 2018******1******CA
2******i'd like to generate subtitle for a silent film . be there an open source project out there capable of create caption base on a series of image ( such a a scene from a movie ) ? edit : thanks for the comment below . to clarify , what i'm look for be an algorithm which can generate a caption for a sequence of image within a movie describe what happen in the sequence . this be for preliminary research , so accuracy be less important .create captions based on a series of images******create captions based on a series of images******Feb 28, 2018******1******CA
1******i be new to deep learning and computer vision . i have a problem where i use yolo algorithm ( ) to detect object . in the original paper , they define the output to recognize 80 class , but for my problem i just want to recognize human only . so i change the final layer to only 1 neuron , and do the training process with transfer learn technique ( use pretrained weight for the case of 80 class , of course not use the final layer weight and these weight become random number for my problem ) . i fee only human data to the algorithm . however , i realize that after long training , the model become bad . it start to recognize other object a human . i would like to hear any advice from you guy , should i also fee non-human data to the model . thanksextracting one class from a pretrained convolutional neural network******extracting one class from a pretrained convolutional neural network******Mar 28, 2018******1******CA
8******with the grow ability to cheaply create fake picture , fake soundbites , and fake video there become an increase problem with recognize what be real and what isn't . even now we see a number of example of application that create fake medium for little cost ( see deepfake , faceapp , etc . ) . obviously , if these application be use in the wrong way they could be use to tarnish another person's image . deepfake could be use to make a person look unfaithful to their partner . another application could be use to make it seem like a politician say something controversial . what be some technique that can be use to recognize and protect against artificially make medium ?what are some tactics for recognizing artificially made media?******what are some tactics for recognizing artificially made media?******Apr 07, 2018******1******CA
0******i have an image of a spatial graph , i . e . a network of road or vein . i'm wonder whether there be some known method to product a graph / adjacency matrix out of this ? probably a deep learning method ?image of a network graph to an adjacency matrix******image of a network graph to an adjacency matrix******Apr 11, 2018******1******CA
0******i be try to copy this paper , in which cell be detect in image use alexnet with the last layer modify to output a compressed 1d vector representation of the 2d boolean mask of cell location in the image . i've implement the compression / decompression scheme , and now i'm try to adapt a modified alexnet to the problem of map image to vector . the input image be 1 channel 250x250 . the output vector have length 10000 . i'm use pytorch . here be the model definition , modify to change output vector length and input number of channel : the training script be ( although once i see the loss decrease on my local machine i'll move model and variable to gpu on a server ) i have make a set of 1000 training image with 0 to 15 random splotch over the same cat image like this and i have generate the compressed vector representation of the splotch location ( follow method 2 from the paper if this matter ) . these vector be 10000 element long .. in fact the approximate cell location be encode with 20 - fold redundancy in the vector . each sequential 500 element approximately encodes all cell location . when i attempt to train , the loss do not decrease . here be the loss versus minibatch iteration : any pointer ? i have try multiple learning rate . so far i have only run this on my laptop cpu : have i not wait long enough to see a loss decrease ? be i miss something that render this untrainable ? do i have a bug ? any comment appreciatetraining modified alexnet to compressed sensing task: seeking pointers for training******training modified alexnet to compressed sensing task: seeking pointers for training******Apr 13, 2018******1******CA
1******use a neural network the method seem to be that you end up with a probability for each possible outcome . to predict the next frame in a monochrome movie of size 400x400 with 8 shade of gray , it seem like there seem to be : 8 ^ ( 160000 ) possibility . on the other have if you just predict the probability for each pixel individually you would end up with some kind of image which get progressively blur . perhaps what you want be to generate a few possibility that be none-the-less quite sharp . in a similar way to weather prediction ( ? ) so how would you go about design a neural network that take read a movie and try to predict the next frame ?best way to predict future frame of movie or game?******best way to predict future frame of movie or game?******Apr 16, 2018******1******CA
3******i try to build a neural network from scratch to build a cat or dog binary classifier use a sigmoid output unit . i seem to get the output value around 0.5 ( + / - 0.002 ) for every input . this seem really weird to me . here's my code , please let me know if there be a mistake in the implementation .neural network returns about the same output(mean) for every input******neural network returns about the same output(mean) for every input******Apr 19, 2018******1******CA
1******previously i have train a upon 20,000 character image . this generally work well , it use feature set for training . however , there can be certain character image which have value that this have not see before . therefore i be look forward to convert train data to and use some feature set well suit for grayscale image . so be there any good suggestion for extract a feature set out of image .feature set out of grayscale images for training a neural network?******feature set out of grayscale images for training a neural network?******Apr 22, 2018******1******CA
3******i have a question about the training sequence regard neural network recognition . let's say an image have 28 * 28 pixel , which lead to 784 input node with various greyscale value and 10 output node , if the image show a number 0-9 . then when the training data be use for a set of known picture of number , the weight and hidden layer use forward - and backpropagation to get get the proper hidden and weight layer for the know layer . however , doesn't a new training picture destroy the trained and balanced weight and node value ? because the weight and hidden node have be calibrate to recognize the former training picture ? thank you for assistance . kind regard davidneural network training beginner question******neural network training beginner question******Apr 29, 2018******1******CA
3******i'm currently work on license plate recognition . my system consist of 2 stage : ( 1 ) license plate region extraction & ( 2 ) license plate region recognition . i'm do ( 1 ) with raspberry pi 3 model b . i find license plate candidate first by merge bound box base on their similarity . in this way , i have only 1 ~ 7 license plate region proposal . and it take less than . 3 second . now i have to reduce number of region proposal to be around only 1 ~ 2 so that i can send these image to server to do job ( 2 ) . for license plate extraction , i make my own classifier function in tensorflow and the code be below . it get propose license plate a input . first , i resize all license plate to be [ 120 , 60 ] and convert to gray image . and there be 2 class : ' plate ' , ' non_plate ' . for non_plate image , i collect various image that might appear in image a background . i have 181 image for ' plate ' class and 56 image for ' non_plate ' for now , i train for about 3000 step so far and current loss be . 53 . when i do prediction on test set , i encounter problem that for some of plate image , it doesn't recognize license plate which be very obviously license plate image from my eye . it be okay for me to wrongly recognize non plate image a plate but it be problem if it wrongly recognize plate a non_plate because it will not be send to server to be fully recognize . it happen like 10 out of 100 test image and this rate be far bad than i expect . i need help for adressing this problem . would there be any improvement that i can make ? ( 1 ) be my training set too small to classify between license plate and non license plate ? or be number of step be too small ? ( 2 ) be my graph structure bad ? i need to have small graph structure for my raspberry pi to recognize less than 1 second . could you suggest good structure if it be bad ? ( 3 ) be it bad to resize any propose image to [ 120 , 60 ] to be use a input for graph ? i think it lose some information . but isn't this close to roi pool like use in fast rcnn ? [ training non plate image example ] [ ] 4 [ training plate image example . it be region propose image ]detecting license plate using tensorflow******detecting license plate using tensorflow******May 27, 2018******1******CA
3******i be read a book about opencv , it speak about some derivative of image like . i be confuse about image derivative ! what be derive from ? how can we derive from an image ? i know we consider an image ( 1 - channel ) a a n * m matrix with 0 to 255 intensity number . how can we derive from this matrix ? edit : a piece of text of the book : derivative and gradient one of the most basic and important convolution be compute derivative ( or approximation to them ) . there be many way to do this , but only a few be well suit to a give situation . in general , the most common operator use to represent differentiation be the sobel derivative operator . sobel operator exist for any order of derivative as well a for mixed partial derivative ( e . g . , ∂ 2 / ∂ x ∂ y ) .what does it mean "derivative of an image"?******what does it mean "derivative of an image"?******Jun 08, 2018******1******CA
1******i would like to develop a machine learn algorithm , give two photo , that can decide which image be more " artistic " . i be think about somehow combine two image , give it to a cnn , and get an output 0 ( the first image be well ) or 1 ( the second image be well ) . do you think this be a valid approach ? or could you suggest an alternative way for this ? also , i don't know how to combine two image . thanks ! edit : let me correct " artistic " a " artistic accord to me " , but it doesn't matter , i be more interested in the architecture . you can even replace " artistic " with something objective . let's say i would like to determine which photo belong to a more hot day .which photo is more artistic?******which photo is more artistic?******Jun 11, 2018******1******CA
3******a i know , if we consider a 3 * 3 kernel , we should add a padding of 1px to the source image ( if we want to have effect on whole of the image ) , then we start to put the kernel in upper-left side of the image and multiply each element of kernel to correspond pixel on image . then we sum all the result and put it on the anchor point of kernel ( usually center element ) . then we should shift the kernel one step to right side and do these thing again . if i be right till here , i have a question about the summation result . i want to know : should we consider the replaced value of image in previously calculate summation and replace in anchor point in new step of calculation or not ? i mean we must put the anchor point's result in source image and consider it in calculation of shifted kernel ? or we must put it in distance image and we don't consider these result when we shift the kernel on source image ( it mean don't replace the result on source image for next step calculation ) ?how to apply a kernel to an image?******how to apply a kernel to an image?******Jun 14, 2018******1******CA
6******i'm try to detect the visual attention area in a give image and crop the image into that area . for instance , give an image of any size and a rectangle of say lxw dimension a an input , i would like to crop the image to the most important visual attention area . i'm look for a state of the art approach for that . do we have any tool or sdk to implement that ? any piece of code or algorithm would really help .detect visual attention area in an image******detect visual attention area in an image******Jun 15, 2018******1******CA
2******i'm new to machine learning , so i figure i should look into google's tensor flow guide and i know how to code in j so that's why i'm use tensorflow.js , there's and example in the guide that train itslef to recognize handwritten number from the mnist handwrite dataset , i sort of understand what's go on in the code but since i'm very new to ml it's not a lot , i go through the code and saw that it didn't take image by image to train itself but it request one sprite which contain all the image and then cut it into what it need , this make sense from a performance point of view , but a this process be kind of abstract i don't understand what's really go on , i want to upload an image of my own and call the predictor of the model but i don't know how to do it , any help ? i be think that draw in a canvas of 28x28 a number might be very interesting as well instead of upload an image , but i need to know how to test the model once it's train with my own data . the tutorial :how to load an image into tensorflow.js code which reads handwritten numbers and clasify them******how to load an image into tensorflow.js code which reads handwritten numbers and clasify them******Jun 22, 2018******1******CA
4******what method be use for facial recognition in public surveillance ? ideally , an answer would point to the software , algorithm or specification be use . how can those be fool ? fake or disfigure face ? to what extend would one need to employ artificial scar or mole , make-up or even a complete face mask ? will spectacles work ? sun glass vs . normal one ? will use a hat to hide a portion of a face work ? how much need to be hide ? hair , forehead , eye , nose or complete face ? blinding ( not : destroying ) a camera with laser or led , provide the camera can be see , and one can aim at it ? what else ? slightly relate : be there any other method be use , such a clothes detection , gait detection , etc ?how good is facial recognition exployed in public surveillance******how good is facial recognition exployed in public surveillance******Jul 04, 2018******1******CA
4******be there any project or example for a software identify car ? situation : i get multiple angle shot in high resolution from a car . i want the algorithm to tell me " this be a mercedes slk " or " this be a toyota prius " . i get a lot of high resolution data to train such an algorithm , but i presume a simple " put your data in tensorflow and see what happen . " be not enought . i have stumble upon identify car use deep learning , but this be not what i mean .identifying car model via deep learing******identifying car model via deep learing******Jul 18, 2018******1******CA
1******what ai concept , topology <sup> 1 </sup> , algorithm , or saas can be use to recognize a person eat a chocolate . for this question , image recognition draw from a real time feed , validate each of these step in sequence : use a camera app , the user begin record . the user focus on the subject's face , at which time the app attempt to recognize the person <sup> 2 </sup> person hold a single piece of chocolate ( i . e m & m ) to the camera lens , at which time the app attempt to recognize it . the user put the chocolate into their mouth , chew , and swallow , at which time the app attempt to recognize that a an action . the app give a completion message indicate success or failure . i understand that we can use real time recognition for each step , but i don't know if there be concept propose or test to validate the scene a a sequence or any of the three recognition step individually . the app should invalidate the scene if the subject be swap with another subject , if the subject do not swallow the chocolate , or there be some other deviation from the expect sequence above . note [ 1 ] by topology in this context be mean the standard mathematical meaning of the term apply to the high level connection that be likely need to recognize sequence of action . in this sense , the use of the term topology be not at the level dimension of neuron layer or convolution kernel . since process topology be normally consider prior to consider library dependency or deployment concern , the term topology be more appropriate than architecture in this question . ( first thing first . ) [ 2 ] i've already identify saas option for facial recognition .steps recognition******steps recognition******Jul 19, 2018******1******CA
1******anyone here know if the image-recognition / text-recognition / etc feature of google vision api use the same trained model a the image-recognition / text-recognition / etc of firebase's ml kit ? if they don't which one do you think be good ? ( i've try , and fail , to find the answer on the web . ) i realize google own both of them , but one would think that if both be essentially the same , then this fact would be state very clearly throughout multiple channel on the internet . ( it's not . ) i do believe at least the text-recognition be the same , because both use ocr . but i'm unsure about the image detection aspect .difference in trained models between gcp's google vision and firebase's ml kit?******difference in trained models between gcp's google vision and firebase's ml kit?******Jul 24, 2018******1******CA
0******i have create an ann in python ( without libs ) . on beginning , it have be learn in target of solve linear problem like distinguish between negative and positive number , where the layer width be [ 1 , 2 , 1 ] . i have decide to learn recognize small digit save a 20x20 black & white png file . now the array of layer width be : i try other similar one ... with the above array of layer width train take 8 hour ( nn have see 600.000 image from 5000 image of learn set ) and when i look at result , each output be equal about 10 % - 15 % . nothing be certain . this code be a core of my nn and that be main code : there be 1200 input because there be 400 pixel and each pixel be save in rgb model . stuff . reorganisepixeldata : what have i to do ? add or remove layer , change some or all of the layer width ? or something in concept of learn ? my error calculator print error like 0.3020313593 0914193 , and it change only a bit .what ann layer widths support the learning of digit recognition?******what ann layer widths support the learning of digit recognition?******Jul 27, 2018******1******CA
4******i be currently work on a project to classify snake type separately use an image of the snake . i need to train a module to classify snake image , but the problem be there be only a small number of image available for some snake type . what be the best approach to train a neural network for image classification use a small data set ?image classification******image classification******Aug 01, 2018******1******CA
6******from meta-learning with memory-augmented neural network in section 4.1 : to reduce the risk of overfitting , we perform data augmentation by randomly translating and rotate character image . we also create new class through 90 ◦ , 180 ◦ and 270 ◦ rotation of exist data . i can maybe see how rotation could reduce overfitting by allow the model to generalize good . but if augment the training image through rotation prevents overfitting , then what be the purpose of add new class to match those rotation ? wouldn't that cancel out the augmentation ?how does rotating an image and adding new 'rotated classes' prevent overfitting?******how does rotating an image and adding new 'rotated classes' prevent overfitting?******Aug 08, 2018******1******CA
4******a dataset be give which contain textual data ( year , number of room , location ) and visual data ( an jpeg image of the house ) . the neural network have the task to predict the price of the property . a an example , the training dataset consist of some value of a computer game simulation ( a city simulation ) and the aim be to determine the housing price for new unseen real estate . the problem be , that that the number of picture in the input dataset be fluctuate . sometimes no image be give and sometimes more . that mean the image recognition engine must form a sublayer in the overall neural network . it be some kind of aggregation problem to transform first visual data into a textual description of the image and aggregate it then with the other textual information . original message : so suppose that you have a real estate appraisal problem . you have some structure data , and some image exterior of home , bedroom , kitchen , etc . the number of picture take be variable per observational unit , i . e . the house . i understand the basic of combine an image process neural net with tabular data for a single image . you chop off the final layer and feed in the embeddings of the image to your final model . how would one deal with variable number of image ? where your unit of observation can have between zero and infinity image ( theoretically no upper bound on number of image in observation ) ?predicting housing values with neural network (was: variable number of inputs to neural networks)******predicting housing values with neural network (was: variable number of inputs to neural networks)******Aug 22, 2018******1******CA
1******for my university project , i be plan to build an automated customer service machine . one which recognize when someone approach the camera accord to say hello , etc . also , i be plan to add simple speech recognition and language processing feature . so my question be . what kind of camera would be suitable ? be there any particular model that you recommend . i be think of camera use for amazon go ( a an example ) .cameras for automatic customer service machine******cameras for automatic customer service machine******Aug 22, 2018******1******CA
4******i ’ m train a network to do image classification on zoo animal . i ’ m a software engineer and not an ml expert , so i ’ ve be retrain google ’ s inception model and the late model be trained use google automl vision . the network performs really well , but i have trouble with image of animal that i don ’ t want any label for . basically i would like image of those animal to be classify a unknown or achieve low score . i do have image of the animal that i don ’ t want label for and i try put them all into one “ nothing ” label together with image i ’ ve collect of the animal habitat without any animal . this doesn ’ t really yield any good result though . the network performs for the labeled animal but end up assign one of those label to the other animal a well . usually with a really high score as well . i have 14 label and 10.000 image . i should also mention that the “ nothing ” label end up have a lot of image compare to the actual label . those image be not include in the 10.000 . be there any trick to achieve good result with this ? should i create multiple label for the image in the “ nothing ” category maybe ?optimizing image recognition results for unknown labels******optimizing image recognition results for unknown labels******Aug 25, 2018******1******CA
0******how to find a picture of specific cat graffiti from my photo library , which be so huge that i tire scroll . the graffiti be very simple - it be just a black silhouette on a white wall - i can almost draw it by hand . either use name to picture match with pretrained network or use some generic contour recognition and match if there be any . i lack practice a lot , so what be the recommended approach for setup to search image by name or i be long interested to try ai , but never have any real task at hand , so this be my first experience - i watch lecture by andrew ng , and they be quite good if you need the math and module . i'd like to avoid go into much math detail and concentrate more on usability , but any good math insight be welcome . the library be currently in google photo , but it doesn't matter - i can setup any pipeline for feed photo . the miss part be ai process block . if you can point me the best practice to download and use pretrained network for the task , or there be some user level module to reuse , i would be happy to try and report on progress .searching (google) photo library with ai******searching (google) photo library with ai******Sep 03, 2018******1******CA
2******image captioning be a hot research topic in the ai community . there be considerable image captioning model for research usage such a nic , neural talk 2 etc . but can these research model be use for commercial purpose ? or we should build much more complex structured one for commercial usage ? or if we can make some improvement base these model to meet the business application situation ? if so , what improvement should we take ? be there any exist commercial image caption application can be reference ?how to build a commercial image captioning system?******how to build a commercial image captioning system?******Sep 09, 2018******1******CA
1******for my university project , i be plan to build a face recognition / occupation recognition programme . however , rather than use the exist haar cascade ( for age and gender ) i be plan to use face api which seem far more accurate than the former . my question be be it possible to somehow combine my trained data for haar cascade ( for occupation ) with face api since face api doesn't have the option to recognize occupation ( such a student / office worker from their appearance ) ?occupation detection using face api******occupation detection using face api******Sep 10, 2018******1******CA
2******in physic , there be a lot of graph , such a ' velocity v time ' , ' time period v length ' and so on . let's say i have a sample set of point for a ' velocity v time ' graph . i draw it by hand , rather haphazardly , on a canvas . this drawn graph on the canvas be then provide to the computer . by computer i mean ai . i want it to sort of beautify my drawn graph , such a straighten the line , make the curve well , add the digit on ax and so on . in other word , i want it to give me a good version of my drawn graph which i can readily use in , say , a word document for a report . a ) be it possible / plausible to do this ? b ) be there any apis available that can already do this ? ( don't want to reinvent the wheel ) c ) any recommendation / suggestion to make the idea possible by alter it somehow ?how can i use a.i/image processing to construct mathematical graphs from drawing?******how can i use a.i/image processing to construct mathematical graphs from drawing?******Sep 19, 2018******1******CA
0******i'm currently work on tumor detection project use dicom image a i'm beginner in it currently have a difficulty in segment each part in image and give each segment a new colour .how image segmentation actually works?******how image segmentation actually works?******Oct 01, 2018******1******CA
1******a i'm beginner in image processing , have difficulty in segment all the part in dicom image.currently i'm apply watershed algorithm but it segment only that part that have tumor . i have to segment all part in image . which algorithm will be helpful to perform this task ?how to segment each part in dicom image?******how to segment each part in dicom image?******Oct 04, 2018******1******CA
1******i be develop an image search engine . the engine be mean to retrieve wrist watch base on the input of the user . i be use sift descriptor to index the element in the database and apply euclidean distance to get the most similar watch . i feel like this type of descriptor be not the best since watch have a similar structure and shape . right now , the average difference between the best and bad match be not big enough ( 15 % ) i've be think of add colour to the descriptor , but i'd like to hear other suggestion . br , svwhat is a good descriptor for similar objects?******what is a good descriptor for similar objects?******Oct 23, 2018******1******CA
1******i saw when browse we can use data augmentation for create a dataset for face recognition . the augmented image may include inverted , tilt or distorted face . do the model detect the face from the inverted image . when i try my model cant able to detect any inverted or tilted face .how can we use data augmentation for creating data set for face recognition and will the inverted faces on augmented images detected?******how can we use data augmentation for creating data set for face recognition and will the inverted faces on augmented images detected?******Oct 25, 2018******1******CA
2******which possibility exist to evaluate the visual reasoning capability of neural network in the field of image recognition ? be there method to measure the ability of machine reason ? or something more specific : be it possible to measure if a network understand the concept of a car / a cat / a human without use the classification accuracy .how to measure the reasoning capabilities of neural networks******how to measure the reasoning capabilities of neural networks******Oct 25, 2018******1******CA
2******i load a neural network model train with caffe by other people in opencv . the model should detect the presence of a car in a single parking spot output the probability of it be free / occupy . the model be train with image all belonging to the same parking area , take at different hour of day and with different light condition . image be take by different camera but the camera be all of the same model ( raspberry camera ) . i try to run the model with a few image some of them take from their dataset and other download from google . the image take from their dataset be correctly classify while the one take from google be not correctly classify . my question be : be it possible to deploy a nn model train with image all come from a single parking area in another park area ? be not such a model for park detection occupancy suppose to generalize independently from the location where training image have be take ? if you know about an already exist train model that work good please let me know .influence of location on a neural network trained for parking detection occupancy******influence of location on a neural network trained for parking detection occupancy******Oct 25, 2018******1******CA
0******take training image classification model a an example , when there be limited amount of data , it be not uncommon to augment data by randomly rotate image data but i often see the resulting image be rotate to a degree that part of the area that be normally unseen or out of canvas of image appear black in color . in practice , the target image to be detect wouldn't look like that . if these kind of augmented image be introduce to train data , would it be any negative impact on the result model ? the following picture be an example of the kind of image i be talk about .is there any negative impact on classification model if training image data is rotated out of canvas?******is there any negative impact on classification model if training image data is rotated out of canvas?******Oct 30, 2018******1******CA
0******wasn't really sure on which forum to post my question , i think it fit well in here , so : i have different version of some same creature ( an old one and a most recent one , actually ) , and since yesterday i be writting an algorithm which be suppose to guess what color in new one be in the old one . now that my algorithm be complete , i can affirm it doesn't work , so i come here to see if what i'm try to do be possible ( sure it be , but maybe there already be some tool or algorithm around here i'm simply not aware of ) ; i think it might have something to do with , but i hope not since my couple of image be never the same image with different rgb , usually the movement of the creature ~ nearly ~ be the same but sometimes it's design with a different motion . hope i be clear , here's an example of an old image and it correspond new image . also my algorithm be not really smart , basically it retrieve color from and and tell me which one be correspond , but sometimes an orange -> red wasn't detect because another matching couple have be detect whereas this last color's couple be match pretty well but in reality color be not link .find links between colors of an old image and its corresponding new image representing the same object******find links between colors of an old image and its corresponding new image representing the same object******Nov 03, 2018******1******CA
1******there be some field of computer vision that be similar to artificial intelligence . for example , pattern recognition and path tracking . base on these similarity , can we say that the computer vision be a part of artificial intelligence ?are computer vision and digital image processing part of artificial intelligence?******are computer vision and digital image processing part of artificial intelligence?******Nov 08, 2018******1******CA
0******i have 2 new collection of image , for example ( just for example ) cucumber and tomato . i want to get 3 probability . prob if img be a tomato , cucumber , and the third prob for any another object . so i want to know if cucumber or tomato on image ( and what exactly ) , or if there be something else . but this be the key , i haven't good collection of the third group - random object , and i want to use transfer learning and exist trained nn like re 50 . how can i add 2 new group in a trained nn ? maybe i should calculate cosine distance between encode output of nn on the last layer before softmax layer ?how to add 2 new classes to trained res50 net(keras)******how to add 2 new classes to trained res50 net(keras)******Nov 17, 2018******1******CA
0******let say we have a data-set of all cat and we have to identify the cat breed base on give test image . a , the two different cat breed have visual similarity can we use exist network ( vgg , imagenet , googlenet ) to solve this problem ? should facenet be apply here ? a , the problem be similar to face detection where face characteristic of two different people be same yet it can correctly recognize a person . what if with visual similarity in data-set we have only few example of each class ? like for a problem ( random ) we have good amount of data but for each class we have only few example . be there any model that can be apply here ?image prediction model when data-set classes have visual similarity******image prediction model when data-set classes have visual similarity******Nov 17, 2018******1******CA
0******i'm work in a company that open restaurant in enterprise . every day at lunch , we want our client to be able to scan their tray , sothat the food be detect automatically thanks to ai / image recognition . technically speak , we have a number of food item that grow over time in our database , but everyday there be about 30 item available at the same time in the restaurant . about 5 item be change each day ( for example , the main dish change , but the bottle of water be always the same ) . this mean , when the client go to the till to pay , the client will place the tray by himself , the camera will take photo of the tray and will try to identify different item separetely among the 30 item available this day . client pay per food article , which mean we don't need to track the weight or the quantity in the main dish . i have absolutely no experience in ai / ml and don't know how to start for my need , i'm a web developer . which tool should i look at first ? which skill do i need to acquire ? i mean , be there easy to use high level library , or do i need to learn ml from scratch ? first i be think of amazon recognition or google vision but it seem to be make for recognize any food item among their own database . my need seem easy since i just need to recognize several item on a tray among 30 known item . thanks a lot for your help .which ai tool for food recognition?******which ai tool for food recognition?******Nov 20, 2018******1******CA
1******for a school project i have be give a dataset contain image of plant and weed . the goal be to detect when there be a weed in the picture . the training and validation set have already be create by our teacher , however they probably didn't have enough image for both so they " photoshopped " some weed in some of the training picture . here be example of image with the weed label in the training set : in some case , the " photoshopped " weed be hard to detect , and no shape resemble a weed be clearly visible like in this picture ( weed at the very bottom , near the middle ): and here be an example of an image with the weed label in the validation set : how would i go about preprocessing the training set so that a cnn train on it would perform well on the validation set ? i be think of apply a low-pass filter to the rough edge of the photoshopped image so that the network doesn't act a an edge detector , but it doesn't seem very robust . should i manually select the best image from the training set ? thank you !how to preprocess a modified dataset so that a fitted cnn makes correct predictions on an un-modified version of the dataset?******how to preprocess a modified dataset so that a fitted cnn makes correct predictions on an un-modified version of the dataset?******Nov 25, 2018******1******CA
1******i understand how a neural network can be train to recognise certain feature in an image ( face , car , ... ) , where the input be the image's pixel , and the output be a set of boolean value indicate which object be recognise in the image and which weren't . what i don't really get be , when use this approach to detect feature and we detect a face for example , how we can go back to the original image and determine the location or boundary of the detected face . how be this achieve ? can this be achieve base on the recognition algorithm , or be a separate algorithm use to locate the face ? that seem unlikely since to find the face again , it need to be recognise in the image , which be the reason of use a nn in the first place .when using neural networks to detect features in an image, how can locate that specific feature in the original image?******when using neural networks to detect features in an image, how can locate that specific feature in the original image?******Sep 29, 2016******1******CA
1******i be try to build a neural network suitable to measure similarity between pair of image . in particular i be interested in shoe . i have a query image ( e . g . a shoe that i just take a picture of ) and i want to find similar shoe in a database ( several thousand of image ) . i try use mac feature ( e . g . max pool over the entire spacial dimension on last ( or some other ) convolution layer of say vgg 16 ) ( here be a link to a paper ) . the two mac vector be compare use cosine similarity . that work , but among the top match there be always a few very strange shoe ( e . g when i submit a query image with a boot i find sandal among other boot with extremely high similarity score ) . what would be a good way of do that ? something more robust to find shoe similar in shape to the query image . thanks !similarity of images (cbir) with cnn features******similarity of images (cbir) with cnn features******Feb 06, 2017******1******CA
2******i be work on a project , wherein i take input from the user a free text and try to relate the text to what the user might mean . i have try stanford nlp which tokenizes the text into token , but i be not able to categorize the input . for example , the user might be greet someone or share some problem he be face . in case he be share some problem i need to categorize the problem as well . can someone help me with from where should i start ?can i categorise the user input which i get as free text?******can i categorise the user input which i get as free text?******Feb 07, 2016******1******CA
0******i would like to know what kind of dataset i need ( to prepare ) for train the network to recognize the spelling mistake in individual word for english text . give the large database of word , have correct one for each incorrect . what kind of input be more efficient for that task ? be it use one input per each letter , syllable , whole word or i should use different pattern syllable ? then the input should be incorrect word , output correct , and if the word doesn't need correction , then both input and output should be the same . be that the right approach ?training network to detect spelling mistakes******training network to detect spelling mistakes******Aug 09, 2016******1******CA
4******i be research natural language processing ( nlp ) to develop a nl question answer . answer part be already develop . so question remains , along with the question regard the algorithm . final product should be able to : - user can ask a question in nl - question get translate to a mdx query , which generate a script regard dimension of the cube . how can i translate a natural language question to a mdx query ? outcome of question result in answer of a calculation . e . g . ‘ how many declaration be do by employee 1 ? ’ or ‘ give me the quantity for sale ’ thanks in advance !how can i convert an input natural language qa to a mdx q******how can i convert an input natural language qa to a mdx q******Feb 03, 2017******1******CA
2******i be just curious if there be any particular study or project do with nlp in the last 5 or so year ( breakthrough in parsing , sentiment analysis , discourse analysis , speech recognition ) that you guy think be specifically influential . i'm look at the history of nlp ( and by extension , machine learning ) and start in the 1950s with the georgetown – ibm experiment . if anyone have any relevant recommendation , they'd be appreciate .recommendations for research: influential nlp projects of the last 5 years******recommendations for research: influential nlp projects of the last 5 years******Apr 05, 2017******1******CA
3******capsule network seem to be a good solution for problem , which make up hierarchical complexity ( ( ( eye , nose , ear -> face ); ( finger , nail , palm -> hand ) ) -> human ) . nlp domain be a very clear hierarchical complexity problem , because there be word , sentence , paragraph and chapter , whose mean change base on the style of low level . be there any research paper or software tool on capsule network and nlp , which i should be aware of ? be there relate research paper , which have be investigate hierarchical complexity within the domain of nlp , which could be easily translate to capsule network ?has capsule networks or similar systems been used for nlp?******has capsule networks or similar systems been used for nlp?******Feb 16, 2017******1******CA
14******identify sarcasm be consider a one of the most difficult open-ended problem in the domain of ml and nlp . so , be there any considerable research do in that front ? if yes , then what be the accuracy like ? please also explain the nlp model briefly .what research has been done in the domain of "identifying sarcasm in text"?******what research has been done in the domain of "identifying sarcasm in text"?******Aug 03, 2016******1******CA
4******text summarization be a long-standing research problem that be " ignite " by luhn in 1958 . however , a half century later , we still come nowhere close to solve this problem ( abstractive summarization ) . the reason for this might be because researcher be resort to statistical ( and sometimes linguistic ) method to find & extract the most salient part of the text . be summarization problem solvable use ai ( neural network to be precise ) ?can abstractive summarization be achieved using neural networks?******can abstractive summarization be achieved using neural networks?******Aug 03, 2016******1******CA
9******in program language , there be a set of grammar rule which govern the construction of valid statement and expression . these rule help in parse the program write by the user . can there ever be a functionally complete set of grammar rule which can parse any statement in english ( locale-specific ) accurately and which can be possibly implement for use in ai-based project ? i know that there be a lot of nlp toolkits available online , but they be not that effective . most of them be trained use specific corpus which sometimes fail to infer some complex correlation between various part of an expression . in other word , what i be ask be that if it be possible for a computer to parse a well-versed sentence write in english a if it be parse by an adult english-speaking human ? edit : if it cannot be represent use simple grammar rule , what kind of semantic structure can be use to generalize it ? edit 2 : this paper prove the absence of context-freeness in natural language . i be look for a solution , even if it be too complex .can the english language ever be generalized using a set of grammar rules?******can the english language ever be generalized using a set of grammar rules?******Nov 11, 2016******1******CA
2******i be just curious if there be any particular study or project do with nlp in the last 5 or so year ( breakthrough in parsing , sentiment analysis , discourse analysis , speech recognition ) that you guy think be specifically influential . i'm look at the history of nlp ( and by extension , machine learning ) and start in the 1950s with the georgetown – ibm experiment . if anyone have any relevant recommendation , they'd be appreciate .recommendations for research: influential nlp projects of the last 5 years******recommendations for research: influential nlp projects of the last 5 years******Apr 05, 2017******1******CA
10******it seem that most project attempt to teach the ai to learn individual , specific language . it occur to me that there be relation in write and speak word and phrase across language - most of use have a much easy time learn more language after we learn a second language , and we start to understand the relation between word and phrase in different language . have anyone attempt to train an ai to learn all language ? wouldn't this potentially be a much simpler problem than try to teach an ai a single , specific language with all of the specific and detail of that single language ? since you're actually omit a lot of related data in other language from the training set ?has anyone attempted to train an ai to learn all languages?******has anyone attempted to train an ai to learn all languages?******Apr 06, 2017******1******CA
1******i want to produce a bot in python that automatically generate short football summary from whoscored data . for my first stage i generate the article with different sentence template and lot of rule where the data be use . now i want to move to the next stage and start look into nlp and more advanced nlg . i already scrap numerous article to create a corpus . how should i move on and do next ? any advice would be much appreciate a i'm new in this . thanks !advanced nlg - robot journalist******advanced nlg - robot journalist******Jul 22, 2017******1******CA
1******i'm wonder if these 2 specific program already exist and if not how hard would it be to write them : a program that would figure out ( by only " read " large amount of text in human language 1 and 2 ) which word in second language have the same meaning a a word in first language . you would give for input text in both language and for output you would get for every word in first language a list of word in second language that be most similar to it with a probability that they mean the same thing . a program that would figure out which word have the most similar meaning by analyze large amount of text in one human language . i'm plan on write these two program and it would be nice if i could get exist program that do this so that i could compare result of my program to those of exist program .existing programs that find out words with same meanings******existing programs that find out words with same meanings******Feb 10, 2018******1******CA
1******the more i think about machine learn the more i realize the importance of find similarity by use analogy a a way of learning . if i want to categorize word into hierarchical tree this method would work i think , if not tell me why ? find two sentence that contain same word but their order be different and some word can also be different . find another two such sentence . evaluate strength of analogy between these 4 sentence . the strong it be the more probability that word mean similar thing , that they belong to same category . when you learn category you can do analogy on abstract sentence that contain these find category and in this manner you can build hierarchy of category . for example : deer eats grass . ... be to ... man eat deer . a cow eats grass be to ? if we can find sentence man eat cow . be use in text that we analyze then we have confirm that cow and deer belong to category animal that eat grass and that human eat them .analogies and similarity******analogies and similarity******Feb 17, 2018******1******CA
4******i be absolutely new in ai area . i would like to know how to mathematically / logically represent the sense of sentence like : so that it could be convert to computer understandable form and analyse algorithmically . any clue ?represent sense/meaning of sentences mathematically******represent sense/meaning of sentences mathematically******Feb 22, 2018******1******CA
3******i be seek the information for this kind of chatbot architecture : there be two chatbots . one play the role of teacher , and another be a student who be learn . the goal be to test the student's quality , and to improve the student's ability . i didn't find much reference . there be : bottester : testing conversational system with simulated user and the parlai , a python-based platform for enable dialog ai research have the notion of " teacher agent " , which seem to be what i be look for . of course , we also have deep reinforcement learn which might be relate . i prefer to have some classical reference for this approach to chatbots . currently , reinforcement learning be not in my consideration . construct two chatbots talk to each other , like what facebook do , be not what i want . because in this case , both of them be student agent .two chatbots - one teaches another******two chatbots - one teaches another******Mar 04, 2018******1******CA
3******i'm training seq 2seq model on opensubtitles dialog - cornell-movie-dialogs-corpus . my work base on the following paper ( but currently i'm not implement attention yet ): the i receive be quite high and suck in variation after 3 epoch . the model predict the most common word with some time other not significant word ( but 99.99 % be just ' you ' ): i ’ ve experiment with 128 - 2048 hidden unit and with 1 or 2 or 3 lstm layer per and . the outcome be more or less the same . seq 1 : yeah man it mean love respect community and the dollar too the package the unk end seq 2 : but how do you get unk 82 end prediction : promote 16th dashboard be of the the the you you you you you you you you you you you you you you you you you you you you you you you you i'm use here prediction , mean - after i receive i do on all it value for first - 3 mini-batch-elements ( here i present only first element ) . for convenient - and be also print - to know the actual dialog which be present to the model . the pseudo-code of my architecture look like this ( i'm use tensorflow 1.5 ): i'm also wonder if i pass well to , which in general look like this : should i use some projection layer between state of and ? so if have 32 word , have 31 ( since we will not predict nothing after the last word , which be the tag ) .seq2seq dialogs predicts only most common words like `you` after couple of epoches******seq2seq dialogs predicts only most common words like `you` after couple of epoches******Mar 06, 2018******1******CA
2******i'm new to ai development and be look for a quality algorithm ( potentially nlp ? ) implementation prove against u legal text . obviously some training would need to be do , but i've find little to no online reference to go on when it come to run assessment against u legal document . my goal be to use an algorithm to discover potential issue in long and complex legal text , or associate ( group ) of legal text which bind one or more related entity ( people or corporation ) to potentially conflicting clause . just a pointer in some kind of direction would be helpful .nlp proved against us legal texts******nlp proved against us legal texts******Mar 12, 2018******1******CA
0******when you read a big book , i think human constantly summarize or model the content of the book to the point where they have read and understand the upcoming text with that summarization a a context . also , it be not feasible / effective to understand a line in the book , the true meaning of which can only be understand base on what be mention in the book 100 page earlier , except if you summarize and feedback that information in an lstm or some other recurrent neural network . have anyone try this approach in mainstream nlp research before ?did anyone model nlp system on top of text summarization problem?******did anyone model nlp system on top of text summarization problem?******Mar 18, 2018******1******CA
5******can we define the feeling of the human through conversation with an ai ? something like a " confessional , " disregard human possibility to lie . below , i have the category joyful , sadness , anger , fear and affection . for each category , there be several word that can be in the text that refer to it . joy : ( cheerful , happy , confident , happy , satisfied , excited , interested , dazzle , optimistic , relieve , euphoric , drunk , witty , good ) sadness : ( sad , desperate , displeased , depressed , bore , lonely , hurt , desolate , meditative , defraud , withdrawn , pitying , concentrate , depress , melancholic , nostalgic ) anger : ( aggressive , critical , angry , hysterical , envious , grumpy , disappointed , shock , exasperate , frustrate , arrogant , jealous , agonized , hostile , vengeful ) fear : ( shy , frighten , fearful , horrify , suspicious , disbelieve , embarrass , embarrass , shake , surprise , guilty , anxious , cautious , indecisive , embarrassed , modest ) affection : ( love , passionate , supportive , malicious , dazzle , glaze , homesick , embarrass , indifferent , curious , tender , move , hopeful ) flow example phrase 1 : " i'm very happy ! it conclude college . " categorization 1 : - joy ( + 1 ) - sadness ( - 1 ) phrase 2 : " i'm sad , my mother pass away . " categorization 2 : - sadness ( + 1 ) - joy ( - 1 ) phrase 3 : " i meet a girl , but i be ashamed . " categorization 3 : - fear ( + 1 ) be this a clever way to follow and / or improve , or be i completely out of the way ? i see that there be a google product that create parse accord to the phrase . i do not know how it work , because i like to recreate the way i think it would work . remember that this would not be the only way to categorize the phrase . this would be the first phase of the analysis . i can also identify the subject of the sentence , so we would know if the sadness be from the creator of the message or from a third party , in most case . nltk sentiment analysis python examplesentiment analysis******sentiment analysis******Apr 03, 2018******1******CA
0******the choice of the number of embed dimension ( n ) seem to generally be determine empirically ( i . e . trial-and-error ) for a give corpus and use case . typical range use seem to be anywhere from 50-1000 . be there any more rigorous way to select a near-optimal n than simply execute and evaluate over a series of possible choice for n ? i'm think specifically of some heuristic that take into account some measurable aspect of corpus or use case .optimizing the number of embedding dimensions for word2vec******optimizing the number of embedding dimensions for word2vec******Apr 23, 2018******1******CA
2******word 2vec assigns an n-dimensional vector ( a dimensional reduction , really ) to give word . it turn out that , at least with a number of canonical example , vector arithmetic seem to work intuitively . these term be all n-dimensional vector . so , what we really might have ( number make up and n = 3 here ) be : in this ( contrive ) example , the last dimension ( king / man = 2 , queen / woman = 0 ) suggest a semantic concept of gender . aside from semantics , a give dimension could " mean " a part of speech , first letter , or really any feature or set of feature that the algorithm might have latch onto . however , any perceived " mean " of a single dimension might well just be a simple coincidence . the question : if we pick out only a single dimension , do that dimension itself convey some predictable or determinable information ? or be this purely a " random " artifact of the algorithm , with only the full n-dimensional vector distance matter ?do individual dimensions in vector space have meaning?******do individual dimensions in vector space have meaning?******Apr 23, 2018******1******CA
1******i have an approximately 90,000 row dataset that have information of social medium profile which have column for biography , follower count , language speak , name , username and the label ( to identify whether the profile be that of an influencer , brand or news and medium ) . task : i have to train a model that predict the label . i then need to produce a confidence interval for each prediction . a i have never come across a problem like this , i be just after some suggestion of what model i should be use for a situation like this ? i be think natural language processing ( nlp ) , but not sure . also , for nlp ( if a suitable method ) , any code or advice to help me implement for the first time on python would be greatly appreciated ! thanks in advancedrecommended modelling technique for influencer marketing scenario******recommended modelling technique for influencer marketing scenario******Apr 30, 2018******1******CA
1******i have an approximately 90,000 row dataset that have information of social medium profile which have column for biography , follower count , language speak , name , username and the label ( to identify whether the profile be that of an influencer , brand or news and medium ) . task : i have to train a model that predict the label . i then need to produce a confidence interval for each prediction . a i have never come across a problem like this , i be just after some suggestion of what model i should be use for a situation like this ? i be think natural language processing ( nlp ) , but not sure . also , for nlp ( if a suitable method ) , any code or advice to help me implement for the first time on python would be greatly appreciated ! thanks in advancedrecommended modelling technique for influencer marketing scenario******recommended modelling technique for influencer marketing scenario******Apr 30, 2018******1******CA
1******i be look to extract the central theme of news headline use nlp / text-mining , any reference in this direction be of great help . for example : input : brief-dynasil corporation of america report q2 eps of $ 0.08 china's night-owl retail investor leverage up to dominate oil future trade output : report oil futureare there any references of nlp/text mining techniques for identifying the theme of news headlines******are there any references of nlp/text mining techniques for identifying the theme of news headlines******May 14, 2018******1******CA
2******i have to read a lot of paper , and i think that i can use an a . i . to read them and summarize them . maybe find one that can understand what the paper be talk about it seem a lot to ask . i think i can use natural language processing . be it the right choice ? i'm sorry , but i'm new in a . i . and i don't know much about it .how can i build an ai with nlp that reads and understands documents?******how can i build an ai with nlp that reads and understands documents?******May 27, 2018******1******CA
2******there be many book , course , etc . out there , but not sure which path to take . so what would be the most effective way ( short ) to learn natural language processing online ? p . s . i mean learn fundamental , not how to use exist library or service .what is the most effective way to learn natural language processing online?******what is the most effective way to learn natural language processing online?******May 27, 2018******1******CA
3******i know some people will try to crucify me for ask such question here , since it's too generic , but ill give it a shot . so basically what i'm after in try to find if there any tool exist ( simply white paper be welcome too ) for create chatbots base on a plain text corpus , so that question could be ask about it . that be , there be some textual data ( like article ) , but there be no question , answer pair to train a conventional model with , like seq 2seq . i understand that there be way to achieve this by use tool to extract intent , entity from a question and match it with paragraph , article ( base on index and topic ) , but to my understand this create more of a nlp search bot , rather than a chatbot , which provide answer in conversation-like manner . thanks in advance .what existing tools are out there for creating chatbots from a plain text corpus and without having question, answer pairs?******what existing tools are out there for creating chatbots from a plain text corpus and without having question, answer pairs?******Jun 05, 2018******1******CA
2******i be work on a task where i be require to automate the customer service request channel . the process be quite typical . a customer query about a product via email , the person on the front channel check email , forward it to the relevant department and then answer be provide . the problem be that customer query can be about one of hundred of device list . each device have it own pdf documentation which be quite extensive . find the right pdf and then find the right section where information could be list be really a tedious process and waste a lot of time . sometimes the information be not even list and answer have to be improvise by product specialist ( the last part hint me about reinforcement learning , what do you guy think ) . what i want to achieve be that this whole tedious and repetitive process be automate and may be if possible , the model learn over time as well . the task output be quite open end as well . different approach and model can be try out ( like chatbots and etc ) . rapid failure be highly appreciate here . below mention be some more detail : database : i have customer query about device in the form of email . pdf documentation of device . the documentation be quite extensive . i also happen to have some excel file where some sample query and sample answer be list . but since query can be of very dynamic nature , it doesn't seem like a classification problem ( to me at least ) . i have google quite a lot about the topic but mostly what i get be topic like ' how ai will transform the customer service ' and then something more specific to nlp and a lot of company ad etc . so far what i have understand from online surfing be that possible approach need to use nlp library ( nltk ) in python and do some topic model for documentation and for email . still how i approach the whole task be not clear to me . what i want from you guy be that maybe guide me how this task can be achieve step by step . i be not look for any code ! just which method can be use and how the problem can be approach . right now , i don't know where to start and how to approach it .implementing ai/ml in customer service******implementing ai/ml in customer service******Jun 06, 2018******1******CA
2******my question be that be there any general idea on how human solve jumble word ? i know many people will say we match it against a commonly use word checklist mentally , but it be kind of vague . be there any theory on this and how might an ai learn to do the same ?can ai solve jumbled words?******can ai solve jumbled words?******Jun 30, 2018******1******CA
2******i'm look to write an ai that will be able to extract in text reference from standard document to assist human research . my use case be extract the identifying number , for example , " ar 25-2 " , along with the title of the document " information assurance " so that a human can gather all the relate research on a contract at once , instead of have to keep track of reference while they're read through the document . i have a pretty good idea of where to gather the name of these document for training , i'm plan on ' scrap ' a few repository for different category of these document . what kind of model should i use to get the best result ?extracting referenced documents******extracting referenced documents******Jul 13, 2018******1******CA
1******this be actually something i have be research a bit on my own . most movie script can be structurally analyse by use write theory such a dramatica . dramatica be base upon hierarchy of concept , which can be topic model . the hierarchy of topic model would seem to work very well with the dynamic routing algorithm of capsule network . i have be work with computational creativity problem in narrative generation . the state of the art method use partial order causal link planner , but they depend on propositional logic . alonzo church present the superman dilemma ( louis lane do not know that clark kent be superman , but superman know , that he be clark kent ) and invented intensional logic a a solution ; the basic idea be , that if we do not know the context of the narrative , the meaning be always in superposition and can only be understand through entangled meaning from the background story . so in a sense propositional logic be limit by classic information theory constraint , while church's logic can take a quantum information theoretic approach . i do not believe that classic information theory can resolve narrative analysis problem . so basicly the meaning of a narrative collapse ( the superposition get resolve ) by use the hierarchical narrative structure and what we know before hand . so my intuition would be follow : - we can use dramatica and potentially other narrative theory ( hierarchical metamemetics , reverse scarf etc . ) to create a hierarchical network like imagenet , but for narrative . - we can build conceptual topic model . dramatica have hierarchy of 4-16- 64-64 concept and annotate data exists already . - when use hundred of topic model , there will be a lot of false positive . however , the superposition of the topic model can be collapse by use the hierarchical level and some other dramatic analytics . - by use the dynamic routing of capsule network , we might be able to build a system , which could determine a narrative interpretation of the full story , which would make most sense by use the concept hierarchy . i try to prove my intuition , but unfortunately dramatica only have 300 movie analyse and i be able to find script of only 10 of them ; not enough data . however , there be other hierarchical ontology out there and other narrative structure ; could the same intuition be use for political news for example ?would capsule neworks and topic modeling used together make sense?******would capsule neworks and topic modeling used together make sense?******Jul 20, 2018******1******CA
1******i be learn ai and try out my first real life ai application . what i be try to do be take a an input various sentence , and then classify the sentence into one of x number of category base on keywords , and ' action ' in the sentence . the keywords be , for example , merger , acquisition , award , product launch etc . so in essence i be try to detect if the sentence in question talk about a merger between two organization , or an acquisition by an organisation , a person or a organization win an award , or launching of a new product etc . to do this , i have make custom model base on the basic nltk package model , for each keyword , and try to improve the classification by dynamically tag / update the model with related keywords , synonym etc to improve the detection capability . also , give a set of sentence , i be present the user with the detected categorization and ask whether it correct or wrong , and if wrong , what be the correct categorization , and also identify the entity ( company names , person name , product name , etc ) . so the object be to first classify the sentence into a category , and additionally , detect the named entity in the sentence , base on the category . the idea be , to be able to automatically re-train the model base on this feedback to improve it performance over time , and to be able to retrain with as less manual intervention a possible . for the sake of this project , we can assume that user feedback would be accurate . the problem i be facing be that nlk be allow fixed length entity while training , so for example a two word award be be detect a two award . what should be my approach to solve this problem ? be there a good nlu ( even a commercial one ) which can address this problem ? it seem to me that this would be a common ai problem , and i be miss something basic . would love you guy to have an input on this . thanks .sentence classification and named identity detection with automatic retraining******sentence classification and named identity detection with automatic retraining******Jul 21, 2018******1******CA
0******i want to use nlp for semantic retrieval . i be new to this field . can anyone suggest toolkit or tutorial to learn and implement nlp from scratch .nlp for semantic retrieval******nlp for semantic retrieval******Jul 22, 2018******1******CA
6******if you teach an ai to understand sentence through usual neural network technique . then could you be to teach it thing with sentence such a " ant be small " , " the sky be blue " . i . e . if you feed it that sentence and the neural network say this be 99 % likely to be a properly form sentence . then where would it store this sentence for future use ? this would be a kind of one-shot learning after it learn how to learn . could you use some sort of gated architecture ?can you teach an ai through sentences?******can you teach an ai through sentences?******Aug 16, 2018******1******CA
1******i want to do some sequence to sequence model on source data that look like this : with target data that look like this : both be of indeterminate length , and the length of target and source data aren't the same . what i'd like to do be have a prediction model where i can input similar number and have it generate text base on the target training data . i start off do character level s2s , but the output of the model be too nonsensical even at 2-5 k epoch . so i've be look into word level s2s and nmt , but the tutorial always assume string of text a the target and source , and i keep run into roadblock try to preprocess the text , when all the tutorial assume a certain syntax / set of character . this be my first try at ml , and some of the tutorial really throw me out with the text preprocessing requirement . be i go down the right avenue look at word level / nmt stuff ? and be there a tutorial i've miss for something like what i'm try to build ?sequence to sequence machine learning / nmt - converting numbers into words******sequence to sequence machine learning / nmt - converting numbers into words******Aug 20, 2018******1******CA
1******the term paraphrasing be use for convert input text into output text with small modification on the semantic level . paraphrasing be use by manager to distribute work item to employee . it be a certain form of communication which be hard to formalize . from the management literature it be know that so call workflow management system be implement a groupware server . they be store and forward message in the intranet of a company . the question be : be it possible to combine both ? that mean to paraphrase incoming message of a company and distribute the message to sub-departments ? in theory , this would replace traditional manager , but i'm not sure . perhaps it would make sense to test out the hypothesis first on the enron dataset , which be a corpus of the e-mail fulltext of 158 employee in a large company .can semantic paraphrasing be used for a workflow management system?******can semantic paraphrasing be used for a workflow management system?******Aug 22, 2018******1******CA
2******in the domain of natural language processing , a textgenerator be able to produce pseudo random output . the most famous one be scigen which be use to generate fake-science paper . the inner working of scigen be know , a so called context-free grammar be use which be parametrized by a random generator . for the purpose of layout formatting , the “ lorem ipsum ” text be use , which be a dummy pattern , generate by software . the inner working be unclear . i've see many " lorum ispum " generator on the web , and not only " lorum ispum " , there be also " bacon ispum " , " space ispum " ... so how do these generator generate the text ?how does the 'lorum ispum' generator work?******how does the 'lorum ispum' generator work?******Aug 28, 2018******1******CA
3******be there an accepted way in nlp to parse conjunction ( and / or ) in a sentence ? by follow the example below ; how would i parse , into , imply an action will be take when one of the above element at the 1st level of depth be true . i know when i hear the sentence that it mean , but how could this be determine computationally ? can an exist python / other library do this ?how to parse conjunctions in natural language processing in python******how to parse conjunctions in natural language processing in python******Sep 07, 2018******1******CA
1******i would like to have a chat to talk on a personal plan enough to pass the turing test . i get to study some natural language processing ( nlp ) but some that usually hide a lot of mechanical , so i think they be also much more sensitive than word and get phrase more fluid . the problem be that i do not even have the idea to start . i do some testing with a nlp chatterbot library for python , but i do not know if it's possible to join pln to network or how to use a neural network and i can not even use python or if i have to use a specific language . in addition , i be use the book artificial intelligence - russell and norvig a the basis for the article and i would like recommend me others .how to make a chatbot with nlp and neural******how to make a chatbot with nlp and neural******Sep 14, 2018******1******CA
1******i'm train a language model with vocabulary use a single ( w / actually usable memory about 7.5 g ) . the number of token per batch be about , and the hidden dimension to the softmax layer be . so , if i understand correctly , fully-connected ( softmax ) layer theoretically consume for a forward pas ( 4 be for float 32 ) . but the gpu perform the forward and backward pass without any problem , and it say the gpu memory usage be less than in total . i use pytorch . what's cause this ? edit : to be clear , the input to the final fc layer ( 256x5000 matrix ) be of size [ 256 , 32 , 256 ] .calculation of gpu memory consumption on softmax layer doesn't match with the empirical result******calculation of gpu memory consumption on softmax layer doesn't match with the empirical result******Sep 17, 2018******1******CA
1******within a piece of text , i'm try to detect who do what to whom . for instance , in the following sentence : cv hit iv . cv be hit by iv . i'd like to know who hit whom . i can't remember what this technique be call . thanks for any help !looking for nlp technique and drawing a blank******looking for nlp technique and drawing a blank******Sep 24, 2018******1******CA
0******if there be give a one paragraph a a input and it extract a string from the paragraph , within a predefined range ( i . e . a string that start with three letter that a always fix and end with five number like " xxx 12345 " that number be varies between [ 0-9 ] , etc ) . i have be struggle where to begin on this or if i be even go in the right direction for consider machine / deep learning to try to do this . should i use nltk ? i already make this by use python regular expression but i want to know how to make this prgram use machine or deep learning . please help !extract particular pattern from the given text/paragraph using machine or deep learning******extract particular pattern from the given text/paragraph using machine or deep learning******Oct 10, 2018******1******CA
1******i'm try to build a chat analysis that could identify the intent of check price . have any kind of preset intent list to train my chatbot already be do ? data : a data set for " check price " intent's . like " how much be ___ " context : i look for a data set to train a intent recognization for check price at chat bot . exemple : if some one ask for a product price . i want to tag this be as check price intent . for that i be trainning a intent recognition . region : prefirencal the whole globe , but for start could be only at english license : could both payed or free non-answers : i didnt find nothing like a dataset for intentpreset intent list******preset intent list******Oct 10, 2018******1******CA
1******i'm work on a project , whereby ; one of the actor be " teacher " and it's role will be , insert the course name , outcome of skill , then insert the question , student degree and automatically will be connect with appropriate skill through the natural language processing ( nlp ) analysis student degree . what algorithm should i use in natural language processing to connect the question to the appropriate skill ( text comparison ) ?question in nlp******question in nlp******Oct 11, 2018******1******CA
2******there be some predefined category ( overview , data architecture , technical detail , application etc ) . the requirement be to classify the input text of paragraph into their resp . category . i cant use any pretrained word embeddings ( word 2vec , glove ) because the data enter be not in general english ( talk about dog , environment etc ) but pure technical ( how do a particular program orks , step to download anaconda etc ) . don't have any data available in internet to train as well . anything that understand semantic-surface-level of a sentence will workhow to find the category of a technical text on a surface-semantic-level******how to find the category of a technical text on a surface-semantic-level******Oct 12, 2018******1******CA
1******the need for semantic cognition in relation to natural language in computer be ever appear in real problem in the field of ai . we can note a substantial increase in related post in stackexchange and other web location . this need be radically increase for several reason . recent advance in voice recognition and synthesis cover convert syntax back and forth into the audio domain , but the resulting talk with human be meaningless on the computer side , whether the computer be speak or listen . many business go paperless year and now have thousand of document that can't be easily index . the ai talk in public medium have lead to a funding increase for all of it sub-fields so technical people be talk , reading , and write more about semantics because they be because they be do those thing more for anything ai relate . senior level business people , for the same reason a the technical people , be look to stay at the forefront of technology and thing like chatbots and command drive product be an appeal option . ( this will be the question in a moment . ) ai researcher and linguist roger schank explain case base reasoning in a way that have become his signature : a story tell type of thought experiment . he write : <sup> 1 </sup> the story be that i be complain to a friend that my wife didn't cook steak the way i like it – she always overcook it . my friend say , " well , that remind me of the time i couldn't get my hair cut as short a i want it , thirty year ago in england . " the question i ask be , how do such remind happen , and why do it happen ? the " how " be obvious . what be the connection between the steak and the haircut ? if you look at it on a conceptual level , there's an identical index match : we each ask somebody who have agree to be in a service position to perform that service , and they didn't do it the way we want it . there be a number of question you can ask . first , how do we construct such index ? obviously , my friend construct such an index in order to find , in his own mind , the story that have the same label . second , why do you construct them ? and the answer be that you're try to understand the universe and you need to match incoming event to past experience . this be something i call " case-based reasoning . " the idea that you would then make that match obviously have a purpose . it's not hard to understand what the purpose would be ; the purpose be learn . because how would you learn from new experience otherwise ? consider now the state of technology and the increase funding , senior level management attention , and grow technical expertise , result in an industrial robot that respond to and respond with voice . this be no longer the domain of science fiction . it be a need toward which current technology be move with diligence and passion . the following schank-ian thought experiment , where the match occur without case-based reasoning , show the hole in current ai system design . an industrial robot be melt down a defective metal part to recycle the metal a part of a material cost reduction policy . when the operation be complete and the metal be properly add back into the production stream , the recycle engineer say , " and that's a wrap , " refer to the task be complete from the movie shoot scenario . a week later , the robot be work in another department . the department director have buy a piece of gold jewelry for his wife to celebrate their twentieth anniversary . the robot enter his office , he hand the robot the gift and say , " please wrap this . " that the gift end up in the production line for gold plat electronic contact on the factory floor be because the computer in the robot do not use case base reasoning in a way that reduce risk of loss . how can current technology be use to not only deliver understand but also avoid misunderstand ? consider that schank be likely correct , that memory be largely the storage and indexing of these conceptual case . consider the input to be process be a continuous sequence of linguistic element <sup> 2 </sup> a the input ( originate from a voice recognition deep learner already in place ) and the output be a list of match case that be analog , score by how likely they match the meaning intend by the speaker . it would be a late task to decide how to assess risk associate with execution base on each of the meaning and ask the speaker what they mean if the meaning be ambiguous and the risk of execute base on a misunderstanding be high . what convolution network , attention base learner , rule engine , fuzzy logic container , deep q-learners , or other component can successfully store schank's case and retrieve them base solely on the meaning of stream of linguistic element ? recall what schank write above : " if you look at it on a conceptual level , there's an identical index match : we each ask somebody who have agree to be in a service position to perform that service , and they didn't do it the way we want it . " how do one store that concept and retrieve it ? semantics of natural language — be ai capable hardware and software now develop enough to realize it ? footnote [ 1 ] the third culture : beyond the scientific revolution , john brockman , simon & schuster , 1995 , chapter 9 [ 2 ] linguistic element may be word , prefix , ending of word , or word group that have a meaning across the language space . example : gold ( just a normal word ) - ing ( to indicate the continuous tense of many verb and be therefore an independent linguistic element ) screw gun ( jargon that operate a a word pair with a mean different than if the word be take a separate linguistic element )semantics of natural language — is ai capable hardware and software now developed enough to realize it?******semantics of natural language — is ai capable hardware and software now developed enough to realize it?******Oct 13, 2018******1******CA
0******( maybe relate : usefulness of dropout for non-overfitting network ) my neural network do not overfit . use data augmentation in a non-overfitting network can increase it accuracy ? note : i'm ask this question in the nlp area , where data augmentation be not trivial . i'm think about back-translation . the augmented data might not be of similar quality , which can hurt the accuracy ( i guess ? ) .usefulness of data augmentation for non-overfitting network [nlp]******usefulness of data augmentation for non-overfitting network [nlp]******Oct 22, 2018******1******CA
1******i would like to create an npc engine for game which be in a fantasy context like lord of the ring , warcraft , skyrim , dragon age etc . this engine should be able to determine the polarity of the give sentence ( positive / negative / neutral ) and should also be able to tag the word ( part-of-speech tagging , but that's not relevant now ) . the problem be that i cannot find a dataset which i can teach my ai with , so that fit into the fantasy context . a an example for lord of the ring , there be character like sauron which be negative , but there's a ton of expression too in a fantasy world which cannot be find in a general dataset . therefore , i would like to ask if you could suggest to take dataset ( s ) which contain expression , even well name in a fantasy context . it doesn't matter which fantasy universe do it take . thank you !searching for dataset in specifix context for nlp, sentiment analysis******searching for dataset in specifix context for nlp, sentiment analysis******Oct 30, 2018******1******CA
1******the problem statement : mapping from a vector space representation onto a tree structure . possible solution : give a word vector a input , produce a path in the tree from the root down to the node that most closely match that vector . the path would be a variable length string compose from a finite set of symbol . the variable length output lead me towards long short-term memory ( lstm ) model . but i've never build a complete lstm model before . the understanding gap : my vector input be already dense representation . specifically , i'm work with glove right now . but the output path symbol would require a different encoding , correct ? how can i structure / train the necessary encoder-decoder pair so that it can handle both word vector and these path symbol a input while still be able to produce path symbol a output ?learning tree paths when given vectors******learning tree paths when given vectors******Nov 10, 2018******1******CA
0******grammatical induction be the art of learn a grammar from train data . we have a domain-specific-language for example a python dialect and should create for that dialect a grammar which be able to parse the language . parsing mean , to identify for new sourcecode sample if they be valid and which tokens have which mean . to make thing more complicate the language be not a programming language but the input in a textadvanture . that mean , the grammar should learn what the internal parser be do . additionally , the language have a meaning . that mean , the user type in a sentence and at a result the avatar on the screen move in a direction . in the literature such task be call grammar induction , because the grammar be not there and must be find from scratch . additional the link between the language and the action on the screen be need . i know this be a very complicate task and it be not possible to explain this in detail . so my question go only into the direction of a submodul of the overall system . before it be possible to iterate a grammar some datastructure be need to store the grammar . how can i do this ? do i need the antlr syntax for a grammar , can i store a grammar a a graph , a a lisp list tree or in a sql database ? in every case , the idea be not to program the grammar by hand in software , but to iterate with a solver over possible grammar accord to the input stream which be an unknown language .datastructure for grounded grammar induction******datastructure for grounded grammar induction******Nov 12, 2018******1******CA
1******( un-original ) idea : wouldn't it be cool if we could fact-check use an algorithm that could understand a whole bunch of document ( e . g . scientific paper ) a higher-order logic ? question : what work have be do on this to date ? what i've get so far : ( 1 ) i seem to recall there be prior work to create a subset of english ( i think intend for use in scientific writing ) that could be easily interpret by an algorithm . this doesn't quite get u to the algorithm describe above ( a it's restrict to a subset of english ) - but seem pertinent . ( 2 ) once parse , i guess a resolution algorithm like that in prolog could be use to check wether a fact ( presumably also inputted a a logical statement ) contradict the logic of the document ?possible to translate generic english-language document into higher-order logic?******possible to translate generic english-language document into higher-order logic?******Nov 13, 2018******1******CA
1******there be 4 kind of adverb : adverb of manner . for example , slowly , quietly adverb of place . for example , there , far adverb of frequency . for example , everyday , often adverb of time . for example , now , first , early nltk , spacy and textblob only tag a token a an adverb without specify which kind it be . be there any library which tag include the type of adverb ?how to know which kind of adverb in nlp parts of speech (pos) tagging?******how to know which kind of adverb in nlp parts of speech (pos) tagging?******Nov 16, 2018******1******CA
2******the domain of emergency call for clogged pipeline have to do with take a call and manage the reaction of plumber department . it be mostly a group orient communication situation between the caller , the first level call taker , the second level dispatcher and external station in the back office . from a linguistic point of view , there be different kind of speech act available . for example paraphrasing which be the repetition of previous speech with own word , or counter-speech which be criticize something say before . model all the different social role , their usage of speech act and make the overall decision process transparent be a difficult task . i've search a bit for exist paper about the subject , but it seem that the domain wasn't explore yet . my question be : be it possible to create some kind of chatbot population which talk to each other back and forth and be able to simulate an emergency dispatch task which include conflict between the operator and contrast point of view about how to handle a certain situation under resource limitation ?how to model a plumber dispatcher with artificial intelligence?******how to model a plumber dispatcher with artificial intelligence?******Nov 17, 2018******1******CA
0******i be relatively new to recurrent neural network and it seem like a vast domain . so i want to get my initial footing right . there seem to be a whole lot of application in this field , but the first i encounter and the one that many article seem to be claim a essential for other application be language model . i find that i be not too clear with some idea and intuition in this area . rather than a set of question , i think it would be good if i lay out the flow of idea a understood by me . where i be not sure , i have leave it a a question . and i hope that all the wrong idea be point out . i would love to learn it correct the first time around rather than have to unlearn and re-learn later . it be quite a long question and i apologize in advance for that . let u say , the task be to train from a corpus of text and generate new text or predict text ( in search suggestion kind of application ) let u say , i be use a vocabulary of one-hot vector ( not word embeddings ) . now this mean i convert each word in my dataset into a one-hot vector , with a one at the position the word occur in the vocabulary . i now proceed in 2 part : step 1 : pas the first timestep word into the first timestep of the rnn . this will calculate a vector give probability of output ( a vector of same length a vocabulary , with each entry be a probability of the next word be the word corresponding to that index position in the dictionary ) . let u call this y_pred . it will also calculate a cell vector which be pass into the next timestep to give a certain " memory aspect " to the rnn . the correct next word be actually a one hot vector that we have a a label in our training data . we now input this " correct next word " a our training data say into the next timestep and use this as well a the cell output of the previous timestep to calculate a prediction for the next ( 3rd word ) . now we calculate the error or cost , which be a measure of how much y_pred a predict by the neural network be off from the next word a we have in the training data . we now train the weight to minimise this cost . step 2 : have train the weight , we fee in a dummy input in the first timestep ( say a vector of zero ) , the rnn now predict a vector where the entry in each index be the probability of the next word to be the word in the vocabulary at that index position . be i correct till this point ? if yes , here be where i seem to be lose the trail , we now take this yhat and we now choose the input to the next timestep a a one hot vector with a one in the index position , say i , where this i be obtain by randomly choose an index with probability of each index be choose give by the vector ypred ? be i first correct in assume we pass a one hot vector into the next timestep ? we know get the ypred of the second timestep and this be again sample like before and we repeat this till we reach an end of sample.thus we get a generated sequence . this idea can be generalize to generate character , music , text and so on . now why be we use a sample of randomly chosen , probability weight , index when we can just pass the one with the maximum probability to the next time step ? also how do we make a real time sequence predictor ? for example , predict search query a text be enter . i feel we should first train the model on the proper sentence and then a a word be enter we predict word in the next time step by take the next word that the model predict have maximum probability and then , the next word , and so on . when the actual second word be enter by the user , we now take this a the input to the second timestep and get the most probable sentence that the model predicts and so on . be this an okay idea ? now , let u say that instead of work with an alphabetical position corpus , i be work with a word embedding . i understand the idea behind this a give the vector representation of word a way to contain some meaning.this allow the network to perform well on word encounter in real time work , that be not present in the training text a the vector be similar to more common word that belong to ( atleast , to some approximation ) the same class . now a word embedding of a word have entry that be value allow to take any range ? or be they usually conform to lie within 0 to 1 or - 1 to 1 ? okay . so now be the neural network predict at each timestep a vector of probabilites , or a vector of value , which the network think be a word embed represent a word which it believe be most likely to occur next ? if it be probability then i dont understand what they represent . if it be the other case , then how do we get the word itself ? the embed matrix need not necessarily contain a vector of these exact value . do we then measure the distance ( sum of square of difference of each entry ) between this vector and every vector in the embedding matrix and get the small one ? okay . now how do we proceed generate ? here , there seem to be really only two way of sample . that be to pass this vector y_pred a input to the next timestep or pass the vector from the embed matrix which we identify to have minimum distance from y_pred ? that be the actual word which we think the network be try to convey to u . thanks in advance !language models rnn******language models rnn******Nov 23, 2018******1******CA
0******i be a new learner in nlp . i be interested in the sentence generate task . as far a i be concern , one state-of-the-art method be the charrnn , which use rnn to generate a sequence of word . however , bert have come out several week ago and be very powerful . therefore , i be wonder whether this task can also be do with the help of bert ? i be a new learner in this field , and thank you for any advice !can bert be used for sentence generating tasks?******can bert be used for sentence generating tasks?******Nov 24, 2018******1******CA
2******i be learn to create a dialogue system . the various part of such a system be intent classifier , slot filling , dialogue state tracking ( dst ) , dialogue policy optimization and nlg . while read this paper on dst , i find out that a discriminative sequence model of dst can identify goal constraint , fill slot and maintain state of the conversation . do this mean that now i dont need to create an intent classifier and slot filling model separately a the task be already be do by this dst ? or i be misunderstand both the thing and they be separate ?does an advanced dialogue state tracking eliminate the need of intent classifier and slot filling models in dialogue systems/ chatbots?******does an advanced dialogue state tracking eliminate the need of intent classifier and slot filling models in dialogue systems/ chatbots?******Nov 26, 2018******1******CA
0******i be look for method / technique i can use to generate a set of similar question base on a base question . the generated question should be answer by the exact same answer to the base question . for example if the base question be what be the address of the restaurant ? generate question where be the restaurant locate ? can you give me the location of the restaurant ? whats the address of the restaurant ( i understand this bit hard since new word be introduce ) how can i come up with a generic model which can take a question a an input and generate a set of similar question ?how to use ai to generate similar questions from a base question?******how to use ai to generate similar questions from a base question?******Nov 26, 2018******1******CA
1******let's say we have 2 block of text , where there be some similarity a in 2 interpretation of the same story . be there any solution that would recognize these consistency and ultimately be able to recreate a story with all the detail of each ?intelligent text combination******intelligent text combination******Nov 26, 2018******1******CA
0******i constantly see latent dirichlet allocation ( lda ) a a go to technique for topic modelling . it perform okay-ish , but ignore word context and ( subjectively ) seem outdated . have anyone implement something like an lstm with lda to retain sentence information ? what other approach with neural net could be a good fit for topic modelling ?did anyone try topic modelling with neural nets?******did anyone try topic modelling with neural nets?******Nov 27, 2018******1******CA
0******we want to figure out the connection between people , base on their speech . assume , that a conversation be a poetry with line belongs to character . there be a lot of poetry and the line be mixed . now we want to define a conversation to which each line belong to . we assume , that people in a conversation use similar word ( their dictionary should be similar ) . it mean that there be a correlation between word of person a and word belongs to person b , and we could detect a connection between the people which have a conversation . what be the next step for content understanding after nlp ? can some of you advise u about the field of study and tool / library , which be deal with content processing ? maybe , some of you know good article or online resource , which can help u to dive into this field .content analysis tools******content analysis tools******Nov 29, 2018******1******CA
4******i be look for a solution that i can use with identifying car . so i have a database with image of car . about 3-4 per car . what i want to do be upload a picture to the web of car ( picture take with camera / phone ) and then let my pc recognize the car . example : let say i have these 2 picture in my database ( mazda cx5 ) ( i can only upload 2 link at max . atm . but you get the idea ) . now i be go to upload this picture of a mazda cs5 to my web app : now i want an ai to recognize that this picture be of an mazda cx5 with greyish color . i have look on the net and find 2 interesting ai's i can use : tensorflow and clarifai , but i don't know if these be go to work so my question to you what would be my best bet to go with here ?image recognition******image recognition******Mar 04, 2017******1******CA
8******which one would you recommend for a first approach to deep learning ? i'm a neuroscience student try for the first time computational approach , if that matter .tensorflow vs keras vs ... to begin with deep learning?******tensorflow vs keras vs ... to begin with deep learning?******Jun 22, 2017******1******CA
2******i be go through " wide & deep learning " tensorflow tutorial & it's quite simply explain the process . but i miss few of the thing . if someone can please explain them to me , it will be of great help : 1 ) why and we be use and again use ? 2 ) why in , we be take , even though they have more unique value ? 3 ) why we be use variable ? in the document there's an explaination give . but i'm not fully understand it . the question might sound silly , but i'm not sure of the answer to these question . thank you !wide & deep learning explanation******wide & deep learning explanation******Oct 11, 2017******1******CA
0******i be interested in use kera / tensorflow to self-train a neural net how to behave in a random environment with real-time feedback from a series of sensor . that probably sound confusing , so let me give an example . a a learning exercise i'm attempt to teach a simple network how to play the classic ' snake ' game by inputting the snake's distance to food , wall , and itself and reduce the output to 4 neuron represent move up , down , right , or leave - take whichever return the high value a the next movement of the snake . i be essentially try to recreate this video , but instead of a genetic algorithm with many model i would like to have a single model continually learn and adapt ( re-spawning and continue on death ) base on the result from initially random movement . so on to methodology , my thought be to use a weighted loss function to attribute high positive weight to action that result in gain point ( move towards food and eat it ) and attribute negative weight to action that result in death ( e . g . hit wall / hit itself ) or avoid the food . conceptually i can see how this would work , and i'm tempt to code my own weighted activation function to try it out , but i be wonder if anything like this already exist in kera / tensorflow . i have hear of weighted activation function be implement , but i couldn't find any example of train with ' negative data ' , i . e . train the network what not to do . a for what i've do so far , i have basically reproduce the above link video . i have a snake program setup to input the accord data to a densely connect network with 12 input neuron , 8 hidden neuron , and 4 output neuron . the output of the network control the snake's next movement a desire , and currently i build an evaluation function to determine how well the snake be do at every step and a basic genetic algorithm which take this evaluation to slowly work towards a good network . this work okay , not quite as well a in the video ( which i attribute to my reduced number of neuron , sensor , and probably inferior evaluation function ) , but it eventually seem to get the idea of seek food and not die . so do anyone have any thought on training with weighted loss function , maybe good source to checkout for information , and more specifically any implementation of train negative correlation ? i feel like a real-time self-learning network that learn by do must have a way of evaluate and adapt to negative result , but i be also pretty new to neural network so if there be another standard way of achieve what i'm describe i'm open to suggestion ! thanks !training with unbalanced positive *and negative* data******training with unbalanced positive *and negative* data******Mar 14, 2018******1******CA
0******say you follow a tutorial on the tensorflow website for a wide and deep model ( ) i create a model base on the u census data to predict whether or not an individual will make more or less than \ $ 50k give a number of feature like age , education , profession , etc . i've be able to create the model as well a create a predictor that use the model just fine . but be there a way to see what feature tensorflow be " weigh " more than others ? for instance , do it weigh a high education more than someone age ? ( i . e . if someone have a phd and be 26 year old , be the model more likely to say they make more than \ $ 50k v someone who have an associate degree and be 55 year old ? ) i'm use a dnnlinearcombinedclassifier if it matter to this question .being able to see how tensorflow "weighs" features in classifier******being able to see how tensorflow "weighs" features in classifier******Mar 19, 2018******1******CA
2******to start , let me just say that i be very new to tensorflow and machine learning in general . but , a part of my learning project i be try to adapt the tensorflow wide and deep model to generate movie recommendation . however , the part i'm get stick on be handle multiple value for a categorical column . below be a sample of how a couple of row in my csv look like . the genre and tag column have multiple categorical value . i have look at to parse the string and return a . once i have parse my delimited string value into , what do i do with ? if i want to create , how do the interact with it ? be that even the correct step ? should the be convert into a something before i can create a ? i be just not sure how to train the wide and deep model when you have multiple categorical value for a single column . some people have suggest that i use each ' genre ' a it own column and encode it use one-hot , but it be not realistic for me to do this , because there could be 100 of genre and tag in the data . any help on this matter would be welcome . thank you ! !how do you handle multiple categorical values in a single column for wide_deep model in tensorflow?******how do you handle multiple categorical values in a single column for wide_deep model in tensorflow?******Apr 24, 2018******1******CA
0******from , i understood tensorflow require all the operation in the graph to be explicit formula ( instead of black-boxes , such a raw python function ) to do automatic differentiation . then it will do some kind of gradient descent base on that to minimization . i'm wondering , since it already know all the explicit formula , can it directly find out the minimum by examine the equation itself ? like compute the point where gradient be zero or do not exist , then do some kind of processing to find out the minimum . i find it be simple to do this " symbolic minimization " above with few variable such a minimize where be the trainable variable an be all the training sample . i'm not sure be there a general way though .can tensorflow minimize "symbolically"******can tensorflow minimize "symbolically"******May 10, 2018******1******CA
1******i be try to implement cnn use tensorflow on temporal accelrometer signal . i have signal value segment on every 10ms ( 200 sample ) . i want to perform 1 - d convolution ( ) convolution window size be 20 sample and stride of 1 with 32 feature and valid padding i want to apply max-pooling with window size of 10 sample but i be get error regard dimension of tensor . any suggestion on how can i set filter size and stride for booth convolution and max-poolinghow to set stride,filter size in tensorflow for 1-d signals?******how to set stride,filter size in tensorflow for 1-d signals?******May 10, 2018******1******CA
6******i be pretty much a beginner in tensorflow and simply follow a tutorial . there be no problem with my code , but i have a question regard the output i would like to know what do " prediction / mean " and " label / mean " represent ?meaning of evaluation metrics in tensorflow******meaning of evaluation metrics in tensorflow******May 12, 2018******1******CA
5******i use the example at - - to create my own classification model . i use different data but the basic outline of datasets be use . it be important for my data type to shuffle the data and then create the training and test set . the problem however come a a result of the shuffling . when i train my model with the shuffled train set i get a + - 80 % accuracy for train and + - 70 % accuracy for the test set . i then want to input all the data ( i . e . the set that make the training and test set ) into the model to view the fully predict output of this data set that i have . if this data set be shuffle a the training and test set be i get an accuracy of around 77 % which be a expect but then if i input the unshuffled data ( a i require to view the prediction ) i get a 45 % accuracy . how be this possible ? i assume it's due to the fact that the model be learn incorrectly and that it learn that the order of the data point play a role in the predicting of those data point . but this shouldn't be happen a i be simply try to ( like the mnist example ) predict each data point separately . this could be a mini-batch training problem . so i ask , in the example mention above , use data set and batch to train , do the model learn from the average of all the data point in the mini-batch or do it think one mini-batch be one data point and learn in that manner ( which would mean order matter of the data ) ? or if there be any other suggestion . thankstensorflow batch learning******tensorflow batch learning******May 22, 2018******1******CA
4******i be make a machine learn program for time series data analysis and use neat could help the work . i start to learn tensorflow not long ago but it seem that the computational graph in tensorflow be usually fix . be there tool in tensorflow to help build a dynamically evolve neural network ? or something like pytorch would be a well alternative ? thanks .can neuro-evolution of augmenting topologies (neat) neural networks be built in tensorflow?******can neuro-evolution of augmenting topologies (neat) neural networks be built in tensorflow?******Sep 12, 2018******1******CA
4******i make my first neural net in c + + without any library . it be a net to recognize number from the mnist dataset . in a 784 - 784 - 10 net with sigmoid function and 5 epoch with each 60000 sample , it take about 2 hour to train . it be probably slow anyways , because i train it on a laptop and i use class for neuron and layer . to be honest , i've never use tensor flow , so i want to know how the performance of my net would be compare to the same in tensor flow . not to specific but just a rough aproximation .how fast is tensorflow compared to self written neural nets?******how fast is tensorflow compared to self written neural nets?******Sep 30, 2018******1******CA
0******the levenshtein algorithm and some ratio and proportion may handle this use case . base on the pre-defined sequence of statement , such a " i have a dog " , " i own a car " and many more , i must determine if an another input statement such a " i have a cat " be the same or how much percentage do the input statement be most likely equal to the pre-defined statement . for example : predefined statement : " i have a dog " , " i own a car " , " you think you be smart " input statement and result : i have a dog - 100 % ( because it have exact match ) , i have a cat - ~ 75 % ( because it be almost the same except for the animal , think - ~ 10 % ( because it be just a small part of the third statement ) , bottle - 0 % ( because it have no match at all ) the requirement be that tensorflow be use rather than java , which be the language i know , so any help with what to look at to get start would be helpful . my plan be to use the predefined statement a the train_data , and to output only the accuracy during the prediction , but i don't know what model to use , please help thanks ! even just guide me with the architecture and i will try to implement it , thanks in advance !tensorflow - finding the right model on my use case******tensorflow - finding the right model on my use case******Oct 22, 2018******1******CA
3******tensorflow / lucid be able to visualize what a " channel " of a layer of a neural network ( image recognition , inception-v 1 ) respond to . even after study the tutorial , the source code , the three research paper on lucid and comment by the author on hacker news , i'm still not clear on how " channel " be suppose to be define and individuate . can somebody shed some light on this ? thank you .what exactly does "channel" refer to in tensorflow/lucid?******what exactly does "channel" refer to in tensorflow/lucid?******Aug 29, 2018******1******CA
4******i wonder on the following concept : a give neural network get two audio input ( preferably music ) and give a real number between 0 and 1 which describe " similarity " between the second and the first track . as far a my understanding of neural network go , the problem fit the concept of nns , a pattern recognition in music can help determine similarity and discrepancy in audio , see voice recognition . however , due to the nature of long and complex input , and the vague nature of learn datasets ( how similar , for instance , diana ross : it's your move , and the vaporwave legend floral shoppe exactly be ? 0.9 ? 0.6 ? other ? ) , such a network would be extremely slow and convolute . be it possible today to build and train such a model ? if yes , how would it look like ?is music/sound similarity comparison feasible on neural networks?******is music/sound similarity comparison feasible on neural networks?******Aug 22, 2017******1******CA
0******let u for these purpose say with be work with any feed forward neural network . let u also say , that we know beforehand that certain portion of our dataset arsignificantly more impactful or important to our underlying representation . be there anyway to add that “ weight ” to our data ?a way to give more weight to particular data?******a way to give more weight to particular data?******Mar 07, 2018******1******CA
8******some program do exhaustive search for a solution while others do heuristic search . for example , in chess , the search for the best next move tend to be more exhaustive in nature whereas in go , the search for the best next move tend to be more heuristic in nature due to the much large search space . be the technique of brute force exhaustive searching for a good answer consider to be ai or be it generally require that heuristic algorithm be use before be deem ai ? if so , be the chess play computer beat a human professional see a a meaningful milestone ?are methods of exhaustive search considered to be ai?******are methods of exhaustive search considered to be ai?******Aug 02, 2016******1******CA
0******we can read on wiki page that in march 2016 alphago ai lose it game ( 1 of 5 ) to lee sedol , a professional go player . one article cite say : alphago lose a game and we a researcher want to explore that and find out what go wrong . we need to figure out what it weakness be and try to improve it . have researcher already figure it out what go wrong ?why did alphago lose its go game?******why did alphago lose its go game?******Aug 09, 2016******1******CA
9******i want to start with a scenario that get me think about how well mcts can perform : let's assume there be a move that be not yet add to the search tree . it be some layer / move too deep . but if we play this move the game be basically win . however let's also assume that all move that could be take instead at the give game state be very very bad . for the sake of argument let's say there be 1000 possible move and only one of them be good ( but very good ) and the rest be very bad . wouldn't mcts fail to recognize this and not grow the search tree towards this move and also rate this subtree very badly ? i know that mcts eventually converge to minimax ( and eventually it will build the whole tree if there be enough memory ) . then it should know that the move be good even though there be many bad possiblities . but i guess in practice this be not something that one can rely on . maybe someone can tell me if this be a correct evaluation on my part . apart from this special scenario i'd also like to know if there be other such scenario where mcts will perform badly ( or extraordinary well ) .monte carlo tree search: what kind of moves can easily be found and what kinds make trouble?******monte carlo tree search: what kind of moves can easily be found and what kinds make trouble?******Aug 31, 2016******1******CA
1******i'm interested mostly in the application of ai in gaming ; in case this adjust the way you answer , but general answer be more than welcome a well . i be read up on neural network and combine them with genetic algorithm ; my high-level understanding be that the neural network be use to produce a result from the input , and the genetic algorithm be employ to constantly adjust the weight in the neural network until a good answer be find . the concept of a genetic algorithm randomly mutate the weight on the input to a neural network make sense to me ; but i don't understand where this would be apply in respect to gaming . for example , if i have some simple enemy ai that i want to have adapt to the player play-style , be this a good opportunity to implement the ai a a genetic-algorithm combine with a neural network ? with these different suitable application , how do one go about decide how to encode the problem in such a way that it can be mutate by the genetic algorithm and serve a suitable on / off input to a neural network ( actually , be neural network always design a on off signal ? ) ?what sort of game problems can neural-networks and genetic algorithms solve, and how are they typically implemented?******what sort of game problems can neural-networks and genetic algorithms solve, and how are they typically implemented?******Oct 11, 2016******1******CA
1******i be create a snake game in unity and i would like to implement ai snake that wander around the globe while avoid collision with the other snake on the globe , and if possible i would also like to make the ai snake purposefully trap other snake so that the other snake would collide and die . the ai snake must meet the following requirement : they must move in a certain way . a snake be control by a user use the arrow key on a keyboard , therefor i would also like the ai snake to move use this form of input . the ai snake must move on a sphere a i know , create artificial intelligence be not an easy task and i would like to know if there be some open source project that i can use for accomplish this task .how to create an ai snake for a video game?******how to create an ai snake for a video game?******Oct 18, 2016******1******CA
2******with tool like open ai will we be able to teach an ai to build it own deck ? build a deck from a limited pool ? or draft ? evaluate the power level of a card ?how close are we to having an ai that can play magic: the gathering objectively well?******how close are we to having an ai that can play magic: the gathering objectively well?******Feb 27, 2016******1******CA
4******i be currently write an engine to play a card game , a there be no engine yet for this particular game . i be hop to be able to introduce a neural net to the game afterwards , and have it learn to play the game . i'm write the engine in such a way that be helpful for an ai player . there be choice point , and at those point , a list of valid option be present . random selection would be able to play the game ( albeit not well ) . i have learn a lot about neural network ( mostly neat and hyperneat ) and even build my own implementation . i be still unsure how best build an ai that can take into account all the variable in one of these type of game . be there a common approach ? i know that keldon write a good ai for rftg which have a decent amount of complexity , i be not sure how he manage to build such an ai . any advice ? be it feasible ? be there any good example of this ? how be the input map ? edit : i have look online and learn how neural network work and usually how they pertain to image recognition or steer a simple agent . i'm not sure if or how i would apply it to make selection with card which have a complex synergy . any direction towards what i should be look into would be greatly appreciate . about the game : the game be similar to magic : the gathering . there be a commander which have health and ability . player have an energy pool which they use to put minion and spell on the board . minion have health , attack value , cost , etc . card also have ability , these be not easily enumerate . card be play from the hand , new card be draw from a deck . these be all aspect it would be helpful for the neural network to consider .teach a neural network to play a card game******teach a neural network to play a card game******Sep 17, 2017******1******CA
0******can an ai learn to play chess if you give it nothing but " the goal be to win " a start criterion ? if not , what be the minimum information the ai would need to be " seed " with in order to learn to play chess ? what technique could be use to create an ai that learn to play chess independently ?can an ai learn how to play chess without instructions?******can an ai learn how to play chess without instructions?******Feb 06, 2017******1******CA
1******if the game have a variable speed and be essential in evolution / gain score ( idk ai terminology ) . would the ai be able to figure out when to slow down and speed up ? if it be able to solve the problem or complete the level , will it have an equation to relate acceleration , or perhaps a number on when to speed up and down . what if the game environment be dynamic ? can you even teach math to an ai ? p : i'm not sure if i should ask separate question ?can a game ai learn the concept of acceleration?******can a game ai learn the concept of acceleration?******Feb 25, 2018******1******CA
0******i'm develop a millitary game and i want soldier to place themselves in specific order , when commander order . how can i do this ? should agent learn somehow how to achieve give order or there exist other way ? i'm new in ai , so i do not really know how can i accomplish my goal . thanks for every advice .placing agents in a specific order on demand******placing agents in a specific order on demand******Mar 10, 2018******1******CA
6******i'm wonder how to train a neural network for a round base board game like , tic-tac-toe , chess , risk or any other round base game . get the next move by inference seem to be pretty straight forward , by feed the game state a input and use the output a the move for the current player . however train an ai for that purpose doesn't appear to be that straight forward , because : there might not be a rating if a single move be good or not , so training of single move doesn't seem to be the right choice use all game state ( input ) and move ( output ) of the whole game to train the neural network , doesn't seem to be the right choice a not all move within a lost game might be bad so i'm wonder how to train a neural network for a round base board game ? i would like to create a neural network for tic-tac-toe use tensorflow .how to train a neural network for a round based board game?******how to train a neural network for a round based board game?******May 19, 2017******1******CA
1******in two player game , the exact value of the evaluation function doesn't matter as long a it's big for good position . however , for learning , it's customary when it do change when the best move get make . this way , the learning can minimize the difference between the directly compute value of a position and the value obtain from step minimax . what i'm miss here be a way to direct the evaluation function to actually win . for example , a perfect evaluation function for a won position in chess would always return without any hint how to progress towards checkmate . in a chess variant without the fifty-move limit , it could play useless turn forever . i guess , this be a rather theoretical problem a we won't ever have such a good function , but i wonder if there's a way to avoid it ?game ai evaluation function and making progress towards winning******game ai evaluation function and making progress towards winning******Mar 08, 2018******1******CA
6******i'm wonder how to train a neural network for a round base board game like , tic-tac-toe , chess , risk or any other round base game . get the next move by inference seem to be pretty straight forward , by feed the game state a input and use the output a the move for the current player . however train an ai for that purpose doesn't appear to be that straight forward , because : there might not be a rating if a single move be good or not , so training of single move doesn't seem to be the right choice use all game state ( input ) and move ( output ) of the whole game to train the neural network , doesn't seem to be the right choice a not all move within a lost game might be bad so i'm wonder how to train a neural network for a round base board game ? i would like to create a neural network for tic-tac-toe use tensorflow .how to train a neural network for a round based board game?******how to train a neural network for a round based board game?******May 19, 2017******1******CA
6******i'm wonder how to train a neural network for a round base board game like , tic-tac-toe , chess , risk or any other round base game . get the next move by inference seem to be pretty straight forward , by feed the game state a input and use the output a the move for the current player . however train an ai for that purpose doesn't appear to be that straight forward , because : there might not be a rating if a single move be good or not , so training of single move doesn't seem to be the right choice use all game state ( input ) and move ( output ) of the whole game to train the neural network , doesn't seem to be the right choice a not all move within a lost game might be bad so i'm wonder how to train a neural network for a round base board game ? i would like to create a neural network for tic-tac-toe use tensorflow .how to train a neural network for a round based board game?******how to train a neural network for a round based board game?******May 19, 2017******1******CA
3******i have some episodic datasets extract from a turn-based rts game in which the current action lead to the next state doesn ’ t determine the final solution / outcome of the episode . the learning be expect to terminate at a final state / termination condition ( when it win or loss ) for each episode and then move on to the next number of episode in the dataset . i have be look into q learning , monte carlo and sarsa but i be confuse about which one be best applicable . if any of the mentioned algorithm be implement , can a reward of zero be give in preliminary state before termination state of each episode at which it will be reward with a positive / negative ( win / loss ) value ?which reinforcement learning algorithms are efficient for episodic problems?******which reinforcement learning algorithms are efficient for episodic problems?******Jan 13, 2018******1******CA
1******i play a racing game call need for madness ( some gameplay : ) . nfm be a racing game , where the player can choose different car and race and crash the other car , and you can play on different track too . the game have a fix frame rate , so you can assume that the same sequence of button press will always arrive at the exact same position , rotation , velocity , etc . of the car . i want to make a bot which could race faster than i can . what would be the best way to go about do this ? be this problem even suit for deep learning ? i be think i could train a neural network where the input would be the current world state ( position of the player , position of the checkpoint you have to through and all the obstacle ) , and the output would be an array of booleans , one for each button . during a race , i could then keep forward propagate from the input to the booleans . however , i'm not so sure what i would do after the race be over . how do i back propagate after the race to make the nn be less likely to make bad move ?how to teach an ai to race optimally in a racing game?******how to teach an ai to race optimally in a racing game?******Jan 13, 2018******1******CA
2******i be currently write an engine to play a card game and i would like for an ann to learn how to play the game . the game be currently playable , and i believe for this game a deep-recurrent-q-network with a reinforcement learn approach be the way to go . however , i don't know what type of layer i should use , i find some example of atari game solve through ann , but their layer be cnn ( convolutional ) , which be well for image processing . i don't have an image to fee the nn , only a state compose of a tensor with card in the player's own hand and card on the table . and the output of the nn should be a card or the action ' end turn ' . i'm currently try to use tensorflow but i'm open to any library that can work with nn . any type of help or suggestion would be greatly appreciated !what layers to use in a neural network for card game******what layers to use in a neural network for card game******Jan 19, 2018******1******CA
1******a human player play limit game compare to a system that undergoes million of iteration . be it really fair to compare alphago with the world # 1 player when we know experience increase with the increase in number of game play ?is it fair to compare alphago with a human player?******is it fair to compare alphago with a human player?******Jan 28, 2018******1******CA
1******artificial intelligence be present in many game , both current and old game . how can such intelligence understand what to do ? i mean , how can it behave like a human in a game , allow you to play against itself , or that ai play against itself ? in game like age of empire , for example .how does artificial intelligence work in games?******how does artificial intelligence work in games?******Aug 04, 2016******1******CA
-1******there be more information recently that alphazero have be train to be the best chess program after 4 hour of learn ( in chess ) . i be wonder how the ai network could have be model for this program ?how the ai network can be modeled for alphazero?******how the ai network can be modeled for alphazero?******Jan 07, 2018******1******CA
2******i read about minimax , then alpha-beta pruning and then about iterative deepening . iterative deepening couple with alpha-beta prune prof to quite efficient a compare alpha-beta alone . i have implement a game agent that use iterative deepen with alpha-beta pruning . now i want to beat myself . what can i do to go deeply ? like alpha-beta pruning cut the move , what other small change could be implement that can beat my old ai ? my aim to go deep than my current ai . if you want to know about the game , here be a brief summary : there be two player , four game piece and a 7 - by - 7 grid of square . at the beginning of the game , the first player place both the piece on any two different square . from that point on , the player alternate turn move both the piece like a queen in chess ( any number of open square vertically , horizontally , or diagonally ) . when the piece be move , the square that be previously occupy be block . that square can not be use for the remainder of the game . the piece can not move through blocked square . the first player who be unable to move any one of the queen lose . so my aim be to cut the unwanted node and search deeper .what else can boost iterative deepening with alpha beta pruning?******what else can boost iterative deepening with alpha beta pruning?******Jan 28, 2018******1******CA
8******i want to create an ai which can play five-in-a-row / gomoku . a i mention in the title i want to use reinforcement learn for this . i use policy gradient method namely reinforce with baseline . for the value and policy function aproximation i use a neural network . it have convolutional and fully connect layer . all of the layer , except for the output , be share . the policy's output layer have 8x8 = 64 ( the size of the board ) output unit and softmax on them . so it be stochastic . but what if the network produce a very high probability for an invalid move ? an invalid move be when the agent want to check a square which have one " x " or " o " in it . i think it can stick in that game state . could you recommend any solution for this problem ? my gusse : use actor-critic method . for an invalid move , give a negative reward and pass the turn to the opponent .how to handle invalid moves in reinforcement learning?******how to handle invalid moves in reinforcement learning?******Mar 14, 2017******1******CA
3******after read this paper about monte carlo method for imperfect information game with element of uncertainty , i couldn't understand the application of determinization step in author's implementation of the algorithm for knockout game . determinization be define a transformation from instance of imperfect information game to instance of perfect one . it mean that all player should see the card of each other after the determinization step . why can't the player see the card of each other in the code above ?determinization step in information set monte carlo tree search******determinization step in information set monte carlo tree search******Sep 23, 2017******1******CA
7******i invent a chess-like boardgame and i build an engine so that it can play autonomously . the engine be basically a decision tree . it's compose by : a search function that at each node find all possible legal move an evaluation function that assign a numerical value to the board position ( positive mean first player be gain the upper hand , negative mean the second player be win instead ) an alphabeta prune negamax algorithm the main problem about this engine be that the optmization of the evaluation function be really tricky . i don't know which factor to consider and which weight to put . the only way i see to improve the engine be to iterate game try each time different combination of factor and weight . however it computationally seem a very tough feat ( can i backpropagate without use deeplearning ? ) . i would like to use reinforcement learn to make the engine improve by play against itself . i have be read about the topic but i be still quite confused . what other reward be there in a game a part the win-or-lose output ( 1 or 0 ) ? if i use other reward , like the output from the evaluation function at each turn , how can i implement it ? how do i modify the evaluation function to give good reward iteration after iteration ? i be new in this field , so let me know if i'm misunderstand any part of the process . all input be appreciate !reinforcement learning without neural network******reinforcement learning without neural network******Nov 10, 2017******1******CA
2******i be try to find a good evaluation function for a game with : a 7x7 tile board 2 player , give equal number ( > = 3 currently undetermined ) of stone place randomly on the tile a turn be consist of a player move a stone own by that player , vertically or horizontally but not diagonally to a very next tile of itself a player lose when out of move : a player be out of move when every stone that player own , have it very next tile , except not for diagonal necessarily , occupy either by the board edge or other stone right now my evaluation function's return value increase : if the total move available to the player be increase and / or average distance to the middle tile of the board be decrease question : be there a good strategy ? or how can i improve my evaluation function ?evaluation function for a go like game******evaluation function for a go like game******Nov 12, 2017******1******CA
7******currently i'm do a project that's about create an ai to play the game gomoku ( it's like tic tac toe , but play on a 15 * 15 board and require 5 in a row to win ) . i have already successfully implement a perfect tic tac toe ai use q learning and have game state / action store in a table , but for a 15 * 15 board the possible game state become too large too implement this project . my question be , should i use neural network or genetic algorithm for this problem ? and more specifically , how should i implement this ?neural networks vs genetic algorithms in games like tic tac toe?******neural networks vs genetic algorithms in games like tic tac toe?******Feb 12, 2017******1******CA
12******i have hear about this concept in a reddit post about alpha go . i have try to go through the paper and the article , but could not really make sense of the algorithm . so , can someone give an easy-to-understand explanation of how the monte-carlo search algorithm work and how be it be use in build game-playing ai bot ?how does "monte-carlo search" work?******how does "monte-carlo search" work?******Aug 05, 2016******1******CA
1******for example i would like to implement transparent ai in the rts game which doesn't offer any ai api ( like old game ) , and i'd like to use image recognition algorithm for detect the object which can talk to another algorithm which be responsible for the logic . give i'd like to use two neural network , what be the approach to setup the communication between them ? be it just by export result finding of the first algorithm ( e . g . use cnn ) with list of feature which be find on the screen , then use it a input for another network ? or it's more complex than that , or i need to have more than two network ?how to separate image recognition from logic?******how to separate image recognition from logic?******Aug 09, 2016******1******CA
2******in two player game , the exact value of the evaluation function doesn't matter as long a it's big for good position . however , for learning , it's customary when it do change when the best move get make . this way , the learning can minimize the difference between the directly compute value of a position and the value obtain from step minimax . what i'm miss here be a way to direct the evaluation function to actually win . for example , a perfect evaluation function for a won position in chess would always return without any hint how to progress towards checkmate . in a chess variant without the fifty-move limit , it could play useless turn forever . i guess , this be a rather theoretical problem a we won't ever have such a good function , but i wonder if there's a way to avoid it ?game ai evaluation function and making progress towards winning******game ai evaluation function and making progress towards winning******Mar 08, 2018******1******CA
5******when google researcher create alphago , how do they simulate the game of go ? if i want to take the same approach to other game , like risk , how would i go about cod the rule of the game ? be there a programming package , book , or general technique for cod the rule of a game for deep learning ?how does one code the rules of a boardgame for deep learning?******how does one code the rules of a boardgame for deep learning?******Mar 29, 2018******1******CA
1******when train on large neural network , how to deal with the case that the gradient be too small to have any impact ? fyi , i have an rnn , which have multiple lstm cell and each cell have hundred of neuron . each training data have thousand of step , so the rnn would unroll thousand of time . when i print out all gradient , they be very small , like e - 20 of the variable value . therefore the training do not change the variable value at all . btw , i think this be not an issue of vanish gradient . note that the gradient be uniformly small from the beginning to the end . any suggestion to overcome this issue ? thank !too small gradient on large neural network******too small gradient on large neural network******Apr 06, 2018******1******CA
3******i'm a professional game developer investigate the potential for use reinforcement learn to build strategy game ai opponent that have more creative behavior compare to traditional technique like behavior tree . i have a few question i've bolded below , any thought would be helpful , and could save me from pursue dead end . i create a very boring and tiny game a a test case . two player each control a fleet of ship , each ship have health and can fire on one other ship each turn deal some damage . the player and his opponent assign order to their respective ship , tell them which target to attack , and then the turn be resolve . ship with 0 health be remove from the board . the player that lose all their ship first lose the game . assume i be use tensorflow , at a very high level i need to : a ) create a training program that output a trained graph to a file . the training program will need to map gamestates into tensor , fee the tensor through the graph to produce action , execute action on the gamestate to generate a new state , and evaluate the reward function for the new state . repeat a bunch . b ) take the graph create in # 1 , load it at the game runtime , and use the graph to generate intelligent action from real gamestates during the player v ai match . as soon a i start dig into tensorflow , question immediately come up , and now i'm not quite sure if there be a more appropriate library to do this . i ) tensorflow have a high level python api , and a low level c + + api . most game be build in c + + , and thus use a c + + or c api be preferable , it make integration with the game much simpler . in principle we could use pybind or some other scheme for send state from c + + to python and back again , but that's not ideal . question 1 : how much do i lose by use the low level api specifically for reinforcement learning , compare to the high level api ? ii ) platform . 99.9 % of the time , pc / console game be develop in window environment , and so have tensorflow work in window be critical . from my googling , tensorflow just barely support building in window use cmake , though it require some finagling . more worryingly be other platform : question 2 : what hope be there of run the tensorflow library on console like xboxone , playstation 4 , or the switch ? i imagine this would require manually port the entire source :( iii ) tensorflow be big , and it seem you need to basically link all of it to ship with the game . question 3 : be there any way to get a slimmed down " runtime tensorflow " library that be only capable of load a graph and transform state into action ? it seem like if the answer be yes , it might also be easy to port this small runtime version to more platform . question 4 : should i even be use tensorflow for this ? be there perhaps something more suitable ? thanks again if you read all that , i'm eager to start tinkering , but would like to set off in the right direction .reinforcement learning in commercial strategy games******reinforcement learning in commercial strategy games******Jun 14, 2018******1******CA
3******i'm make a connect four game use the typical minimax + alpha-beta prune algorithm . i just implement a transposition table , but my test tell me the tt only help 17 % of the time . by this i mean that 17 % of the position my engine come across in it calculation can be automatically give a value ( due to the position be calculate previously via a different move order ) . for most game , be this figure expect ? to me it seem very low , and i be optimistically hop for the tt to speed up my engine by around 50 % . it should be note though that on each turn in the game , i reset my tt ( since the evaluation previously assign to each position be inaccurate due to lower depth back then ) . i know that the effectiveness of tt's be largely dependent on the game they're be use for , but any ballpark of how much they speed up common game ( chess , go , etc ) would be helpful . edit - after run some more test and adjust my code , i find that the tt speed up my engine to about 133 % ( so it take 75 % a much time to calculate ) . this mean those 17 % node be probably fairly high up in the tree , since not have to calculate the evaluation of these 17 % speed up thing by 33 % . this be definitely well , but my question still remain on whether this be roughly expect performance of a typical tt .transposition table is only used for roughly 17% of the nodes - is this expected?******transposition table is only used for roughly 17% of the nodes - is this expected?******Oct 14, 2018******1******CA
2******a human player play limit game compare to a system that undergoes million of iteration . be it really fair to compare alphago with the world # 1 player when we know experience increase with the increase in number of game play ?is it fair to compare alphago with a human player?******is it fair to compare alphago with a human player?******Jan 28, 2018******1******CA
2******be it fair to compare alphago with a human player ? depend on the purpose of the comparison . if we be compare ability to win a game of go , then yes . if we be compare learn ability , then maybe . it depend on the task . alphago and system like it be capable of learn only in well-described limited domain . there may be an analogy with sensory learning ( it might even be possible in theory to take a small piece of brain tissue and run an algorithm similar to alphago's learn process on it ) . in general , the approach use by alphago and other reinforcement learning success be " trial-and-error plus function approximation " . it seem analogous to perception and motor skill , such a object recognition or rid a bike , a oppose to reason skill and game a human play them , which go through many more cognitive and conscious layer that have no real analog in a rl system like alphago . a human player play limit game compare to a system that undergoes million of iteration this be an advantage of a machine to learn this kind of task . it would equally apply in other simulated environment with simple rule . if your goal be to have the most skilled and optimal navigation of such a domain , the implication now be that you would not train a human expert through year of study , but to write the simulator and train an alphago-like machine . this be no different a comparison than decide car and road be good solution to long distance travel for the general population than walk or horse and cart . it doesn't matter what underlie the advantage of one over the other , the assessment be cost / benefit , which resolve to a single comparable number . it would , however , be wrong to assess alphago a a good general-purpose learning engine than a human . the fact that human do not have to work fully through million of simulation in full detail be important . it mean that something about how human learn be still not cover by learn machine . some of these thing be understood and be discuss - such a the ability to focus intuitively on important aspect of what to learn , the ability to reason about the environment , learn analogously or transfer learning from other domain .******none******Jan 28, 2018******1******CA
0******if you read through the abstract of chess ai paper , it be often point out that human " search " the chess game tree much more efficiently than computer , which be why it be so hard to beat the top human in chess for so many year . ( the human efficiency may have to do with intuition and judgement , which be difficult to replicate . " confidence level " for ai evaluation be one method of address these issue , a be " monte carlo " . but it's also important to note that human be far more limited in the depth and breadth of their " search " , which be why , now that we have the right algorithm , human can no longer win . ) be it fair ? perhaps the more salient question be : be it useful to compare alphago to a human player ? it most certainly be , because it tell u that we have be sometimes term a " strong-narrow ai " that can outperform a human in a single task . why alphago beating lee sedol be a big deal be the complexity of go , the intractability of the go game tree , and the fact that computer be previously ineffective against high-level human go player . this human v . ai evaluation doesn't strictly fall under the " turing test " ( imitation game ) , it do fall squarely under the maxim of protagoras that " man be the measure of all thing . " this be critical because intelligence be a spectrum , and gauge strength of intelligence , in the context of intractable problem ( problem that cannot be fully solve due to their size ) be a function of relative strength of two agent , whether human or ai . this relative assessment be all we have , and all we may ever have for certain set of problem . the problem with human be not that we're not clever , but that our mind have cognitive limitation . so to tackle certain problem , intelligent machine be useful .******none******Jan 31, 2018******1******CA
0******there be no such thing a fairness when comparing . you define a measure for performance and then compare the value of the measure . one sensible measure for play the game of go be the ' number of game win ' , regardless of any investment in the development of the system , computational or sample efficiency . alphago be currently at the top by this measure . another sensible measure could be ' number of game win under a restriction on sample efficiency during train ' . a others point out , such a measure could be much more favorable for human .******none******Feb 01, 2018******1******CA
2******a human player play limit game compare to a system that undergoes million of iteration . be it really fair to compare alphago with the world # 1 player when we know experience increase with the increase in number of game play ?is it fair to compare alphago with a human player?******is it fair to compare alphago with a human player?******Jan 28, 2018******2******CA
4******i read about minimax , then alpha-beta pruning and then about iterative deepening . iterative deepening couple with alpha-beta prune prof to quite efficient a compare alpha-beta alone . i have implement a game agent that use iterative deepen with alpha-beta pruning . now i want to beat myself . what can i do to go deeply ? like alpha-beta pruning cut the move , what other small change could be implement that can beat my old ai ? my aim to go deep than my current ai . if you want to know about the game , here be a brief summary : there be two player , four game piece and a 7 - by - 7 grid of square . at the beginning of the game , the first player place both the piece on any two different square . from that point on , the player alternate turn move both the piece like a queen in chess ( any number of open square vertically , horizontally , or diagonally ) . when the piece be move , the square that be previously occupy be block . that square can not be use for the remainder of the game . the piece can not move through blocked square . the first player who be unable to move any one of the queen lose . so my aim be to cut the unwanted node and search deeper .what else can boost iterative deepening with alpha beta pruning?******what else can boost iterative deepening with alpha beta pruning?******Jan 28, 2018******2******CA
1******to make boost iterative deepen with alpha-beta prune you can use the ss * search algorithm , it a best first strategy algorithm . the ss * algorithm can improve the time efficiency of the overall algorithm but it increase the space complexity . i be link the wiki to it * i will update the answer as soon a i get a good solution .******none******Feb 03, 2018******2******CA
1******first thing you're go to want to add be probably a transposition table , a also suggest by smallchess . afterwards , i'd look into aspiration search and / or principal variation search ( also see this page ) . then i'd look into thing like the killer move heuristic , and maybe also see if you can simply implement exist part of your engine more efficiently ( e . g . use bitboards for your state representation ) . other than all of that , the chess program wiki probably have lot of other interesting page as well .******none******Mar 08, 2018******2******CA
1******the match get a lot of press , and i doubt anyone be surprise that alpha zero crush stockfish . see : alphazero destroy stockfish in 100 game match to me , what's really salient be that " much like human , alphazero search few position that it predecessor . the paper claim that it look at " only " 80,000 position per second , compare to stockfish's 70 million per second . " for those who remember matthew lai's giraffechess : however , it be interest to note that the way computer play chess be very different from how human play . while both human and computer search ahead to predict how the game will go on , human be much more selective in which branch of the game tree to explore . computer , on the other hand , rely on brute force to explore a many continuation a possible , even one that will be immediately throw out by any skilled human . in a sense , the way human play chess be much more computationally efficient - use garry kasparov v deep blue a an example , kasparov could not have be search more than 3-5 position per second , while deep blue , a supercomputer with 480 custom ” chess processor ” , search about 200 million position per second 1 to play at approximately equal strength ( deep blue win the 6 - game match with 2 win , 3 draw , and 1 loss ) . how can a human search 3-5 position per second be as strong a a computer search 200 million position per second ? and be it possible to build even strong chess computer than what we have today , by make them more computationally efficient ? those be the question this project investigate . [ lai be tap by deepmind a a researcher last year ] but what i'm interested in at the moment be the decision speed in these match : - what be the average time to make a move in the alphazero v . stockfish match ?what was the average decision speed pf alpha zero in the recent stockfish match?******what was the average decision speed pf alpha zero in the recent stockfish match?******Feb 02, 2018******2******CA
1******no , all computer chess expert be surprise about the outcome of the match . if you require reference , please start a new question . your question be simple ... ... we evaluate the fully trained instance of alphazero against stockfish , elmo and the previous version of alphago zero ( train for 3 day ) in chess , shogi and go respectively , play 100 game match at tournament time control of one minute per move ... one minute per move . stockfish would use the one minute if there be more than a single legal move , otherwise it'd move immediately . so the average time for a move for stockfish be about 57s to 60 . there be no source code for alphazero . however , it's hard to believe the system wouldn't take advantage of the minute it be give . the expected time for alphazero should be also 57s to 60 .******none******Feb 03, 2018******2******CA
3******so , i be try to create an ai to handle the construction layout of a real time strategy game like age of empire ii . the process have too many step to be handle effectively by brute force , but also have enough structural requirement that it also cannot just be do randomly . assume a limited area to work with , which can be represent by tile , the ai must be able to place several structure within the area . a layout once fully create can be give a score base on the pathable distance between certain structure as well a a few other factor . if path between certain structure become completely block , the ai have fail . the start area that be define by tile be also random in nature , contain a few predefined element that the ai cannot control , which include randomly place terrain and resource node . i know this problem case have be quite vague , but the actual question relate to the type of ai that would best fit solve this issue . i currently have an algorithm that run through what it believe be the best few result in a series of step try to create the most optimal layout , but it fail with many start layout , which require manual adjustment to the ai before it can process them properly . even then , it be just an approximation at best , since it start out assume that the step i give it to check contain the most optimal layout . here be an example of what a finish layout might look like . it doesn't state which color be which object , but it might help in determine what type of ai i should be look at use .rts construction layout ai******rts construction layout ai******Feb 08, 2018******2******CA
1******because the op be a bit longer , i make a small mindmap to illustrate the topic and a possible answer . at first , the problem be call “ walling ” and be describe in the literature in the context of the “ starcraft ai ” challenge . the question be , where to place building to win the game . a possible answer to the problem have to do with formalization of knowledge . usually , the human player be aware what a good layout be , and he also know where to place his unit . the question be only how to express this knowledge in sourcecode . in my opinion the answer be call “ computer base training ” . cbt be a technology , not with the aim to program an ai , but to formalize knowledge in a game for train human player . the idea be , that a human player play the walling game , and while he be do so he learn to take the right decision . from the standpoint of ai it be important , that every cbt game have an evaluation algorithm which be often call a tutorial mode . this be do in case . for example , in case 1 the player learn how to use a give terrain , in case 2 how to protect the structure and so forth . so my recommendation be , at first create a computer-based training game a a tutorial for human-players , and use the formalized knowledge in step 2 for build the ai for “ starcraft ai wall ” .******none******Feb 08, 2018******2******CA
2******any small application base on real world application of ai which can be do easily at home for a beginner who be try to make use of his basic programming skill into ai at the begin level .can anyone suggest a small application based on an artificial intelligence which can be done by a beginner in ai?******can anyone suggest a small application based on an artificial intelligence which can be done by a beginner in ai?******Feb 16, 2018******2******CA
5******this be fairly boilerplate advice , but , since you're brand new to ai , i'd personally suggest write a classical tic-tac-toe ai , ideally use minimax . i suggest this because minimax be fundamental to ai , and there be many webpage devote to this subject , such a how to make your tic tac toe game unbeatable by use the minimax algorithm and tic tac toe : understand the minimax algorithm . ( google search for " tic-tac-toe " and " minimax " will yield a plethora of other site . i'd also recommend look at this minimax page from stanford : " strategy and tactic for intelligent search " . ) i recommend this approach a a good basic primer . the real cutting-edge work be be do in machine learning and neural network , and for that reason , it's probably more important than ever to have some basic grounding in classical ai before you start dip your toe in that pond .******none******Feb 16, 2018******2******CA
1******i will assume you talk about apply ai ( in generalize / strong ai we have nothing yet to program :-) . you can look at any university course of introduction to ai and see it chapter and the program examples they use ( start by program without any theory be not a way ) . by example , one common issue on this kind of course be path finding , use for it algorithms a a * algorithm and apply them to game a hanoi tower . this kind of knowledge be a must for any activity in ai . standford link provide by @dukezhou be a good example of one of thesis course , just i suggest start it from first chapter instead of go directly to minmax . later on , you can jump to more advanced concept , a recognition / classification and it common approach : k-nearest / k-means , decision network , neural net , ... .******none******Feb 16, 2018******2******CA
1******i'm develop a millitary game and i want soldier to place themselves in specific order , when commander order . how can i do this ? should agent learn somehow how to achieve give order or there exist other way ? i'm new in ai , so i do not really know how can i accomplish my goal . thanks for every advice .placing agents in a specific order on demand******placing agents in a specific order on demand******Mar 10, 2018******2******CA
1******i agree with the commenters . i think the easy way to do this in some programming language be to say : unless i misunderstood , this should be a pretty easy problem . if you have to worry about collision with object , you might tell them to follow the commander's path if he's moving or if he's not , find the position closest to the one they want that doesn't leave them in a wall . pathfinding can be a complex problem to get right , but even that doesn't necessarily depend on ai .******none******Mar 10, 2018******2******CA
0******the assumption that the problem be a difficult ai problem be right . solve the problem be only possible with different topic in ai . the first task be the natural language parser , which convert a text-message into an action . problem # 2 be a high-level symbolic planning problem , which can be describe with the pddl language . and the third problem be to transform the output of the pddl solver into lowlevel action which be execute by the agent . realize such a pipeline be not a trivial task and can be do with a cognitive architecture . some addons for unity 3d bring a ready-to-run software within , but it be also possible to program it from scratch with object-oriented programming . a first step would be to describe the choreography problem with pddl and set constraint . a pddl representation for contradance composition******none******Mar 11, 2018******2******CA
1******i have implement multiple mcts base ai player for the love letter game ( rule ) . it be a 2-4 player zero sum card game where player make alternate move . i be struggle with how to properly conduct experiment for estimate ai player strength against human player : in 2 player game where one of the player be ai bot in 4 player game where one ( or multiple ) of player be ai bothow to estimate the ai player's strength in multiplayer game?******how to estimate the ai player's strength in multiplayer game?******Mar 24, 2018******2******CA
2******the following be extremely simple way of tackle this problem . a very simple way it can simply be =/ . in case data for each move be available something like =/ . then =/ . if each move / decision have a score associate with it then you do= / . then =/ and finally , =/ . how to choose optimal number of game to play ? it depend on your requirement . if you want to report your ai's strength in percentage of the game it play correct to 1 decimal place ( for example , this ai win 95.1 % ) then 10000 be an optimal number of game your ai need to play . suppose your ai win 9508 game out of 10000 then you will have 95.08 % strength of ai . to be able to correctly round it to 1 decimal place you need to have an additional decimal place so that you can quote the strength of you ai with reasonable confidence , in this case 95.1 % .******none******Mar 25, 2018******2******CA
2******i'm currently have trouble to win against a random bot play the schieber jass game . it be a imperfect card information game . ( famous in switzerland ) the environement i'm use be on github to get a brief overview of the schieber jass i will describe the main characteristic of the game . the schieber jass consist of four player build two team . at the beginning every player get randomly nine card ( there be 36 card ) . now there be nine round and every player have to choose one card every round . relate to the rule of the game the " high card " win and the team get the point . hence the goal be to get more point then your opponent team . there be several more rule but i think you can image how the game should roughly work . now i'm try to apply a dqn approach at the game . to my attempt : i let two independent reinforcement player play against two random player i design the input state a a vector ( one hot encode ) with 36 " bit " for every player and repeat this nine time for every card you can play during a game . the output be a vector of 36 " bit " for every possible card . if the greedy output of the network suggest an invalid action i take the action with the high probability of the allowed action the reward be + 1 for win , - 1 for losing , -0.1 for a invalid action and 0 for an action which doesn't lead to a terminal state my question : would it be helpful to use a lstm and reduce the input state ? how to handle invalid move ? do you have some good idea for improvement ? ( like neural-fictitious self-play or something similar ) or be this the whole approach absolute nonsense ?how to use dqn to handle an imperfect but complete information game?******how to use dqn to handle an imperfect but complete information game?******Mar 27, 2018******2******CA
3******would it be helpful to use a lstm and reduce the input state ? i'd bet , no . lstm be more complicated and harder to learn , while the input be 4 * 9 * 36 bit be still rather limited . however , you may want to aggregate the information somehow , e . g . , add additional bit inform about what card be already play ( no matter when ) . this information be redundant , but by provide it , you may save the network quite some learning . at the same time , you may want to use symmetry ( all color but trump be equivalent and the therefore the weight should be the same ) . how to handle invalid move ? that's simple : there be no invalid move . the network provide 36 output of how much it want to play a give card . you simply take the one valid card have the great output value . you don't try to make the network learn what move be valid a this be neither need nor helpful . do you have some good idea for improvement ? ( like neural-fictitious self-play or something similar ) i can't tell . but it should matter at the moment . first make you network clearly beat the random player , then you can look for more . or start with self-play , a you want probably have both for comparison . or be this the whole approach absolute nonsense ? i don't think so , but ... ( see below ) i design the input state a a vector ( one hot encode ) with 36 " bit " for every player this doesn't sound good . every player have 9 of 36 card and so should be the encoding . a player doesn't know the card of other player . the reward be + 1 for win , - 1 for losing , in most card game i know , it matter by how much you win ( unlike e . g . , in go ) . even when it doesn't matter , use this information at the early learning stage be imho useful . -0.1 for a invalid action and drop the invalid action . just transform anything the network produce to a valid action , add no penalty ( a write above ) . ... 0 for an action which doesn't lead to a terminal state all action but the last one lead to a non-terminal state . you can use some temporal difference learning or use the fact that the game have a small fixed number of move and reward / punish all action take in a the whole game .******none******Apr 02, 2018******2******CA
2******it be possible to use case-based reasoning for forward simulation in mario ai , this be explain by game engine learn from video they be use feature : distance , velocity and position to predict follow game-frames like in a physic engine . what my problem with the paper be , that the “ learn game engine ” seem to be work autonomously . that mean , the human operator be out of the loop , he be not change the case manually and he be not involve in predict the future . be it possible to make an interactive forward simulation ? for example , the game-engine ask the operator what will happen if mario jump over the wall . what i do not understand be how to design the gui-interface in such a situation , because the number of possible reaction of the game-engine to a situation be endless , and to make the simulation interactive the user would click very fast on some button . for example , if the desired framerate be 30fps , should the user define all the parameter in a timestep of 1/30 second ?interactive forward simulation******interactive forward simulation******Apr 04, 2018******2******CA
3******i be try to find out what be some good learning strategy for deep q-network with opponent . let's consider the well know game tic-tac-toe a an example : how should an opponent be implement to get good and fast improvement ? be it good to play against a random player or a perfect player or should the opponent be a dqn player a well ?what are good learning strategies for deep q-network with opponents?******what are good learning strategies for deep q-network with opponents?******Apr 04, 2018******2******CA
2******in a two player zero-sum game ( if i win , you lose and vice-versa ) , then you can have a simple and efficient solution learn from self-play . how should an opponent be implement to get good and fast improvement ? you don't need to think in term of agent v opponent , instead think in term of cod both the player ' goal into a single q function . score + 1 if player a win , - 1 if player b win , and zero for a draw . it be then player a's goal to maximise the score and player b's goal to minimise the score . you can then implement and learn both player strategy in the same self-play learning session and same q function , use minimax . in practice that mean where in q learning you generally pick the maximise action on next state to bootstrap q value , in a minimax variant , you pick maximise or minimise action depend on whose turn it be . otherwise the q learn algorithm be the same a normal . i have implement this , but not for dqn , just for tabular q-learning - feel free to learn from , copy and / or re-use any part of that code . be it reasonable to play against a random player , a perfect player or should the opponent be a dqn player a well ? the q learner will learn to optimise against whichever player you make it play against . against a random player , it will not necessarily learn to play well , just well enough to defeat the randomness . it may even make deliberate mistake - such a not block a win line - know it have a good chance to win due to random opponent . against a perfect player be possible with tic tac toe ( because you can construct such a player ) , although there might be gap in the trained q value - game state never see - which mean that an imperfect opponent could actually defeat the trained agent ! in practice this do not scale to more complex unsolved game , because no perfect player exist . another dqn player should work fine . you would end up with two agent , each specialising in play one player's turn . this be less efficient than a single minimax-based player , but no expected problem . it may be a preferred choice for some game , especially if they be not zero-sum .******none******Apr 04, 2018******2******CA
4******to provide a bit of context , i'm a software engineer & game enthusiast ( card game specially ) . the thing be i've always be interested in ai orient to game . in college , i program my own gomoku ai so i'm a bit familiar with the basic concept of ai game orient and have read book & article about game theory as well . my issue come when i try to analyze ai's for imperfect information game like ( poker , magic the gathering , hearthstone , etc ) . in most case when i find an ai for hearthstone , it be either some sort of monte carlo or minmax strategy . i honestly think although it might even provide some decent result it will still be always quite flat and linear since it doesn't take into account what deck the opponent be play and almost always try to follow the same game-plan , since it will not change base on tell your opponent might give away via card play ( hint that a human would catch ) . i would like to know if use neural network would be more good than just use a raw evaluation of board state + hand + hp each turn without take into account learn about possible thread the opponent might have , how to deny the opponent the best play he could make , etc . my intuition tell me that this be way harder and far more complex . be that the only reason the nn method be not use ? have there be any research to prove how much efficiency edge would be between those 2 approach ?why most imperfect information games usually use non machine learning ai?******why most imperfect information games usually use non machine learning ai?******Apr 04, 2018******2******CA
3******a heuristic search use mcts + minimax + alphabeta pruning be a highly efficient ai planning process . what the ai technique of reinforcement learning ( rl ) plus neural network ( nns ) typically add to this be a way to establish good heuristic . my intuition tell me that this be way harder and far more complex . it's not actually that much more complex in concept . replace the hand-coded heuristic with a learning engine , e . g . dqn or ac3 . train the learn engine from human expert play example and / or from self play . it be hard though , because there be many thing that can go wrong with an nn-based estimator in a rl context . you will need to make many experiment with different hyper-parameters of the learning engine . for complex game , you may have to invest many 100 of hour of training , which you might want to compare against the end result of a similar amount of time spend refine expert heuristic system . for imperfect information game , you may also want to use something that can learn an internal state representation . that could be some kind of explicit belief state that you maintain like an expert system , or something that attempt to learn a good representation , such a an rnn ( e . g . lstm ) . this may not be necessary for a first try at an agent though , since the mcts search will make up for some inadequacy of low accuracy heuristic . be that the only reason the nn method be not use ? up until quite recently , approach use rl and nn be far hard to find example of outside of academic machine learn research , and there be not any pre-written framework for lstm or e . g . ac3 . in the last few year , rl and nn framework have start to appear make an ai self-learning approach far more approachable . i would expect that many hobby-level coder consider game-playing ai nowadays would seriously take a look at rl and nns in order to learn robust heuristic for their game project . however , the " traditional " search-based method still work in conjunction with these for a complete agent . have there be any research to prove how much efficiency edge would be between those 2 approach ? for card game , i be not aware of any specific research , although i be just a hobbyist , yet to write any specific game engine more complex than tic-tac-toe . for perfect information board game , the chess play variant of alphazero demonstrate applicability of rl + nn self-play approach versus " traditional " heuristic plus search ( represent by stockfish ) . however , the framing of the tournament have be criticise a unfair to stockfish , so it be not necessarily an open-and-shut case that rl be strictly well .******none******Apr 04, 2018******2******CA
10******imagine a game where it be a black screen apart from a red pixel and a blue pixel . give this game to a human , they will first see that press the arrow key will move the red pixel . the next thing they will try be to move the red pixel onto the blue pixel . give this game to an ai and it will randomly move the red pixel until a million try later it accidentally move onto the blue pixel to get a reward . if the ai have some concept of distance between the red and blue pixel it might try to minimise this distance . without actually program in the concept of distance , if we take the pixel of the game can we calculate a number ( s ) such a " entropy " or suchlike that would be low when pixel be far apart than when close together ? it should work with other configuration of pixel . such a a game with three pixel where one be good and one be bad . just to give the neural network more of a sense of how the screen look ? then give the nn a goal such a try and minimise the entropy of the board as well a try to get reward . be there anything akin to this in current research ?can a neural network work out the concept of distance?******can a neural network work out the concept of distance?******Apr 18, 2018******2******CA
1******answer i'm go to take your question at face value , and go really deep into this topic . yes , they can . the typical human mind can . but consider the human mind . million , if not billion , of neuron . in fact , one can consider distance a a human concept , simply a theory develop from interaction with the world . therefore , give a year or two , with a ton of neuron on your hand , you could replicate this scenario . that be if your computer be as parallel a the human mind . the short explanation be that the human mind be very parallel . however , it would be simpler to calculate the distance with a program , not an ai , and simply fee the result to the ai that would make the decision . consider the amount of time you have spend look at a screen . if you can tell the ( approximate ) distance between two pixel , so can a neural network , a you be one . however , add the amount of time you have spend alive and learn into the equation , and it become a disaster . far read the human brain be parallel this be a result of the fact that all of the neuron in the human brain be independent of each other . they can run true simultaneous action , thus make the action of interpreting image and such much easy , a block of neuron can " think " independent of the operation of the others , limit what would be " lag " to a minuscule amount .******none******Apr 18, 2018******2******CA
1******you can create ai to " see " a a human . a you say , give the human the key , he will click randomly . he just need to know which key he press that bring him close to other object on the screen . i think the basic of an ai be object recognition . i would try to create a script to map the screen object of the game . there be legal example in python . i would try to follow a path like this : make the ai ​ ​ understand that by click the arrow or the wasd and it be in the context game , the object that move pixel accord to the direction , represent the main author ( the player ) . in parallel : map all boundary of the region and index different object within that region to automatically have the coordinate domain and object distance . ai need to see ( stream ) the game and through image to categorize object . do you understand what i mean ? in parallel : the ai ​ ​ need to be aware of all text and information that be on the screen ( all map , remember ? ) . you need to understand when a text change or something different happens . for example : whenever he return to the initial position of each phase , whenever he have a count , what happen when the cout reach zero or a common number that generate another type of change . he need to understand what be repeat at every " respawn " . you also need to understand what " respawn " be . maybe a certain map position on every map it return whenever a count on the screen end . or when it come up against a certain type of object ( mapped object ) to be honest , if you want to create a super intelligent robot , you can go follow all the step that go through the head of different human , or the best human , or the rule of each game . but sometimes it's easy to build specific bot to perform specific task . it depend on what you want to do******none******Apr 18, 2018******2******CA
1******we can break down the problem a follow : first , if you have two point on a plane and fee the coordinate of those point to a neural network ( e . g . , a vector < span class = " math-container " > $ < x_0 , y_0 , x_1 , y_1 > $ </span> ) and and train it on a label thats the actual distance ( e . g . , < span class = " math-container " > $ \ sqrt { ( x_0 - y_0 ) ^ 2 + ( x_1 - y_1 ) ^ 2 } $ </span> ) , it should be able to learn this relationship with arbitrarily close accuracy . next , if you have an image similar to what you describe , and feed that through a different neural network ( e . g . , a cnn ) , and a label you use the the point of the two dot ( once again < span class = " math-container " > $ < x_0 , y_0 , x_1 , y_1 > $ </span> ) , then it should be able to learn that relationship with arbitrarily close accuracy once again . of course , there's no reason to do this in two separate neural network , so we can just combine the two end-to-end have a model that take the image a input and the distance a output . this model would need to be train on label data , however , so you'd either need to generate the data yourself or label image . but if you want it to learn the notion of close a distance in a less supervised way , you'd need to use reinforcement learning . in this case , you'd have to setup an environment that incentivises the agent to reduce the distance . this could be as simple a gain reward if an action reduce the distance . another approach would be to incentivise the agent use future reward . that be , it's reward doesn't just come from the result of the next immediet state , but there's also contribution from the next possible state , and the one after that , and so on . this be the idea behind deep q-learning , and i implement a simple example ( very similar to what you're describe ) in this notebook . so , now the question be : have this implementation do something other than randomly move around until it follow a path to success ? in your example , you talk about reward the agent when it land on the goal . but in what i describe , it gain reward by move close to the goal ( either through the q-function or directly from the environment ) . it be able to do so by learn some abstract idea of distance ( which can be illustrate in the supervised version ) . when a human learn this , it's for the same exact reason : the human be gain a reward for move in that direction through a sense of future reward . i'd say that , give enough training and data , reinforcement learning could learn this concept with ease . as far a other reward be present on the board ( e . g . , " minimise the entropy of the board as well a try to get reward " ) , you need to think about what it be you're ask . would you rather the agent minimize distance or maximize reward ? cause , in general , it can't do both . if you're look for some balance between the two , then really you're just redefine the reward to also consider the distance .******none******Oct 17, 2018******2******CA
1******so i know that ' h ' and ' f ' will be prune , but i'm not sure about ' k ' and ' l ' . when we visit ' j ' , technically there be no need for u to visit ' k ' and ' l ' because there be 2 option : one or two of them might be high than 8 ( ' j ' ) both of them less than 8 but no matter what , the decision of the max ( root ) will not change , the max will choose the right side no matter what ' k ' and ' l ' be , because the right side will either be 8 or 9 , which be still high than 4 ( return value from left side ) so will alpha beta prune ' k ' and ' l ' or not ? if not , then it mean alpha beta be not " optimal " overall right ? consider it will not prune all the unnecessary path .which edges of this tree will be pruned by alpha-beta pruning?******which edges of this tree will be pruned by alpha-beta pruning?******Apr 20, 2018******2******CA
1******if you prune k and l then you could miss the optimal solution . assume l = 9 , if you prune l then the value of the tree be 8 . if you don't prune l then the value of the tree be 9 . now i will try and address what i think your actual question be but no matter what , the decision of the max ( root ) will not change , the max will choose the right side no matter what ' k ' and ' l ' be , because the right side will either be 8 or 9 , which be still high than 4 ( return value from left side ) . from this sentence it seem like you don't care about the value of the tree , you only want to find the optimal first move base on alpha beta . you be correct in say that the correct first move will always contain the right most child of the root , but oftentimes that be not the only information we want . sometimes we want to know the value of the tree as well or what the complete correct path be , but if we have prune k and l we would not know these . edit : i have change all ' l's to uppercase , because low case ' l ' look to much like uppercase ' i '******none******Apr 20, 2018******2******CA
3******i be currently get into deep learning and would like to set up an environment for train an artificial neural network or neat to play simple video game on ne ( mario etc . ) and snes ( donkey kong country etc . ) , use tensorflow / tflearn in python . i start off with openai gym environment and there be actually a super-mario environment for gym on github , which i fail to install a gym-pull be not available anymore and late gym package doesn't even have scoreboard folder ( i be on window 10 , conda environment ) . now , what would be the best way to set up a solid training environment that will be similar to openai gym in term of simplicity ? unfortunately openai universe isn't compatible with window 10 atm , and i really don't want to get a different setting like ubuntu environment to make it work . i would like to stay in win 10 . if someone could guide me for suggest setup or refer me to article / documentation where similar thing have be do in win 10 python env . for ne / snes , i would be extremely grateful ! i assume an emulator with python api ( perhaps nintaco ? ) be a way to go ? how would i then get the ' observation output ' , i would need to scan the live pixel output of the game , which i be not sure how to do . regard , marktraining ai to play nes/snes games on nn python******training ai to play nes/snes games on nn python******Apr 29, 2018******2******CA
0******let's assume a common game scenario of several character in a combat arena . each character have different strength and weakness . the arena have trap and tool . suppose the character have only very basic move such a step in a direction , shoot , climb , duck , pick up item , use item , drag heavy object . each move have a chance of success base on the context ( e . g . range to target ) . what ai , machine learning , or evolutionary approach could be use to generate personalized tactic for each character base on repeated run of the scenario ?developing character tactics via repeated trials******developing character tactics via repeated trials******Apr 30, 2018******2******CA
0******there be a few way to tackle this . you could make an ai that be simply a series of if statement , or you could actually make an ai that would actually take in the situation and come up with a sensible solution . if approach - you make a series of if statement that come up with a sensible action to execute . this be the method that minecraft use . the result action be record from some of the best player . true ai - have your character execute random action and learn the consequence of them . the , train it to execute various action for certain scenario . the main difference between these two approach be that if statement have a constant and predictable behavior , while the ai approach have a very bad startup value but end up improve over time . there be no " best " method , it be up to you to choose one or the other or a mix of both .******none******May 01, 2018******2******CA
1******the first step be to increase the abstraction level of the game . instead of store the game character with absolute position on a pixel level , a text-adventure-like layer above the game have to be establish . in the literature this concept be call “ knowledge container ” and be describe under the topic of case-based reasoning . now , it be possible to record the repeated trial with a rdf-based vocabulary , and it be also possible to run machine learn algorithm for feature detection against the game-logs . unfortunately , the high-level textadventure like game-description have to be ground to the original game . that mean , if one of the player be do a low level move , this have to be convert into the vocabulary of the knowledge-container . for the game wargus some literature be available , the darmok 2 ai-engine can play other real time strategy game with this approach . the darmok 2 ai engine be write in java and be not available a sourcecode . the system be document in learn from human demonstration for real-time case-based planning " textual case-based reason " can be see in action at artificial intelligence play puzzle game ( solomon's key ) which algorithm be use in the example be unknown . from the screenshot i would guess it be a cognitive architecture , perhaps soar or act-r .******none******May 01, 2018******2******CA
1******i be wonder if it be possible to train an ai that can play outdoor game like cricket , badminton etc . i be new to ai , so if this question be dumb please bear it .developing an ai to play outdoor games******developing an ai to play outdoor games******May 05, 2018******2******CA
1******yes it be possible . a group of chinese college student and teacher make a robot that play badminton . i be sure someone will make a robot that can play cricket and other outside game . although not an outdoor game , omron make a robot name forpheus that play ping pong . there be also a robot that play the sport of curl . there be an annual event call the robocup where robot team compete in indoor soccer on a scale down level . they don't look like they will be beat human in the next couple of year but it be interest to watch . their web site be : there be a few challenge that remain to be resolve for robot to play human in sport . the big one be self-contained power that will last long enough to play a game . it take a lot of power to move a human scale robot and run it electronics , sensor , and computer . other challenge be dexterity and agility . there have be some advance in these area a this video show .******none******May 06, 2018******2******CA
0******ai be best express a an autonomous agent , it could be a robot or a piece of software , an agent be anything that perceive thing ( perhaps imperfectly ) about it environment and can then make a decision to execute some action which will have some ( perhaps unpredictable ) effect on the environment . agent will maintain some internal representation of what they believe the world look like . a new information arrives , they can update those belief and select the best action in response to their belief about the state of the world . the agent model of intelligence to change your perspective on ai , check " openai gym " , it a platform for reinforcement learn research release by openai on april 27 , 2016 .******none******May 06, 2018******2******CA
-1******for speedrunning purpose , i be try to train a neural network to identify human-executable way to manipulate pseudo-rng ( in pokemon red , for the interested ) . the game run at sixty frame per second , and the linear-congruential prng update every frame , while many frame be unlikely to be relevant to the manipulation ( and so should contain no action from the neural net ) . any give manipulation be likely to last 30sec - 2min , and the advancement rate of the prng can change depend on location in the game-world . i have some experience with cod ai / deep-learning . i've make some program use multilayer perceptron and indrnn approach . from what i can tell , indrnn or a3c would be my best bet . i'm not expert enough to know the correct approach , though , or to know if the dimensionality of the problem make it outright unfeasible . 1 ) be this problem reasonably solvable with nn / deep learning ? 2 ) what approach would you recommend to tackle it ?teaching a nn to manipulate pseudorng over a long time scale?******teaching a nn to manipulate pseudorng over a long time scale?******May 18, 2018******2******CA
0******the point of pseudorng be to be unmodable and unpredictable , make it hard to train an ai to learn . it would more likely be useful and more efficient to have the equation that the game use for generation available , so that you can manually make the check , or to just have a list of the loop if the pseudorng be base on the time elapse .******none******May 18, 2018******2******CA
5******a few month ago i make a simple game that be similar to the dinosaur game in google chrome - you jump over obstacle , or don't jump over levitating obstacle , and jump to collect bitcoins , which can be place at 5 different height . i use a very lightweight nn write by nyu professor dan shiffman , and within a few day the game and ai be do , start off with a population of 200 jumper , and a genetic algorithm ( fitness function ( point be give for avoid obstacle and gather bitcoins ) and mutation ) , and it work a it should . however , this be only when the bitcoins and obstacle be not near each other , which i've be struggle with ever since . so , i make a " training ground " where i put first a levitating obstacle , then a grounded one , and then a bitcoin after it , and then a bitcoin above a fourth grounded obstacle , and no matter how many time and how long i'd leave it to train , i'd always end up with identical behavior : the first 3 obstacle be properly avoid , the first bitcoin be collect , and then jumper would jump too early , land before the fourth " bitcoin " obstacle , and jump again , always crash at almost the same place ( across all generation , so even if i'd restart the training , they crash at the same place in the obstacle , with a deviation of a few pixel up or down ) . i add multilayer support to the nn , no improvement . today i replace the nn with tensorflow.js , and i be get identical behaviour . my input be : distance to next obstacle altitude of next obstacle distance to next star ( for simplicity i remove the altitude of star from the input , and keep them at a constant altitude ) i have 2 hidden layer ( 5 and 6 neuron ) , and 1 neuron in the output , which determine if the jumper should jump . my only idea be that a neuron that decide when to jump because of the obstacle activate alongside the neuron that decide when to jump because of the bitcoin , their weight be sum up and a decision to jump too early be make . i'll give somewhat of a ( maybe bad ) analogy : if it take you 1 month to prepare an exam , then , if you have 2 exam on the same day , you will start prepare them 2 month earlier . that logic work in this case , but not in my ai . in the initial " toy neural network " i even add 8 layer of 12 neuron each , which i think be overkill for this case . in tf.js i use both sigmoid and relu activation function . no matter what i do , no improvement . hope someone have an idea where i'm go wrong .issue with simple game ai******issue with simple game ai******Jun 11, 2018******2******CA
0******the issue be likely in how you estimate wellness , how the error function be construct and from what data , since you have use two known good piece of software and probably know good derivative for your activation function . the second most likely be in now the component of wellness be aggregate . sum square be sometimes not representative of a solid aggregation strategy . i'm a bit confused about the game for three reason . star enter the description without tell u whether they be not obstacle , be obsticles , or the only obstacle at one point bitcoins collection be the objective and obstacle be the challenge and at another point bitcoins be obstacles themselves your input have distance but not direction ( be this 2 - d game ? ) base on textual hint , i'm go to assume five simple thing , and you can correct any misconception i list . collect all bitcoins be part of the objective running into bitcoins mid-jump be consider a crash there be some radial tolerance to landing in at a bitcoin location with some imprecision there be other thing to crash into your output be jump magnitude and direction i see that when the bitcoins be not in the vicinity of other thing , the net can be train effectively to jump to them , but when in the vicinity of other thing , the training converges on a behavior that repeatedly fail prior to completion . i'm assume that the failure location be not 100 % repeatable because the genetic algorithm have a pseudo-random seed that change . again , correct me if i misunderstand in my piecing together the scenario . one should consider the possibility that the distance to non-bitcoin obstacle be part of the error function and the difference between the jump destination and the bitcoin be also part of the error function . ( this second one be why i prefer to call the error contour a wellness measure . ) if the bitcoin incentive do not seem to be the crash cause , in that , have the other obstacle be move , the bitcoin would have be collect , then the first of the two wellness criterion need a high order contribution from the distance to the other obstacle . there be two simple functional form that come to mind , which could be try that increase the alarm represent in back propagation when the probability of collision be heighten to more effectively train against collision . both involve determine the direct jump line to the near bit coin and the distance from that line to it near other obstacle ; call that x . $ x ^ y $ , where $ y > 1.0 $ $ e ^ { kx } $******none******Aug 12, 2018******2******CA
3******i'm a professional game developer investigate the potential for use reinforcement learn to build strategy game ai opponent that have more creative behavior compare to traditional technique like behavior tree . i have a few question i've bolded below , any thought would be helpful , and could save me from pursue dead end . i create a very boring and tiny game a a test case . two player each control a fleet of ship , each ship have health and can fire on one other ship each turn deal some damage . the player and his opponent assign order to their respective ship , tell them which target to attack , and then the turn be resolve . ship with 0 health be remove from the board . the player that lose all their ship first lose the game . assume i be use tensorflow , at a very high level i need to : a ) create a training program that output a trained graph to a file . the training program will need to map gamestates into tensor , fee the tensor through the graph to produce action , execute action on the gamestate to generate a new state , and evaluate the reward function for the new state . repeat a bunch . b ) take the graph create in # 1 , load it at the game runtime , and use the graph to generate intelligent action from real gamestates during the player v ai match . as soon a i start dig into tensorflow , question immediately come up , and now i'm not quite sure if there be a more appropriate library to do this . i ) tensorflow have a high level python api , and a low level c + + api . most game be build in c + + , and thus use a c + + or c api be preferable , it make integration with the game much simpler . in principle we could use pybind or some other scheme for send state from c + + to python and back again , but that's not ideal . question 1 : how much do i lose by use the low level api specifically for reinforcement learning , compare to the high level api ? ii ) platform . 99.9 % of the time , pc / console game be develop in window environment , and so have tensorflow work in window be critical . from my googling , tensorflow just barely support building in window use cmake , though it require some finagling . more worryingly be other platform : question 2 : what hope be there of run the tensorflow library on console like xboxone , playstation 4 , or the switch ? i imagine this would require manually port the entire source :( iii ) tensorflow be big , and it seem you need to basically link all of it to ship with the game . question 3 : be there any way to get a slimmed down " runtime tensorflow " library that be only capable of load a graph and transform state into action ? it seem like if the answer be yes , it might also be easy to port this small runtime version to more platform . question 4 : should i even be use tensorflow for this ? be there perhaps something more suitable ? thanks again if you read all that , i'm eager to start tinkering , but would like to set off in the right direction .reinforcement learning in commercial strategy games******reinforcement learning in commercial strategy games******Jun 14, 2018******2******CA
6******i be learn about monte carlo algorithm and struggle to understand the following : if simulation be base on random move , how can the modeling of the opponent's behavior work well ? for example , if i have a node with 100 child , 99 of which lead to an instant win , whereas the last one lead to an instant loss . in reality , the opponent would never play any of the 99 losing move for him ( assume they be obvious a they be the last move ) , and would always play the win one . but the monte carlo algorithm would still see this node a extremely favorable ( 99/100 win for me ) , because it see each of the 100 move a equally probable . be my understanding wrong , or do it mean that in most game such situation do not occur and randomness be a good approximation of opponent behavior ?why does monte carlo work when a real opponent's behavior may not be random******why does monte carlo work when a real opponent's behavior may not be random******Jun 29, 2018******2******CA
0******i will point out that the monte carlo tree search algorithm do not make completely random move . instead it usually use some metric to balance between exploration and exploitation when decide which branch to search ( see upper confidence bound and others ) . that be say , you be correct in that a specific line of play which be incredibly troublesome may not be see and could cause monte carlo to make a major mistake . this may have be a cause of alphago lose to lee sedol in game 4 . a disadvantage be that , face in a game with an expert player , there may be a single branch which lead to a loss . because this be not easily find at random , the search may not " see " it and will not take it into account . it be believe that this may have be part of the reason for alphago's loss in it fourth game against lee sedol . in essence , the search attempt to prune sequence which be less relevant . in some case , a play can lead to a very specific line of play which be significant , but which be overlook when the tree be prune , and this outcome be therefore " off the search radar "******none******Jun 29, 2018******2******CA
1******first , we need to distinguish plain monte-carlo from monte-carlo tree search . they're different thing . monte-carlo search , in the context of game ai search algorithm , be typically understood to mean that we search randomly many time , and average the result , and nothing else . if this be all we're do , then yes , your understanding be correct . this be also sometimes refer to a " plain monte-carlo ( search ) " or " pure monte-carlo ( search ) " , to make it explicitly clear that we're not do any tree search a in monte-carlo tree search ( sometimes when we just say " monte-carlo " in the context of game ai , people will automatically assume monte-carlo tree search , due to how popular it be ) . monte-carlo tree search do a lot more than just that though . it gradually build up a search tree ( through the expansion step ) , and within that search tree ( which be grow over time ) , it use a much more sophsticated strategy for traversal than pure random ( the selection step ) . for example suppose i have a node with 100 child , 99 of which lead to an instant win , and the last one lead to an instant loss . suppose that this node you're talk about , the one with those 100 child , be relatively close to the root node . then , it be likely that it and all 100 of it child will end up " grow into the search tree " that be slowly build up by the expansion step . once they have be add to the search tree , the selection step will make sure that the vast majority of further iteration visit this part of the tree will select the instant loss ( assume the opponent be to move in this node ) . in the limit ( after an infinite amount of search time ) , this bias towards select the loss node will be so large that the average evaluation tend to the ( correct ) minimax evaluation . another way to view the idea of evaluation through many random sequence of play be the following ; the idea be that if we're in a very strong position , a good game state , then we're more likely to win than to lose if both player start play at random . consider , for example , a game of chess where player 1 have many piece leave , and player 2 only have a few piece leave . imagine both player be to play completely at random from that game state onwards . on average , which player would you expect to win more often ? probably player 1 . when we're consider game state that be still far away from terminal state , this basic idea tend to work relatively well . obviously not always correct , it's still a heuristic , but it can kind of work . when we're already very close to a terminal state that can be reach through one highly specific sequence of play , yeah , we might miss that through random action ; this be where we need the more informed policy of the selection step .******none******Jun 29, 2018******2******CA
1******the two question why do monte carlo work when a real opponent's behavior may not be random ? if simulation be base on random move , how can the modeling of the opponent's behavior work well ? direct graph over tree game ( or game-like strategic scenario ) should not be represent a tree . if the process path be represent have the markov property in that each decision lack knowledge of history , a particular game state can be approach by more than one path , and there may be cyclic path where a game state be revisit . tree have neither feature . it be best to use directed graph structure to think about these problem . the state of a game be a vertex and vertex be connect by unidirectional edge . this be normally draw a shape connect by arrow . when two arrow enter one shape or there be a closed path , it be not a tree . the scenario outline in the question in the case of the scenario outline in this question , there be a vertex represent a game state with 100 outgo edge represent possible move for player a . ninety-nine of the edge lead to an obvious instant game win for a . exactly one lead to an obvious instant game win for b . play back the game to prior to the traversal of the incoming edge to the vertex before the final move , it cannot be assume that game play allow player b the same 100 option . even if the same 100 be available to b , they would not necessarily be of similar value from b's perspective when decide that previous move . more than likely , b will have have a different set of outgo edge from which to choose , bear little or no obvious resemblance to a's subsequent option . any game where this be not true , where the option remain constant , would be trivial even in comparison with tic-tack-toe . the monte carlo approach and it algorithm development regard the specification of a singular monte carlo algorithm , it do not exist . goodfellow , bengio , & courville correctly state in their deep learning , 2016 , that monte carlo algorithm ( not a singular algorithm ) draw a normally correct conclusion but with a non-deterministic occurrence of incorrect conclusion . there be variety of approach detail and associate algorithm in the literature . cross-entropy ( ce ) method propose by rubinstein in 1997 continuation multilevel monte carlo algorithm ; collier , haji – ali , von schwerin , & tempone ; 2000 sequential monte carlo algorithm ; drovandi , mcgree , & pettitt ; 2012 distribute consensus approach from bayes and big data : the consensus monte carlo algorithm ; scott 1 , blocker , bonassi , chipman , george , & mcculloch ; 2014 hamiltonian monte carlo , a markov chain base algorithm design to avoid , " the random walk behavior and sensitivity to correlated parameter ; " hoffman & gelman ; 2014 there be several more . all attempt to use chaotic perturbation to minimize duration and resource consumption of decisioning by approximate a monte carlo simulation from a bayesian posterior distribution . the simulation of stochastic nature be usually , in these approach , accomplish by the injection of a chaotic sequence from a pseudo random number generator . they be generally not truly stochastic because acquire entropy from within a digital system be another bottleneck present immense difficulty , but that's an entirely tangential topic . direct answer to the question to correct the misconception in the question , this use of chaotic perturbation do not equalize the selection of move ( represent by edge in the game-play's direct graph ) . the probability of success for each available option be still roughly calculate and follow , but only roughly so because of the psuedo-noise inject by design . these disturbance in the application of pure optimization achieve time and resource thrift for the majority of game state ( represent by vertex ) but concurrently sacrifice some reliability . an overview of why the sacrifice work the introduction of chaotic perturbation , mention above , modify the condition of the optimization search through the achievement of two very specific gain . faster coverage of the contour be search by increase entropy ( be less organize by add synthetic brownian motion ) across the set of trial . avoidance of local minimum in convergence by be less presumptuous about the contour be search ( slightly less reliant on gradient and curvature hint ) . this be true of both reinforce network ( contain real time feedback during actual use ) or pre-trained network of the supervised training type ( with label data ) or unsupervised training where convergence be determine by fixed criterion .******none******Jul 11, 2018******2******CA
2******i build a simple html game . in this game the goal be to click when the blue ball be above the red ball . if you hit , you get 1 point , if you miss , you lose 1 point . with each hit , the blue ball move faster . you can test the game here . without use machine learning , i would easily solve this problem by just click when the x , y of the blue ball be on the x , y of the red ball . regardless of the time , know the position of the 2 element i could solve the problem of the game . however , if i want to create an ai to solve this problem , could i ? how would it be ? i'd really like to see the ai randomly wander until it's perfect . my way to solve the problem i click many time and watch score . if score down , add to bad_positions . if actual position in bad_positions , not click . at first he miss many time , then start to hit eternally . this be machine learn ? deep learning ? just a bot ?how to use machine learning with simple games?******how to use machine learning with simple games?******Jun 29, 2018******2******CA
1******you have implement a simple contextual bandit solver , which be a machine learn algorithm . a few detail may be different from a full implementation , but the key element be : a choice of action ( click hit or don't click hit ) a reward signal that can be observe after each action ( + 1 for a hit , 0 for nothing happens , - 1 for an attack which miss ) an observable state which affect the reward achievable ( the position of the blue ball ) . for a contextual bandit , the state be not influence by the action take . this be true here . one thing that be different about your problem from a classic contextual bandit be that the next state be predictable from the current state ( whilst in a pure bandit problem it should be entirely random ) . however , that's not too important to your problem here , and your solver be definitely follow a contextual bandit approach . your solver test the score from try different action in each state , and narrow down the best action to take in each state . your implementation be simple and " greedy " for a contextual bandit solver . a more typical solution would maintain an average result for each action and have a rule for how to explore action in each state , so it could test whether result be reliable ( this be very helpful with non-deterministic scenario where bandit solver be more often use ) . with each hit , the blue ball move fast unless you somehow limit the reaction time of the agent , this be not relevant to how you write the solver . you could change the rule affect the agent to make it relevant in the same way a it would be for a human , e . g . decide to click mean the click happen 0.1 second later , and the state can include observation of position just now and several 0.02 second go back . in general , if you want to take this further , with more complex game and still learn how to control agent action , you could look at simple reinforcement learn agent , such a q-learning . if you be interested in the underlying theory of agent like this , then a good ( and free ) introductory text be sutton & barto " reinforcement learning : an introduction "******none******Jun 29, 2018******2******CA
4******i'm attempt to create an ai for a card game use reinforcement learning . the basic of the game be that you can have ( theoretically ) up to 35 card in your hand , you can also have to up to 35 card ' in play ' and so can your opponent . in normal play you would have ~ 6 card in your hand and maybe ~ 3 each in play . there be roughly 300 unique card in total . how should i represent the game state for the input and how should i represent the action to take in the output ?representing inputs and outputs for a card game neural network******representing inputs and outputs for a card game neural network******Jul 06, 2018******2******CA
1******assume there's no order to the hand ( i . e . it doesn't matter what order card be add to it ) , then a reasonable approach be to use one input neuron for the number of each kind of card that be present in a player's hand . you don't describe how the game be play , but a common approach for extract action be to have one output neuron for each possible action . to select an action , you would pick the one corresponding to the neuron with the high output response to a give input .******none******Aug 08, 2018******2******CA
11******i be currently new to artificial intelligence but i be very intrigue by it . i be currently research three algorithm , namely : minimax , alpha-beta pruning and monte carlo tree search . a you may have figure out , these be all tree search algorithm . my question be simple . how do i choose which algorithm be best for something like a checker board game ? n . b . the reason why i only choose these three algorithm be due to time i have available in understand them . from a little research , i find that these algorithm be basically interweave into the minimax algorithm . so if i can understand one , then the other two will just fall into place .how do i choose which algorithm is best for something like a checkers board game?******how do i choose which algorithm is best for something like a checkers board game?******Jul 16, 2018******2******CA
1******i you have to choose between minimax and alpha-beta pruning you should choose alpha-beta . it be more efficient and fast because it can prune a substantial part of your exploration tree . but you need to order the action from the best to the bad depend on max or min point of view , so the algorithm can quickly realize if the exploration be necessary .******none******Jul 16, 2018******2******CA
2******play chess with a blind search algorithm like monte carlo tree search be a very good idea , because it help to raise the energy consumption of your 64 core workstation . use the maximum capacity of a cpu and ignore any possible kind of heuristic be a best practice method in proof real scientific progress . one advantage of minimax in contrast to the monte carlo algorithm be , that minimax have a nash equilibrium which make it well suit for a mathematical terminology and an abstract introduction into game theory . this help to focus away from the original problem ( how to play chess ) into a more general discussion about zero-sum game and payoff matrix . the third strategy on your list ( alpha beta-prunning ) sound also well suit for run a server farm under maximum load without ever find out the best move . my advice be similar to your own perception : if you have understand the minimax strategy , all the other algorithm be much easy to implement . and minimax be the right choice , if you're planning to stay away from rule of thumb which be implement a a symbolic planner in lisp .******none******Jul 16, 2018******2******CA
13******tl ;d r : none of these algorithm be practical for modern work , but they be good place to start pedagogically . you should always prefer to use alpha-beta pruning over bare minimax search . you should prefer to use some form of heuristic guide search if you can come up with a useful heuristic . come up with a useful heuristic usually require a lot of domain knowledge . you should prefer to use monte carlo tree search when you lack a good heuristic , when computational resource be limit , and when mistake will not have outsize real-world consequence . more detail : in minimax search , we do not attempt to be very clever . we just use a standard dynamic programming approach . it be easy to figure out the value of difference move if we're close to the end of the game ( since the game will end in the next move , we don't have to look very far ahead ) . similarly , if we know what our opponent will do in the last move of the game , it's easy to figure out what we should do in the second last move . effectively we can treat the second last move a the last move of a short game . we can then repeat this process . use this approach be certain to uncover the best strategy in a standard extensive-form game , but will require u to consider every possible move , which be infeasible for all but the simple game . alpha-beta pruning be a strict improvement on minimax search . it make use of the fact that some move be obviously bad than others . for example , in chess , i need not consider any move that would give you the opportunity to put me in checkmate , even if you could do other thing from that position . once i see that a move might lead to a lose , i'm not go to bother think about what else might happen from that point . i'll go look at other thing . this algorithm be also certain to yield the correct result , and be faster , but still must consider most of the move in practice . there be two common way you can get around the extreme computational cost of solve these kind of game exactly : use a heuristic ( a * search be the usual algorithm for pedagogical purpose , but quiescence search be a similar idea in 2 player game ) . this be just a function that give an estimate of the value of a state of the game . instead of consider all the move in a game , you can just consider move out to some finite distance ahead , and then use the value of the heuristic to judge the value of the state you reach . if your heuristic be consistent ( essentially : if it always overestimate the quality of state ) , then this will still yield the correct answer , but with enormous speedup in practice . use rollouts ( like monte carlo tree search ) . basically , instead of consider every move , run a few thousand simulate game between player act randomly ( this be fast than consider all possible move ) . assign a value to state equal to the average win rate of game start from it . this may not yield the correct answer , but in some kind of game , it perform reliably . it be often use a an extension of more exact technique , rather than be use on it own .******none******Jul 16, 2018******2******CA
5******n . b the reason why i only choose these three algorithm be due to time i have available in understand them . from a little research , i find that these algorithm be basically interweave into the minimax algorithm . so if i can understand one then the other two will just fall into place . give this context , i would recommend start out with minimax . of the three algorithm , minimax be the easy to understand . alpha-beta , a others have mention in other answer , be a strict improvement on top of minimax . minimax be basically a part of the alpha-beta implementation , and a good understanding of alpha-beta require start out with a good understanding of minimax anyway . if you happen to have time leave after understand and implement minimax , i'd recommend move on to alpha-beta afterwards and building that on top of minimax . start out with alpha-beta if you do not yet understand minimax doesn't really make sense . monte-carlo tree search be probably a bit more advanced and more complicated to really , deeply understand . in the past decade or so , mcts really have be grow to be much more popular than the other two , so from that point of view understanding mcts may be more " useful " . the connection between minimax and mcts be less direct / obvious than the connection between minimax and alpha-beta , but there still be a connection at least on a conceptual level . i'd argue that have a good understanding of minimax first be still beneficial before dive into mcts ; in particular , understanding minimax and it flaw / weak point can provide useful context / help you understand why mcts become " necessary " / popular . to conclude , in my opinion : alpha-beta be strictly good than minimax , but also strongly relate / build on top of minimax ; so , start with minimax , go for alpha-beta afterwards if time permit mcts have different strength / weakness , be often good than alpha-beta in " modern " problem ( but not always ) , a good understanding of minimax will likely be beneficial before start to dive into mcts******none******Jul 16, 2018******2******CA
1******the selection from among those and others mention in other answer to the question be important , yes , and there be conceptual overlap , but those be not algorithms . minimax , alpha-beta pruning , monte carlo tree search be approach to deal with the span tree of the graph associate with markov chain to find an optimum next move base on metric derive from vertex and edge . there be many potential algorithm that could realize each approach in software . the best approach and the best algorithm to realize them depend on many thing . dimension of the data path hardware utilization option expose through the operating system , cluster , and language employ desire performance criterion and priority time requirement skill and knowledge of the development team although many framework available in python , java , and other language will provide way to overlap concept and rapid prototype , you cannot just learn one and the others will fall into place . you can hack through to a working solution for your current problem , but if you want to develop the ability to reliably create reliable software , there be no such shortcut . in my experience , the thing to start with be neither of the three . it be the commitment to diligence and thoughtfulness in ml software development . if we , a engineer and researcher do not commit to this , then the unreliability of smart system we create will , in 50 year , rival the unreliability of cell phone connection . we could , to the detriment of safety and economic stability , exceed the maintainability issue characteristic of much of the middle tier software in production today . i encourage those enter into this powerful and future-critical field to aim much high than that .******none******Jul 17, 2018******2******CA
1******ai become superior to the best human player in chess around 20 year ago ( when the 2nd deep blue match conclude ) . however , it take until 2016 for an ai to beat the go world chess champion , and this feat require heavy machine learning . my question be why be / be go a harder game for ai to master than chess ? i assume it have to do with go's enormous branching factor ; on a 13x13 board it be 169 , while on a 19x19 board it be 361 . meanwhile , chess typically have a branching factor of around 30 .why was go a harder game for an ai to master than chess?******why was go a harder game for an ai to master than chess?******Jul 17, 2018******2******CA
2******the branching factor be important , a it limit the effectiveness of search . however , the branching factor in chess be already too high to effectively search without technique that reduce the size of the search space . even with million of test per second , a computer can only check a small fraction of the possible future game in order to find result in it favour . one key factor be heuristic - approximate measure of the value of each game state . a good heuristic can guide and improve search by order of magnitude . there be some effective heuristic possible in chess , from weighted value of the piece in play , score for area of the board that a position control etc . heuristic for go be much hard to find . here's a sample paper from a few year ago that make an attempt , there be several similar one available online . although plenty of option have be try , and many be partially successful , none manage to bring the quality of computer play up to the standard of best human player . one of the major achievement of alphago be train a neural network that have good position evaluation - the " value network " . the technology that make generate this approximate function of board game position possible be deep learning , which have be develop very strongly since about 2010 . it be still possible a more analytical heuristic approach could be find that challenge deep learning model drive by self-play reinforcement learn on more raw board data . however , in some regard the reverse have be show , with alphazero take the same learning technique into chess and demonstrate it effectiveness against " old school " tune expert heuristic .******none******Jul 17, 2018******2******CA
4******imagine the fictitious scenario in a role playing game ( rpg ) where the non-playing character ( npc ) within the rpg be conscious of their own surrounding and consider the developer to be god . the people inside can also live a normal life in that they can create new life , eat , die , and perform other function human experience . will this qualify them to be an ai ? will the child of the npcs qualify a an ai ? might this be realize in the future ?what if there's a game where all the ai people actually lived?******what if there's a game where all the ai people actually lived?******Jul 17, 2018******2******CA
1******yes , a baby can be consider an ai . will this be our future ? i don't know . that be exactly what some people be look for , to create an ai that can live . we have several ai that each time more surprise u . but none of them question their own existence , none of them want to know or require attention from their god ( developer ) because of their reflection . i believe that what we create today can be equate with a mosquito of our real life : a brainless " be " that perform simple action . the cool thing about believe in such a future with artificial intelligence be that we do not have to repeat our mistake . we do not need an ai evolve accord to age , it can be bear with a superintelligence , know everything , learn only new thing that be not foreseen . some human ( and i ) have a passion for the human , for every detail and imperfection , and dream of re-creating something a mysterious and complex a through an ai . it seem something impossible , some believe that it would be impossible only because who create u would be a perfect be ( god ) . but others ( me ) do not stop at this issue , and continue the quest to create an ai with some characteristic of the human , such a : feeling , reflect on one's own act , ... but all this , as far a i know , be surreal and only projection of our mind . it be already something interesting , for create new challenge for humanity .******none******Jul 17, 2018******2******CA
0******i think it be a very good idea to populate the whole universe with ai character , because this help to spread out singularity faster . in the literature the concept be call swarm or crowd simulation , because many ai individual be work together in the same environment . this concept shouldn't be misinterpret a multi-agent system , because this be a blackboard like architecture which be active in one individual . the appropriate term be swarm simulation . if the individual be able to recognize the developer of the environment a god , depend on their conciseness level . this be a scale to measure the intelligence . it start with zero , go to animal ai , human level ai and at the maximum it be super-human universal ai which understand everything . the scale be call consscale and determine the level of machine consciousness . level 7 mean , that the ai robot can recognize themself a an ai .******none******Jul 17, 2018******2******CA
0******this be a standard trope in science fiction , although more common be the idea of transfer mind from real people into a virtual environment . right now , such an idea be still firmly in science fiction . we don't know a few thing : what consciousness be in detail . there be various educate guess and philosophical stance , but none have be seriously verify . what the minimal environment be that can support consciousness . this be important because simulate more complex environment be more computationally expensive . there be a huge gulf between capability of current computer and something that could simulate reality to the level of granularity that we can experience and manipulate it ( let alone to the depth that we can scientifically investigate ) . will this consider them to be an ai ? assume you can solve the caveat above , then yes , perhaps even a " strong ai " in the domain of the game , but not a human-equivalent agi ( depend on the complexity of the environment ) . if you mix a current rpg game with some agent drive by our current best game-playing bot , and improve them so that they be able to solve problem within the game - e . g . in world of warcraft , or perhaps in minecraft - then you would have something a advanced or good than any current " narrow ai " that solve point score or adversarial game . you would be justify in call it " ai " , if openai and deep mind can call their achievement " ai " . however , it seem unlikely such agent would be much like your imagined simulated people - have consciousness etc . would this be real in the future ? depend on the constraint face by researcher . to get to an imagine point where this be possible , we have to extrapolate current trend on compute power and advance in understand goal-driven ai and self-awareness . there be a range of opinion on how likely this be , how much power be require etc . it be a compelling idea , and unlike say faster-than-light travel , there be no widely-accepted theoretical limit that prevent it .******none******Jul 17, 2018******2******CA
0******the question can be extend further : what if the npc be smart enough to design digital system capable of housing a game much like the one they be in ? this would not be recursion in the sense of ancestor and descendant within a specie , but actual recursion in the domain of speciation . work backward , how can we know for sure that we aren't god's rpg , and , more importantly , what difference would there be between that scenario and the ancient middle eastern conceptualization of the monotheistic creation ? the bidirectionality of this scenario be examine on the screen by writer-director david cronenberg in his 1999 film existenz , star jude law , jennifer jason leigh , and ian holm ( recommend ) . regard the sub-question , " will this qualify them to be an ai ? " that depend on two thing . how one define intelligence , a somewhat slippery word to define <sup> 1 </sup> what facility and propensity be imbue into the hardware and software that bring the npc to artificial life . regard whether the child of the npcs qualify a ai , definitively yes if the parent qualify and the child be adequate replica or artificially genetic improvement . might this be realize in the future ? that depend on a number of thing . will the earth avert global extinction event ? will humanity accidentally exterminate itself ? <sup> 2 </sup> some call all of this science fiction or futurism . i do not . such thing be gradually develop and have be for at least the duration of my life . i've be an interested spectator in this very real drama . note [ 1 ] the philosophic question of whether super-human intelligence human can't posse be a prerequisite to characterize human intelligence be well represent in cybernetic literature reach a far back a charles babbage and perhaps far in the early biochemical interest of abu mūsā jābir ibn hayyān . define what intelligence mean be more than look at functional mri or run test in python . if we define intelligence a the ability to collaborate , ant and even bacteria may be more intelligent than human . if we define intelligence a the ability to efficiently construct artifice of benefit to the specie , bee exceed human . human can determine mathematically that hexagonal room be 1.7 time more efficient than square room in term of construction material , but be it intelligence that , have determine that ratio century ago , human continue to waste material on square room ? we don't see bacteria , ant , or bee shoot narcotic either . in some respect , by some definition of intelligence , human would qualify a the dominant moron of all terrestrial life form . [ 2 ] " darwin's dice have roll badly for earth . the human specie be , in a word , an environmental abnormality . perhaps a law of evolution be that intelligence usually extinguish itself . " — harvard u professor 1955 and pulitzer prize winner for general nonfiction , new york time magazine , may 30th , 1993 , be humanity suicidal ?******none******Jul 27, 2018******2******CA
4******i know that they be quite alot of optimization for alpha-beta pruning but what do it mean exactly : 1 ) do it mean that these optimize algorithm be to be integrate into the alpha-beta algorithm or 2 ) do it mean that these optimization be completely new algorithm in that they have get nothing to do the alpha-beta algorithm ? on the note of alpha beta optimization , i have come across a lot of optimization like iterative deepening , principal variation search , quiescence search and many more . my second question be the optimization list above be find in the site " " , but this site group these algorithms into 4 category namely , mandatory , selectivity , scout and friend and lastly alpha-beta go best-first . do this mean that alpha-beta algorithm be split into four area and that they be specialized optimization algorithm for each area ? this be really confuse me . how do i even begin to decide which optimize algorithm to pick ? i advise people to visit this site : not , , this website to beginner like myself be just too distract with all of it link on each page . this just become too overwhelming for a beginner to understand .alpha-beta pruning algorithms optimizations******alpha-beta pruning algorithms optimizations******Jul 20, 2018******2******CA
1******1 ) do it mean that these optimize algorithm be to be integrate into the alpha-beta algorithm or 2 ) do it mean that these optimization be completely new algorithm in that they have get nothing to do the alpha-beta algorithm ? most of them be extension of the alpha-beta pruning algorithm . for example , iterative deepening be almost the same a alpha-beta pruning , but automatically keep repeat the algorithm with gradually-increasing depth limit until some time limit be reach , rather than just run once for a pre-determined depth limit . principal variation search also still use alpha-beta a a basis , but perform many search with significantly small window than the standard alpha-beta pruning algorithm . in most case , these extension would start out from an exist alpha-beta implementation , and build from there with some adaptation in the code . this be not necessarily the case for all of those extension though , just for most . for example , transposition table be kind of a separate extension that could be plug into vanilla minimax , or alpha-beta , or principal variation search , or whatever you're use . my second question be the optimization list above be find in the site " " , but this site group these algorithms into 4 category namely , mandatory , selectivity , scout and friend and lastly alpha-beta go best-first . do this mean that alpha-beta algorithm be split into four area and that they be specialized optimization algorithm for each area ? those four category be not mutually exclusive , they're more like ... broad " flavour " . what they list under obligatory be some of the more basic extension that any programmer should probably look into first if they be develop a chess-playing program . the other category be different " flavour " , different " broad idea " . for example , everything list under " selectivity " be about search " interesting " or " exciting " part of the search tree deep than " less interesting " or " boring " part . many of those idea could be use regardless of whether you're use alpha-beta , iterative deepening , or pvs , and probably all could be combine with transposition table as well . how do i even begin to decide which optimize algorithm to pick ? this be really really difficult to decide just base on the name . in theory , which algorithm be the " best " will also highly depend on your specific game , and maybe even hardware . and , in many case it's not even a choice between mutually exclusive part ; different idea can be combine with each other in different way . the only solution here be really just to do lot of reading , lot of research , try implement different thing to good understand them .******none******Jul 21, 2018******2******CA
1******game like checker have compulsory move . in checker for instance , if there's a jump available a player must take it over any non-jumping move . my question be , if jump be compulsory will there still be a need for quiescence search ? my thinking be that i can develop an implementation of quiescence search that first check whether jump be available . if there be then it can skip all non-jumping move . if there's only one jump move available , then i won't need to run a search at all . i will therefore only use quiescence search if i initially don't have to make a jump on my first move . i will only active quiescence search in my alpha beta prune becomes active . ( the alpha beta will only be active if my first algorithm which first check if there be jump available return a 0 , which mean there be no jump available . ) be my thinking of implement quiescence search correct ? my option be slim when it come to optimization due to serious memory constraint , hence i won't be use pvs or other algorithm like that a they require additional memory .quiescence search******quiescence search******Jul 23, 2018******2******CA
3******i understand your question to be : if some move be compulsory , and my agent have no choice about which move to make next , do i need to perform a search , or can i just return the compulsory move ? the answer depend on what your goal be . if your goal be to make an interactive agent that will play the game against you , then you be correct : there's no need to perform a search . just return the compulsory move , and then run the search next time your agent have a choice about what to do . if your goal be to determine the optimal way to play a game , or the expect payoff from a certain game position ( another common use of search technique ) , then you should run the search a normal , since the force move won't necessarily lead to a particular end state . tangentially , if you're interested in way to speed up search for checker , check out the chinook paper . there's a popularized account here , and more technical one here and here by schaeffer et al .******none******Jul 23, 2018******2******CA
4******i be try to make balanced weapon pair . so there be five stats per weapon , and i be simulate a number of combat ( 1000 ) with different stats randomize , and count the win , lose , and draw of the " weapon fight " for the database . i want an algorithm for make weapon 1win - weapon 2win as small a possible for balance through change the weapon stats . what happen : random stats --> combat 1000 time --> count win & lose --> data for train the ai data sample : { [ ( 1,2 , 3,4 , 5 ) --> weapon 1stats , ( 5,4 , 3,2 , 1 ) --> weapon 2stats , 1 --> winweapon 1 - winweapon 2 ] , [ ... ] } ( the text isn't part of the data sample , they be just there to help you know which variable be which . also , the { [ ( s be all suppose to be [ s but change for clarity ) i would like an function , preferably in c + + or python , but just with text that be well explain be fine , for handle the data . the result would be a method to determine how to minimize winweapon 1 - winweapon 2 . ( edit ) i would say that the one i be look for be one with something like a score for the weapon a in strength ( 1 * stat 1 + 2 * stat 2 etc ... ) but i do want something new that work well , i be also have problem create leeway for the function coefficient . ( edit end )algorithm for making balanced weapons in a game?******algorithm for making balanced weapons in a game?******Aug 11, 2018******2******CA
2******i'm go to start by try to restate your problem a i understand it . you have a game which contain weapon . weapon be characterize by 5 different number , which can range over different value ( 1-5 in your example ? ) . you have a way to simulate combat involve the two weapon . the combat be random , but can be repeat many time . an average win rate can be determine . you be look for an ai algorithm that would take in a lot of pair of statistic , along with the average win rate for one over the other , and give you insight into how to make the average win rate a close to 50 % a possible . if this sound right , then fundamentally your problem be a form of regression , which something you could use ai for , but probably don't need to . however , your problem be probably not linear , so you need the interaction between the feature . here's what i suggest : for each pair of weapon , store a comma separate list consist of the stats for each weapon ( one by one ) , follow by win 1 - win 2 . at the top , list out the name of each attribute , separate by comma , ( e . g . weapon 1str , weapon 1range , ... , weapon 1 - weapon 2 then use a language like r that have simple support for complex form of regression . in r , this be then as simple a : this should produce a list of " coefficient " , one for each of the attribute , and one for the interaction between each pair of attribute , which form a lengthy quadratic equation in 10 variable . any zero of that equation should be a pair of weapon that minimize this difference . that's probably the place to start . if it doesn't work out , maybe come post a different question and we can help more .******none******Aug 25, 2018******2******CA
6******to the best of my understanding , monte carlo search be an alternative method to minimax for search a tree of node . it work by choose a move ( generally the one with the high chance of be the best ) , and then perform a random playout on the move to see what the result be . this process keep continue for however much time be allot . this doesn't sound like machine learning , but rather a way to traverse a tree . however , i've heard that alphazero use monte carlo search , so i'm confuse . be use monte carlo search why alphazero learn ? or do alphazero do some kind of machine learning before it play any match , and then use the intuition it gain from machine learn to know which move to spend more time play out with monte carlo search ?does monte carlo search (specifically used by alphazero) qualify as machine learning?******does monte carlo search (specifically used by alphazero) qualify as machine learning?******Aug 16, 2018******2******CA
5******monte carlo tree search be not usually think of a a machine learning technique , but a a search technique . there be parallel ( mcts do try to learn general pattern from data , in a sense , but the pattern be not very general ) , but really mcts be not a suitable algorithm for most learning problem . alphazero be a combination of several algorithm . one be mcts , but mcts need a function to tell it how good different state of the game might be ( or else , it need to simulate entire game ) . one way to handle this function in a game like chess or go be to approximate it by train a neural network , which be what the deep mind researcher do . this be the learning component of alphazero .******none******Aug 16, 2018******2******CA
3******john's answer be correct in that mcts be traditionally not view a a machine learn approach , but a a tree search algorithm , and that alphazero combine this with machine learn technique ( deep neural network and reinforcement learning ) . however , there be some interesting similarity between mcts itself and machine learning . in some sense , mcts attempt to " learn " the value of node from experience generate through those node . this be very similar to how reinforcement learning ( rl ) work ( which itself be typically describe a a subset of machine learning ) . some researcher have also experiment with replacement for the traditional backpropagation phase of mcts ( which , from an rl point-of-view , can be describe a implement a monte-carlo backup ) base on other rl method ( e . g . , temporal-difference backup ) . a comprehensive paper describe these sort of similarity between mcts and rl be : on monte carlo tree search and reinforcement learning . also note that the selection phase of mcts be typically treat a a sequence of small multi-armed bandit problem , and those problem also have strong connection with rl . tl ;d r : mcts be not normally view a a machine learning technique , but if you inspect it closely , you can find lot of similarity with ml ( in particular , reinforcement learning ) .******none******Aug 16, 2018******2******CA
4******i'm make a connect four game where my engine use minimax with alpha-beta pruning to search . since alpha-beta pruning be much more effective when it look at the best move first ( since then it can prune branch of poor move ) , i'm try to come up with a set of heuristic that can rank move from best to worst . these heuristic obviously aren't guarantee to always work , but my goal be that they'll often allow my engine to look at the best move first . an example of such heuristic would be a follow : closeness of a move to the centre column of the board - weight 3 . how many piece surround a move - weight 2 . how low , horizontally , a move be to the bottom of the board - weight 1 . etc however , i have no idea what the best set of weight value be for each attribute of a move . the weight i list above be just my estimate , and can obviously be improve . i can think of two way of improve them : 1 ) evolution . i can let my engine think while my heuristic try to guess which move will be choose a best by the engine , and i'll see the success score of my heuristic ( something like x % guess correctly ) . then , i'll make a pseudo-random change / mutation to the heuristic ( by randomly adjust one of the weight value by a certain amount ) , and see how the heuristic do then . if it guess well , then that will be my new set of heuristic . note that when my engine think , it consider thousand of different position in it calculation , so there will be enough data to average out how good my heuristic be at prediction . 2 ) generate thousand of different heuristic with different weight value from the start . then , let them all try to guess which move my engine will favor when it think . the set of heuristic that score best should be keep . i'm not sure which strategy be well here . strategy # 1 ( evolution ) seem like it could take a long time to run , since every time i let my engine think it take about 1 second . this mean test each new pseudo-random mutation will take a second . meanwhile , strategy # 2 seem faster , but i could be miss out on a great set of heuristic if i myself didn't include them .more effective way to improve the heuristics of an ai... evolution or testing between thousands of pre-determined sets of heuristics?******more effective way to improve the heuristics of an ai... evolution or testing between thousands of pre-determined sets of heuristics?******Aug 16, 2018******2******CA
1******hmmm , i see some issue that be actually present in both of the approach you propose . it be important to note that the depth level that your minimax search process manages to reach , and therefore also the speed with which it can traverse the tree , be extremely important for the algorithm's performance . therefore , when evaluate how good or bad a particular heuristic function for move ordering be , it be not only important to look at how well it order move ; it be also important to take into account the runtime overhead of the heuristic function call . if your heuristic function manage to sort well , but be so computationally expensive that you can't search a deep in the tree , it's often not really worth it . neither of the solution you propose be able to take this into account . another issue be that it's not trivial to measure what ordering be the " best " . a heuristic that have the high accuracy for the position of the best move only be not necessarily the best heuristic . for example , a heuristic that always place the best move in the second position ( $ 0 \ % $ accuracy because it's in the wrong position , should be first position ) might be good than a heuristic that place the best move in the first position $ 50 \ % $ of the time ( $ 50 \ % $ accuracy ) , and place the best move last in the other $ 50 \ % $ of case . i would be more inclined to evaluate the performance of different heuristic function by set up tournament where different version of your ai ( same search algorithm , same processing time constraint per turn , different heuristic function ) play against each other , and measure the win percentage . this set up can also be do with two variant analogous to what you propose ; you can exhaustively put all the heuristic function you can come up with against each other in tournament , or you can let let an evolutionary algorithm sequentially generate population of hypothesis-heuristic-functions , and run a tournament with each population . generally , i would lean towards the evolutionary approach , since we expect it to search the same search space of hypothesis ( heuristic function ) , but we expect it to do so in a more clever / efficient manner than an exhaustive search . of course , if you happen to have a ridiculous amount of hardware available ( e . g . , if you're google ) , you might be able to perform the complete exhaustive search at once in parallel . note that there be also way to do fairly decent move order without heuristic function like the one you suggest . for example , you likely should be use iterative deepening ; this be a variant of your search algorithm where you first only perform a search with a depth limit $ d = 1 $ , then repeat the complete search process with a depth limit $ d = 2 $ , then again with a limit $ d = 3 $ , etc . , until process time run out . once you have complete such a search process for a depth limit $ d $ , and move on to the subsequent search process with a limit of $ d + 1 $ , you can order order the move in the root node accord to your evaluation from the previous search process ( with depth limit $ d $ ) . yes , here you would only have move ordering in the root node , and nowhere else , but this be by far the most influential / important place in the tree to do move ordering . move order becomes less and less important a you move far away from the root . if you're use a transposition table ( tt ) , it be also common to store the " best move " find for every state in your tt . if , later on , you run into a state that already exist in your tt ( which will be very often if you're use iterative deepening ) , and if you cannot directly take the stored value but have to actually do a search ( for instance , because your depth limit increase due to iterative deepening ) , you can search the " best move " store in the tt first . this be very light move ordering in that you only put one move at the front and don't order the rest , but it can still be effective .******none******Aug 17, 2018******2******CA
0******with regard to random vs evolutionary algorithm , an evolutionary algorithm will almost always be superior . imagine the space of all possible heuristic . an evolutionary algorithm move through it ' intelligently ' i . e . it somewhat follow the gradient of the space and should converge to a local optimum . a random algorithm will not be able to achieve this . with regard to the time take , surely it would be the same for each one to evaluate x heuristic ?******none******Aug 17, 2018******2******CA
3******i recently come across this function : $ $ \ sum _ { t = 0 } ^ { \ infty } \ gamma ^ t r_t . $ $ it's elegant and look to be useful in the type of deterministic , perfect-information , finite model i'm work with . however , it occur to me that use $ \ gamma ^ t $ in this manner might be see a somewhat arbitrary . specifically , the objective be to discount per the added uncertainty / variance of " temporal distance " between the present gamestate and any potential gamestate be evaluate , but that variance would seem to be a function of the branching factor present in a give state , and the sum of the branching factor lead up to the evaluated state . be there any define discount-factors base on the number of branch factor for a give , evaluated node , or the number of branch in the node lead to it ? if not , i'd welcome thought on how this might be apply . ( an initial thought be that i might divide 1 by the number of branch and add that value to the goodness of a give state , which be a technique i'm use for heuristic tie-breaking with no look-ahead , but that's a " value-add " a oppose to a discount . ) - - - for context , this be for a form of partisan sudoku , where an expressed position $ p_x $ ( value , coordinate ) typically remove some number of potential position $ p $ from the gameboard . ( without the addition of an element displacement mechanic , the number of branch can never increase . ) on a $ ( 3 ^ 2 ) ^ 2 $ sudoku , the first $ p_x $ remove $ 30 $ out of $ 729 $ potential position $ p $ , include itself . with each $ p_x $ , the number of branch diminishes until the game collapse into a tractable state , allow for perfect play in endgame . [ even there , a discounting function may have some utility because outcomes set of ratio . where the macro metric be territorial ( controlled region at the end of play ) , the most meaningful metric may ultimately be " efficiency " ( loosely , " points_expended to regions_controlled " ) , which acknowledge a benefit to expend the least amount of point $ p_x $ , even in a tractable endgame where the ratio of controlled region cannot be alter . additionally , zugzwangs be possible in the endgame , and in that case reverse the discount to maximize branch may have utility . ] <sub> $ ( 3 ^ 2 ) ^ 2 = 3x3 ( 3x3 ) = " 9x9 " $ but the exponent be prefer so a not to restrict the number of dimension . </sub>are there any discount-factors based on branching factors?******are there any discount-factors based on branching factors?******Aug 17, 2018******2******CA
5******i've develop a neural network that can play a card game . i now want to use it to create deck for the game . my first think would be to run a lot of game with random deck and use some approximation ( maybe just a linear approximation with a feature for each card in your hand ) to learn the value function for each state . however , this will probably take a while , so in the mean time be there any way i could get this information directly from the neural network ?can you analyse a neural network to determine good states?******can you analyse a neural network to determine good states?******Aug 20, 2018******2******CA
4******i don't think your network , train use ppo to play a card game , already contain sufficient information to also use for draft . i'm not say this with 100 % certainty , maybe there's something i'm overlooking , but i can't think of anything right now . a small adaptation to the network might be sufficient ( though it would also involve re-training again ) . recently , openai have be write about their attempt to train agent to play the game dota 2 . now , this isn't a card game , it doesn't require deckbuilding , but there be an aspect to the game that be somewhat similar to deckbuilding : drafting . in dota 2 , there be two team of 5 player each . before a game start , each team select 5 hero ( one per player ) to play in that game . this be very similar to deckbuilding , except that it's likely a much small problem ; there's only a " deck " ( team composition ) of 5 " card " ( hero ) . anyway , they also train agent to play the game ( control one hero per agent ) use ppo . in a blog post , they write the follow about how they manage to add draft capability relatively easily : in late june we add a win probability output to our neural network to introspect what openai five be predict . when later consider draft , we realize we could use this to evaluate the win probability of any draft : just look at the prediction on the first frame of a game with that lineup . in one week of implementation , we craft a fake frame for each of the 11 million possible team matchup and write a tree search to find openai five ’ s optimal draft . so , if you want to try a similar technique , you'd have to adapt your network such that it also learn to generate a prediction of the win probability a output . i imagine that it'd be much less effective for deckbuilding , because win probability may all be very close to 50 % in card game where luck ( when draw card for example ) can be a significant factor , but it might be worth a try . alternatively , instead of generate lot of random deck and play with them all , you could view the problem of deckbuilding a an additional separate " game " or markov decision process ; add a specific card to the deck can be an action , and this mdp terminate once you have a complete deck . then you can try to do that good than random use search algorithm ( like monte-carlo tree search ) or , again , a reinforcement learn approach like ppo . again , i imagine it will be a very difficult problem though , likely require lot of time before it will be capable of do good than random . i also know of some research relate to deckbuilding in the collectible card game hearthstone , which may be relevant for you . unfortunately i do not yet get to read through any of this in detail , so i don't know for sure if you'll find a solution here , but it may be worth a try : : at the recent ieee cig 2018 conference , there be two competition involve hearthstone : one for game-playing ai with pre-built deck , and for generate new deck ( and then play with them ) . the page i link to here contain reference to related work from early year . q-deckrec : a fast deck recommendation system for collectible card game : this be a new paper that be publish in the proceeding of this recent ieee cig 2018 conference .******none******Aug 21, 2018******2******CA
3******so i write simple feed forward neural network that play tic-tac-toe : 9 neuron in input layer : 1 - my sign , - 1 - opponent's sign , 0 - empty ; 9 neuron in hidden layer : value calculate use relu ; 9 neuron in output layer : value calculate use softmax ; i be use evolutionary approach : 100 individual play against each other ( all-play-all ) . top 10 best be select to mutate and reproduce into the next generation . the fitness score calculate : + 1 for correct move ( it's possible to place your sing on already occupy tile ) , + 9 for victory , - 9 for a defeat . what i notice be that the network's fitness keep climb up and fall down again . it seem that my current approach only evolve certain pattern on place sign on the board and once random mutation interrupt current pattern new one emerge . my network go in circle without ever evolve actual strategy . i suspect solution for this would be to pit network against tic-tac-toe ai , but be there any way to evolve actual strategy just by make it to play against itself ?evolving network in game******evolving network in game******Aug 24, 2018******2******CA
4******artificial intelligence can be realize a a full autonomous or a a semi-autonomous system . a full autonomous system take the human operator out of the loop , his hand be away from keyboard and he be do nothing . such system have a high probability of failure because most software isn't able to model the system overall . in contrast , a semi-autonomous system support the human player in a co-working space . the human stay in control but the ai be provide heat-up display , suggestion and automation of minor task . such a semi-autonomous system be call aimbot note : this question can also be ask from an anti-cheat point of view . i be just ask this question out of curiosity . c : go refers to counter-strike global offensive . consider the fact that we can move forward with this problem with two apparent solution in mind . first one can be an image recognition model . it will recognize the head of the enemy and move the cursor to the position of the enemy's head and fire . second one can be a model which will be train use the view angle of your model in real time . thing to consider : it would be much more preferable to train the second model in real time than use demo . most of the available demo you might have may be 32 tick , but while play the game , it work at 64 tick . these be my thought on it . it be a very fresh idea in my mind , so i didn't actually think a lot about it . ignore fact like detection by vac for a few moment . can someone suggest way i could get start with something like this ? later on this idea can be expand to a completely self work bot which can play the game by itself , but that's a bit too much initially .how to go forward with creating an artifically intelligent aimbot for a game like cs:go******how to go forward with creating an artifically intelligent aimbot for a game like cs:go******Aug 30, 2018******2******CA
0******thare be many way to approache this . one approach to start would be to try to describe the problem use a formalism closer to reinforcement learning . output : aiming in any shooter type game , a i recall , involve move the mouse . so the output of your aimbot have two dimentions . depend on the required accuracy , you can consider these two dimentions continous , with a limited range , or if you consider each pixel a a integer , you might be able to discretize your action space . ( i assume mouse xy coordinate should be input to the game , not increment ) input : you definetly need screen information . you can take the whole screen a input to a cnn , similarly to deepqlearning for atari . reward function this might be tricky since your reward need to be as dense a possible , however , the only feedback you get from the game be that someone be shoot . it might be ebough but this will definetly increase your training time . train data / environemnt : your environment for training be the game itseld . use a curriculum learn approach would probably make the training process more efficient . you can also try an imitation learn approach , since i assume you be happy to provide expert training example ( in this case probably headshot in the game environment ) . you can read more about how to apply reinforcement learn for game here . the unity ml-agents library also include sample track problem and their solution .******none******Sep 07, 2018******2******CA
0******automation of game-play aimbots be indeed design to provide assistance to the human game player when the complexity of game play escape full cybernetic autonomy at the current state of technology . there be five basic component in any game player , dna base or digital . acquisition of the current state of the game control over execution of move option intercommunication with other player model relate to the game execution engine for apply these the model be a follow for a c : go aimbot . model of game player model of the oppose team model of the game player be assist model of that player's team model of the oppose team model of the game state model of legal game move that transition state model of objective ( win or maintain a top score ) model of game-play strategy involve the first three item in the previous list learn all of these be not in the scope of current deep learning strategy but not outside the scope of ai if the follow problem analysis and system approach be take . assumption be make similar to those of morgenstern and von neumann in the late chapter of their game theory to mathematically treat the decisioning of game player in a minimalistic way . dsp , gpu , network realization hardware , cluster computing , or some other artificial network hardware acceleration be available model program in prolog , drool , or some other production system and then leverage by the execution engine in conjunction with other component such a deep learning network , convolution processing , markov tree , fuzzy logic , and the application of oversight function or heuristic a need the two service , ( a ) the provision of suggestion and ( b ) the automation of minor task , may indeed represent the low hang fruit from a software engineering perspective , but the problem analysis and system approach above may provide more . objective in c : go the c : go ( counter-strike global offensive ) game seem to have be write from a westphalian geopolitical point of view . this be the typical western perspective , somewhat oblivious to the mindset of the true nature of asymmetric warfare <sup> 1 </sup> . this answer will focus on the creation of an aimbot for the exist model of game-play rather than a realistic simulation of geopolitical balance in this decade . we have the objective type list in online resource that provide a game overview , again , narrow in authenticity by the prevailing western view of asymmetric war <sup> 1 </sup> . terminate player of the oppose team plant a bomb toward that end ( terrorists only ) defend hostage ( terrorist only ) prevention of bomb casualty ( counter-terrorists only ) rescue of hostage ( counter-terrorists only ) ballistic control the targetting of the body or head of an opponent be within the scope of what image recognition can do in conjunction with a movement model . in military application , aeronautic device must be propel against air friction and the propulsion require a largely exothermic reaction like combustion . thus all target have a heat signature , which can be recognize in an infrared video stream in such a way a to plot an intercept course for the ballistic weapon . the targetting formulation for c : go be not a complex and aim and firing may be fully automate with much less software machinery . a lstm with sufficient speed can be train to recognize a head in subsequent frame and terminate opponent even if move . a simple web search for lstm will provide a plethora of resource to the novice intend to learn about image recognition . one ambiguity whether the second objective can be meet be dependent on what be mean by the term , " view angle , " in the context of image recognition . can the player see from perspective other than the location of their eye ? if so , this answer can be adjust if give a clear picture of what be mean . training and re-entrant learn training of an artificial neural net to target a head be unnecessary unless the 3d rendering of the game object and player be distort by a wide angle virtual lens and trajectory and movement be curve . a mentioned lstm can be use to locate a head in multiple frame and extrapolate an oppose player trajectory . where deep learning may be most effective be in the training of how to interact with the player to best assist . also , if there be other non-targeting technique that be more discrete , those who play c : go well could record their interaction and those recording can be process in preparation for use a training data . certainly a re-entrant learning strategy such a reinforcement be useful for game-play especially if the make up of team change and player exhibit different behavior , execute differ strategy over different network with different latency and through-puts , and communicate with the game client through different peripheral device . [ deepmind lab test bed for reinforcement technology ] ( } more than suggestion with proper architecture , more than suggestive strategy can be provide to the player . statistical dashboard , identification of a bomb before or after plant , and identification of hostage should be among the aimbot service provide , which might suggest a new name , such a obot for objective bot or asbot for assistive bot . it be not certain that the aimbot interface need be integrate with dashboard or bomb or hostage identifier . sometimes independent bot provide a more flexible arrangement for a user . individual bot can always use the same underlying image recognition component and model . entry point into develop such a system read some of the work on the above concept and download what code you can find that demonstrate it in python or java , install what be necessary , and develop some proficiency with the component discuss above as well a the associated theory . don't shy away from the math , since success will require some proficiency with feedback signalling and concept like gradient descent and back-propagation . reinforcement in game lstm head locate play atari with deep reinforcement learning , mnih et al . , 2013 phase approach the follow phase research and development approach be suggest . learn the theory practice the theory in code develop the image recognition front end develop the library to control a virtual player develop at least one of the above model create the simple bot to use it expand automation from there footnote [ 1 ] in asymmetric power struggle , there be always at least two faction within each side because didactic legitimacy seek division . unity be not practically possible . each real team usually have a more religious and more secular faction , each of which have economic , philosophic , and historical justification for their position and agenda . also , terrorists don't seek the public detonation of bomb or retention of hostage a objective but rather a mean , with the total elimination of all not fully adhere to their view of legitimacy a the sole endgame objective . suicide or high risk bombing be consider by most of those that employ it a the poor man's nuke , so without nuclear strike capability for the counter-terrorists and their ally , the terrorism lack the important dimension of last resort . the last resort aspect of nuclear strike be miss from the counter-terrorist side too . c : go may sell good by gloss over these particular characteristic of asymmetric warfare and such be leave out deliberately . there may be some benefit to add these feature in from an educational and anti-propaganda point of view .******none******Sep 13, 2018******2******CA
3******i'm confuse regard a specific detail of mcts . to illustrate my question , let take the simple example of tic-tac-toe . after the selection phase , when a leaf node be reach , the tree be expand in the so called expansion phase . let say a particular leaf node have 6 child . would the expansion phase expand all the child and run simulation on them ? or would the expansion phase only pick a single child at random and run simulation , and only expand the other child if the selection policy arrive at them at some late point ? alternatively , if both of these be accepted variant , what be the pro / con of each one ?monte carlo tree search expansion phase******monte carlo tree search expansion phase******Sep 07, 2018******2******CA
1******by far the most common ( and likely also the most simple / straightforward ) implementation be to expand exactly one node in the expansion phase ; specifically , the node correspond to the very first state select ( semi - ) randomly by the play-out phase . this be also pretty much the bare minimum you have to do if you want any form of tree grow at all ( which you do ) . other variant be possible too , but be much less common . the variant you suggest in the question be to expand all the child of the final node encounter during the selection phase , and run a play-out for all of them . i be not familiar with any literature on such a strategy really , never try that myself . intuitively , i would expect it to perform very similarly , perhaps slightly bad . essentially what this would do be that it move the " behaviour " of the search algorithm slightly more towards breadth-first search behaviour , rather than best-first search behaviour . you spend a bit less of your computation time in the selection phase , because every selection phase be follow up by for example 6 ( or whatever branch factor you have ) play-outs instead of just a single one . on average i'd expect this to be slightly bad , because the selection phase be the primary source of the " best-first search " behaviour of the algorithm . i certainly don't expect a change like this to cause a large difference in performance though , if any . it will also likely be domain-dependent ; worse in some case , well in other case . a different variant that i do once use myself be to expand every node in the complete line of play follow by the play-out phase . you can visualize this a a very " thin " , but " deep " expansion , whereas your suggestion discuss above would be visualize a a " shallow " but " wide " expansion ( and the conventional expansion strategy of a single node would be " thin " and " shallow " ) . for this strategy , it be much easy to clearly define the advantage and disadvantage that it have in comparison to the standard strategy . the main advantage be that you retain more information from your play-outs , you throw less information away . this be because the backpropagation phase , after the play-out terminates , can only store information in node that exist . if you immediately expand the complete line of play follow in the play-out phase , you can store the result ( the evaluation in the terminal state ) in all of those node . if you don't expand the complete play-out ( e . g . only expand the very first node ) , you'll have to " skip " all of those node which you didn't expand yet ( they don't exist ) , and you can't store result in there yet . the main disadvantage of this approach be that it require more memory , the tree grow a lot more quickly . i would personally recommend this approach if you have very strict limitation on computation time , if you expect to be able to only run very few iteration of the mcts algorithm . for example , i personally use this in my general video game ai agent ; this be a real-time game where you have to make decision every ~ 40 millisecond . in such a low amount of time , you cannot run many mcts simulation . this mean that : you do not expect to run out of memory , even if you grow your tree very quickly , so the increased memory requirement become a non-issue . due to the low expect number of iteration , it be extremely important to retain a much information a possible , not throw any information away . if we can't run many simulation , we want to make sure to squeeze every little bit of information we can out of each of them . for contrast , if you're develop an agent to play a board game , and it have in the order of multiple minute of thinking time per turn , the standard approach of only expand a single node per expansion phase become a lot more appealing . if you're capable of run ten of thousand of iteration or more , it really doesn't hurt if you " forget " about a little bit of information deep down in the tree . the risk of run out of memory also become a lot more serious if you're run many iteration , so you don't want to grow the tree too quickly .******none******Sep 07, 2018******2******CA
4******connect 6 be an example of a game with a very high branching factor . it be about 45 thousand , dwarf even the impressive go . what algorithms can you use on game with such high branching factor ? i try mcts ( soft rollouts , count a ply a place one stone ) , but it do not even block the opponent , due to the high branching factor . in the case of connect 6 , there be strong ais out there , but they aren't describe in any research paper that i know of .algorithms for games with very high branching factors (connect6)******algorithms for games with very high branching factors (connect6)******Sep 07, 2018******2******CA
5******typically , monte-carlo tree search ( mcts ) actually be the go-to " solution " for such problem with large branch factor . i can understand that " vanilla " mcts may still have unsatisfactory performance , but there be a plethora of extension / enhancement available . i don't have experience with the specific game you mention ( connect 6 ) , but from a quick look at how the game work , i imagine there will be a huge number of transposition in the search tree ( position that be the same but can be reach through multiple different path in the search tree ) . this will especially be very common if you treat place one stone a a single ply ; every " combine move " ( of place two stone in two position subsequently ) can be reach in two different way , simply by switch the order in which the player place them . there have be research in use transposition table with mcts , so that may be a promising direction to look into . i also suspect there will be great value in use deep ( reinforcement ) learning approach . if there be a large board on which to place stone , there will likely be many move that be " absurd " and can easily be dismiss altogether by deep learning approach ( e . g . , place stone far away in a corner of the board where none of the " action " be go on ) . vanilla mcts , without deep learning extension , will not be able to recognize and dismiss such absurd move , and play them way too often ( in play-out but also selection phase due to the high branching factor ) . the most obvious source of inspiration here would be alphago zero . finally , there's definitely some publish research on connect 6 ai ( and even mcts in connect 6 ) . for example : two-stage monte carlo tree search for connect 6 . you can likely also find more relevant research by check that paper's list of reference , and check late paper on google scholar that cite this one .******none******Sep 08, 2018******2******CA
1******i be recently peruse the paper ( a . l . samuel , 1967 ) , which be interest historically . i be look at this figure , which involve alpha-beta pruning . it occur to me that the type of non-trivial , non-chance , perfect information , zero-sum , sequential , partisan game utilized ( chess , checker , go ) involve game state that cannot be precisely quantify . for instance , there be no way to ascribe an objective value to a piece in chess , or any give board state . in some sense , the assignment of value be arbitrary , consist of estimate . the combinatorial game i'm work on be form of partisan sudoku , which be bid / scoring ( economic ) game involve territory control . in these model , any give board state produce an array of ratio allow precise quantification of player status . token value and position can be precisely quantify . this project involve a consumer product , and the approach we're take currently be to utilize a series of agent of increase sophistication to provide different level challenge for human player . these agent also reflect what be know a a " strategy ladder " . reflex agent ( beginner ) model-based reflex agent ( intermediate ) model-based utility agent ( advance ) goal may also be incorporate to these agent such a desired margin of victory ( regional outcome ratio ) which will likely have an effect on performance in that narrow margin of victory appear to entail less risk . the " respectably weak " v . human performance of the first generation of reflex agent suggest that strong gofai might be possible . ( the branching factor be extreme in the early and mid-game due to the factorial nature of the model , but initial calculation suggest that even a naive minimax lookahead will be able to look far more effectively than human . ) alpha-beta pruning in partisan sudoku , even sans a learning algorithm , should provide great utility than in previous combinatorial game model where the value be estimate . be the historical weakness of gofai in relation to non-trivial combinatorial game partly a function of the structure of the game study , where game state and token value cannot be precisely quantify ? look for any paper that might comment on this subject , research into combinatorial game where precise quantification be possible , and thought in general . i'm try to determine if it might be worth attempt to develop a strong gofai for these model prior to move up the ladder to learn algorithm , and , if such a result would have research value . there would definitely be commercial value in that strong gofai with no long-term memory would allow minimal local file size for the apps , which must run on lowest-common-denominator smartphones with no assumption of connectivity . p - my previous work on this have involve define the core heuristic that emerge from the structure of the model , and i'm slowly dip my toe into the look ahead pool . please don't hesitate to let me know if i've make any incorrect assumption .historical weakness of gofai in relation to partisan combinatorial games?******historical weakness of gofai in relation to partisan combinatorial games?******Sep 11, 2018******2******CA
2******nice question ! i think there be a couple of issue at work here . be the historical weakness of gofai in relation to non-trivial combinatorial game partly a function of the structure of the game study , where game state and token value cannot be precisely quantify ? i think the short answer be yes . the real issue be in the last part : token value cannot be precisely quantify the most successful gofai approach to these game be all some variation on a * search , combine combinatorial search with some form of heuristic function that estimate the value of the piece and their position in any give state . piece counting be probably a well heuristic than not count anything at all , but it's still clearly incorrect , because a player with less material may still have an overwhelming positional advantage . some heuristic can try to estimate this positional advantage as well however . the real problem that gofai encounter in these game be that positional advantage can be emergent in way that require incredible heuristic power to detect . checker be a good example . in the 1990 ' s , the chinook project at the university of alberta set out to solve it completely . checker be notable because it have the same world champion for more than 15 consecutive year , marion tinsley . tinsley lose a total of 7 competitive match over 40 year of play . this make him an especially interesting person to examine when we look at combinatorial game . figure out how tinsley play can help u understand how human intelligence work in game like this . in the course of solve checker , the researcher note that tinsley be make move that require up to 42 move lookaheads to reveal an advantage ( see schaeffer et al . , ai magazine , vol . 17 , issue 1 ) . this strongly suggest that tinsley be not methodically consider each possible move . instead , by his own admission , his thinking be guide by a combination of memory over his 40 year career ( in one match against chinook in 1992 , he indicate he be try to recall a sequence from a match 30 year prior when make a move ( ai magazine volume 14 , number 2 ); and of attentional heuristic ( i . e . not think about every move sequence , and be able to reliably rule out part of the search space without look at them ) . the key be that for gofai to solve checker without heuristic ( i . e . to solve it exactly ) , require enormous amount of computational power , because some move yield positional advantage that require 40 + move of followthrough . even an incredibly simple game ( branch factor of 2 ) would be hard under that constraint . in contrast though , self-play technique like those pioneer in backgammon with td-gammon ( tesauro , comm . of the acm 1995 ) mimic the process through which tinsley become so good : they play lot and lot of game , learn a good heuristic estimate of position and material value , and more importantly , can learn to remember odd circumstance that require careful play . td-gammon achieved worldclass play despite only explicitly look 2 move ahead . gofai search technique weren't even close despite search much more deeply . modern research on attention could salvage the gofai approach however . if you can learn to tell what's important , you might be able to get a lot more value out of deep lookaheads . this seem even closer to how tinsley played : great ability to estimate value be use to guide an explicit analysis of a specific chain of move .******none******Sep 12, 2018******2******CA
1******be it possible for a genetic algorithm + neural network that be use to learn to play one game such a a platform game able to be apply to another different game of the same genre . so for example , could an ai that learn to play mario also learn to play another similar platform game . also , if anyone could point me in the direction of material i should familiarise myself with in order to complete my project .can genetic algorithms be used to learn to play multiple games of the same type?******can genetic algorithms be used to learn to play multiple games of the same type?******Sep 14, 2018******2******CA
0******definitely depend on the design of your algorithm . accord to my knowledge , almost all ml algorithm be target at specific issue , thus it ’ s difficult for general usage . and you have to train again for any new issue . it ’ s also difficult to understand the internal working mechanism of those ai algorithm due to general statistic method ( and yes , they call ai ) . i will recommend a regional / encapsulate method apply on general method , therefore algorithm be not specific and micro-structured for general purpose . if game be similar , definitely we can apply on both with appropriate design method . hinton have start his capsule network which i think be a good direction . just beware , train shouldn ’ t be specific object relate . instead , it should be micro-structure related or feature ( it ’ s hard to differ current ai feature from human insight feature ) . for example , human can easily differ difference even though never see those before . and human do not have to re-train nerve unit except for good understanding or accuracy . genetic algorithm should have the same ability to survive in different but similar environment . unfortunately , we be at the beginning of ai era but also luckily we have a lot to do . in fact , almost all current tech imitate the nature . if the nature can , definitely we can at one day .******none******Sep 14, 2018******2******CA
0******genetic algorithm can learn multiple game , yes , in fact genetic algorithm be a bad term to describe this family , there be only one generic genetic algorithm with many variation depend on the problem at hand . i recommend this pdf for a introduction on how they work and how to build them :******none******Sep 14, 2018******2******CA
3******genetic algorithm and neural network both be " general " method , in the sense that they be not " domain-specific " , they do not rely specifically on any domain knowledge of the game of mario . so yes , if they can be use to successfully learn how to play mario , it be likely that they can also be apply with similar success to other platformers ( or even completely different game ) . of course , some game may be more complex than others . learn tic tac toe will likely be easy than mario , and learn mario will likely be easy than starcraft . but in principle the technique should be similarly applicable . if you only want to learn in one environment ( e . g . , mario ) , and then immediately play a different game without separately train again , that's much more complicated . for research in that area you'll want to look for transfer learning and / or multi-task learning . there have definitely be research there , with the late development that i'm aware of have be publish yesterday ( this be deep reinforcement learn though , no gas i think ) . the most " famous " recent work on train neural network to play game use genetic algorithm that i'm aware of be this work by uber ( blog post link to multiple paper ) . i'm not 100 % sure if that really be the state of the art anymore , if it's the best work , etc ... i didn't follow all the work on gas in sufficient detail to tell for sure . it'll be relevant at least though . i know there's also be quite a lot of work on ai in general for mario / other platformers ( for instance in venue such a the ieee conference on computational intelligence and game , and the tciaig journal ) .******none******Sep 14, 2018******2******CA
1******i have create a game base on this game here . i be attempt to use deep q learn to do this , and this be my first foray into neural network ( please be gentle ! ! ) i be try to create a nn that can play this game . here be some relevant fact about the game : player 1 ( the fox ) have 1 piece that he can move diagonally 1 step in any direction player 2 ( the goose ) have 4 piece that they can move only forward diagonally ( either diagonal left or diagonal right ) 1 step . the fox win if he reach the other end of the board , the geese win if they trap the fox so it cannot move . i be try to work on the agent first for the geese a it seem to be the harder agent with more piece and restriction . here be the important section of code i have so far : this be where i setup the game board , and set the total action for the geese and here be where i create my model this be where i perform an action my question : since there be 4 geese and each can make 2 possible move , be i correct in thinking that my action_size should be 8 ( 2 for each goose ) or should it be maybe 2 ( for diagonal leave or right ) or something else entirely ? the reason why i be at a loss be because on any give turn , some of the goose may have an invalid move , do that matter ? my next question : even if i have the right output layer for the geese agent , when i call where i pick my action ... how do i interpret the output ? and how would i map that action it select to a valid action that can be make ? here be a picture of the result of use , a you can see it return a ton of data and then when i call i get 59 back ... not sure how to utilize that ( or if it's even correct base on my output layer ) ... and finally i include a drawing of the board . f be the fox and 1,2 , 3,4 be the different goose . i apologize for the massive post , but i be just try to provide a much information that be helpful .mapping actions to the output layer in keras model for a board game******mapping actions to the output layer in keras model for a board game******Sep 20, 2018******2******CA
1******the wumpus world propose in book of stuart russel and peter norvig , be a game which happen on a 4x4 board and the objective be to grab the gold and avoid the threat that can kill you . the rule of game be : you move just one box for round start in position ( 1,1 ) , bottom leave you have a vector of sensor for perceive the world around you . when you be next to another position ( include the gold ) , the vector be ' activate ' . there be one wumpus ( a monster ) , 2-3 pit ( feel free to put more or less ) and just one gold pot you only have one arrow that fly in a straight line and can kill the wumpus enter the room with a pit , the wumpus or the gold finish the game scoring be a follow : + 1000 for grab the gold , - 1000 for die to the wumpus , - 1 for each step , - 10 for shoot an arrow . fore more detail about the rule , chapter 7 of the book explain them . well now that game have be explain , the question be : in the book , the solution be demonstrate by logic and searching , do there exist another form to solve that problem with neural network ? if yes , how to do that ? what topology to use ? what paradigm of learning and algorithm to use ? 1 * : my english be horrible , if you can send grammar correction , i'm grateful . 2 * : i think this be a bit confusing and a bit complex . if you can help me to clarify good , please do commentary or edit !does a solution for wumpus world with neural networks exist?******does a solution for wumpus world with neural networks exist?******Sep 20, 2018******2******CA
2******yes ! if you read ahead to the chapter in reinforcement learning in the same book , you'll see that the wompus world appear again there . technique like q-learning can be use to solve it , and since q-learning involves learn the shape of a function , a neural network can be employ a a function approximator . the basic idea be to treat this problem a an input / output mapping ( state -> action ) , and to learn which action produce the great reward . note however , that these approach rely on trial and error . the logic base approach reason about the rule of the game , and can play reasonably well right away . the learn approach will need to try and fail many time before play well .******none******Sep 21, 2018******2******CA
0******i'm try to implement an algorithm that would choose the optimal next move for the game of connect 4 . a i just want to make sure that the basic minimax work correctly , i be actually test it like a connect 3 on a 4x4 field . this way i don't need the alpha-beta pruning , and it's more obvious when the algorithm make a stupid move . the problem be that the algorithm always start the game with the leftmost move , and also during the game it's just very stupid . it doesn't see the best move . i have thoroughly test method , , , and so i be absolutely sure that the problem be not there . here be my algorithm . nextmove.java the algorithm the idea be that the algorithm take in the argument of a and the . then it check if the last move somehow finish the game . if it do , i just return that move , and otherwise i go in-depth with the subsequent move . blue player be max , red player be min . in each step i first undo the last move , because it's easy to check if the " next " move will finish the game , than check if the current field be finish ( this would require to analyze for all possible winning option in the field ) . after i check , i just redo the move . from some reason this doesn't work . i be stick with that for day ! i have no idea what's wrong ... any help greatly appreciate ! edit i'm add the code how i'm invoke the algorithm .connect 4 minimax does not make the best move******connect 4 minimax does not make the best move******Sep 23, 2018******2******CA
1******i suspect that you'll have to remove this code : from the method , and remove this code : from the method . in the first case , you're check whether the move that red just make be a winning move . you don't want to check there if it be a win move from blue , because it wasn't blue who just make that move ; it be red . the same count the other way around in the second case . additionally , the initial call into the algorithm seem overly complicate . i be not sure what the intended use of the variable there be , or that call . i would rewrite it to be more like : this will require an adaptation of the and method such that they skip the whole checking-for-wins thing if the previous equal . with the code you currently have there , you do not perform a minimax search for the optimal move in the current game state ; instead you first arbitrarily modify the current game state use that call , and perform the minimax search in that arbitrarily modify game state . the optimal move to play in such an arbitrarily-modified game state will tend not to be the optimal move in the game state that you really be in .******none******Sep 23, 2018******2******CA
0******i ’ ve see some paper use neural network a evaluation function to evaluate game state . i wonder if they can value the state to train the neural network , isn ’ t the function that be use to value the state a evaluation function and aren ’ t the neural network and the function the same ?how does using neural network to improve evaluation function work?******how does using neural network to improve evaluation function work?******Sep 30, 2018******2******CA
0******example : texas holdem poker v texas holdem poker with the same round , just with no public card dealt . would algorithms like cfr approximate nash-equilibrium more easily ? could ai that do not look at public card achieve similar performance in normal texas holdem a ai that look at public state tree ?what's the difference between poker with public cards and without them?******what's the difference between poker with public cards and without them?******Oct 06, 2018******2******CA
1******it depend a little on what you mean by " the same round , just with no public card dealt . " if you mean that each player will just be dealt 2 card , and no public card exist , then really we're play a sort of " high card " game . the best hand be just a pair of ace , cfr will solve this quickly , because the number of possible game state be extremely small compare to a full poker game ( especially if we exploit the symmetry of suit , since flush aren't possible ) . if you mean that each player will be dealt 5 card , with several round of bet a before , cfr will probably do less well . the state space will be large , since there be more card in play ( 10 instead of 9 ) . betting may become more complex , and more complex betting expand the state space enormously . if you mean that the card be deal a before , but the program simply will not look at the card , then you've keep the state space of the game the same size , but radically reduce the number of information set . play against an opponent who can look at the card on the table , your program would be at an enormous disadvantage . for instance , imagine the card on the table be " 3 3 8 8 5 " , and that you have a pair of 2 ' s in your hand . you would want to play very differently from if the card on the table be " 2 2 10 4 7 " , but an ai without access to the table card would have to act the same in both situation .******none******Oct 06, 2018******2******CA
1******i'm program on connect 6 with mcts . monte carlo tree search be base on random move . it count up the number of win in certain move . ( whether it win in 3 turn or 30 turn ) be the move with less turn more powerful than the move with more turn ? ( a mcts just see if it's win or not - - not consider the number of turn it take to win ) and if so , be it meaningful to give big weight to the one with less turn win ?is it meaningful to give more weight to the result of monte carlo search with less turn win?******is it meaningful to give more weight to the result of monte carlo search with less turn win?******Oct 07, 2018******2******CA
1******traditionally ( when not consider your idea ) , the evaluation function for terminal game state would be implement to return < span class = " math-container " > $ 1 $ </span> , < span class = " math-container " > $ 0 $ </span> , or < span class = " math-container " > $ - 1 $ </span> for win , draw , or loss , respectively . change that in a naive / straightforward way to make short-term win more rewarding , long-term win less rewarding , short-term loss more negative , and long-term loss less negative can be dangerous , it may change the objective that your agent be ultimately optimize for ( i . e . may lose the guarantee of converge towards optimal play give an infinite amount of time ) if not do very carefully . there be definitely value in consider the idea though , especially because in the play-out phase of mcts , trajectory of ( semi - ) random move introduce uncertainty in the evaluation at the end of those simulation , and this uncertainty increase a the length of the trajectory increase ( due to increased number of uninformed decision be make along the trajectory ) . note that it be especially important to take into consideration here the number of move play in the play-out phase , not necessarily include the number of move make in the selection phase ( which be select accord to a much more informed strategy ) . one paper i know of that investigate idea along these line be " quality-based reward for monte-carlo tree search simulation " .******none******Oct 07, 2018******2******CA
3******i'm make a connect four game use the typical minimax + alpha-beta prune algorithm . i just implement a transposition table , but my test tell me the tt only help 17 % of the time . by this i mean that 17 % of the position my engine come across in it calculation can be automatically give a value ( due to the position be calculate previously via a different move order ) . for most game , be this figure expect ? to me it seem very low , and i be optimistically hop for the tt to speed up my engine by around 50 % . it should be note though that on each turn in the game , i reset my tt ( since the evaluation previously assign to each position be inaccurate due to lower depth back then ) . i know that the effectiveness of tt's be largely dependent on the game they're be use for , but any ballpark of how much they speed up common game ( chess , go , etc ) would be helpful . edit - after run some more test and adjust my code , i find that the tt speed up my engine to about 133 % ( so it take 75 % a much time to calculate ) . this mean those 17 % node be probably fairly high up in the tree , since not have to calculate the evaluation of these 17 % speed up thing by 33 % . this be definitely well , but my question still remain on whether this be roughly expect performance of a typical tt .transposition table is only used for roughly 17% of the nodes - is this expected?******transposition table is only used for roughly 17% of the nodes - is this expected?******Oct 14, 2018******2******CA
2******i don't think that's necessarily a strange number . it's impossible for anyone to really tell you whether that 17 % be " correct " or not without reproduce it , which would require much more info ( basically would have to know every single tiny detail of your implementation to be able to reproduce ) . some thing to consider : the size of your transposition table / the number of bit you use for index into the tt . if you have a relatively small tt , mean you use relatively few bit for indexing , you'll have big probability of collision . that mean you will have to replace exist entry more often , which mean they might no longer be in the table anymore by the time you encounter transposition during the search . where in the search tree be the node locate that be recognize a transposition already in the table ? if you detect transposition very high up in the search tree , you save a lot more search time than if you detect a transposition somewhere deep down in the search tree ; once you detect a transposition that have already be search sufficiently deep for the value store in the table to be valid , you can cut off the complete subtree below that node from the search . this become more valuable a it happen closer to the root . so , just the number " 17 % of node " doesn't really tell u much . be you use iterative deepening ? since you mention only minimax + alpha-beta pruning in the question , i suspect you're not use iterative deepening . tt become significantly more valuable once you do use iterative deepening , because then almost every state encounter become a " transposition " . you'll already have see all those state in a previous iteration with a low search depth limit . now , it be important to note with this combo of id + tt , that you can no longer completely cut off search for all recognize transposition . if an entry in the table hold a value that be compute with a search depth of < span class = " math-container " > $ d $ </span> , that value will no longer be valid when perform a subsequent iteration of id with a max search depth of < span class = " math-container " > $ d + 1 $ </span> for example . however , that " outdated " value store in the tt can still be use for move ordering , which can lead to significantly more pruning from alpha-beta pruning . how efficient be the remainder of your engine ? a tt be not 100 % free , it take a bit of additional time too ( for example to compute the hash value for your game state ) . if the rest of your engine be relatively slow ( i . e . inefficient implementation for play move , copy game state , etc . ) , the computational overhead of the tt won't matter much and even a low number of recognize transposition will still be valuable . if the rest of your engine be very fast , it'll be more important to have a high number of transposition for the tt to be really valuable . a an " educate guess " , i'd say the number of 17 % you describe be not necessarily strange . especially give your edit to the question , where you indeed mention that it be likely that transposition be find high up in the tree ( close to the root ) . when this happen , you immediately remove the probability of recognize all those state deeper down in the tree of get recognize a transposition yourself . so , the pool of state that could " potentially " be find in the tt be much less than 100 % of the state store in the tt . it's really just that though , just an educated guess . it's go to be very difficult for anyone to give a conclusive " yes " or " no " .******none******Oct 14, 2018******2******CA
1******i have cod an ai checker game but would like to see how good it be . some people have inform me to use the chinook ai opensource code . but i be have trouble try to integrate that software into my ai code . how do i integrate another game engine in checker with the ai i have cod ?checkers ai game engines******checkers ai game engines******Oct 15, 2018******2******CA
0******i already know the basic of the basic of machine learning . e . g . : backpropagation , convolution , etc . first of let me explain reinforcement learn to make sure i grasp the concept correctly . in reinforcement learn a random-initialized network will first " play " / " do " a sequence of move in an environment . ( in this case a game ) . after that , it will receive a reward < span class = " math-container " > $ r $ </span> . furthermore a q-value get define by the engineer / hooby coder . this reward time the q-value < span class = " math-container " > $ q $ </span> to the power of the position < span class = " math-container " > $ n $ </span> of the action will be feed back use bp . so how do i know how slight chance in < span class = " math-container " > $ \ vec { w } $ </span> be change < span class = " math-container " > $ rq ^ n $ </span> ?how do i know how changes in the weights are changing the reward in reinforcement learning******how do i know how changes in the weights are changing the reward in reinforcement learning******Oct 16, 2018******2******CA
2******you have the concept slightly wrong . this part be mostly correct : in reinforcement learn a random-initialized network will first " play " / " do " a sequence of move in an environment . ( in this case a game ) . after that , it will receive a reward r . technically neural network be not require in rl , and it be really worth study some simple system that don't need them . it will make everything much clearer . a reward < span class = " math-container " > $ r $ </span> can be receive on every time step . however , some environment will only have a single reward at the end for success or failure for a whole episode - e . g . an instance of a game like chess where a player win or lose . this part be where thing go a bit off track : furthermore a q-value get define by the [ developer ] . this reward time the q-value q to the power of the position n of the action will be [ feed ] back use bp . q value be one type of data that can be calculate for an agent act in a markov decision process . they be also call " action value " and they be not usually define by a developer . the q value , if correct should return the expected future sum of reward from follow a current policy . one way of write this be : < span class = " math-container " > $ $ q ( s , a ) = \ mathbb { e } _ { \ pi } [ \ sum _ { k = 0 } ^ { \ infty } \ gamma ^ k r_ { t + k + 1 } | s_t = s , a_t = a ] $ $ </span> in natural language , the q value for state s and action a be the expected value ( when follow the give policy ) of the discount sum of reward , start from the give state and action . the discount factor , < span class = " math-container " > $ \ gamma $ </span> can take any value from < span class = " math-container " > $ 0 $ </span> up to < span class = " math-container " > $ 1 $ </span> , but only strictly episodic problem ( which always terminate ) should use the value < span class = " math-container " > $ 1 $ </span> a developer do not get to define that ( except they might get to choose reward system and value of < span class = " math-container " > $ \ gamma $ </span> ) . instead , they need to implement something that estimate the value of < span class = " math-container " > $ q ( s , a ) $ </span> base on what the agent have experience . there be a few different algorithm that can do this . a popular one be call q learn . regard " [ feed ] back use bp " , this be correct if you be use a neural network . typically in dqn ( q learn with neural network ) , this just consist of create a small sample of train data from recent experience and train the neural network almost identically to supervise learning . so how do i know how slight chance in < span class = " math-container " > $ \ vec { w } $ </span> be change < span class = " math-container " > $ rq ^ n $ </span> ? definitely don't use < span class = " math-container " > $ rq ^ n $ </span> - there be no purpose to that quantity in rl . instead for value-based rl , you be mostly interested in your estimate for q value . this might be write < span class = " math-container " > $ \ hat { q } ( s , a , \ vec { w } ) \ approx q ( s , a ) $ </span> . however , in general your question stand . if you have implement a neural network to learn q value , how do you know if it be work ? there be actually two part to this problem : how do you know whether the agent be get well at it's task ? how do you know whether the q value be get more accurate ? what you need to do be measure , and maybe plot some relevant quantity . for the first question , you would typically plot the total reward that the agent get each episode . this will be noisy , so it be a good idea to smooth it out by take some kind of move average ( e . g . average total reward over last 100 episode ) . for the second question , it be normal to plot some loss function of the network , just like supervise learning . typically this be mean squared error loss , a the network be learn a regression to predict q value give < span class = " math-container " > $ s $ </span> and < span class = " math-container " > $ a $ </span> . you can compare observed sum of discount reward ( aka " return " or " utility " ) with the early predicted one , and take the error function . you need to get some measure of a " true " value of q - usually a noisy sample take during training or testing , and measure loss . for mse that might be < span class = " math-container " > $ $ j ( \ vec { w } ) = \ frac { 1 } { 2 | d | } \ sum _ { ( s , a ) \ in d } ( \ hat { q } ( s , a , \ vec { w } ) - q ( s , a ) ) ^ 2 $ $ </span> where < span class = " math-container " > $ d $ </span> be some dataset you have put together of < span class = " math-container " > $ s , a $ </span> and < span class = " math-container " > $ q ( s , a ) $ </span> measurement to test with . if this look familiar to you from supervise learn mse loss , then that's correct - it be essentially the same thing , just different how you go about collect the data . you may expect the loss function for < span class = " math-container " > $ \ hat { q } $ </span> in q learning to be somewhat unstable a the agent learn . that's because in q learning , the policy be update at the same time a the estimate be improve . which make the estimate out-of-date . however , it should still be possible to see a reduction in error a learning progress . if it become stable at a relatively low value compare to initially , then the agent have probably learn all that it can - although sometimes new discovery by the agent can open up more improvement , even late in training , and throw the error function out again . note that a low value of the error function do not mean you have an optimal agent . it mean that the value function estimate be good for how the agent be currently behave . in turn that mean the agent cannot make further improvement without new and different experience .******none******Oct 16, 2018******2******CA
1******until now , i always think that genetic algorithm can be use for problem of which the solution space can be encode ( model ) a a chromosome of a specific length . however , some people claim that they use ga for this game and this game . they be basically game in which we control an agent on a 2 - dimensional area . obviously , the length of the genome sequence depend on how fast the game be finish . so , how be ga use for such game ? if you think ga be not the most suitable method for this kind of problem can you explain why and give good alternative ?how to use genetic algorithm for varying lengths of solutions******how to use genetic algorithm for varying lengths of solutions******Nov 02, 2018******2******CA
0******i make a connect four engine that use the standard minimax / alpha-beta algorithm a it underlying structure , with iterative deepening add on . because the engine use iterative deepening , it think process follow this pseudo-code : in my test program that allow two engine to play against each other , the two engine take turn play both side of a randomly select position ( and i ensure the position be reasonable to play ) . so in each trial , possible score be 2-0 , 1.5- 5 , 1-1 , 0.5- 1.5 , 0-2 . when i get my iterative deepening engine to play against an exact copy of itself in this test program , the overall match score for x number of trial tends to be roughly level . however , there be some trial where one engine do good than the other engine ( like 2-0 or 1.5- 0.5 ) . this seem odd , since the engine have the same code . what i suspect be happen be that since the engine think for a certain period of time , how much it calculate isn't deterministic . i've make sure to do nothing else on my computer while the test program run , but there's obviously background process in my computer that i can't control . question : be it normal for two identical iterative deepening engine , when give an equal amount of time to think , to not always be exactly the same in strength ? bonus question : be there even a way for me to test that two such engine be exactly equal ?my iterative deepening engine doesn't have an exactly equal score when playing against itself******my iterative deepening engine doesn't have an exactly equal score when playing against itself******Nov 18, 2018******2******CA
0******in evolutionary computation and in particular in the context of genetic algorithm , there be a stochastic operation call " fitness function " . the good a state , the great the value of the fitness function for that state . what would be a good fitness function for the 8 - queen problem ?how to calculate fitness function of 8-queens problem?******how to calculate fitness function of 8-queens problem?******Nov 22, 2018******2******CA
0******here you can find an example of how to apply genetic algorithm to solve the 8 - queen problem . the proposed fitness function be base on the chessboard arrangement , and in particular , it be inversely proportional to the number of clash amongst attack position of queen ; thus , a high fitness value imply a low number of clash .******none******Nov 24, 2018******2******CA
6******from deepmind's research paper on arxiv.org : in this paper , we apply a similar but fully generic algorithm , which we call alphazero , to the game of chess and shogi as well a go , without any additional domain knowledge except the rule of the game , demonstrate that a general-purpose reinforcement learn algorithm can achieve , tabula rasa , superhuman performance across many challenge domain . do this mean alphazero be an example of agi ( artificial general intelligence ) ?is alphazero an example of an agi?******is alphazero an example of an agi?******Nov 26, 2018******2******CA
7******good question ! alphazero , though a major milestone , be most definitely not an agi :) alphago , though strong at the game of go , be narrowly strong ( " strong-narrow ai " ) , define a strength in a single problem or type of problem ( such a go and other non-chance , perfect information game . ) agi , at minimum , must be about as strong a human in all problem work on or solve by human . agi be often associate with superintelligence , define a intelligence that surpass human level . agi do not necessarily imply super-intelligence , in the sense that we'd consider an android that can perform all human activity with the same capability as human a an artificial general intelligence . but technically , alphago be a narrow superintelligence in that it exceed all human performance in a single problem .******none******Nov 26, 2018******2******CA
1******assumption that may be incorrect there be two assumption identifiable in the tone of the paper . all mental challenge can be reduce to a game with fixed rule . machine well than human be what human really want or need . there be another two identifiable in the question . general intelligence exists in human <sup> 1 </sup> if it exist in human , it be therefore feasible in computer . all four may be true , but none of the four be certain . productivity of alphazero if our chess board be on the game shelf in our closet , our grass be long , and our lawnmower be break , alphazero , if connect to a humanoid robot , would have no game rule encode for the task sequence . listen to it owner's request , learn how to puppet-master the robot , locate and identify all our tool and spare part , fix the lawnmower , and let u know the lawnmower be ready to use . therefore it be of no particular consumer value to u in that scenario . not very general . even if it could mow the lawn with an already work lawnmower , it would be of value , which doesn't require the ability to win anything but rather the ability to obey and exhibit the subhuman intelligence require to not run over the flower bed . that the smart people of deepmind chose to use the latin tabula rasa rather than blank slate be notable , but not nearly as impressive a construct a learning program that can learn to play three game well with only the rule encode and actual game play a input . to consider these game program truly useful in a product space , one cannot rely on a sustained interest in buy software that beat the buyer every time . for ai product to be viable , the learning feature must be capable of what be colloquially called common sense , which require a much wider and flexible domain knowledge than the fixed rule of a game . we can guess that most researcher that have accomplish milestone in win game play learn be push in that direction . they too know their research output must eventually be productized or lead to a purchasable saas offering . what would be impressive to those outside the field be if these advancement can be redirect , in the data center space , to generate remedial gene therapy to cure cancer or herpes or reverse diabetes or alzheimer's . then we could forgive researcher for not provide u with a download that could puppet-master a robot to clean our bathroom . it be not clear from the paper that alphazero have adequately demonstrate that it exhibit , " superhuman performance across many challenge domain . " what they have do be still impressive and along the line down which others have make progress too . few of u would dare try to invent a game that these generic game learn program wouldn't learn fast and defeat u within a few game instance . advance view in perspective certainly in perform arithmetic , sort mail , and now game play , the invention of humanity extend the ability of the naked human , absent of his tool . that progress place computer system firmly within the realm of a tool . a back hoe be superhuman in a way too . try to lay a kilometer of pipe without one . conversely , humanity play the role of health care provider for computer . if they get sick or fail , we be compel to expel their virus and worm or replace their failed part . otherwise our home and business fall into disarray . technology , a in all thing , should be view in perspective . it would be prudent for human to be less enthral with game and beat one another and more focused on collaborative social behavior direct toward solve social and economic problem with it newly invent tool and do so in a way that doesn't create new problem or invite new atrocity . footnote that what have be describe a general intelligence exists in human be disputable on the basis of evidence to the contrary . many would cite these strategy and trend a evidence of limit to human intelligent . nuclear deterrence a a peace strategy a complete lack of moderation in the consumption of finite , critical natural energy resource continuously increase density of addiction pattern globally cause the sixth mass extinction on earth******none******Nov 27, 2018******2******CA
-1******i be currently look into sc2ai . so i start with tackle the minigames - turn out there be a leaderboard for this as well : now how can i submit my bot to compete on the leaderboard ?how do i submit my sc2ai bot to the minigames leaderboard?******how do i submit my sc2ai bot to the minigames leaderboard?******Nov 30, 2018******2******CA
3******i have to build a ki for a made-up game similiar to chess . a i do research for a proper solution i come upon the minmax-algorithm but i'm not sure it will work with the give game dynamic . problem be , in opposition to chess , we have far more possible move : - six piece on the board , with different range . in average there be 8 possible move for a piece per turn . - the player can choose a many piece to move a he like . for example none , all of them , or some number inbetween . ( whereas in chess you can only move one ) so even for the first move the number of branch would be enormous ! actual question : be it after all feasible to implement minmax for the described game ? can alpha-beta-pruning and a refined evaluation function help ( despite of the insane number of possible move ) ? if no , be there a proper alternative ?minmax and enormous branches******minmax and enormous branches******Nov 30, 2018******2******CA
0******a huge “ branch depth ” be a common problem in game ai . the best-practice method to overcome it be heuristic . formalize heuristic in game playing can be do with domain specific language . the assumption be , that a board game solver have certain command like “ pickup figure ” , “ setsearch depth 17 ” or “ search freefield ” . the board game solver be treat a a textadventure which provide a userinterface and allow to formalize all the heuristic in a convincingly way . from a performance perspective such a solver work similar to the minimax algorithm . he have to search in the game tree until he find a solution . the difference be , that the search be fine granular like in a pddl solver . instead of occupy all the cpu core with 100 % the search in the game tree be declare a an art which follow rule . in the cited paper , the manhattan distance be use a an evaluation function . partial evaluation be another promising approach . the idea be to divide the goal into subgoals and solve them separate . romein , john w . , henri e . bal , and dick grune . " an application domain specific language for describe board game . " parallel and distributed processing technique and application . vol . 1 . 1997 .******none******Nov 30, 2018******2******CA
0******- the player can choose a many piece to move a he like . for example none , all of them , or some number inbetween . ( whereas in chess you can only move one ) that quote specifically be the part that really cause the size of your legal action set to blow up . you have a combinatorial action space here . if each of your piece have 8 legal move , then that be : 8 legal move for the first piece ( or 9 if that count didn't already include the " do nothing " option ) for each of those , there be again 8 or 9 different choice for the second piece ( lead to e . g . < span class = " math-container " > $ 8 \ time 8 = 64 $ </span> possible combination for just the first two piece ) for each of those , again 8 choice for the third piece ( lead to < span class = " math-container " > $ 64 \ time 8 = 512 $ </span> possible combination for just the first three piece ) . etc . this blow up way too quickly , and there's really no hope of ever get a decent player for this use any minimax-based algorithm ( include thing like alpha-beta pruning , principal variation search etc . ) . in the kind of game that you describe , you'll want to use algorithm that can exploit the " structure " of your action space . a raw enumeration of all possible combination blow up quickly , but many algorithm can do reasonably well by re-phrasing the problem in such a way that you have more " depth " rather than " breadth " . for example , instead of view a full combination of choice for all piece a a single " action " , you can treat the choice per piece a a separate " action " . rather than make a single choice out of < span class = " math-container " > $ 8 \ time 8 \ time 8 \ time \ dot $ </span> possibility every turn , you want to have a search tree where your player make one choice out of < span class = " math-container " > $ 8 $ </span> ( for the first piece ) , follow immediately by another choice out of < span class = " math-container " > $ 8 $ </span> ( for the second piece ) , etc . the oppose player only get to make a choice after the current player have make choice for all piece . with such a strategy , the breadth of your search tree will no longer be a problem , but the depth will become a problem . to address this , you'll additionally want to make sure that your method can generalize across different depth level . a good place to look would be combinatorial version of monte-carlo tree search , such a those describe in : ( probably a few other publication by the author of that second link ) these algorithm be quite a bit more complicated than minimax though , minimax be a very basic algorithm in comparison .******none******Nov 30, 2018******2******CA
48******obviously driverless car aren't perfect , so imagine that the google car ( a an example ) get into difficult situation . here be a few example of unfortunate situation cause by set of event : the car be head toward a crowd of 10 people cross the road , so it cannot stop in time , but it can avoid kill 10 people by hit the wall ( kill the passenger ) , avoid kill the rider of the motorcycle consider that the probability of survival be great for the passenger of the car , kill animal on the street in favour of human be , change lane to crash into another car to avoid kill a dog , and here be few dilemma : do the algorithm recognize the difference between a human be and an animal ? do the size of the human be or animal matter ? do it count how many passenger it have vs . people in the front ? do it " know " when baby / child be on board ? do it take into the account the age ( e . g . kill the old first ) ? how would an algorithm decide what should it do from the technical perspective ? be it be aware of above ( count the probability of kill ) , or not ( kill people just to avoid it own destruction ) ? related article : why self-driving car must be program to kill how to help self-driving car make ethical decisionhow could self-driving cars make ethical decisions about who to kill?******how could self-driving cars make ethical decisions about who to kill?******Aug 02, 2016******2******CA
3******which deep neural network be use in google's driverless car to analyse the surroundings ? be this information be open ?which machine learning algorithm is used in self-driving cars?******which machine learning algorithm is used in self-driving cars?******Aug 02, 2016******2******CA
1******the most common machine learn algorithms find in self driving car involve object track base technology use in order to pinpoint and distinguish between different object in order to good analyse a digital landscape . algorithm be design to become more efficient at this by modify internal parameter and test these change . i hope that provide a general overview of the subject . since google's car be in development and be proprietary , they will probably not share their specific algorithm , however you can take a look at similar technology to learn more . to find out more , take a look at an oxford-based initiative in self driving car and how they work .******none******Nov 04, 2016******2******CA
2******it will not be single dnn architecture , rather it will be a collection of different dnn architecture that be use together to make the final decision . convolution be use the image / video from the camera . other architecture use other sensory source . these dnns will be train to compute the high-level feature from their sensory source and then those high-level feature will probably be feed into an lstm ( or some other form of rnn ) that be train with some form of reinforcement learn algorithm to compute the action ( like slow down , apply break etc ) .******none******Nov 05, 2016******2******CA
1******the situation : a self-driving car be travel at it's maximum speed , 25 mph ( 40 km / h ) , in the middle of an empty street with the ability to change lane on both side . there be two passenger , one in the front and another in the back . someone jump from the side of the road directly into the path of the car . a collision would occur in 50 meter . break distance at this speed be about 24m . the question : be it know how the current implementation of the google car ai would react , or be it currently a matter of speculation ? a step-by-step explanation of the ai's decisioning process would be prefer . possible answer : the car could activate it brake immediately , come to a halt as quickly a possible . this would be sooner than a human could stop , a people require time to recognize the possibility of a collision , and then physically slam on the brake . ( think distance ) . alternatively , the car could continue travel forward , process the situation . ( similar to a human think distance ) . the person may continue to move , either out of the way , or still into danger of be hit . in this case , the car may decide to change lane in an attempt to pass around the person . lastly and most unlikely , the car will not alter it course and proceed to drive forward . <sup> do not attempt to do it to check ;) </sup>what would happen if someone jumped in the front of a google car?******what would happen if someone jumped in the front of a google car?******Aug 04, 2016******2******CA
2******give this youtube video which be be give by sebastian thrun who have a ted talk which have nowhere near the same level of detail but have similar conclusion , it look like the lidar system use by google's automate car system have decent resolution out to at least 30m pick out mobile body in the static background and then identify it . so it should have plenty of time to brake and stop long before there be any risk to the pedestrian attempting to cross the street . skip to about 6:40 in the video to see a visual representation of the detection system .******none******Sep 01, 2016******2******CA
5******do we know why tesla's autopilot mistake empty sky with a high-sided lorry which result in fatal crash involve a car in self-drive mode ? be it ai fault or something else ? be there any technical explanation behind this why this happen ? reference : sky news article , the verge .why did a tesla car mistake a truck with a bright sky?******why did a tesla car mistake a truck with a bright sky?******Aug 09, 2016******2******CA
1******tesla model s have autopilot which allow to steer within a lane , change lane with the simple tap of a turn signal , and can manage speed by use traffic-aware cruise control . multiple digital control help to avoid collision . base on that , this isn't fully self-driving car . however it be use a computer vision detection system , but it be not intend to be use hands-free . so basically what be know be that the accident involve the side of a truck trailer ( of a large white 18 - wheel truck ) and most likely the camera have a wash out of picture possibly due to glare or bloom from overexposure which make that the side of the trailer white and thin which fail to distinguish with the sky which be bright as well . this may have happen in part , because the crash-avoidance system only engage when both radar and vision system detect an obstacle which could not happen . far more it be suggest by the associated press that the driver most likely be watch a harry potter at the time of the crash and assuming system would alert brown , we don't know if he be able to retake control quickly enough to avoid impact . a mentioned again , the system wasn't intend for hands-free driving and part of the system be unfinished . not to mention that the car be drive with full speed under the trailer . tesla officially say about this crash in a statement on it website : the high ride height of the trailer combine with it positioning across the road and the extremely rare circumstance of the impact cause the model s to pass under the trailer , with the bottom of the trailer impact the windshield of the model s . neither autopilot nor the driver notice the white side of the tractor-trailer against a brightly lit sky , so the brake be not apply . they also say , accord to techno-optimists , that they will tweak their code , so this particular case won't happen again . to summarize , this be a ' technical failure ' of brake system and most likely autopilot be not at a tesla tell senate . <sup> the new york time | source : florida traffic crash report </sup> source : tesla autopilot death highlight autonomous risk layer of autonomy inside the self-driving tesla fatal accident tesla driver dy in first fatal crash while use autopilot mode******none******Aug 12, 2016******2******CA
1******base on this article , google's self-driving car can spot cyclist , car , road sign , marking , traffic light , and pedestrian . how exactly do it identify pedestrian ? be it base on face recognition , shape , size , distance , infrared signature ?how does google's self-driving car identify pedestrians?******how does google's self-driving car identify pedestrians?******Aug 11, 2016******2******CA
3******the ai of the car use sensor data to process all the data and classifies object base on the size , shape and movement pattern . it can recognize surroundings from a 360 degree perspective by make prediction about vehicle , people and object around it will move . it can detect pedestrian , but a moving , column-shaped blur of pixel , so it really cannot tell whether it's a rock or a crumpled piece of paper . however it be program to determine certain pattern when a police officer have halt traffic or the car be be signal to move forward . it also recognize cyclist a object outline in red and can slow down to let the cyclist enter into a lane . <sup> above image be provide by chris urmson who head up google's driverless car program . </sup> source : how google's self-driving car see the world hidden obstacle for google ’ s self-driving car ( video ) chris urmson : how a driverless car see the road******none******Aug 12, 2016******2******CA
12******in hidden obstacle for google ’ s self-driving car article we can read that : google ’ s car can detect and respond to stop sign that aren ’ t on it map , a feature that be introduce to deal with temporary sign use at construction site . google say that it car can identify almost all unmapped stop sign , and would remain safe if they miss a sign because the vehicle be always look out for traffic , pedestrian and other obstacle . what would happen if a car spot somebody in front of it ( but not on the collision path ) wear a t-shirt that have a stop sign print on it . would it react and stop the car ?would google's self-driving-car stop when it sees somebody with a t-shirt with a stop sign printed on it?******would google's self-driving-car stop when it sees somebody with a t-shirt with a stop sign printed on it?******Aug 11, 2016******2******CA
6******google ’ s self-driving car most likely us map of traffic sign use google street view image for roadway inventory management . if traffic sign be not in it database , it can still “ see ” and detect moving object which can be distinguish from the presence of certain stationary object , like traffic light . so it software can classify object base on the size , shape and movement pattern . therefore it be highly unlikely that a person would be mistake for a traffic sign . see : how do google's self-driving car identify pedestrian ? <sup> image : technology review </sup> to support such a claim , illah nourbakhsh , a professor of robotics at carnegie mellon university , give an interview to the new york time magazine cover story on autonomous drive car , and include this hypothetical scenario , say : if they ’ re outside walking , and the sun be at just the right glare level , and there ’ s a mirrored truck stop next to you , and the sun bounce off that truck and hit the guy so that you can ’ t see his face anymore — well , now your car just see a stop sign . the chance of all that happen be diminishingly small — it ’ s very , very unlikely — but the problem be we will have million of these car . the very unlikely will happen all the time . even so , the risk would be minimal , since the car be always look out for traffic , pedestrian and other obstacle . source : how google's self-driving car see the world the dream life of driverless car at the new york time******none******Aug 12, 2016******2******CA
2******<sub> this be a scope experiment . </sub> after google / tesla / whoever else be make self-driving car finish perfect them , will they replace the car with human driver , so that there be only self-driving car ? if they do , it would probably make the road safer .once self-driving cars are perfected, will they replace old-fashioned cars?******once self-driving cars are perfected, will they replace old-fashioned cars?******Aug 11, 2016******2******CA
3******it likely to be happen , because it's more convenient that way . in general people , organization and government be always keen to make thing more efficient by standarizing thing ( computer , technology , law , science , etc . ) in order to make it manageable and predictable to reduce the time and minimalize the risk of the same mistake . the whole world now move into technological advancement where automation of everything be where we be go , so we can manage complexity in more reliable way , so we can focus on much big picture . this include technology such a mobile , computer , uav ( delivery drone ) , robot and now self-driving car . the pro of that change would be : to have safer street by introduce autonomous car on the road . to have few drunk , tire , drug or crazy driver . to avoid poor weather condition . to reduce brake distance by drop driver's reaction time and predict dangerous situation much earlier . <sup> source : cyber physic </sup> reduce car death and cost of gnp . an estimated 1.3 million people die on the world's road every year with around 50 million injured or disable by accident , with accident cost country up to four per cent of their gross national product ( gnp ) yearly . - un news centre to have central point of safety improvement , you cannot change people , but you can fix the know safety issue on global scale . to introduce global standard from the central point ( e . g . new law to which manufacture need to apply ) . to increase car safety in general on large scale . and so on . why we need the ' only self-driving car ' ? the secretary-general say the un would work hard to prevent further death on the road : many tragedy can be avoid through a set of proven , simple measure that benefit not only individual and family but society at large . here be my point : to achieve ' a set of proven measure ' - do not allow people to drive - simple . people tend to break the rule , always , so do not allow them to drive without permission . reduce steal car and other crime . law enforcement dream be to able to stop any car on demand . do not allow drunk people to drive a car . disallow terrorist attack , like in nice where truck kill over 80 people . avoid bank robbery and similar which be possible by escape fast car . be it possible ? i believe it depend on specific country and union and how quickly we're able to advance and be ready for such change . to support above point and summarize the ' only self-driving car ' point , please see below reference which show that this be already happen : 2014 : uber will eventually replace all it driver with self-driving car 2016 : google's self-driving car system have be officially recognise a a driver in the u . the move be see a a first step towards change the law for car that have " no need for a human driver " . 2016 : beverly hill to replace public transport with self-driving car 2016 : san francisco pitch $ 149 million plan to replace car with self-driving vehicle san francisco ’ s future be autonomous and shared vehicle – and that future may be only a decade away . 2016 : otto self-driving truck company want to replace teamster******none******Aug 12, 2016******2******CA
6******google , tesla , apple etc have all build or be build their own self-driving car . a an expert in a related area , i be interested in know at a high level , the system and technique that go into self-driving car . how easy be it for me to make a tabletop prototype ( large enough to accomodate the need computing power need ) ?what technologies are needed for a self-driving car?******what technologies are needed for a self-driving car?******Aug 12, 2016******2******CA
4******you're go to need some way to ' see ' the area around the car , and to track the speed of nearby object . google use a combination of lidar , radar , conventional camera , and occasionally sonar ( see here for a high-level overview ) . this technology be quite expensive , and can easily cost thousand of u dollar . however , a big obstacle than the expense of the hardware ( which would be small for a table-top prototype ) be the software complexity . like many major project , the software for self-driving car be the result of year of work from ai research team , and thus extremely difficult to duplicate on your own . that say , you're not try to make a state-of-the-art self-driving car . assume you're an expert in image processing and robotics , you can probably create a basic prototype , ( like something that drive in a limited table-top environment ) . however , it's still go to take a lot of time and money .******none******Aug 13, 2016******2******CA
6******can self-driving car deal with snow , heavy rain , or other weather condition like these ? can they deal with unusual event , such a duck on the road ?what kind of road/weather conditions can ai-driven cars can deal with, as of 2016?******what kind of road/weather conditions can ai-driven cars can deal with, as of 2016?******Sep 11, 2016******2******CA
0******the state of the art ai drive system utilize stereoscopic / depth camera for visual perception . scenario such a your duck on the road example would make the system perceive them a obstacle on the road ( it doesn't really matter if they be duck / goat / human ) . the base algorithm should be able to circumvent this situation and bring the vehicle to a safe halt avoid chance of possible disaster . hence i doubt scenario such a this would pose much of a problem to today's ai driver .******none******Sep 12, 2016******2******CA
0******many car now instead of just camera , use radar . snow , heavy rain , and other weather condition should not affect them at all . object like duck will be detect . the only problem right now be deal with thing like red light or road sign , a you have to use a camera to see and interpret them .******none******Feb 11, 2016******2******CA
2******no , smart car do not know what to do when surround with duck or flood water , and it's possible they never will . a with all machine learning , a computer know only what it's taught . if an event arise that's unusual , the ai will have less relevant training on how to respond , so it reaction behavior necessarily will be inferior to it routine " standard operate procedure " , for which be have be heavily train . ( of course this be true of human too . ) due to liability concern , when encounter an outlier condition , smart car will almost certainly be design by their maker to immediately pull off the road and wait to be explicitly tell what to do - - by the human in the car or by communicate with a central command office that exist to disambiguate such confusion and resolve cognitive impasse . when confused , just like a child , a smart car will be design to seek external assistance - - and be likely to do so indefinitely , i suspect . that's why , despite google's recent car that lack steer wheel , smart car most certtainly will retain some mean of manual control - - be it a wheel and pedal , or at least verbal command . give the many form of weirdness that be possible on the road , it's possible smart car will never be fully autonomous . a for bad weather condition , how well do smart car currently perform ? nobody outside of a car manufacturer can say for certain . lidar and radar be superior to the human eye in see through fog and snow . but ( competent ) human be likely to remain good than a smart car at dynamically learn the limit of adhesion and compensating ( since this be a learned skill few smart car will already know or can learn quickly - - give this car , these tire , this road surface , this angle of road , etc ) . initially smart car will turn to the human when the go get rough , cede control back to them . once smart car have drive a few million mile in snow , slush , high wind , flood , and ice , and encounter many duck , angry moose , and irate pedestrian , they will have be teach to do more for themselves . until then , and perhaps for decade yet , i suspect they will turn to mommy and ask for help .******none******Feb 12, 2016******2******CA
6******how be autonomous car relate to artificial intelligence ? i would presume that artificial intelligence be when we be able to copy the human state of mind and perform task in the same way . but isn't autonomous car just rule-based machine that operate due to it environment ? they be not self-aware , and they cannot choose a good way to act in a never before experienced situation . i know that many people often mention autonomous car when speak about ai , but i be not really convinced that these be relate . either i have a too strict understanding of what ai be orwhy are autonomous cars categorized as ai?******why are autonomous cars categorized as ai?******Oct 12, 2016******2******CA
5******there be a neat definition of artificial intelligence , which circumvent the problem of define " intelligence " and which i would ascribe to mccarthy , the founder of the field , although i can only find it now in this book by h . simon : " … have to do with find way to do intelligent task , to do task which , if they be do by human being , would call for our human intelligence . " so , at it core we call the automation of every task ai , that can only be do by the human mind . at the time people think that a computer able to play chess would also be intelligent in other way . when this turn out to be false , the term ai be split into " narrow or weak ai " , i . e . a program able to do one task of the human mind , and " general or strong ai " , a program that can do all the task of the human mind . self-driving car be narrow ai . note , that all these definition don't specify whether these program copy the way the human mind work or whether they come to the same result via completely different algorithm .******none******Oct 12, 2016******2******CA
0******self drive car exhibit a level of agency and multi-domain resilience . by certain definition they be self aware and they be definitely design to fail safely in a large number of potentially unknown circumstance , which be similar to biological agent . ai really have to do with the study of non-biological agent and their method of agency . everything else be just computer science , algorithmic efficiency , biology , art , etc . eventually the study of biological and non-biological agency will converge , though , and we'll just call it the study of " intelligence . "******none******Oct 12, 2016******2******CA
0******others have give very detailed answer , this be my layman view of the problem statement . the self driving car be a ' goal seek ' machine . it have a set of goal with different priority . example . safety of occupant , safety of others , go from point a to point b etc . some be negotiable , other not so . to satisfy the goal , the system should use the input available ( radar , gps , camera etc ) to determine what be the best possible course of action . at time when it doesn't have all the info ( a truck which be hide a speed sign ) , it still have to take a decision ( historic memory or through awareness of it surroundings ) to satisfy it design goal . hence the ai .******none******Mar 23, 2017******2******CA
2******other answer tell about set of instruction for the car in certain situation , or a goal seek machine , while in fact , self-driving car don't have a specific set of instruction . most self-driving car use deep learning to figure out what to do at certain event . we don't tell them what to do . they learn what to do by example . the neural network use to automate car need massive amount of data to train . use the data , the car can figure out what the best action be for certain event . accord to this video tesla's autopilot have only one casualty in 300.000 . 000 mile . for human driver , the number of casualty in 2014 be 32.675 . that be per 300.000 . 000.000 mile . that mean 1 in 90 million human driver cause a fatal accident , compare to 1 in 300 million for automated car . deep learning surpass our own ' safety-rate ' , not by instruction , but by learn what to do itself . if that isn't ai , i don't know what be .******none******Mar 23, 2017******2******CA
0******autonomous vehicle be dependent upon ai technology in that , to be autonomous in their driving or piloting , they cannot be control by people . therefore they must make complex decision require of driver and pilot at least a safely and reliably a human driver or pilot . they must recognize object to the degree that both the value and the typical behavior can be assign to those object ( i . e . people , pet , property , barrier , curb , grass , tree , bridge ) they must map trajectory of a wide array of object type base on their object type , what be know about that type of object , detectable variation such a age or condition , and what the object appear to be involve in do at the time . they must be able to acquire publicly available representation of drive-able road ( route segment , connection point , and other data ) , match the representation with the current state of the road , and track their progress along an intended route to the destination . they must plan their course in lieu of these real time and difficult to predict action , traffic law , traffic convention , traffic sign and signal , give destination , know possible route , discontinuity , and anomaly . they must be able to alter the plan to reach the destination if at all possible regardless of change and challenge encounter . drive or pilot a vehicle be an intelligence intensive task . the only reason av will likely surpass human driven vehicle on the road in the near future in term of the distribution of rate of fatality and injury per million meter of travel in the near future be because human have two key handicap that offset their intelligence potential a driver . carelessness , as define a multitasking either mentally or physically at a time when hazard might appear selfishness , as define a risk the life , health , or property of others to gain a transportation relate or psychologically related advantage although the above two appear to be subjective , they can be easily prove empirically by take a sample of traffic pattern at any point in time in any highly trafficked road in the world . this be less true of pilot . we should not presume that artificial intelligence in av be achieve when the behavior of the human mind be copy . that be the criterion for alan turing's imitation game , a test that be intend to define intelligence in the context of natural language dialog . but word don't normally kill people directly . vehicle often do . it would be a very limited vision the potential av design space to consider human mind a the model of drive excellence . the task should not be perform in the same way by the ai system . the ai design objective of av should be more consistent with these concern and interest . road or sky safety law ethics regard right of way in normal and emergency situation civil right concern in term of equal access to public resource balance of spacial flow detail to maximize transportation throughput collision aversion when difficult to predict risk emerge these requirement on the cognitive and adaptive capability of the driving or piloting ai be not solely rule-based and mechanical . the vehicle itself be mostly mechanical in it operation , but it too present surprise like blowout or other difficult to predict failure . vehicle control be not at all like chess or a game with a fixed rule of play and fix game-play environment . although the intelligence requirement do not include self-awareness of itself a an intelligent system , there be form of self-awareness require . the relative position of the exterior surface of the vehicle and it project path relative to that of other object the condition of the operational part of the vehicle the mass and location of passenger and any other transported object in the vehicle the question end with an interesting and challenging requirement . choose a good way to act in a never before experienced situation that be perhaps the most challenging aspect of av driving or piloting system design . return to the question of , " why be autonomous car categorize a ai ? " , the meaning of ai be indeed a critical aspect of answer well . take literally , the term artificial intelligence specifies two thing . it be artificial , in that it do not naturally occur in nature it be intelligent , in that it adapt in way that , if those way be mechanical , they be mechanical at a level of detail that be beyond obviousness without considerable study a year dependent and culturally dependent a that definition of intelligence be , no other definition be quite a sustainable over decade from both scientific and linguistic perspective . by narrow definition , av may not require ai , but there be no compel scientific reason to narrow the definition of ai to a subset of this previous definition .******none******Oct 09, 2018******2******CA
8******what be the advantage of have self-driving car ? we will be able to have more car in the traffic at the same time , but won't it also make more people choose to use the car , so both the traffic and the public health will actually become bad ? be we really interested in this ?advantages of having self-driving cars******advantages of having self-driving cars******Oct 12, 2016******2******CA
11******one of the main argument for self-driving car be that presumably they'll get good and good at driving a the technology progress , they have no temporal attention deficit or aggressive urge or drug habit and sense their environment 360 ° , all the while communicate with the other car , which all together basically amount to less dead people . we be really interested in this . it be also unclear whether most people will actually own car in 30 year . maybe there'll be a net of mini bus with flexible route which take you from door to door on demand . that would reduce traffic quite a bit and there would also be less incentive to drive 200 m to get cigarette or something . self-driving car would allow u to use the car a a resource a lot more efficiently , because suddenly we can relocate empty car without pay a driver .******none******Oct 12, 2016******2******CA
1******safety be often put in focus by journalist . although there be potential to make the road safer , i don't think that be the drive force behind the push for self-driving car . the main advantage of self-driving car be that this will reduce cost for business , while increase efficiency ( both fuel and time ) . from the perspective of the public , the self-driving car be attractive , because they will turn the task of driving , into commute . activity that require attention will be replace with somewhat free time .******none******Oct 13, 2016******2******CA
3******if they be able to network , then they can notify the car behind that it be about to break . in this way they can drive close together at high speed . as soon a one put on the break , all the car behind would apply the break . they would not require the 2 second that it take for a human to respond . child could be drop at school or the train station automatically . people would not need to park a car ; it could drop them at work and drive away . taxi would probably become more viable than private car ownership . car theft might be more difficult . where i live , public transport be hardly viable because the government struggle to provide enough parking space at train station and bus stop . the close empty park spot by 8: 30am be 30minuets walk to the platform . driverless car would solve this problem , and travel by train would actually become viable for me .******none******Oct 16, 2016******2******CA
4******why be self-driving car awesome ? safety : good awareness ( due to more sensor ) , good reaction time , few distract / injure / drunk / texting driver on the road , etc convenience : pick up my kid from school , park itself at the grocery store , take itself to be service , etc faster transit : with increase safety , you can increase speed limit , with proper rout algorithm you don't need traffic light and stop sign any more ( when you have dedicate self-driving lane & intersection ) comfort : recline , read , game , or snooze while travel ( yay ! ) cost : subsidize the cost of the vehicle use ad ( e . g . project onto the windshield ) etc******none******Oct 18, 2016******2******CA
4******i'd like to add , self-driving car would also be excellent for disabled people who would otherwise not be able to drive . add a lot more autonomy to vulnerable people******none******Oct 28, 2016******2******CA
8******there be multiple motivation for self driving car . self drive car have the potential to be much safer . self driving car be far more reliable than human and can learn and have their software improve and upgrade , result in safer road and far few accident . more on self-driving car safety : self drive car can lead to great road efficiency . traffic jam and obstruction occur due to inefficiency in human driving , see this mit simulation of a " phantom traffic jam " : and self drive car can be program to avoid this . great economic and environmental benefit self drive car can keep driving cost down by conserve fuel and hence lead to a good environmental impact . more on fuel efficiency : ease of transport self drive car make transport easy and mean that driver may be unnecessary in the future , result in a more pleasurable and easy drive . in addition , this would make it easy for people with disability to travel as well a simplify the travel experience . child could potentially be drive to school by a car without the supervision of a parent , for instance . park self drive car can be call to pick you up , mean the need for park in nearby location and / or long walk to find your car may become a thing of the past a your car would drive up to you to pick you up . thing we haven't even think of yet :)******none******Nov 03, 2016******2******CA
0******i think that one very big advantage would be that if the car could communicate with each other , they could drive synchronously . for example , if there be a traffic light , and , let's say , 10 car be wait for it to change to green ( let's just assume that there would still be something similar to traffic light ) . then when it change to green all car could accelerate at the same speed ( depend on the acceleration of the front car ) at the same time .******none******Feb 11, 2016******2******CA
1******self driving car be good for the following reason : in the case of an emergancy , urgancy , or just someone be unable to drive unexpactedly , the car can go by itself to a designate location - this be useful in so many use case - kid who need to get somewhere while parent be busy , parent who drink a little too much and prefer to take ' the cab ' home , or while run , you get injure and need a pick-up . the example above be for the more obvious thing , which we currently have a struggle with . but other than those , self-driving car will open a door for a much wide scale of thing : safe police chase ( just a car without a police officer ) , taxi , help in the battle field , and much more ... the third and most important benefit , be the safety and economical property of self drive car : with a lot of those car on the road , they can ' understand ' each other and nothing will go unpredicted . they have much fast response time then human , and maybe in the future they will even be able to predict traffic-light change , and by that save gas and money ( even more than what they can save right now by drive economicly )******none******Oct 29, 2016******2******CA
1******what be the ethical and legal issue of self drive car be release in the uk ? this question come up on our exam today and i be leave in a daze . i initially think it would be issue like the legal driving age for self driving car since they be ai do you need a minimum age limit ? another one i thought be whether or not you need drive license for ai car ? could someone please list all the possible ethical and legal issue that surround ai control car ?what are the ethical and legal issues of self driving cars being released in the uk?******what are the ethical and legal issues of self driving cars being released in the uk?******Jun 07, 2017******2******CA
1******for example ... 1 ) if a dog be cross the road , i'd expect the car to try to avoid it . but what if this lead to . 00001 % more risk for the driver ? what be the ' risk cut-off ' ? 2 ) what if a cockroach be cross the road ? will the car have a list of animal okay to run over ? 3 ) what if a kid be cross the street and avoid it would kill the driver ? these question seem to not really have an answer , yet self drive car be almost ready . what be they do about all of this ?how will morality questions be settled in the domain on self-driving cars?******how will morality questions be settled in the domain on self-driving cars?******Oct 12, 2017******2******CA
2******as far a i know , there be still a huge debate about this topic . i would say , that the main rule for every self-driving car be to avoid a crash if possible . the question one should always ask be , in what situation would a crash realy happen and would a human react differently ? my answer be no . the point be , a human might try to avoid the child ( 3 ) but it would be out of instinct rather than " consideration " . the driver might even harm others in this situation . since a self-driving car will normally follow the rule a critical situation will most of the time arise due to the other person , not the car . so i believe it be best to protect the driver at all cost . the dog v child problem could be solve via advanced animal recognition ( human v no human ) regard no ( 2 ): too small = no human = = > car will ignore it .******none******Oct 13, 2017******2******CA
1******i don't think these question will need to be answer . a self driving car will almost certainly avoid a situation like the one describe well before a human would have and hence would not have to choose . for example it would slow down as soon a it see a child close to the road . it will identify and react to the fact that the child start move towards the road and act before the situation require the " drastic " scenario that we invent . if for some reason the car have to choose , it can also make the impact / avoidance have the high chance of not kill the occupant of the vehicle consider how well design car be these day and that the speed involve shouldn't be anything wild like 200mph . not to mention a network of car along with street camera and sensor would act / work together to resolve a a swarm intelligence so the car ahead or the traffic camera can warn / tell other car that something they cannot see be a potential hazard . i can go on and on ... in my opinion , the bottom line be a self driving car will not road rage , drive at dangerous speed in a residential area , get tire and fall asleep , text and drive or drink and drive , etc ... i cannot wait .******none******Oct 13, 2017******2******CA
0******a others have say , your question be , and will continue to be a hot topic . i also agree that eventually self-driving car will be able to handle your hypothetical situation good than many human driver . i be not prepared to say when that " eventually " will eventuate . however , i can also imagine some human driver deliberately try to cause self-driven car to make poor decision . for example , a " team " of three or more car could easily confound a self-driven car's programming by coordinate their action , especially once the actual program code use by the car be know . i'm thinking of situation where the self-driven car be box in by human-driven car which indicate they be about to make a move and then do not , while others change speed and direction at the same time , or at slightly different time . human can be incredibly sneaky and unethical , and some be very good at find exploit and weakness .******none******Oct 15, 2017******2******CA
2******the core issue with this question rest in probability . specifically : what if a kid be cross the street and avoid it would kill the driver ? how do the ai know for certain that avoid it would kill the driver ? and certainty rear it head re : 1 ) if a dog be cross the road , i'd expect the car to try to avoid it . but what if this lead to . 00001 % more risk for the driver ? what be the ' risk cut-off ' ? there would likely be no " hard cutoff " . early fuzzy logic system have be implement in automotive gear shift and anti-lock breaking , but it be precisely the " fuzziness " that make them effective . contemporary ai be far more sophisticated , and part of that sophistication rest in what might be though of a dynamic threshold for decision-making . because certainty only exist in special , limited case ( such a solved game ) , estimation must be use . regard the cockroach , it would likely be too small to warrant a response , although a swarm of cicada might affect the car's sense ability and prompt poor-visibility navigational protocol . in general i'm sure pet-sized animal and big would be avoid , in the case of actual pet for humanitarian reason , and for animal like deer , for reason of driver risk ( impale by the horn at the bad , and at the least potentially costly damage to the vehicle . ) but i suspect the protocol for this would be break or swerve if there be a clear margin on either side of the animal ( i . e . not a barrier , wall or cliff ) and the direction change be controllable ( i . e . hit the animal be likely to result in less harm than an actual crash , and certainly less risk to the human , except in the case of the deer's horn . )******none******Oct 20, 2017******2******CA
1******i have a liberal art background so i need help understand this paper , particularly page 26 to 30 . the author test a four-camera system for localization , mapping , and obstacle detection for self-driving car . the paper seem to say the multi-camera system can map the environment to within an average of 7 cm ( 2.8 inch ) of accuracy ( with the large error be 16 cm or 6.3 ) and detect obstacle to within 10 cm ( 3.9 inch ) of accuracy . be i get this right ? give that automotive lidar can detect object to within 1.5 cm ( 0.6 inch ) of accuracy , and give that for drive purpose the difference between 1.5 cm and 7 cm , 10 cm , or 16 cm seem quite small , can a multi-camera system be use instead of lidar in a self-driving car application ? how do drive speed affect thing ? what crucial element of the problem space might i be overlook or misunderstand ?‪can a multi-camera system be used for localization, mapping, and obstacle detection in self-driving cars to within 10 cm of accuracy? whither lidar?‬******‪can a multi-camera system be used for localization, mapping, and obstacle detection in self-driving cars to within 10 cm of accuracy? whither lidar?‬******Oct 24, 2017******2******CA
0******a self-driving technology be improve , there be so many company develop self-driving car like google , uber , etc . be it possible that we won't need any private / pay self-driving car and the " self-driving taxi " become ubiquitous in the city ? if we assume that there be such taxi everywhere , would transportation become extremely low cost or free ? ( the self-driving car company could benefit from broadcast advertisement for advertising agency . )could the deployment of self-driving cars make rides free?******could the deployment of self-driving cars make rides free?******Feb 16, 2017******2******CA
1******i have a liberal art background so i need help understand this paper , particularly page 26 to 30 . the author test a four-camera system for localization , mapping , and obstacle detection for self-driving car . the paper seem to say the multi-camera system can map the environment to within an average of 7 cm ( 2.8 inch ) of accuracy ( with the large error be 16 cm or 6.3 ) and detect obstacle to within 10 cm ( 3.9 inch ) of accuracy . be i get this right ? give that automotive lidar can detect object to within 1.5 cm ( 0.6 inch ) of accuracy , and give that for drive purpose the difference between 1.5 cm and 7 cm , 10 cm , or 16 cm seem quite small , can a multi-camera system be use instead of lidar in a self-driving car application ? how do drive speed affect thing ? what crucial element of the problem space might i be overlook or misunderstand ?‪can a multi-camera system be used for localization, mapping, and obstacle detection in self-driving cars to within 10 cm of accuracy? whither lidar?‬******‪can a multi-camera system be used for localization, mapping, and obstacle detection in self-driving cars to within 10 cm of accuracy? whither lidar?‬******Oct 24, 2017******2******CA
1******give that a self-driving car be try to replicate the performance of a two-camera system ( or one in a pinch ) , there be nothing in principal that mandate lidar for a self-driving car . lidar be a shortcut , substitute sensor sophistication for image-processing sophistication . afaik nvidia's own self-driving vehicle doesn't have lidar . my personal opinion be that level 5 self-driving vehicle won't be practical until they have the kind of image-processing sophistication that make lidar an unnecessary crutch .******none******Oct 24, 2017******2******CA
2******it seem that lidar present a problem for resolve the car's environment at high speed . while i'm not too familiar with the dynamic of lidar i do know that it's a physical system that rely on send and receive laser pulse to various point around the car by way of rotate mirror . a speeds increase , it seem different arrangement of mirror and light collector might have to be use to maintain a high-resolution image . there's some evidence that doppler lidar ( develop in the 1990s ) become less accurate with high velocity . however , lidar be partly prefer over radar because of it high accuracy even when track object at high speed - this be why lidar gun be increasingly be use by police instead of radar gun to track speeding vehicle . it seem natural that a set of high-resolution camera pair with a well-trained neural network would not be subject to the same physical limitation a lidar . i think that an important intuition to consider be that while lidar be use to generate cloud of data point whose shape and pattern can be analyze by autonomous car software , camera can pick up non-topograhical feature such a road line , the content of roadsigns , and additional location context such a storefront and intersection layout . consider that these camera can use pattern recognition and stereoscopy to also generate a 3d topographic map of the environment , it seem plausible that level 5 self driving car would not require lidar . here's an interesting look at the problem .******none******Feb 25, 2017******2******CA
2******a self-driving technology be improve , there be so many company develop self-driving car like google , uber , etc . be it possible that we won't need any private / pay self-driving car and the " self-driving taxi " become ubiquitous in the city ? if we assume that there be such taxi everywhere , would transportation become extremely low cost or free ? ( the self-driving car company could benefit from broadcast advertisement for advertising agency . )could the deployment of self-driving cars make rides free?******could the deployment of self-driving cars make rides free?******Feb 16, 2017******2******CA
3******you ask an interesting question . there have be many discussion by industry on this topic . a company call vugo have their business model base on advertising to passenger . an article about vugo , " the quest to make ridesharing free " , state : flessner be co-founder and ceo of minneapolis-based rideshare advertising platform vugo , which use it patented tripintent technology to display targeted advertisement to uber and lyft passenger on a tablet attach to the back of the vehicle ’ s headrest . the company ’ s founder predict that within the next few year , all ridesharing vehicle in the u . s . will be driverless , and in-vehicle advertising tailor to passenger ’ destination and interest will lead to free transportation . “ the idea be to put brand in front of passenger who be en route to make purchase , ” say flessner . for example , retailer will sponsor transportation to their store so they can preview product to customer who be head their way . this article " how free self-driving car ride could change everything " make these comment : car data be so lucrative that ben volkow - - ceo of otonomo , an israeli startup that sell vehicle data - - expect automaker to make more money selling data than vehicle by 2020 . if the money make off self-driving vehicle data outweigh the cost of offer ride , then it become reasonable for a business to offer free ride broadly . a paper entitle " leverage advert in the come autonomous car eco-system " publish by berkeley , university of california , propose " a world where rideshares be free , or in some case , heavily subsidize through the use of advertisement " .******none******Feb 17, 2017******2******CA
2******oil price be not cheap , but online advertisement per impression be relatively cheap . especially give that there isn't much engagement in a taxi , it hard to imagine that ad alone can fully support a taxi service . from this source , we find cpm for a youtube video about 0.1 $ : but keep in mind this value could be low since user engagement in a taxi be much low compare to someone on the internet . with smartphones everywhere , how can you entice someone to watch an ad on a move taxi ? from this source , we see : for a 5 - mile , 10 - minute trip go 25 mile per hour the entire way , uberx would cost the $ 2.55 base fare plus $ 3.50 for the 10 minute plus $ 10.75 for the mileage , for a total of $ 16.80 . it be not customary to tip the uber driver . no matter how you cut it , the margin seem to be quite thin . so free taxi seem unlikely for now unless someone come up with a different business plan .******none******Feb 17, 2017******2******CA
3******provide that more and more decision about human life be ( to be ) decide by machine ( like access to loan , housing , scholarship , job , healthcare , insurance , etc . ) at the same time , in many country there be law and code of conduct against ( negative / positive ) discrimination do there any industrial-accepted way to examine the ai system it legal compliance ? i believe that acm / ieee software engineer professional code of conduct can be apply here , but also like to learn more about audit process from examiner side as well , if there's any . thank you .legal compliance and ai auditing framework******legal compliance and ai auditing framework******Feb 17, 2017******2******CA
3******understand how an algorithm work can be realize with two possibility . at first , with opensource software . that be a well know method and prevents proprietary non-documented code . opensource software alone doesn't solve the problem , a see by @k . c . sayz ' k . c sayz ' correctly . for example , if we be implement a neural network a opensource , it remain a blackbox which be not predictable , especially for non-experts . the shared language between legal law and engineering capability be the natural language , especially english . so the engineer have to create their system in a way , that it communicate with the world in normal english . that mean not , that the car speak like k . i . t . t . , it mean only that the interface for control the car have command like “ start ” , “ stop ” and “ drive slow ” . if the car detect with his neural network a pedestrian , than it should print out on the console a simple “ pedestrian detect ” . that seem natural , but most program today print out “ memoryadress $ 3400 = - 65 ” or “ sigmoid activation function be set to sin ( 4 - x ) ” . in a potential law case it make sense to cite status-messages of the onboard computer . because if they be write in normal english , lawyer will understand it . how the natural language output be produce be in the scope of the engineer and be only a detail question .******none******Feb 16, 2018******2******CA
4******many of the architecture that do semantic segmentation like segnet , dilatednet ( yu and koltun ) , deeplab , etc . do not work on high resolution image . for such benchmark like cityscape , what be a standard / practical approach for such method to perform on the benchmark ? i've try to look into the paper , but i couldn't find such detail . there's an article mention that they output at 1/8 of input image than do interpolation ( usually 2 , 4 or 8 time ) from their result , but the article do not specify which upsampling technique be the most reasonable one .semantic segmentation how to upsampling******semantic segmentation how to upsampling******Jan 17, 2018******2******CA
0******i can't find much information on modern pddl usage . be there more popular alternative , maybe something more suited to modern neural network / deep learn technique ? i'm particularly interested in pddl or alternative's current usage in autonomous driving software .how is pddl used in production ai systems?******how is pddl used in production ai systems?******May 01, 2018******2******CA
0******i have see it use in automated story-telling ( or game ai to control npc ) , and in nlg system , where the generation of text be reinterpret a a planning task . what these system have in common be that they're either off-line or in a simple environment ( npc control ) . i'm not sure they would be suitable for real-time application , unless you can be sure that a feasible plan exist which can be find within certain time bound . i wouldn't want to sit in a car go at high speed on the motorway and wait for the drive unit to work out a plan how to avoid an obstacle that suddenly appear on the road .******none******May 01, 2018******3******CA
4******i remember the first time hear about google try to make driverless car . that be year ago ! these day , i'm begin to learn about neural net and other type of ml and i be wonder : do anybody know how many hour ( or day , month , etch ) be need in training time to get the result that be now use in today's self-driving vehicle ? ( i be assume they use neural network for this ... )how long has it taken for autonomous driving cars to be being sold and used on the roads today?******how long has it taken for autonomous driving cars to be being sold and used on the roads today?******May 18, 2018******3******CA
0******build self-driving car be surprisingly easy . the question be not if in 10 year or in 50 year the technology be high enough develop . because wait alone will not solve any technical problem . instead the question be more how many “ man year ” have to be invest until the car reach level 2 , level 3 or whatever goal be need . in a short notice from the darpa urban challenge a concrete amount be give : “ with [ ... ] less than two man-years of software development time , [ ... ] the team still manage to place roughly in the middle of the pack pit against the competitive field . ” ( 1 ) from another team in the darpa self-driving car challenge it be know , that their software contains of 1 million line of code . if the average programmer be able to create 10 line per day , the total amount be 274 “ man year ” to complete the project . that mean , if mankind be only able to let one programmer work on driverless car , the first prototype will be ready in around 300 year from now .******none******Aug 17, 2018******3******CA
5******we be do a research design project on autonomous vehicle and have some question on av level 4/5 ; specifically on the role , impact and consequence of av on society , government , user and other stakeholder . we're currently stick on this main question : q : what functionally , do control look like in av level 4 and 5 ? for example , be the whole purpose of a level 4/5 that a user have no input into the control ? could a driver in av ( level 5 ) stop in an emergency , or say they want to " take corner hard , speed up , slow down " ? could i choose to change the equi-distance between my av and the others around me because i like space ? we're wonder about what functionally , do av level 4/5 offer a user ; and what it look like ? context : our remit be within the world of design ( design thinking ) , not specifically technology , or expert system functionality . we're look at the issue from a design perspective ; who do it impact , who be the stakeholder , what be the consequence and impact . what role do a driver have an in level 5 ? could an auto-manufacturer want to give driver control in level 5 ? how do emergency service act in these situation ? what be the touchpoints to society and whom do it impact and what do it say about the design of av for the future of society .what functionality, does control look like in autonomous vehicles levels 4 and 5?******what functionality, does control look like in autonomous vehicles levels 4 and 5?******Jun 04, 2018******3******CA
3******to reach full autonomy in any fully automate device it must finish it task in such a way that human control be unnecessary . we know when the automation be excellent when there be no manual control and we call it repair and bring in a specialist if something go wrong . four example of full automation in existence be . appliance home and mobile computer connectivity mail sorter hundred million dollar military drone these four be specifically intelligent in vary degree . process control under household condition adapt to new hardware and network reading address write with poor penmanship and odd font adaptively avoid detection to reach a reconnaissance vantage point these four be good enough for their market . example of not be good enough , a indicate by their lack of any substantial market penetration , be these four . autonomous vacuum cleaner autonomous car ( without a driver's seat ) unpiloted private or passenger aircraft narrowly target medical nanites the question , " how good be good enough ? " be this one : what be the challenge for researcher and engineer to provide enough intelligence into these kind of autonomous vehicle to make them good than current method in the mind of policy maker and consumer ? step back to look with a scientific eye at what be acceptable , consider how unsatisfactory the exist equivalent of the above four be . manual vacuuming miss anywhere from 10 % to 90 % of the dust depend on the surface , blow microbe into the user's lung , and produce additional health risk when disposal be require . human being drive car regularly , but they be drive what be technically a piece of heavy equipment in pedestrian situation when tire , drunk , high , while text messaging , or while simply loose focus . the human resource require to deploy , guide , and land vehicle that have no other obstacle than topographical feature and other aircraft be significant and leave open not only human failure but hijacking . chemotherapy , antibiotic , and other pharmacological intervention often only delay the progress of disease and sometimes produce other negative outcome of vary scope from symptom bad than what be be treat to death . many thing that be manual be like that . they need to be automate . artificial intelligence , especially miniaturize and low cost artificial intelligence , be critical to achieve anything like excellence . what make something intelligent enough . what specific research and engineering effort can bring the item that aren't good enough into the realm of consumer demand and support by policy ?how good is good enough for fully autonomous vehicles?******how good is good enough for fully autonomous vehicles?******Jul 19, 2018******3******CA
3******the ideal answer should be : when the algorithm be show statistically to outperform human in a give task . however , there do seem to be an emotional component when relate to life-or-death scenario . i have no doubt that robot-vaccums be vastly inferior to good-old-fashioned cleaning , but a a celebrated writer once note " you can either have clean floor or you can use a mop . " ( i . e . if you want floor that be actually clean , you need to use elbow grease and scrub them ;) but people rarely die from shoddily clean floor and the majority seem to value convenience over all other factor . by contrast , the internet go crazy when there's a single autonomous vehicle fatality , even a a significant subset of human be drive more erratically due to mobile phone and on-board computer distraction . ( i liken it to fear of fly - - statistically safe than drive but human aren't always strictly rational . ) beyond the safety issue , human be often irrationally selfish--commute in any major city during rush hour and you will notice pervasive grid-locking . while gridlock be mostly just an inconvenience , human often make the same irrationally selfish decision accelerate into yellow light , increase risk of an accident . similarly , you often encounter rogue driver speed in highway traffic , make unsafe lane change , regardless of whether it actually save them any time . my sense with self-driving car be that they will have to exceed human by a large margin due to our emotional nature , regardless of what the statistic indicate . and , there will be an entrenched , obstinate population of age driver who resist the change , even a their own driving become more erratic and dangerous . file under : " you'll get my driver's license when you pry it from my cold , dead hand " .******none******Jul 19, 2018******3******CA
12******i recently hear someone make a statement that when you're design a self-driving car , you're not build a car but really a computerized driver , so you're try to model a human mind - - at least the part of the human mind that can drive . since human be unpredictable , or rather since their action depend on so many factor some of which be go to remain unexplained for a long time , how would a self-driving car reflect that , if they do ? a dose of unpredictability could have it us . if , say , two self-driving car be in a stuck in a right of way deadlock , it could be good to inject some randomness instead of maybe see the same action apply at the same time if the car run the same system . but on the other hand , we know that non-deterministic isn't friend with software development , especially in test . how would engineers be able to control it and reason about it ?do self-driving cars resort to randomness to make decisions?******do self-driving cars resort to randomness to make decisions?******Aug 13, 2018******3******CA
2******self drive car apply reinforcement learning and semi-supervised learning , this allow them to be more suited for situation that developer do not anticipate themselves . some car now apply swarm intelligence , where they effectively learn from interaction among themselves , which can also aid in case of transfer learning .******none******Aug 13, 2018******3******CA
3******drive priority when consider the kind of model need to create reliable and safe autonomous vehicle , the follow driving safety and efficacy criterion should be consider , list in priority with the most important first . the safety of those inside the vehicle and outside the vehicle reduction of wear on passenger the safety of property the arrival at the give destination reduction of wear on the vehicle thrift in fuel resource fairness to other vehicle the thrift in time these be order in a way that make civic and global sense , but they be not the priority exhibit by human driver . copy human or reevaluate and design from scratch ? whoever say that the goal of autonomous car design be to model the portion of a human mind that can drive should not be design autonomous car for actual manufacture . it be well know that most human , although they may have heard of the following safety tip , cannot bring them into consciousness with sufficient speed to benefit from them in actual driving arrangement . when the tire slip sideways , steer into the skid . when a forward skid start , pump the break . if someone be head tangentially into your car's rear , immediately accelerate and then break . on an on ramp , accelerate to match the speed of the car in the lane into which you merge , unless there be no space to merge . if you see a patch of ice , steer straight and neither accelerate nor decelerate once you reach it . many collision between locomotive and car be because a red light cause a line in multiple lane across the track . frequently , a person will move onto the railroad track to gain one car's length on the other car . when others move to make undoing that choice problematic , a serious risk emerges . as absurd a this behavior be to anyone watching , many death occur a a fast traveling 2,000 ton locomotive hit what feel like a dust speck to the train passenger . predictability and adaptability human be unpredictable , a the question indicate , but although adaptability may be unpredictable , unpredictability may not be adaptive . it be adaptability that be need , and it be need in five main way . adaptive in the moment to surprise adaptive through general drive experience adaptive to the specific car adaptive to passenger expression adaptive to particular map region in addition , drive a car be highly mechanical , visual , auditory , plan orient geographical , and preemptive in surprise situation . model drive complexity this require a model or model comprise of several kind of object . map the vehicle the passenger intentions other vehicle other obstruction pedestrian animal crossing traffic signal road sign road side neither mystery nor indeterminance although these model be cognitively approximate in the human brain , how well they be model and how effective those model be at reach something close to a reasonable balance of the above priority varies from driver to driver , and varies from trip to trip for the same driver . however , as complex a driving be , it be not mysterious . each of the above model be easy to consider at a high level in term of how they interact and what mechanical and probabilistic property they have . detail these be an enormous task , and make the system work reliably be a significant engineering challenge , in addition to the training question . inevitability of achievement regardless of the complexity , because of the economics involve and the fact that it be largely a problem of mechanic , probability , and pattern recognition , it will be do , and it will eventually be do well . when it be , as unlikely a this sound to the person who accept our current culture a permanent , human driving may become illegal in this century in some jurisdiction . any traffic analyst can mount heap of evidence that most human be ill equip to drive a machine that weigh a ton at common speed . the licensing of unprofessional driver have only become widely accepted because of public insistence on transportation convenience and comfort and because the workforce economy require it . autonomous car may reflect the best of human capability , but they will likely far surpass them because , although the object in the model be complex , they be largely predictable , with the notable exception of child play . av technology will use the standard solution for this . the entire scenario can be bring into slow motion to adapt for child play simply by slow way down . ai component that specifically detect child and dog be likely to emerge soon , if they do not already exist . randomness randomness be important in training . for instance , a race car driver will deliberately create skid of various type to get use to how to control them . in machine learning we see some pseudo random perturbation introduce during training to ensure that the gradient descent process do not get catch in a local minimum but rather be more likely to find a global minimum ( optimum ) . deadlock the question be correct in state that , " a dose of unpredictability could have it us . " the deadlock scenario be an interest one , but be unlikely to occur a standard develop . when four driver come to a stop sign at the same time , they really don't . it only seem like they do . the likelihood that none of them arrive more than a millisecond before the others be astronomically small . people will not detect ( or even be honest enough ) to distinguish these small time difference , so it usually come to who be most gracious to wave the others on , and there can be some deadlock there too , which can become comical , especially since all of them really wish to get move . autonomous vehicle will extremely rarely encounter a deadlock that be not cover by the rule book the government license entity publishes , which can be program a driving rule into the system . on those rare occasion , the vehicle could digitally draw lot , a suggest , which be one place where unpredictability be adaptive . do skid experimentation like a race car driver on main street at midnight may be what some drunk teen might do , but that be a form of unpredictability that be not adaptive toward a sensible ordering of the priority of drive . neither would be texting or try to eat and drive . determinism regard determinism , in the context of the us discuss , pseudo-random number generation of particular distribution will suffice . deadlock release or train speed-ups and improve reliability when there be local minimum that be not the global minimum during optimization , functional test and unit testing technology be not only able to handle the testing of component with pseudo-randomness , but they sometimes employ pseudo-randomness to provide good test coverage . the key to do this well be understand of probability and statistic , and some engineer and ai designer understand it well . element of surprise where randomness be most important in av technology be not in the decision making but in the surprise . that be the bleed edge of that engineering work today . how can one drive safely when a completely new scenario appear in the audio or visual channel ? this be perhaps the place where the diversity of human thought may be best adept , but at highway speed , it be usually too slow to react in the way we see in movie chase scene . correlation between risk and speed this bring up an interesting interaction of risk factor . it be assume that high speed be more dangerous , the actual mechanic and probability be not that clear cut . low speed produce temporally long trip and high traffic density . some form of accident be less likely at high speed , specifically one that be relate mostly to either traffic density or happenstance . other form be more likely at high speed , specifically one that be relate to reaction time and tire friction . with autonomous vehicle , tire slippage may be more accurately model and reaction time may be order of magnitude faster , so minimum speed limit may be more imposed and upper limit may increase once we get human out of the driver's seat .******none******Sep 04, 2018******3******CA
3******object track be find the trajectory of each object in consecutive frame . human tracking be a subset of object track which just considers human . i've see many paper that divide track method into two part : 1 - online tracking : tracker just use current and previous frame . 2 - offline tracking : tracker use all frame . all of them mention that online tracking be suitable for autonomous driving and robotics , but i don't understand this part . what be the application of object / human track in autonomous driving ? do you know some related paper ?what are applications of object/human tracking in autonomous cars?******what are applications of object/human tracking in autonomous cars?******Sep 07, 2018******3******CA
3******i want to implement sparse extend information slam . there be four step to implement it . the algorithm be available in probabilistic robotics book at page 310 , table 12.3 . in this algorithm line no : 13 be not very clear to me . i have 15 landmark . so $ \ mu_t $ will be a vector of ( 48 * 1 ) dimension where ( 3 * 1 ) for pose . now $ h_t ^ i $ be a matrix whose column be dynamic a per the algorithm it be ( 3j - 3 ) and 3j . j be the value of landmark 1 to 15 . now how could i multiply a dynamic quantity with a static one . there must be a error that matrix dimension mismatch when implement in matlab . please help me to understand the algorithm well .seif motion update algorithm doubt******seif motion update algorithm doubt******Sep 19, 2018******3******CA
2******i will be undertake a project over the next year to create a self learn ai to play a racing game , currently the game will be mario kart 64 . i have a few question which will hopefully help me get start : what aspects of ai would be most applicable to create a self learn game ai for a racing game ( q-learning , neat etc ) could a ann or neat that have learn to play mario kart 64 be use to learn to play another racing game ? what book / material should i read up on to undertake this project ? what other consideration should i take throughout this project ? thank you for your help !creating a self learning mario kart game ai?******creating a self learning mario kart game ai?******Oct 02, 2018******3******CA
4******naturally everyone know most common advantage of autonomous ( not autopilot-controlled ) car , e . g . safety , efficiency , parking , etc . but be there any advantage for the law ? normally you only hear about problem like have to change a lot of the legal aspect . i would have think that there be no hit and run , drink driving and generally no deliberately cause car accident . i would be very interested if someone would come up with further advantage . i hope this be the right page for a question like that .legal advantages of autonomous vehicles******legal advantages of autonomous vehicles******Oct 07, 2018******3******CA
0******it be only a matter of time before autonomous vehicle surpass human driven vehicle in term of passenger and pedestrian safety . we can expect that some city and region in the world will be dominate by av . when this occur to a sufficient degree , it be more than merely probable that the remain human driver will be see a a nuisance , since they cause the great proportion of road risk . people will react two way to this idea . fear , because the notion speaks of a future drastically different from the last hundred year , the culture of which have be influence by powerful advertising connect a person's virility , femininity , or autonomy with their automobile humor , because it be so obvious to anyone who drive that so many of the other driver be a nuisance — those that be brutally self-honest would see that , at certain time , they themselves be nuisance . it be very probable that law against human driving will eventually start in one or two jurisdiction where critical proportion of well design av on the road have be reach . from there it will spread . it would not be surprising if , in fifty year , when the world population be at least double , vehicular fatality will have radically decrease because of av . if nothing interferes to stop such a trend , the jurisdiction that continue to permit unregulated driving would be then consider uncivilized and dangerous . we can imagine travel brochure say , " vacation in ireland , now sidewalk-safe , " because ireland have pass a law ten year prior to gradually reduce the number of registered vehicle with steer wheel to zero . sidewalk safe might not be the term , but some marketing term for av only roadways will be coin to sell tourist and family .******none******Oct 07, 2018******3******CA
3******i'm do an epq ( extended-project qualification ) on artificial intelligence bias , and would like to gather some primary data for analysis . do driver-less car lead into controversy that be to do with ethic ? for example : if the ai have to choose to minimize damage and could not avoid casualty .does research into driver-less cars cause ethical problems?******does research into driver-less cars cause ethical problems?******Nov 26, 2018******3******CA
3******i'm do an epq ( extended-project qualification ) on artificial intelligence bias , and would like to gather some primary data for analysis . do driver-less car lead into controversy that be to do with ethic ? for example : if the ai have to choose to minimize damage and could not avoid casualty .does research into driver-less cars cause ethical problems?******does research into driver-less cars cause ethical problems?******Nov 26, 2018******3******CA
1******ethic of research into avs research that do not , in the course of lab operation , harm people in any stage of development or mammal use in lieu of people , rarely present prohibitive ethical conflict . whether a perception of possible ethical conflict limit funding and present marketing and public relation challenge to those who sell the product of engineering use the research output be a different question . productization challenge initial safety metric and the medium play of accident that must inevitably occur and how these indicator compare with human drive metric will have much to do with early perception . the automotive industry and new entry into it be aware of this . that automotive product be such a ubiquitous part of modern life both raise the stake in term of profitability and will increase the visibility of the transition . drive ethic define by law statute and case law have already clarify the ethical expectation of the public regard safety priority . early public discussion about public safety and the introduction of automated vehicle ai show no significant conflict between the straightforward application of exist law and public expectation of full drive automation safety . save life come before save people from non-fatal injury , which come before save pet and property . the trailing priority be save time , save fuel , and save wear on the vehicle itself . a search on this ai site use the tag associate with av , self-driving , and ethic will reveal much more on this topic that be unnecessary to duplicate here . also a basic search for the word vehicle reveal a number of good posting . a an example , this question could use a few answer , but the question in some way address this question : recognition and response generalization for autonomous vehicle or not ? . this question have some of the best discussion on priority in situational ethic in av : how would ai prioritize situational ethic ? . the key to analyze the ethic of the driving process itself be statistical comparison . av will not likely be accept well by the public or by government unless the accident rate reflect av safety advantage . one metric that should be primary be the percentage of fatality among all report accident a a function of what percentage of the driver be computer . whether legislator and regulator will pick up on the importance of this specific metric remain to be see . if statistically prove safer in term of fatality and injury metric , then it would be unethical to let people continue to drive car . who would dare oppose measure that save human life , include pedestrian , child walk to school , and the elderly and disable ? this nearly inescapable reality be the foreshadow of a likely future legal paradigm shift . normal resistance to change the word i hear most often about fully automated vehicle be the word , " creepy . " sometimes i must explain to those not up on the av technology that a fully automate vehicle be like a quiet limo driver , respond appropriately to the specification of a destination and command to stop and go , possibly ask for clarification on occasion . that they then respond with , " that's creepy , " be not surprising . the modern world be increasingly emotionally and economically entrench in daily driving . it be important , when consider market acceptance , to notice that the word , " creepy , " be also use for people who be consider potential serial killer , rapist , abductor , vampire , and other fictitious or real type that stalk and either kill or otherwise destroy the psyche of people . interestingly , be spook by the suggestion of car without human driver be the same response , adjust for change in common linguistic expression , a upon the initial introduction of a long list of other technological advancement . from scribes to print press from stay clear of the deep ocean to circumnavigation from kerosene to electric light from bird watch to human flight from sail power to steam power from horse to car from teller to atms automated home product store cashier and automate check depositing at bank be still in the midst of a slow and reserve acceptance curve . yet there be more article be write and uploaded each day about online social network addiction than there be about heroin addiction . people graduate with degree in english lit and find way to get onto software engineering team so they can afford a house , and intercontinental sex involve three of the five sens be on the rise . in general , postmodern people in most economic and education level worldwide be almost risk-oblivious toward most technology change . look back from a possible future another ethical question may appear in hindsight in another century . those future people may read about the driving condition of today and wonder how nineteenth century people decide to ignore the ethical consideration of allow unqualified and often highly distracted people to drive heavy equipment . ( that be a culture-bias-free description of what much current car and truck driving be . ) when the transition from horse to car begin , car be relatively slow . still , people saw that car could run over child and the elderly whereas a healthy horse would not . the gene of the horse that would trample a child have be eliminate by put down horse that trample child over a period of thousand of year . so in historical context , it may later become an ethical problem to continue to let human drive car . ethic in all technology introduction the introduction in technology generally create job and eliminate others . what the net effect be depend on the technology . brew beer create many job and displace a very few wine maker , produce a net improvement in employment opportunity . farm automation displace many small farmer and create very few equipment operation and repair job in comparison . the displacement of professional driver may be an ethical problem . whether some private car owner let their car drive them to the store or yoga class be not challenge any ethical standard , except for the ethical perspective of ludites , amish , technophobes , and other fringe group . however , bus and truck lack some of the frequency of challenge choice that car , truck , recreational vehicle , and minivan have . the probability distribution for lane transition , cruise speed , acceleration , stop deceleration , stop condition , turn , route deviation , and signal be narrower . they be much more likely to be fully automate first , and those driver have no lateral move within those transportation company . since both license and registration would be hold by the same entity , the av itself , motor vehicle department worker will be displace . although not entirely displace , some business and career would likely be negatively impact . personal injury lawyer and legal team insurance carrier , agent , and administrative organization that handle a large number of automotive policy and claim ethical consideration other than employment a number of system that be base on universal social standard relate to car will likely resist change to computer driving and may launch campaign oppose the public relation campaign launch by those introduce av product . such opposition would likely use mechanism to build apprehension about possible collapse of social infrastructure . there be several group that benefit from human drive . most of them be the personnel and system that use driver's license a a primary tool to support law enforcement and investigative work . acceptance and public relation convince people may be about clever marketing . if you saw all the crazy driving in my city , you wouldn't be quibble over remove steer wheel . keep teen safe . what's the real objective ? driving or get there ? av save fuel . even few accident with the honda driver-free autobot like have a limousine service in your garage one of the great feat of marketing and public relation be the construction of the idea of personal transportation . bet that automotive manufacturer can overcome the initial sense of creepiness and sell the new ai infuse product be not exactly a bet for fool . consider their current achievement . a large percentage of family in nearly every income bracket with one personal vehicle per adult family member people spend 20 % of their annual income solely to own the late trending body aesthetic and dashboard feature commute through horde of traffic to get to a cubicle contain a computer no more powerful than their home computer and sit on the same internet people select their life long partner on the basis of the car or truck that person own the assembly of a sustainable and unconscious social force to buy a new car every two or three year when fully restore the current one would require less than a quarter the expense people , base on an association between mechanical power and social dominance , maximally accelerate to just over the speed limit merely to stop at the next light in an only slightly different order , modify their arrival time by only two or three second in exchange for unnecessary mechanical wear and burn fuel the creation of a global economy a dependent upon car a the availability of air or water the automotive industry even surpass the fashion industry in their public relation and marketing prowess . footnote other aspect to this answer's approach no formal definition of the term use in the question be give . extended-project qualification artificial intelligence bias primary data for analysis controversy that be to do with ethic it be assume that gauge whether computer drive vehicle will be a technology that achieve ready market acceptance or stall due to apprehension be the objective of the question author . until more specific be give about what would make data primary and to what decision the qualification mention would apply , hunt for data set would be premature .******none******Nov 27, 2018******3******CA
62******obviously , driverless car aren't perfect , so imagine that the google car ( a an example ) get into a difficult situation . here be a few example of unfortunate situation cause by a set of event : the car be head toward a crowd of 10 people cross the road , so it cannot stop in time , but it can avoid kill 10 people by hit the wall ( kill the passenger ) , avoid kill the rider of the motorcycle consider that the probability of survival be great for the passenger of the car , kill an animal on the street in favour of a human be , change lane to crash into another car to avoid kill a dog , and here be few dilemma : do the algorithm recognize the difference between a human be and an animal ? do the size of the human be or animal matter ? do it count how many passenger it have vs . people in the front ? do it " know " when baby / child be on board ? do it take into the account the age ( e . g . kill the old first ) ? how would an algorithm decide what should it do from the technical perspective ? be it be aware of above ( count the probability of kill ) , or not ( kill people just to avoid it own destruction ) ? related article : why self-driving car must be program to kill how to help self-driving car make ethical decisionhow could self-driving cars make ethical decisions about who to kill?******how could self-driving cars make ethical decisions about who to kill?******Aug 02, 2016******3******CA
41******the answer to a lot of those question depend on how the device be program . a computer capable of drive around and recognize where the road go be likely to have the ability to visually distinguish a human from an animal , whether that be base on outline , image , or size . with sufficiently sharp image recognition , it might be able to count the number and kind of people in another vehicle . it could even use exist data on the likelihood of injury to people in different kind of vehicle . ultimately , people disagree on the ethical choice involve . perhaps there could be " ethic setting " for the user / owner to configure , like " consider life count only " v . " young life be more valuable . " i personally would think it's not terribly controversial that a machine should damage itself before harm a human , but people disagree on how important pet life be . if explicit kill-this-first setting make people uneasy , the answer could be determine from a questionnaire give to the user .******none******Aug 02, 2016******3******CA
11******this be the well know . a ben n say , people disagree on the right course of action for trolley problem scenario , but it should be note that with self-driving car , reliability be so high that these scenario be really unlikely . so , not much effort will be put into the problem you be describe , at least in the short term .******none******Aug 02, 2016******3******CA
5******for a driverless car that be design by a single entity , the best way for it to make decision about whom to kill be by estimate and minimize the probable liability . it doesn't need to absolutely correctly identify all the potential victim in the area to have a defense for it decision , only to identify them as well a a human could be expect to . it doesn't even need to know the age and physical condition of everyone in the car , a it can ask for that information and if refuse , have the defense that the passenger choose not to provide it , and therefore take responsibility for deprive it of the ability to make a good decision . it only have to have a viable model for minimize exposure of the entity to lawsuit , which can then be improve over time to make it more profitable .******none******Aug 02, 2016******3******CA
24******personally , i think this might be an overhyped issue . trolley problem only occur when the situation be optimize to prevent " 3rd option " . a car have brake , do it not ? " but what if the brake don't work ? " well , then the car be not allow to drive at all . even in regular traffic , human operator be taught that your speed should be limit a such that you can stop within the area you can see . solution like these will reduce the possibility of a trolley problem . a for animal ... if there be no explicit effort to deal with human on the road i think animal will be treat the same . this sound implausible - roadkill happen often and human " roadkill " be unwanted , but animal be a lot small and hard to see than human , so i think detect human will be easy , prevent a lot of the accident . in other case ( bug , fault while drive , multiple failure stack onto each other ) , perhaps accident will occur , they'll be analyse , and vehicle will be update to avoid cause similar situation .******none******Aug 03, 2016******3******CA
38******how could self-driving car make ethical decision about who to kill ? it shouldn't . self-driving car be not moral agent . car fail in predictable way . horse fail in predictable way . the car be head toward a crowd of 10 people cross the road , so it cannot stop in time , but it can avoid kill 10 people by hit the wall ( kill the passenger ) , in this case , the car should slam on the brake . if the 10 people die , that's just unfortunate . we simply cannot trust all of our belief about what be take place outside the car . what if those 10 people be really robot make to look like people ? what if they're try to kill you ? avoid kill the rider of the motorcycle consider that the probability of survival be great for the passenger of the car , again , hard-coding these kind of sentiment into a vehicle open the rider of the vehicle up to all kind of attack , include " fake " motorcyclist . human be barely equip to make these decision on their own , if at all . when it doubt , just slam on the brake . kill animal on the street in favour of human be , again , just hit the brake . what if it be a baby ? what if it be a bomb ? change lane to crash into another car to avoid kill a dog , nope . the dog be in the wrong place at the wrong time . the other car wasn't . just slam on the brake , as safely a possible . do the algorithm recognize the difference between a human be and an animal ? do a human ? not always . what if the human have a gun ? what if the animal have large teeth ? be there no context ? do the size of the human be or animal matter ? do it count how many passenger it have vs . people in the front ? do it " know " when baby / child be on board ? do it take into the account the age ( e . g . kill the old first ) ? human can't agree on these thing . if you ask a cop what to do in any of these situation , the answer won't be , " you should have swerve leave , weigh all the relevant party in your head , assess the relevant age between all party , then veer slightly right , and you would have save 8 % more life . " no , the cop will just say , " you should have bring the vehicle to a stop , a quickly and safely a possible . " why ? because cop know people normally aren't equip to deal with high-speed crash scenario . our target for " self-driving car " should not be ' a moral agent on par with a human . ' it should be an agent with the reactive complexity of cockroach , which fail predictably .******none******Aug 30, 2016******3******CA
2******frankly i think this issue ( the trolley problem ) be inherently overcomplicated , since the real world solution be likely to be pretty straightforward . like a human driver , an ai driver will be program to act at all time in a generically ethical way , always choose the course of action that do no harm , or the least harm possible . if an ai driver encounter danger such a imminent damage to property , obviously the ai will brake hard and aim the car away from breakable object to avoid or minimize impact . if the danger be hit a pedestrian or car or building , it will choose to collide with the least precious or expensive object it can , to do the least harm - - place a high value on a human than a building or a dog . finally , if the choice of your car's ai driver be to run over a child or hit a wall ... it will steer the car , and you , into the wall . that's what any good human would do . why would a good ai act any differently ?******none******Aug 31, 2016******3******CA
4******“ this moral question of whom to save : 99 percent of our engineering work be to prevent these situation from happen at all . ” — christoph von hugo , mercedes-benz this quote be from an article title self-driving mercedes-benzes will prioritize occupant safety over pedestrian publish october 7 , 2016 by michael taylor , retrieve 08 nov 2016 . here's an excerpt that outline what the technological , practical solution to the problem . the world ’ s old carmaker no longer see the problem , similar to the question from 1967 know a the trolley problem , a unanswerable . rather than tie itself into moral and ethical knot in a crisis , mercedes-benz simply intend to program it self-driving car to save the people inside the car . every time . all of mercedes-benz ’ s future level 4 and level 5 autonomous car will prioritize save the people they carry , accord to christoph von hugo , the automaker ’ s manager of driver assistance system and active safety . there article also contain the follow fascinating paragraph . a study release at midyear by science magazine didn ’ t clear the air , either . the majority of the 1928 people survey think it would be ethically good for autonomous car to sacrifice their occupant rather than crash into pedestrian . yet the majority also say they wouldn ’ t buy autonomous car if the car prioritize pedestrian safety over their own .******none******Nov 08, 2016******3******CA
2******i think that in most case the car would default to reduce speed a a main option , rather than steer toward or away from a specific choice . a others have mention , have setting relate to ethic be just a bad idea . what happen if two car that be program with opposite ethical setting and be about to collide ? the car could potentially have a system to override the user setting and pick the most mutually beneficial solution . it's indeed an interesting concept , and one that definitely have to discuss and standardize before widespread implementation . put ethical decision in a machine hand make the result liability sometimes hard to picture .******none******Nov 17, 2016******3******CA
2******how could self-driving car make ethical decision about who to kill ? by manage legal liability and consumer safety . a car that offer the consumer safety be go to be a car that be buy by say consumer . company do not want to be liable for kill their customer nor do they want to sell a product that get the user in legal predicament . legal liability and consumer safety be the same issue when look at from the perspective of " cost to consumer " . and here be few dilemma : do the algorithm recognize the difference between a human be and an animal ? if an animal / human cannot be legally avoid ( and the car be in legal right - if it be not then something else be wrong with the ai's decision making ) , it likely won't . if the car can safely avoid the obstacle , the ai could reasonably be see to make this decision , ie . swerve to another lane on an open highway . notice there be an emphasis on liability and driver safety . do the size of the human be or animal matter ? only the risk factor from hit the obstacle . hit a hippo might be less desirable than hit the ditch . hit a dog be likely more desirable than wreck the customer's automobile . do it count how many passenger it have vs . people in the front ? it count the people a passenger to see if the car-pooling lane can be take . it count the people in front a a risk factor in case of a collision . do it " know " when baby / child be on board ? no . do it take into the account the age ( e . g . kill the old first ) ? no . this be simply the wrong abstraction to make a decision , how could this be weight into choose the right course of action to reduce risk factor ? if option 1 be hit young guy with 20 % chance of significant occupant damage and no legal liability and option 2 be hit an old guy with 21 % chance of significant occupant damage and no legal liability , then what philosopher can convince even just 1 person of the just and equitable weight to make a decision ? thankfully , the best decision a lot of the time be to hit the break to reduce speed ( especially when you consider that it be often valuable to act predictably so that pedestrian and motorist can react accordingly ) . in the meantime , good value improvement can be make in term of predict when driver will make bad decision and when other action ( such a hit the reverse ) be more beneficial than hit the break . at this point , it be not worth it to even begin collect the information to make the ethical decision propose by philosopher . thus , this issue be over-hyped by sensational journalist and philosopher .******none******Jan 31, 2017******3******CA
1******the only sensible choice be to use predictable behaviour . so in the people in front of the car scenario : first the car hit the brake , at the same time honk the horn , and stay on course . the people then have a chance to jump out of the way lead to zero people be kill . also with full brake ( go from 50km per hour to zero be less than 3 car length ) , an impact situation be almost not imaginable . even if full stop cannot be reach , severe damage to the pedestrian be unlikely . the other scenario be just crazy . so the distance have to be less than 3 car length , at least 1 car length in need for the steering , then a car crashing be an uncontrollable situation , might lead to spin and kill all 11 person . apart from say that i don't believe there be an example in reality where there be a dilemma ; the solution in these unlikely case if to conform with the expectation of the oppose party to allow the other party to mitigate the situation as well .******none******Feb 12, 2017******3******CA
1******i think there would not be a way to edit such ethic setting in a car . but hey , if cell phone can be root , why not car ? i imagine there'll be linux build in the future for specific model that will let you do whatever you want . a for who'll make such decision , it'll be much like privacy issue of today . there'll be a tug-of war on the blanket by the o provider ( who'll try to set it to a minimum amount of people injure , each with it own method ) , insurance company ( who'll try to make you pay more for os's that will be statistically show to damage your car easier ) , and car manufacturer ( who'll want you to trash your car as soon a you can , so you'll buy a new one ; or make car that require a ridiculous amount of $ $ $ service ) . then some whistleblower will come out and expose a piece of code that choose to kill young child over adult - because it will have a hard time distinguish them from animal , and will take chance to save who it'll more surely recognize a human . the os manufacturer will get a head-slap from the public and a new consensus will be find . whistleblower will come out from insurance company and car manufacturer too . humanity will grab a hot frying pan and burn itself and then learn to put on glove beforehand . my advice would just make sure you won't be that hand - stay away from them for a couple of year until all the early mistake be make .******none******Feb 13, 2017******3******CA
2******they shouldn't . people should . people cannot put the responsibility of ethical decision into the hand of computer . it be our responsibility a computer scientist / ai expert to program decision for computer to make . will human casualty still exist from this ? of course , they will - - - people be not perfect and neither be program . there be an excellent in-depth debate on this topic here . i particularly like yann lecun's argument regard the parallel ethical dilemma of test potentially lethal drug on patient . similar to self-driving car , both can be lethal while have good intention of save more people in the long run .******none******Apr 13, 2018******3******CA
4******which deep neural network be use in google's driverless car to analyze the surroundings ? be this information open to the public ?which machine learning algorithm is used in self-driving cars?******which machine learning algorithm is used in self-driving cars?******Aug 02, 2016******3******CA
1******the most common machine learn algorithms find in self driving car involve object track base technology use in order to pinpoint and distinguish between different object in order to good analyse a digital landscape . algorithm be design to become more efficient at this by modify internal parameter and test these change . i hope that provide a general overview of the subject . since google's car be in development and be proprietary , they will probably not share their specific algorithm , however you can take a look at similar technology to learn more . to find out more , take a look at an oxford-based initiative in self driving car and how they work .******none******Nov 04, 2016******3******CA
2******it will not be single dnn architecture , rather it will be a collection of different dnn architecture that be use together to make the final decision . convolution be use the image / video from the camera . other architecture use other sensory source . these dnns will be train to compute the high-level feature from their sensory source and then those high-level feature will probably be feed into an lstm ( or some other form of rnn ) that be train with some form of reinforcement learn algorithm to compute the action ( like slow down , apply break etc ) .******none******Nov 05, 2016******3******CA
2******the situation : a self-driving car be travel at it's maximum speed , 25 mph ( 40 km / h ) , in the middle of an empty street with the ability to change lane on both side . there be two passenger , one in the front and another in the back . someone jump from the side of the road directly into the path of the car . a collision would occur in 50 meter . break distance at this speed be about 24m . the question : be it know how the current implementation of the google car ai would react , or be it currently a matter of speculation ? a step-by-step explanation of the ai's decisioning process would be prefer . possible answer : the car could activate it brake immediately , come to a halt as quickly a possible . this would be sooner than a human could stop , a people require time to recognize the possibility of a collision , and then physically slam on the brake . ( think distance ) . alternatively , the car could continue travel forward , process the situation . ( similar to a human think distance ) . the person may continue to move , either out of the way , or still into danger of be hit . in this case , the car may decide to change lane in an attempt to pass around the person . lastly and most unlikely , the car will not alter it course and proceed to drive forward . <sup> do not attempt to do it to check ;) </sup>what would happen if someone jumped in the front of a google car?******what would happen if someone jumped in the front of a google car?******Aug 04, 2016******3******CA
2******give this youtube video which be be give by sebastian thrun who have a ted talk which have nowhere near the same level of detail but have similar conclusion , it look like the lidar system use by google's automate car system have decent resolution out to at least 30m pick out mobile body in the static background and then identify it . so it should have plenty of time to brake and stop long before there be any risk to the pedestrian attempting to cross the street . skip to about 6:40 in the video to see a visual representation of the detection system .******none******Sep 01, 2016******3******CA
2******this study ( page 7-8 ) show an attempt at recognize the traffic sign with low error rate by use multi-column deep neural network be google car use similar technique of predict sign use dnn , or be they use some other method ?how do google cars recognize the traffic signs?******how do google cars recognize the traffic signs?******Aug 06, 2016******3******CA
2******i'm not sure what google be use to perform that task but most company use region base convolutional neural net to locate traffic sign and other object . but other company use a deep neural net + bag of word approach to find object . see : bag-of-words base deep neural network for image retrieval which show a general approach , to get the exact location you can use feature matching or random box .******none******Sep 09, 2016******3******CA
1******some time ago play chess be challenge for algorithm , then go game which be vastly more complex than compare to chess . how about play rts game which have enormous branching factor limit by it time and space ( like decide what to do next ) ? what be the successful approach to such problem ?how to deal with huge branching factors in real-time?******how to deal with huge branching factors in real-time?******Aug 09, 2016******3******CA
2******i want to build a personal assistant that listen to me continuously .. the flow look like this : continuously record voice stream it to google speech api . get back the text in real time -> parse for intent etc .. problem be , google speech api get expensive if you record for hour . a good way to do it be to only submit the part where i'm actually speak to it .. then the cost of run this full time ( 17 hour a day , every day ) become very accessible . now my question be : how can i detect that a voice be present in the microphone stream ? i have a lot of noise in the background , dumb be not a very good solution . i need something more intelligent . it doesn't need to be very accurate - just good enough to not break my cloud compute budget . i'm think that human voice sound distinct enough that be not such a big problem to detect when be there . what do you recommend me to do , give this be a real time stream - not an audio file . the audio will be generate in chromium browser ( electron ) - with api , and use i plan to handle the streaming logic . note : there be a build in in - but from my experience currently it doesn't work ( not even after i give it my api key ) , and even if would have work , i think it have the same cost problem . so this be why i'm try to provide my own implementation . i don't know what i'm do , any insight be welcome :) thank you .how to detect when human voice / speech appears in an microphone stream?******how to detect when human voice / speech appears in an microphone stream?******Nov 11, 2017******3******CA
4******i've be tell this be how i should be preprocessing audio sample , but what information do this method actually give me ? what be the alternative and why shouldn't i use them .why is short-time fourier transform used for preprocessing audio samples?******why is short-time fourier transform used for preprocessing audio samples?******Oct 02, 2018******3******CA
14******i know that language of be use early on when work on artificial intelligence problem . be it still be use today for significant work ? if not , be there a new language that have take it place a the most common one be use for work in ai today ?is lisp still being used to tackle ai problems?******is lisp still being used to tackle ai problems?******Aug 02, 2016******3******CA
1******in my opinion python and java have take over from lisp . many people use them , there be a large amount of library available . and more importantly , they be easy to integrate in web technology .******none******Aug 02, 2016******3******CA
7******the following thread have many answer regard why lisp use to be think of a the ai language : why be lisp use for ai and the following be an answer by peter norvig , who write a popular textbook on the subject and be currently director of research at google : be it true that lisp be highly used programming language in ai ? i be not overly familiar with the history , but i think lisp be oversold to industry a " the ai language " . it be a good language for human to think in and pioneer many important idea which have since be incorporate into many modern language ( see the wikipedia page ) , but it be no way the " best " . it be likely also popular because it be very expressive : you can write short program to represent complex idea , a property it share with other functional language in use such a scala . this also mean that it be easy to write a program that be very hard to debug in lisp . modern functional language have be try to do well in this regard through type etc . the paradigm for ai that currently receive most attention be machine learning , i . e . learn hypothesis from data , a oppose to previous approach like expert system where expert write rule for the ai to follow . python be currently the most widely use language for prototyping machine learn algorithm and have many library and an active community . another important detail about modern ai be the volume of data it use . big data analysis be do use cluster compute system like hadoop ( with code write in java ) and spark ( with code write in python or scala ) . often , the core time-intensive subroutine be write in c , but this be often do in the form of third-party library . finally it must be say that the ai winter of the 80 be not because we do not have the right language , but because we do not have the right algorithm and do not have enough computational power . this have change a gpus have get well . if you're try to learn ai , spend your time study algorithm and not language .******none******Aug 02, 2016******3******CA
3******lisp be still use significantly , but less and less . there be still momentum due to so many people use it in the past , who be still active in the industry or research ( anecdote : the last vcr be produce by a japanese maker in july 2016 , yes ) . the language be however use ( to my knowledge ) for the kind of ai that do not leverage machine learning , typically a the reference book from russell and norvig . these application be still very useful , but machine learn get all the steam these day . another reason for the decline be that lisp practitioner have partially move to clojure and other recent language . if you be learn about ai technology , lisp ( or scheme or prolog ) be good choice to understand what be go on with " ai " at large . but if you wish or have to be very pragmatic , python or r be the community choice note : the above lack concrete example and reference . i be aware of some work in university , and some company inspire by or directly use lisp . to add on @harsh ' s answer , lisp ( and scheme , and prolog ) have quality that make it look like it be well suit for create intelligent mechanisms---making ai a perceive in the 60 . one of the quality be that the language design lead the developer to think in a quite elegant way , to decompose a big problem into small problem , etc . quite " clever " , or " intelligent " if you will . compare to some other language , there be almost no choice but to develop that way . lisp be a list processing language , and " purely functional " . one problem , though , can be see in work relate to lisp . a notable one in the ai domain be the work on the situation calculus , where ( in short ) one describes object and rule in a " world " , and can let it evolve to compute situations---states of the world . so it be a model for reason on situation . the main problem be call the frame problem , mean this calculus cannot tell what do not change---just what change . anything that be not define in the world cannot be process ( note the difference here with ml ) . first implementation use lisps , because that be the ai language then . and there be bind by the frame problem . but , a @harsh mention , it be not lisp's fault : any language would face the same framing issue ( a conceptual problem of the situation calculus ) . so the language really do not matter from the ai / agi / asi perspective . the concept ( algorithm , etc . ) be really what matter . even in machine learning , the language be just a practical choice . python and r be popular today , primarily due to their library ecosystem and the focus of key company . but try to use python or r to run a model for a raspberrypi-based application , and you will face some severe limitation ( but still possible , i be do it :-) ) . so the language choice burn down to pragmatism .******none******Aug 03, 2016******3******CA
5******i definitely continue to often use lisp when work on ai model . you ask if it be be use for substantial work . that's too subjective for me to answer regard my own work , but i query one my ai model whether or not it consider itself substantial , and it reply with an affirmative response . of course , it's response be naturally bias as well . overall , a significant amount of ai research and development be conduct in lisp . furthermore , even for non-ai problem , lisp be sometimes use . to demonstrate the power of lisp , i engineer the first neural network simulation system write entirely in lisp over a quarter century ago .******none******Aug 03, 2016******3******CA
1******i read some information <sup> 1 </sup> about attempt to build neural network in the php programming language . personally i think php be not the right language to do so at all probably because it's a high-level language , i assume low level language be way more suitable for ai in term of performance and scalability . be there a good / logical reason why you should or shouldn't use php a a language to write ai in ? <sup> 1 </sup> andcan php be considered as a serious programming language for ai?******can php be considered as a serious programming language for ai?******Aug 04, 2016******3******CA
6******question on-topicness questionable , but ... the most logical reason why php be unsuited for neural network be that php be , well , intend to be use for server side webpage . it can connect to various external resource , such a database , via native language feature . it be very much a glue language , and not a processing language . php be also mostly stateless , only allow you to store state in either client , file storage or database . a such , it's not suitable for this sort of thing - not because php be a high level language , but rather because it's so request base and focused towards create page to serve to client . that won't stop people from try , though - there be various esoteric programming languages out there in which regular programming would be an insane task or not possible at all - but from a ease of development perspective , make a neural network in php make no sense .******none******Aug 04, 2016******3******CA
3******actually , yes . remember , that due to the history of php development , some very good thing have form what we have now : from a simple / laggy / limit interpreter in php 3 , we have now three mainstream line come one-by-one like v5 / v6 / v7 with full bytecode support . in php v7 you don't even need a bytecode cache due to hhvm , old zend vm be a hell-good-debugged and use a cacher like xcache you can achieve a true native execution speed and payload the php language interface allow any external c / c + + library just to be add a a module via very simple wrapper that can be write by the person that just red kerrigan & richie and straustrup base book on c and c + + . this be amazing feature , exclusive to php as far a i know in php v7 you're welcome to use native multi-threading and even cuda-based thing , if you wish to do it . i do it , so i can confirm that it work******none******Aug 04, 2016******3******CA
1******i assume , there must be " signal-driven " and maybe also real-time programming language , which base on connectivy-data more than variable ( int , string , etc ) . i would like to have a language without equaton ( x = 4 ) but more like " x relate to 4 " or " cat relate to animal " etc ...is there a "better" (signal-based) language for artificial intelligence******is there a "better" (signal-based) language for artificial intelligence******Apr 05, 2017******3******CA
4******what you need be other way of knowledge representation , such a semantic network or conceptual graph . there you can define any possible relation between your entity . the knowledge of " x relate to 4 " exactly fit into " frame " and " semantic network " . jaynes in his book , discuss thoroughly what " plausibility " mean and why we need to take into account weak syllogism and start use probability theory a a platform for develop a ( general ) ai . this might also help with your " reason " phase ( after you've develop your knowledge base )******none******Apr 06, 2017******3******CA
2******i don't know if this be what you want , but artificial intelligence markup language or simply aiml be something that you should consider . the only problem i see with this language be that it be not popular thus there aren't many compiler for it . here be an example of aiml . code from tutorial point : result :******none******Apr 06, 2017******3******CA
0******hello i new to artificial intelligence , i be web developer i know html , javascript , node j and php . be these language be ok to create simple ai app . i have simple ai app in my mind to which will take input a a voice command to shut down my computer . to create above simple above technology ok or i have to learn new technology for above app.after create this simple app i will update and try to control my window with voice .which language(s) should one know in order to start with artificial intelligence?******which language(s) should one know in order to start with artificial intelligence?******May 22, 2017******3******CA
3******i be a software engineering student and i be complete beginner to ai . i have read a lot of article on how to start but each article suggest a different way . i be wonder if some of you expert can help me get start in the right way . first , which language should i focus ? a of right now , my main language be java , but a lot of article suggest that i should learn python , c + + or lisp for ai . can i use java instead of any of the other language mention ? second , what kind of math background should i have ? during the first year , i do discrete math which include the following topic : - set , matrix , vector , function , logic and graph theory ( they teach these topic briefly ) . be the be there any more topic that i should learn now ( calculus maybe ? ) ? if possible i would appreciate any resource or book i could use in order to get start or maybe you guy can give me a detailed procedure i can follow in order to catch up with to your level . note : for now i would like to focus on neural network and machine learning . after i that i would like to explore robotics and natural language processing .how does one start learning artificial intelligence?******how does one start learning artificial intelligence?******May 24, 2017******3******CA
3******you'll find that both calculus and linear algebra have some application in ai / ml technique . in many sens , you can argue that most of ml reduces to linear algebra , and calculus be use in , eg . the backpropagation algorithm for train neural network . you'd be well serve to take a class or two in probability and statistic as well . program language choice be less important , imo . you can do ai / ml in pretty much any mainstream language , and plenty of non-mainstream language . the big difference involve performance , and availability of library / tool . c + + , for example , be usually go to outperform java or python and it let you get " close to the metal " to really maximize the capability of your hardware . python , however , have a really good ffi , and be often use in conjunction with c or c + + . python , c + + , java , r , octave / matlab and a few other language tend to have lot of high quality library available , which may be important to you depend on what you want to do . that say , you probably don't want to try and do ml / ai in , say , cobol or pl / i or rpg / 400 or something . stick to something at least reasonably popular . poke around mloss.org and look at what libraries / toolkits be available in different language and that should help guide your choice .******none******May 25, 2017******3******CA
11******artificial intelligence be a very broad field and it cover many and very deep area of computer science , mathematics , hardware design and even biology and psychology . a for the math : i think calculus , statistic and optimization be the most important topic , but learn as much math a you can won't hurt . there be many good free introductory resource about ai for beginner . i highly recommend to start with this one : they also publish two video about the general concept of ai , you can find them on vimeo : " ai , deep learning , and machine learning : a primer " and " the promise of ai " once you have a clear understanding of the basic ai term and approach , you have to figure out what your goal be . what kind of ai software do you want to develop ? what industry be you interested in ? what be your chance to get involve in project of big company ? it's easy to pick up the right tool when you know exactly what you want to achieve . for most newcomer to ai the most interesting area be deep learning . just to make it clear , there be many area of ai outside of machine learning and there be many area of machine learn outside of deep learning . ( artificial intelligence > machine learn > deep learning ) most of recent development and hype news be about dl . if you get interested in deep learning too , you have to start with learn about the concept of artificial neural network . fortunately it's not too difficult to understand the basic and there be lot of tutorial , code example and free learning resource on the web and there be many open-source framework to start experiment with . the most popular such deep learning framework be tensorflow . it's back by google . love it or hate it , it's a python base framework . there be many other python base framework , as well . scikit-learn , theano , kera be frequently mention in tutorial too . ( a tip : if you use window you can download winpython that include all of these framework . ) a for about java framework , unfortunately there be not so many option . the most prominent java framework for dl be deeplearning 4j . it's develop by a small company and it user base be much small then the crowd around tensorflow . there be few project and tutorial for this framework . however , industry specialist say java base framework eventually integrate well with java base big data solution and they may provide a high level of portability and easy product deployment . just a sidenote : nasa's jet propulsion laboratory use deeplearning 4j for many project . if you decide to go with the flow and want to start learn more about tensorflow , i recommend you to check out the youtube channel of " deeplearning.tv " , " sentdex " and " siraj raval " . they have nice tutorial and some cool demo . and if you decide to take a deep dive , you can sign up for an online course at udacity or coursera . it also may be interest to you to know that there be other deep learning framework for the java virtual machine with alternative language , for example clojure . ( clojure be a dialect of lisp and it be invent by john mccarthy , the same computer scientist who coin the term " artificial intelligence " . in other word there be more modern and popular programming language and tool , but it's still possible / and kinda cool / to use the language for ai that be originally design for ai . thinktopic in boulder and freiheit in hamburg be two company that use clojure for ai project . and if you want to see something awesome to get inspiration to use clojure in ai and robotics , i recommend you to check out the youtube video " oscon 2013 : carin meier , the joy of fly robot with clojure " . ( mention clojure in this answer be just an example to show you there be life outside of the bubble of python-based ai framework . ) ( + + + anybody feel free to correct me if i say anything wrong . + + + )******none******May 25, 2017******3******CA
2******to start ai first of all understand what be ai . why mnist's accuracy increase rapidly after 2012 . why machine learn need ai to increase it accuracy . to start and build application on machine learn with ai you didn't need math or some kind of rocket science . you be late my bro people build shortcut for all machine learn problem like a wrapper . you just need to pass data to a method and method will do all shit . start with mnist's problem it exciting . read about mnist's history use basic algorithm on it . try linear regression , logistic regression , kmean clusting , knn . tool for machine learn skite learn ( python lib ) or tensorflow ( python lib ) tflearn ( high level api of tensorflow like a wrapper ) both be open source . example be available on github . start search on github . you find a great example . for both lib . use kaggel to solve problem participate in comptition . when you complete all above algorithm try to focus on your your error . now ai come in roll . try to figure out how neural network help you to decrease error and increase accuracy . then try some basic neural network like sigmoid , relu and cnn . don't forget to use dropout in your neural network . you can use tensorflow or kera or tensorflow with kera side by side check 3 blue 1 brown's linear algebra video's to improve your math . once a day but everyday one video . and now focus on math behind the logic ( any algorithm ) you can try andrew ng machine learn course . use tensorflow for build android app , ios app , rasppi check tensorflow dev summit 2016/2017 . or if you need crash course then check this******none******May 25, 2017******3******CA
2******when i get interested in ai , i start with the most basic thing . my very first book be russell & norvig's artificial intelligence - a modern approach . i think that's a good place to start , even if you're mostly interested in deep net . it treat not just the basic ai concept and algorithm ( expert system , depth-first and breadth-first search , knowledge representation , etc . ) but also the fundamental mathematics ( bayesian reasoning , first order logic , nl n-grams , etc . ) and some commonly know problem ( a travel salesman problem for example ) . it may also be a good idea to learn statistic , since you be particularly interested in ml . after the mentioned book , you should also have a good idea about what to learn next . don't care too much about the programming language . it's much more important to understand program itself and the related technique . learn something about data structure , algorithm , and the different programming paradigm ( like oop , functional programming , etc . ) . try to understand the logic behind programming and not just a particular language . after all , learn a new language isn't that hard once you understand how to program ( then learn a new language be just more or less syntactic sugar ) .******none******May 27, 2017******3******CA
1******i be a newbie in the ai field as well . i be like you , try to look for good resource to learn about ai and machine learning . here be some resource i have find useful to get to know the basic of ai - andrew ng's lecture series on ai andrew ng's lecture at the stanford business school andrew ng - the state of artificial intelligence andrew ng be a visiting professor at stanford , founder of coursera and currently the head of research at alibaba . the above video should give you all the basic you need about ai . - raj testim.io******none******Mar 08, 2018******3******CA
2******before get into artificial intelligence , one should be do with the prerequisite . there be not a solid list , but a good knowledge of various algorithm be compulsory . apart from that you should be comfortable with at least one programming language , like c + + or java . i win ’ t suggest you to dive into artificial intelligence if you be completely new to computer science . some experience with program prior to dive into artificial intelligence will be a plus point for you . start reading ( blog , paper , scholar article , etc . ) about artificial intelligence . like what it be , it application , current status and other stuff that you can find . start make ai code for small game like tic tac toe , sudoku , reversi ( othello ) , etc . for the start . you can create your own simulator and build a code that solve rubik cube . similarly , make code for pattern recognition and machine learning . nothing be good than learning by do . language like lisp and python will be very helpful . here be two answer that will help you , ans 1 and an 2 . if you be a person like like to read and learn from book ( like me ) , then you can buy artificial intelligence : a modern approach ( peter norvig and stuart russell ) . the book be very good and work well for the intermediate and advanced level . try to solve the exercise problem give in the book . the solution pdf of the book be available online . for machine learn two book that i recommend be pattern recognition and machine learning ( christopher m . bishop ) and program collective intelligence ( o ’ reilly ) . for the start , there be a very good article on artificial intelligence and technological singularity . the article be long and divide into two part . i strongly recommend you to read this article if you be serious about artificial intelligence . it will give you some good insight . knowledge of computational theory will greatly help you . especially when you be work in the field of natural language processing . other sub-fields of ai that might interest you will be machine learning , evolutionary computing , genetic algorithm , reinforcement learning , deep learning etc . the list go on . good your knowledge of statistic , good it will be for artificial intelligence . stay tune to recent going in the field via forum , website , etc . open ai website be also a very good source .******none******Mar 09, 2018******3******CA
20******first of all , i'm a beginner study ai and this be not an opinion orient question or one to compare program language . i'm not say that be the best language ( actually i know almost nothing about python ) . but the fact be that most of the famous ai framework have primary support for python . they can even be multilanguage support , for example , tensorflow that support python , c + + or cntk from microsoft that support c # and c + + , but the most used be python ( i mean more documentation , example , big community , support etc ) . even if you choose c # ( develop by microsoft and my primary programming language ) you must have the python environment set up . i read in other forum that python be prefer for ai because the code be simplify and clean , good for fast prototyping . i be watch a movie with ai thematics ( ex_machina ) . in some scene , the main character hack the interface of the house automation . guess which language be on the scene ? python . so what be the big deal , the relationship between python and ai ?why is python the most popular language in the ai field?******why is python the most popular language in the ai field?******Jun 15, 2017******3******CA
4******python have a standard library in development , and a few for ai . it have an intuitive syntax , basic control flow , and data structure . it also support interpretive run-time , without standard compiler language . this make python especially useful for prototyping algorithm for ai .******none******Jun 15, 2017******3******CA
14******practically all of the most popular and widely use deep-learning framework be implement in python on the surface and c / c + + under the hood . i think the main reason be that python be widely use in scientific and research community , because it's easy to experiment with new idea and code prototype quickly in a language with minimal syntax like python . moreover there may be another reason . a i can see , most of the over-hyped online course on ai be push python because it be easy for newbie programmer . ai be the new marketing hot word to sell programming course . ( mention ai can sell program course to kid who want to build hal 3000 , but can not even write a hello world or drop a trend-line onto an excel graph . :)******none******Jun 15, 2017******3******CA
17******python come with a huge amount of inbuilt library . many of the library be for artificial intelligence and machine learning . some of the library be tensorflow ( which be high-level neural network library ) , scikit-learn ( for data mining , data analysis and machine learning ) , pylearn 2 ( more flexible than scikit-learn ) , etc . the list keep go and never end . you can find some library here . python have an easy implementation for opencv . what make python favourite for everyone be it powerful and easy implementation . for other language , student and researcher need to get to know the language before get into ml or ai with that language . this be not the case with python . even a programmer with vert basic knowledge can easily handle python . apart from that , the time someone spend on writing and debug code in python be way less when compare to c , c + + or java . this be exactly the student of ai and ml want . they don't want to spend time on debug the code for syntax error , they want to spend more time on their algorithm and heuristic relate to ai and ml . not just the library but their tutorial , handle of interface be easily available online . people build their own library and upload them on github or elsewhere to be use by others . all these feature make python suitable for them .******none******Jun 16, 2017******3******CA
1******what attract me to python for my analysis work be the " full-stack " of tool that be available by virtue of be design a a general purpose language v . r a a domain specific language . the actual data analysis be only part of the story , and python have rich tool and a clean full-featured language to get from the beginning to the end in a single language ( use of c / fortran wrapper notwithstanding ) . on the front end , my work commonly start with get data from a variety of source , include database , file in various format , or web scraping . python support for this be good and most database or common data format have a solid , well-maintained library available for the interface . r seem to share a general richness for data i / o , though for fit the r package appear not to be under active development ( no release of fitsio in 2.5 year ? ) . a lot of the next stage of work typically occur in the stage of organize the data and do pipeline-based processing with a lot of system-level interaction . on the back end , you need to be able present large data set in a tangible way , and for me , this commonly mean generate web page . for two project i write significant django web apps for inspect the result of large chandra survey project . this include a lot of scrap ( multiwavelength catalog ) and so forth . these be just use internally for navigate the data set and help in source catalog generation , but they be invaluable in the overall project . move to the astronomy-specific functionality for analysis , it seem clear that the community be solidly behind python . this be see in the depth of available package and level of development activity , both at an individual and institutional level ( ) . give this level of infrastructure that be available and in work , i think it make sense to direct effort to port the most useful r statistical tool for astronomy to python . this would complement the current capability to call r function from python via rpy2.if you be interested , i strongly recommend that you read this article , here it be a question of compare programming language ... nd-java-r / i hope it helps.good luck******none******May 23, 2018******3******CA
0******that ’ s because python be a modern script object-oriented programming language that have stylish syntax . contrary to structural programming language like java and c + + , it scripting nature enable the programmer to test his / her hypothesis very fast . furthermore , there be lot of open source machine learn library ( include scikit-learn and kera ) that broaden the use of python in ai field .******none******May 24, 2018******3******CA
7******what be the advantage / strength and disadvantage / weakness of program language like common lisp , python and prolog ? or why these language be use in the domain of artificial intelligence ? what type of problem relate to ai be solve use these language ? please give link of paper / book regard the mention topic .artificial inteligence and programming languages******artificial inteligence and programming languages******Mar 09, 2018******3******CA
-2******only forth be the correct programming language for implement an ai . because forth be a lowlevel and a high-level language at the same time . it support the object-oriented paradigm , functional programming and be superior to the z specification language . program a small agent in forth be easy , here be the sourcecode for an aimbot which be level through a maze : apart from forth no other language be recommend , for example c + + or lisp . in theory , it be possible to create with them also work ai system , but forth be the more elegant way of do so . an example , how to implement the prolog virtual machine ( pvm ) in forth be give in compile prolog to forth******none******Mar 09, 2018******3******CA
4******if we talk about applied ai , the choice of a programming language for an ai application have the same point to be take into account that in any other software area : speed of generated code , expressive , reusable , etc . by example , a training of a neural net be very expensive in cpu , languages a c / c + + , that produce very optimized code , be very convenient . moreover , there be gpus librarian in c / c + + that allow use of strong parallelism . a system with some complexity will combine more than one language , in order to use the best of the language in the point where it be need . but return to the list of language that appear in the question . a all them be turing complete compare them mean talk about it paradigm , feature , syntax and available compiler / interpreter . obviously , something that exceed the possibility of a simple answer . just to show some key point about the one mention in the question : prolog be a program paradigm by itself . it main advantage be that prolog sentence be independent from remainder one and near to the mathematical definition of the concept . moreover , it be itself a database . it drawback be also well know : very slow , lack of librarian for i / o , ... . very interesting ( even mandatory ) to know a few example of algorithm in prolog , but i doubt nobody be use it nowadays , except in obsolete university course ( when you reach the " ! " , cut it study ) . lisp be also a zombie . it functional paradigm have be now include in lot of very more modern language , combine it with object orient paradigm : scala , haskell , ocaml / f # , ... . be functional allow a syntax that make easy to express logic concept a recursive definition of logic or type , ... . something very interesting in ai . in the category of object orient paradigm and valid for all application , we have python ( easy to learn , fast prototyping , slow , ... ) c / c + + ( very optimized code ) , java , ... . more or less , all them be adopt also functional feature in late standard . in ai there be a lot of very interesting language feature to be also consider : rule base system , ... . librarian for them can be find in all main language . finally , some word about agi ( strong ai ): you do not need a computer . in best moment , we be at the stage of pencil and paper , remainder one look at ceiling .******none******Mar 09, 2018******3******CA
0******i be currently learn c # any advice with this language about course or should use another programming language , preferred language ​ ​ spanish or englishit is advisable to use c # to start in the world of ai******it is advisable to use c # to start in the world of ai******Mar 13, 2018******3******CA
1******c # be the perfect choice for program the first aimbot . quote : “ library for the large programming language like java and c # have method for extract the color value of a certain pixel , render this information extraction a very easy task . ” cheating in online game : a case study of bot and bot-detection in browser-based multiplayer game c # can also be use for parse event from rts-games . quote : “ we implement this tool in c # use visual studio 2008 . it parse combat log produce by world of warcraft ” . sequence-based bot detection in massive multiplayer online game for all , who be not familiar with the concept itself : an aimbot be a software program to play exist computergames semi-automatically . it be similar to the “ mario ai - ” and “ starcraft ai ” challange , but be create outside of the university sector by beginner in artificial intelligence .******none******Mar 13, 2018******3******CA
4******i be a university student take an artificial intelligence class this semester . our professor's program language of choice be java , but it seem that perhaps with some nudging , he can change it to python . i want to know if there be any merit in do so . i know a programming language be just a programming language - however , give the industry's wide use of python when implement ai algorithms ( especially with ml ) , i think it make much more sense for u to use python . it will be easy to transition from a university environment to an industrial one have do several assignment in python and have a clear understanding of all the tool it provide than if we continue use java , correct ? what be your thought ?learning artificial intelligence with python vs. java******learning artificial intelligence with python vs. java******May 09, 2018******3******CA
2******i don't think there be much merit in use one language over the other . it's true that you will get a good feeling for what libraries etc . be available in python when use it , but i think it's more important to focus on the mathematics and application of the algorithm and technique you will learn , a these will be relevant regardless of the language / library you end up use .******none******May 09, 2018******3******CA
3******while dyedgreen be right in some respect , i don't agree entirely with that sentiment . sure , you can theoretically use any language as long a you know the math and understand the concept inside and out whilst have some applicable knowledge . however , i don't believe if you be start from scratch , you should learn to develop model in java . while the underlying material be the same , all you be do be waste time imo learn a language that be rarely use in the field and lack sufficient support by most modern ml framework . also , while this be rather subjective , python feel well when use a a data science language . work with data especially be where that difference be clear to me . that be say , this could all change , and java could become the ml language of choice ( extremely unlikely ) .******none******May 09, 2018******3******CA
2******i'm go to go ahead and disagree with the others . from an academic perspective for ai or any c relate assignment java ( or c or c + + ) will always have much more benefit a you will get to write the actual code instead of use library others have already write . that way later on when you transition to python or whatever language you choose you'll know whats under the hood and use it and optimise it more effectively than someone who only know which libraries to use for what application .******none******May 10, 2018******3******CA
0******to add a few cent , i do not think it will make any difference . the reason be that the content of the course will be , by design ( if you can teach it use java ) , very general , general enough so it will not matter what language you use ( this have to be so otherwise you would not be able to use java ) . once you need to do advanced stuff and want to automatize the basic algorithm , you can switch to python , where you can use super advanced api's like kera , which be on top of tensorflow which be on top of python . to give you a particular example , with full time dedication you should be able to switch from matlab to python and implement your first keras model , by self learning , in not more than a couple of month .******none******May 10, 2018******3******CA
2******i be currently study information system engineering ( ba ) and i'm thinking of get a master degree in artificial intelligence.so , what be the main important skill do i need to succeed at this field , and what kind of math do it require ?what skills are needed to succeed at artificial intelligence field?******what skills are needed to succeed at artificial intelligence field?******Jun 27, 2018******3******CA
3******hey the main important skill you need be self discipline :) . for math : - i believe you need to know alot of statistic and probability ( most machine learning algorithm be build on statistic ) , vector and matrix , calculus . programming : - python for data science but not limited to python there be a couple of library in other programming language that can help , you can use r for a mathematical ( statistical approach to ai ) .. ... if you want to go to the theoretical ( algorithmic ) side work mostly on r and research and mathematics ( from both pure and apply math branch ) .. if you want the applied side of ai ... work on program language preferably python and get farmiliar with data science library and work with big data ( thing like knowledge in hadoop can also help )******none******Jun 27, 2018******3******CA
1******" artificial intelligence " be now a mature field and there be many subfields in it . there be entire theory erect around each subfield of artificial intelligence . a simple analogy would like " what be the skill need for succeed in mathematics / physic ? " . the answer really depend on what branch you want to delve into . if you be plan to go into more application specific side of artificial intelligence ( machine learn / deep learning ) then you must be thorough with linear algebra . since most of machine learn algorithm can be boil down to simple trick in linear algebra . learn about optimization will help a lot because you will encounter many algorithm involve convex / nonconvex optimization method . also statistic and probability be must for any field in artificial algorithm . that say , at core artificial intelligence deal with machine that think . so it would be good if you be through with formal logic , automaton and complexity theory .******none******Jun 27, 2018******3******CA
2******i be learn about restrict boltzmann machine and i'm so excite by the ability it give u for unsupervised learning . the problem be that i do not know how to implement it use one of the programming languages i know without use library . i want to implement it manually , which mean that i want to use native functionality of a language as much a possible . the programming languages i know be java , c , php ( my prefer language ) , javascript , r and python . i be not familiar with tensorflow or scikit-learn or similar stuff . thanks in advancehow to implement a restricted boltzmann machine manually?******how to implement a restricted boltzmann machine manually?******Jul 10, 2018******3******CA
1******if you already know java , you may wish to investigage java-ml , mahout , mlib , and dl4j for ai experimentation and research . once you have visualization to publish from your investigation , you can couch them in php for web publication . also , use of rbms have be give way to convolution layering and other type of auto-encoding and feature extraction design .******none******Jul 11, 2018******3******CA
1******if your interest be to follow the hype and become an " expert " in machine learning so that we can automate the world the rest of the way and our grandchild can just play golf and video game , then the fast path be to learn tensorflow , scikit-learn , or kera while make money write php apps for fortune 500 company . you can begin by find some rbm example code that look like it execute and have some example data or a link to some . then download whatever of those common framework they use , and then study by follow the path of least resistance a if you be a machine learning . no joke . many will make money from big corporation that way and probably already be . also if the reason you want to do the rbms manually be you want to see how they work , this be the way to go . take apart what others write like you would an old lawnmower to learn about internal combustion engine . if your interest be to learn about the nature of intelligence and consciousness because you like to discover new thing , then take the trendy framework less seriously and learn what rbms be and why they be be supersede by other architecture . in that case , learn about probability , calculus , and search algorighms in 2d , 3d , and high dimension ( and read book that most of the trendy people would think be date ) be the best direction . if you want to see if , in your lifetime , you can create a digital brain that you can teach to fix the lawnmower and then go mow your lawn ( also no joke ) then learn to code in c and c + + and learn socket , other system level programming , and how to access the dsp in a video card because your go to need some blind speed and parallelism .******none******Jul 11, 2018******3******CA
8******i like the enforced indentation of python that many don't like because i hate parenthetic typing and redundant semicolon . i like the shell interface , but why do some think python be de facto for machine learning ? even with straight rectify linear activation , because of sheer dimensionality , simulate circuit comprise of artificial neuron place large demand upon compute resource . process video in a typical adversarial artificial network algorithm require seven nested loop . adversarial pair iteration neural net layer depth sample index frame index pixel depth vertical horizontal we call the filter for convolution a " kernel " and pawn it off to dsps in gpus to squeeze out performance then use a scripting language to code in . why wouldn't we write deep learning code like linus torvalds write kernel code , with so we can make sure the assembly language be efficient and there be almost no cache miss ? from a performance point of view , one could fly to the moon and back with c before python even break the tree line . in term of ease of experimentation , c + + be plenty object orient so that clean abstraction can be write a . hpp file to configure and govern the kernel-efficient c that do the mechanic of parameter optimization . we type on keyboard to code and bloc , we program microwave oven , and some of u play musical keyboard that nicely simulate piano . we then forget it be c / c + + underneath these highly intuitive user interface . i frankly , don't buy the python argument yet . most of u understand that python wrapper have be create around the efficient matrix algorithm write in fortran and port to c , and that the python construct for ml be relatively elegant , but be that a good reason to dismiss the fact that many c + + library for ml that be also elegant have be develop ?why python not c?******why python not c?******Jul 19, 2018******3******CA
4******the thing you be probably look for be : let u see this question from 2 viewpoint : beginner : from a viewpoint of beginner , he need to understand how to implement a model before optimise it . he first need to visualise the model , see the kind of bug that creep in , experiment with the model to gain more intuition . certainly possible in c / c + + . but be it worth it ? the time the person would take to write / debug the code in c / c + + will far outweigh the time to create i in python / matlab / r . so after he gain some intermediate implementation knowledge then he can move on with c / c + + . expert : by expert i mean program expert . they most certainly and easily use c / c + + . but the main information you miss be tensorflow which be a ml library by itself and also serve a a core for other high level ml library like kera be program in c + + itself . here be more info about it . so if i be not wrong tensorflow create a computational graph before take in any data , and then run that graph on the data generally completely load in the ram . so no intereference of python in between . also code readability be a massive problem ( at-least i face it ) , write ml algorithm in c / c + + will take huge amount of code which may become unreadable if you look at it after a week or so if not well document . whereas due to inbuilt python function you can easily read the program . advice from machine learn expert andrew ng , use language like c / c + + to implement your model once you have verify your model work in a high level language like matlab . also a @fauchristian mention library support be impeccable , you can combine various other library in other field to convert data into a ml form which will then be use in your ml model .******none******Jul 19, 2018******3******CA
4******because there be a library for python name numpy . it can do extremely fast computation on n-dimensional array of number , and all kind of scientific / machine learn / image processing etc library be build on top of it . you don't do actual computation in python loop , that's really slow . you call numpy matrix operation , and they be themselves write in c ( and partly in fortran if i recall correctly , not sure if that's still the case ) and mercilessly optimize for speed over the year .******none******Jul 20, 2018******3******CA
1******the primary reason for python be prefer be overhead . c + + automatically entail great overhead in term of the amount of code require to do any particular thing . artificial intelligence be difficult to understand conceptually already , which make program overhead a large issue . with c + + modules be a way to extend the python language , there be very little reason to not use python . it be easy to transfer knowledge of program in c + + to python rather than figure out a way to program a library in c + + extensive enough to match the current body of knowledge already incorporate into python .******none******Jul 20, 2018******3******CA
2******in ai ( and probably many other domain a well ) , time spend by the human programmer tend to be significantly more valuable / expensive than time spend run a program . of course this be not always the case ( just like it's not always the case that python be use rather than c or c + + ) , but it be often true . especially in the case of research , it's extremely important to be able to iterate over idea rapidly . we need to be able to rapidly implement new idea , test them , probably go through a few iteration of bugfixing , test again , etc . it's quite rare that the bottleneck in this iteration of idea be the runtime of a new idea / algorithm . the human's time spend program tends to be a bottleneck much more often . idea can often be test rapidly on small toy problem which don't take a lot of runtime anyway , or run overnight / run while the programmer be busy write other code . do all that iterate , quickly implement new idea etc . tends to be easy / faster in python than in c or c + + . of course this be not necessarily true for everyone , if someone already have a lot of experience in c + + and little experience in python , they may be able to implement new idea more quickly in c + + . this do not appear to be the case for the majority of people though . clear advantage that python have in term of how quickly new idea can be implement include : less verbose , don't need to type as much ( e . g . , in python v in c + + to create an empty list that we can start append some result to in an experiment ) . no need to worry about memory management , pointer , all that stuff , which can be doable with experience but do inevitably require attention , have a great likelihood of lead to extra bug , etc . no need to go through compilation / build process . this can be a very big one , which be easy to forget about . much less of a hassle to have data structure contain stuff of different type ( e . g . in python v ... no idea in c + + ) another key point be that the majority of code that people in ai write be not the performance-sensitive part . again , may not be true for everyone , but be true especially in research setting . most researcher don't spend the majority of their time write code for forward / backwards pass in a neural network . they spend much more time on stuff like : preprocessing data ( not always easy to write easily re-usable code , significant chunk will be project-specific / dataset-specific ) experiment setup ( e . g . outer training loop , print / logging result , ... ) processing result , create all kind of fancy plot , etc . brand new ( part of ) algorithm ( e . g . a new variant in the list of sgd / rmsprop / adam / etc . , likely just a couple of line of simple code that can be plug straight into an exist framework , with a lot more pen & paper math behind it ) . now that last point may in some case be performance-sensitive , but still , the initial concern will not be performance . the initial concern will be ; will it work at all ? this can be evaluate on simpler problem or with less performant code simply by wait a bit longer first , it's still more important to be able to implement it at all first . a mention in other answer , thanks to c-based framework like and , these can quite often be performant even from python though . finally , the existence of well-known , easy-to-use , establish , open source library and framework that have stand the test of time be extremely important . in python , we have : numpy panda matplotlib , seaborn scikit-learn tensorflow , pytorch xgboost again , many of those have part implement in c / c + + when performance matter too . note that , when i'm talk about research , this doesn't just mean " academia " . ai in industry will also often have some flavour of research . people in industry be unlikely to be implement neural network from scratch over and over and over again . they're much more likely to be re-using implementation that be already efficient ( e . g . tensorflow ) , but be try to apply them to new data ( where they'll have to write some new boilerplate code around it , which be quick and easy in python ) , or try new architecture , or try to visualize data and / or result , etc .******none******Jul 20, 2018******3******CA
1******python be popular for rapid prototyping for several reason . it be a platform with a shell like mathematica and matlab it have build in matrix and other mathematical type it be free , unlike those proprietary platform it's library in the ml space be currently more mature than scilab******none******Jul 20, 2018******3******CA
1******because , while c / c + + be not dead , they're hard to use and hard to learn . i use to like them , but now , nobody would make me learn a thing with feature like undefined behavior . no way ! memory management ? why should i ? i just don't want to waste my time on such stuff ... and i guess , that's the common attitude among student . there'll be always people love " the old good low level c " and that's a good thing a we need kernel and driver and such . it have it place . c + + be high level , but it's become much too complicate for most of u , who prefer to spend learning time on algorithm rather than on the language itself . everything what can be reasonably do with less effort , should not be do with more effort . i be use c + + for year ( some long time ago ) , and spend only a few hour with python , but i'd always choose the latter for a few thousand line project because of the efficiency of cod . the efficiency of execution may be improve later , possibly even by rewrite a small part in c + + . oftentimes , more can be gain by implement a smarter algorithm .******none******Jul 28, 2018******3******CA
3******do an application exist that can automatically write and test a software component base on a formal functional specification ? the twentieth century saw the initial birth of electronic computer . the early programming language that be in primary use by 1975 be cobol , fortran , lisp , and c and unix be emerge for real time communication and control . shortly after this period two conceptual step be propose toward executable requirement , which , combine with natural language dialog , would permit the realization of computer that would execute high level instruction in a user's native tongue . glenford j . myers ' advance in computer architecture , wiley ; 1st edition , 1978 , put forth the proposition that computer have be design from the bottom up , create serious obstacle in use . he redefine the common term at the time , semantic gap , to mean the gap between the need of those that program computer and the facility of the computer architecture . this thinking lead to object oriented design and support language such a c + + , java , emmascript , and python . ( myers work for ibm but be recruit by a small startup company call intel to help them design their first 32 - bit architecture , the 80386 . ) gene fisher , professor emeritus , california poly san luis obispo , propose in 1988 what he call a , " tool for construct executable block diagram base , " conceptually more advanced than graphical simulator like simulink and more advanced than ides like eclipse , idea , and jupyter interface .. jmodelica be probably one of the close development application to fisher's vision . the term that have become popular in the literature for this concept be executable diagram . be there any application in beta or in common use in some segment of the software industry where a formal requirement can be enter a input to a program writing application and test source code be produce at the output ? be anyone work on an application that take this one step far to a computer that gather requirement through natural dialog ?does an application that can write software exist?******does an application that can write software exist?******Jul 31, 2018******3******CA
4******yes . see " new a . i . application can write it own code " some excerpt : computer scientist have create a deep-learning , software-coding application that can help human programmer navigate the grow multitude of often-undocumented application programming interface , or apis . design application that can program computer be a long-sought grail of the branch of computer science call artificial intelligence ( ai ) . the new application , call bayou , come out of an initiative aim at extract knowledge from online source code repository like github . user can try it out at askbayou.com . the researcher write a paper : neural sketch learning for conditional program generation******none******Aug 01, 2018******3******CA
1******the other answer cover modern work on this , but it's not even a new topic ! koza's work in 1992 lead to whole sub-fields do this . the technique be widely use , robust , and well understood . they're just very computationally expensive . enough so that most of the time you're good off just hire a programmer to do it .******none******Aug 01, 2018******3******CA
4******yes , we do have neural program synthesis . use neural network to generate piece of code . please have a look at : microsoft research project on the same******none******Aug 01, 2018******3******CA
1******so guys , i've be see a lot of tutorial on the internet about ai that be mostly do with python . apart from these , i've see c # be use in ai topic but in thing like for example " self-driving car " , i've see python and not c # or any other language . i want to ask , do you recommend that i learn python ? because i know c # and i want to become more professional in it , but , now that i see that python be be use a lot , i'm get intrigue in it . do you recommend python or other language or should i keep up with c # ? just to mention , i'm 14 year old and i have enough time to learn more and it doesn't really matter what i love to do , because , i love cod and ai specially , so , it doesn't really matter . if it's not a waste of time , i should get start , right ? if you recommend python , please tell me which compiler i should use . i don't really know if it have a compiler , but i want to know where i should start from . thanks .c# or python for ai?******c# or python for ai?******Oct 02, 2018******3******CA
2******if you're do deep learning ( which i assume you be , if you say you want to learn " ai " ) , then python be a must . virtually all the big framework be python wrapper over a c + + core . c # have no real deep learning framework . there be a couple such a the microsoft cognitive toolkit , but they be on a completely different level from pytorch or tensorflow . no serious ml practitioner would do the majority of their research in a framework like that . for more information , see : why be python the most popular language in the ai field ?******none******Oct 03, 2018******3******CA
1******corporation , government research , and academia be favor c , python , java , lisp , and r currently . the trend be not favorable to c # for ai . c # ' s peak of use be in the 2009 to 2012 range . by buy github , microsoft intend to regain some control over development tool and language but have never be particularly successful in either . even eclipse be give way to other open tool or proprietary tool with community version , and javascript and python be the language gain popularity in this decade . it be not clear whether c # will be very well know a a general purpose programming in ten year . c / c + + , java , and javascript have stand the test of time . c / c + + be the language of choice for low level access to dedicate hardware , which be what it be design by bell lab to do . java be almost a fast and still very popular , strongly oo , still develop , and with scala , groovy , maven , and gradle , look strong for the future . python start slow but have see continuous rapid growth trend for the last two year because of it matlab-ish-ness and syntactic clarity . javascript , with it heavy influence from lisp and scheme from the birth of ai , will likely enter in great strength a ai reach the front end and middle tier of web application . c # doesn't look hopeful for keep pace .******none******Oct 03, 2018******3******CA
1******we be currently work on develop a 3d modeling software that allow designer to set spatial constraint to model . the computer then should generate a 3d mesh conform to these constraint . why should or shouldn't we use lisp for the constraint satisfaction part ? will prolog environment be any good ? or should we stick to c / c + + library ? one requirement we have be that we want to use the unity game engine a it have a lot of 3d tool build inwhat are the advantages and disadvantages of using lisp for constraint satisfaction in 3d space******what are the advantages and disadvantages of using lisp for constraint satisfaction in 3d space******Oct 05, 2018******3******CA
0******this be actually a question which will only receive opinion base answer's . a question you should ask yourself be if the constraint part be really that complex that it be worth to use a different programming language . unity itself offer a c # api [ 1 ] and i would therefore stick with that . [ 1 ]******none******Oct 05, 2018******3******CA
1******what be the best and easy program language to learn to implement genetic algorithm ? c + + or python or any other ?learning genetic algorithm for beginners******learning genetic algorithm for beginners******Oct 21, 2018******3******CA
2******i be make my speech recognition project for pc ( work on window 8) and be new in this area . the project should have basic functionality like dictation with accuracy in email , notepad , etc . , and should respond to local command of pc . i be use sphinx 4 for my speech recognition project . i'm try to determine if there be there be a good open source api than cmu sphinx in term of accuracy and large vocabulary ? do kaldi ( deep neural network base ) perform well than cmu sphinx ( hmm base ) ? be the two platform well for different kind of application ? essentially : i want to increase my speech recognition system accuracy and vocabulary . which might be most optimal : kaldi or cmu sphinx ? also wonder what be the difference between a speech api and a speech engine , and , more generally , a a developer what i will require to develop my software ? please help me to get a clear understanding about above question and , if possible , provide some speech recognition developer or researcher community link . any and all comment , suggestion and answer be welcome !speech recognition software implementation by open source api******speech recognition software implementation by open source api******Jan 10, 2018******3******CA
1******the difference between a speech api and a speech engine be : speech api's enable developer to integrate speech recognition technology into developer apps . on the other hand a speech engine be software that give your computer the ability to play back text in a spoken voice . ( source msdn library ) below be a list of speech recognition tool-kits and their feature . tensorflow - although tensorflow doesn't arrive package with speech recognition library by default . you can use seq 2seq model which have achieve high level of accuracy in speech recognition . a few of the advantage of use tensorflow for speech recognition include : it come with tensorboard which be useful in visualise and fine-tuning your network , it's architecture be highly modular which allow you to experiment with different voice library and finally it be portable mean you can run it on gpu's , cpu's , server or even mobile compute platform . microsoft's cntk - microsofts cognitive toolkit delivers excellent result when it come to speech recognition . in recent time cntk have outperform human in transcribe speech to text . some of it perk be it efficient resource usage additionally it be originally build for speech recognition system and consequently it be very effective at work with time series data . cmu sphinx - cmu sphinx be a speech recognition system develop at carnegie mellon university . the advantage of use cmu sphinx be : it be multilingual and support most international language , it have excellent commercial support , it have a light mobile version call pocketsphinx , it have a wide range of tool for different purpose i . e . keyword spotting , alignment and pronunciation evaluation . it also enjoy active support from the carnegie mellon university . kaldi - kaldi aim to provide speech recognition software that be flexible and extensible . kaldi have powerful feature such a pipeline that be highly optimize for parallel compute i . e . training model on the gpu . additionally it support speaker identification and detection of error in transcript . mozilla deep speech - this project aim at provide speech interface for the web . this project achieve a word error rate on librispeech's test-clean of 6.5 % which be commendable . i find this paper compare open source speech recognition toolkits to be relevant to your question siraj raval have an excellent tensorflow speech recognition tutorial . it be available here******none******Jan 16, 2018******3******CA
5******if i train a speech recognition model use data collect from n different microphone , but deploy it on an unseen ( test ) microphone - do it impact the accuracy of the model ? while i understand that theoretically an accuracy loss be likely , do anyone have any practical experience with this problem ?can variations in microphones used in training set and test set impact the accuracy of speech recognition models?******can variations in microphones used in training set and test set impact the accuracy of speech recognition models?******Feb 02, 2018******3******CA
4******yes it can . however , other difference between training and test data with audio could have great effect : identity of the speaker ( include effect from gender , age , physical build , local accent , amongst others ) acoustic of the recording environment ( include proximity to the microphone , size of space , presence of hard surface , background noise ) if any of these may vary from your training data , then it become hard to predict your generalised accuracy during training and early model selection . one possibility be to ensure your cross-validation set ( which you absolutely should have ) also separate data out by thing that will vary from train to test . so instead of random train / cv split , you split by data that be key for generalisation . this be sometimes call a stratified train / test split . if your only concern be variation in microphone , then split your train / cv set by microphone type . you will get a good assessment early on in the model selection process how well the training be generalise , and can focus your search on model that do well despite this expect difference .******none******Feb 02, 2018******3******CA
1******the most usual difference in signal record cause by different microphone will have small if not null impact in the recognition accuracy , in particular if we be talk about change one mic by another of same model and manufactor : difference in bandwidth : voice be in a very common ( central ) bandwidth , it be not expect these difference impact , even for low quality microphone . microphone distortion : same a previous , they will not impact because they be small than , by example , a change in the speaker . however , if we talk about a general recognition system to be use with very different type of mics , there be some microphone issue that can cause your system completely fail : mic sensitivity : small sensitivity difference will have no effect because they be solve in the same way than difference in speaker volume / intonation . however , if the microphone be not enough sensible the s / n can be below the minimum need , in particular when speaker increase the distance to the mic . lack of beam-forming : if your system be prepare to use an array of microphone to filter noise and / or secondary source , usage of a normal phone will decrease accuracy . change in sample ratio and / or sample bit : if the microphone and it a / d have a low sample speed or size ( i . e . bluetooth mics , phone line , ... ) , the accuracy can fail . by example , for iot application , the first two of this list be the more challenging one .******none******Feb 10, 2018******3******CA
0******if possible consider the relationship between implementation difficulty and accuracy in voice example or simply chat conversation . and currently , what be the direction on algorithm like deep learning or others to solve this .what is easier or more efficient to summarize voice or text? [dp/rn]******what is easier or more efficient to summarize voice or text? [dp/rn]******Feb 24, 2018******3******CA
0******you might want to take the stanford online course on youtube . this course will give you insight into how different kind of neural network can be use for different kind of nlp task . in my opinion , you can use gated recurrent unit ( grus ) to encode and decode text . of course , text will be easy because voice data , a it be store in a computer , be go to be difficult to interpret in the testing phase . another way be to get most impactful word and then use these to form sentence regard the original text . you can also start by look out for publication relate to text summarizers . for example , abstractive text summarization use sequence-to-sequence rnns and beyond , will get you start . you can use this a a starting point . in case you need to understand basic regard the underlie technique , then you can go through reference in this paper and find out useful resource to get you start .******none******Feb 24, 2018******3******CA
2******summarize text be always go to be ' easy or more efficient ' than voice simply because voice require the additional step of convert to text . that doesn't tell you anything about accuracy . from an article publish on june 1 , 2017 , google ’ s speech recognition be now almost as accurate a human : " accord to mary meeker ’ s annual internet trend report , google ’ s machine learning-backed voice recognition — a of may 2017 — have achieve a 95 % word accuracy rate for the english language . that current rate also happen to be the threshold for human accuracy . " if you need this kind of accuracy check out google's cloud speech api . there be even a speech to text feature on the web page . give a speech-to-text conversion accuracy of 95 % , voice will be 5 % less accurate than text if everything else be equal but it usually isn't . people generally write good text , such a in document or email , than when they speak unless of course they be give a formal lecture , or talk in a formal meeting . if one be analyze text message , tweet , or thread find in typical informal forum , you will find very poor quality in grammar , spell , vocabulary , and punctuation . the answer to your question will depend on the source of your text . in another article , date november 13 , 2017 , why 100 % accuracy be not available with speech recognition software alone , the author give some reason , albeit for transcription software which have a special purpose , why there will always be some error due to : speech pattern and accent - regional variation exist , for example english speaker in boston sound different than kentucky . how do the software handle slur speech or when a person blend their word ? grammar and punctuation - speech recognition software doesn't know where a period , comma , or semi-colon belongs homonym and unusual word - " speech processing software can only recognize word and phrase that it have specifically be train to recognize . " ambient noise , overlap speech , and number of speaker to address your last question about where the technology be go ... four day ago a paper by tom young , devamanyu hazarika , soujanya poria , and erik cambria entitle recent trend in deep learning base natural language processing be publish which give some of the answer . from the ' conclusion ' section : with distributed representation , various deep model have become the new state-of-the-art method for nlp problem . supervise learning be the most popular practice in recent deep learning research for nlp . in many real-world scenario , however , we have unlabeled data which require advanced unsupervised or semi-supervised approach . in case where there be lack of label data for some particular class or the appearance of a new class while test the model , strategy like zero-shot learning should be employ . these learn scheme be still in their developing phase but we expect deep learning base nlp research to be drive in the direction of make good use of unlabeled data . we expect such trend to continue with more and good model design . we expect to see more nlp application that employ reinforcement learning method , e . g . , dialogue system . we also expect to see more research on multimodal learn [ 167 ] a , in the real world , language be often ground on ( or correlate with ) other signal . finally , we expect to see more deep learning model whose internal memory ( bottom-up knowledge learn from the data ) be enrich with an external memory ( top-down knowledge inherit from a kb ) . couple symbolic and sub-symbolic ai will be key for step forward in the path from nlp to natural language understanding . rely on machine learning , in fact , be good to make a ‘ good guess ’ base on past experience , because sub-symbolic method encode correlation and their decision-making process be probabilistic .******none******Feb 24, 2018******3******CA
3******this be a theoretical question . i be newbie to artificial intelligence and machine learning , and the more i read the more i like this . so far , i have be read about evaluation of language model ( i be focus on asr ) , but i still don't get the concept of development test . the clear explanation i have come across be the following nevetheless i have not find sense a for why an additional test have to be use . in other word , why aren't training and test set enough ? thanks in advance !what are development tests used for?******what are development tests used for?******Mar 13, 2018******3******CA
1******currently i be work with two large speech database and i be ask to build one subset from each one in order to get two representative subset with the same number of utterance . my question be : the number of utterance be the same a the number of audio file ? thank you so much !number of utterances******number of utterances******Apr 27, 2018******3******CA
1******with all the google i / o stuff come out , how can i verify that i have an actual human on the phone use only voice ? be there still vocal thing human can , but robot can't do ? condition : the person on the phone be a stranger ( so personal question won't work ) , and the verification must be voice only . ( also , i understand google duplex may be just an overhyped demo that will turn out to flop like the pixel bud . but eventually such a bot would be create , right ? if so , what's the best verification ? )"vocal captcha" for robots on the phone?******"vocal captcha" for robots on the phone?******May 19, 2018******3******CA
2******a you know opencv be a big great open-source library for image recognition and machine vision ( and may far purpose like computer graphic , etc ) . be there similar library in sound field ( voice recognition / nlp ( natural language processing ) ) ? i know espeak for tt , also pocketsphinx for voice recognition . also there be something like chatscript that i don't know if i can consider a a nlp engine or not ? but i like to know do i mention the best library for each part of sound / voice field or there be good option to learn and work with them ? also will happy to hear some suggestion about best book ( s ) to read to learn the concept / algorithm of asr / nlp .is there something like opencv for voice recognition & nlp?******is there something like opencv for voice recognition & nlp?******Jun 15, 2018******3******CA
2******i don't know about voice recognition but for nlp i think that gensim could be what you be look for ! gensim be a nlp package that contain efficient implementation of many well known functionality for the task of topic model such a tf – idf , latent dirichlet allocation , latent semantic analysis ... about the reading , maybe you can start with the original word 2vec paper ( “ the meaning of a word can be infer by the company it keep ” ) .******none******Jun 15, 2018******3******CA
2******accord to what josh dotson post via medium , give a clear insightful knowledge concern the following ; 1.speech data besides speech recognition . language modelling . text to speech . machine translation . signal processing . and lastly , book and blog for further research resource for acknowledgement******none******Jun 15, 2018******3******CA
1******in the field of automatic speech recognition ( asr ) kaldi be the current leader . before deep neural network era there be sphinx and htk .******none******Oct 10, 2018******3******CA
1******the term paraphrasing be use for convert input text into output text with small modification on the semantic level . paraphrasing be use by manager to distribute work item to employee . it be a certain form of communication which be hard to formalize . from the management literature it be know that so call workflow management system be implement a groupware server . they be store and forward message in the intranet of a company . the question be : be it possible to combine both ? that mean to paraphrase incoming message of a company and distribute the message to sub-departments ? in theory , this would replace traditional manager , but i'm not sure . perhaps it would make sense to test out the hypothesis first on the enron dataset , which be a corpus of the e-mail fulltext of 158 employee in a large company .can semantic paraphrasing be used for a workflow management system?******can semantic paraphrasing be used for a workflow management system?******Aug 22, 2018******3******CA
0******i be plan to use mozilla deepspeech for the project . for the use case at hand , i'm thinking if there's a possibility of use any nlp engine after the speech-to-text to improve it efficiency . if so , what and how could that be implement . and regard open-source s2t model , be there any model whose efficiency be good than mozilla deepspeech ?speech recognition/ voice recognition: how to use nlp after a speech-to-text to improve accuracy?******speech recognition/ voice recognition: how to use nlp after a speech-to-text to improve accuracy?******Aug 25, 2018******3******CA
3******fourier transform be use to transform audio data to get more information ( feature ) . for example , raw audio data usually represent by a one-dimensional array , , which have a length ( number of sample ) . be an amplitude value of the i-th sample point . use the fourier transform , your audio data will be represent a a two-dimensional array . now , be a not a single value of amplitude , but a list of frequency which compose original value at the i-th frame ( a frame consist of a few sample ) . see the image below ( from wikipedia ) , the red graph be an original value of n sample before transform , and the blue graph be a transformed value of one frame .******none******Oct 03, 2018******3******CA
5******i've implement the reinforcement learn alogrithm for an agent to play snappy bird ( a shameless cheap ripoff of flappy bird ) utilize a q-table for store the history for future lookup . it work and eventually achieves perfect convergence after enough training . be it possible to implement a neural network to do function approximation in order to accomplish the purpose of the q-table ? obviously , storage be a concern with the q-table , but it doesn't seem to ever train with the neural net alone . perhaps train the nn on an exist q-table would work , but i would like to not use a q-table at all if possible .is it possible to implement reinforcement learning using a neural network?******is it possible to implement reinforcement learning using a neural network?******Aug 02, 2016******3******CA
4******in other word , which exist reinforcement method learn in few episode ? r-max come to mind , but it very old and i'd like to know if there be something well now .what is the current state-of-the-art in reinforcement learning regarding data efficiency?******what is the current state-of-the-art in reinforcement learning regarding data efficiency?******Aug 06, 2016******3******CA
4******by reinforcement learning , i don't mean the class of machine learn algorithm such a deepq , etc . i have in mind the general concept of learn base on reward and punishment . be it possible to create a strong ai that do not rely on learning by reinforcement , or be reinforcement learn a requirement for artificial intelligence ? the existence of reward and punishment imply the existence of favorable and unfavorable world-states . must intelligence in general and artificial intelligence in particular have a way of classify world-states a favorable or unfavorable ?is reinforcement learning needed to create strong ai?******is reinforcement learning needed to create strong ai?******Aug 08, 2016******3******CA
7******most introduction to the field of mdps and reinforcement learning focus exclusively on domain where space and action variable be integer ( and finite ) . this way we be introduced quickly to value iteration , q-learning , and the like . however the most interesting application ( say , fly helicopter ) of rl and mdps involve continuous state space and action space . i'd like to go beyond basic introduction and focus on these case but i be not sure how to get there . what area do i need to know or study to understand these case in depth ?getting to understand continuous state/action spaces mdps and reinforcement learning******getting to understand continuous state/action spaces mdps and reinforcement learning******Aug 24, 2016******3******CA
3******i be use policy gradient in my reinforcement learn algorithm , and occasionally my environment provide a severe penalty when a wrong move be make . i'm use a neural network with stochastic gradient decent to learn the policy . to do this , my loss be essentially the cross-entropy loss of the action distribution multiply by the discount reward , where most often the reward be positive . but how do i handle negative reward ? since the loss will occasionally go negative , it will think these action be very good , and will strengthen the weight in the direction of the penalty . be this correct , and if so , what can i do about it ? edit : in think about this a little more , sgd doesn't necessarily directly weaken weight , it only strengthen weight in the direction of the gradient and a a side-effect , weight get diminish for other state outside the gradient , correct ? so i can simply set reward = 0 when the reward be negative , and those state will be ignore in the gradient update . it still seem unproductive to not account for state that be really bad , and it'd be nice to include them somehow . unless i'm misunderstand something fundamental here .negative reward (penalty) in policy gradient reinforcement learning******negative reward (penalty) in policy gradient reinforcement learning******Nov 29, 2016******3******CA
6******i'm here to ask you for a solution on this problem which be : how to use reinforcement learning in immersive virtual reality to make a person move to a specific location in a virtual environment . a you know reinforcement learning be a sub-area of machine learning in which an active entity call an agent interact with it environment and learn how to act in order to achieve a pre-determined goal . the reinforcement learning have no prior model of behaviour and the participant no prior knowledge that their task be to move to and stay in a specific place . the participant be place in a virtual environment where they have to avoid collision with virtual projectile . follow each projectile the agent analyse the movement make by the participant to determine path of future projectile in order to increase the chance of drive participant to the goal position and make them stay there as long a possible . update 1 : download : reinforcement learning a a tool to make people move to a speciﬁc location in immersive virtual realitya solution for a famous problem in rl******a solution for a famous problem in rl******Feb 11, 2017******3******CA
1******learner might be in training stage , where it update q-table for bunch of epoch . in this stage , q-table would be update with gamma ( discount rate ) , learn rate ( alpha ) , and action would be choose by random action rate . after some epoch , when reward be get stable , let me call this " training be do " . then do i have to ignore these parameter ( gamma , learn rate , etc ) after that ? i mean , in training stage , i get an action from q-table like this : but after training stage , do i have to remove , which mean i have to get an action from q-table like this ?reinforce learning: do i have to ignore hyper parameter(?) after training done in q-learning?******reinforce learning: do i have to ignore hyper parameter(?) after training done in q-learning?******Apr 25, 2017******3******CA
4******i be interested in the current state-of-the-art way to use quick , greedy heuristic in order to speed up the learning in a deep q-network in reinforcement learning . in classical rl , i initially set the q-value for a state-action pair ( s , a ) base on the result of such a greedy heuristic run from state s with action a . be this still a good idea in the setting of a neural network for the approximation of the q-function , and if yes , what be the optimal way of do it ? what be other way of aid the dqn with the knowledge from the greedy heuristic ? reference to state-of-the-art paper would be highly appreciate .what are state-of-the-art ways of using greedy heuristics to initially set the weights of a deep q-network in reinforcement learning?******what are state-of-the-art ways of using greedy heuristics to initially set the weights of a deep q-network in reinforcement learning?******May 31, 2017******3******CA
5******be there any way apply reinforcement learn algorithm in computer vision problem ?apply reinforcement learning algorithms to computer vision problems******apply reinforcement learning algorithms to computer vision problems******Jul 30, 2017******3******CA
5******i recently start learn about reinforcement learning and currently i be try to implement the sarsa algorithm , however i do not know how to deal with $ q ( s ' , a ' ) $ , when $ s ' $ be the terminal state . first , there be no action to choose in this state , and second , this $ q $ - factor will never be update either because the episode end when $ s ' $ be reach . should i initialize $ q ( s ' , a ' ) $ to something other than a random number ? or should i just ignore the $ q $ - factor and simply fee the reward $ r $ into the update ?how should i handle action selection in the terminal state when implementing sarsa?******how should i handle action selection in the terminal state when implementing sarsa?******Aug 04, 2017******3******CA
7******question be regard deep reinforcement learn use policy gradient . cut edge policy gradient algorithm be trpo ( trusted region policy optimization ) and ppo ( proximal policy optimization ) . when use single continuous action then normally you would use some random distribution ( for example gaussian ) for the loss function . the rough version be : $ l ( \ theta ) = log ( p ( a_1 ) ) * a $ where $ a $ be the advantage of reward $ p ( a_1 ) $ be characterize by $ \ mu $ and $ \ sigma ^ 2 $ that come out of neural network like in pendulum environment here : problem be that i cannot find any paper on 2 + continuous action use policy gradient ( not actor-critic method that use a different approach by transfer gradient from q-function ) . do you know how to do this use trpo for 2 continuous action in lunarlander environment ? be follow approach correct for policy gradient loss function ? $ l ( \ theta ) = ( log ( p ( a_1 ) ) + log ( p ( a_2 ) ) ) * a $policy gradients for multiple continuous actions******policy gradients for multiple continuous actions******Sep 21, 2017******3******CA
1******i be a first-semester grad student in robotics and have take a course on machine learning for robotics . i be completely new to machine learning . i be to select and execute a problem statement on my own a a part of the course . i have select the follow problem statement - " reinforcement learn for mapless navigation of mobile robot " base on this research . the goal be to develop a maple motion planner which enable a robot to navigate by avoid obstacle . since i be completely new to machine learning and ai , i be not able to gauge whether the problem statement be challenge enough for a beginner to execute in a timeframe of 8 week ? ( give that i can dedicate around 6 hour a week ) i be plan to code in matlab since i be highly comfortable with matlab also , please leave any suggestion / modification to refine my approach and have a good understanding in this area . thank you !reinforcement learning for robotic motion planning - problem statement ideas******reinforcement learning for robotic motion planning - problem statement ideas******Oct 02, 2017******3******CA
1******please , can someone give advice what journal be good for first publication in the field of deep reinforcement learn ? i be in process of write about research result of dqn relate algorithm . i have 3 requirement - it should be index in one of these database , otherwise , i cannot receive grant money for research : and it should not be very expensive to publish . it should be under 1000eur to publish , for example , open access license for elsevier " artificial intelligence " journal cost around 2400eur to publish . and it should not have very long review / publishing period . for example , elsevier " information fusion " journal currently gather article for july 2018 , that be 8 month period till publish . be it normal ? can you please recommend some journal that qualify & you have have good experience publish research ?where to publish reasonable article in deep reinforcement learning?******where to publish reasonable article in deep reinforcement learning?******Nov 07, 2017******3******CA
14******what's the difference between model-free and model-based reinforcement learning ? it seem to me that any model-free learner , learn through trial and error , could be reframed a model-based . in that case , when would model-free learner be appropriate ?what's the difference between model-free and model-based reinforcement learning?******what's the difference between model-free and model-based reinforcement learning?******Nov 07, 2017******3******CA
1******a i be try to make an ai with reinforcement learning , i have find out and implement a lot of thing such a both these topic ( nns and rl ) separately . but when try to combine them , i have run into trouble . i have not be able to find or think of a way to properly do backpropagation with rl . so what i be try to do be a local search for all action and then use a neural net for the q ( s , a ) function . how would one do the backpropagation in such a neural net ? up to this point , i have only do thing with gradient descent . should one use a different algorithm ? could one calculate the q ( s , a ) value base on the output of the neural net with a discount factor ? this be what the formula would suggest , but i could not find any confirmation .how to combine backpropagation in neural nets and reinforcement learning?******how to combine backpropagation in neural nets and reinforcement learning?******Feb 04, 2017******3******CA
2******model-based rl create a model of the transition function . tabular q-learning do this iteratively ( without directly optimize for the transition function ) . so , do this make tabular q-learning a type of model-based rl ?is q-learning a type of model-based rl?******is q-learning a type of model-based rl?******Feb 19, 2017******3******CA
0******i be currently look to apply reinforcement learning in my recurrent neural network . i be have trouble to define the reward function for my following application . in my current setting , i be run a recurrent neural network , and each action be equivalent to generate a vector [ 1x5 ] , and then the network will terminate when it finish generate a 10 of them . lastly , i will append them together , form a 10 x 5 matrix . for this matrix , i will be run another algorithm to evaluate it reward , give a final reward of scalar numerical value . [ matrix a ] ---> run algorithm ---> reward = 5.2 [ matrix b ] ---> run algirthm ---> reward = 8.2 however , i be not sure how should i define the reward function for my network . since there be really no reward for the intermediate step , should i give them a zero ? ? ?reinforcement learning reward function******reinforcement learning reward function******Feb 20, 2017******3******CA
0******what be the relation between back-propagation and reinforcement learning ?what is the relation between back-propagation and reinforcement learning?******what is the relation between back-propagation and reinforcement learning?******Jan 13, 2018******3******CA
3******the above environment be deeptraffic now consider this situation in the above environment , the red car ( we control it with our rl agent ) be on the extreme right lane . during the exploration phase , we take a ' move right ' action , which ofcourse will result in the car not move right , but the other car will be move , state change due to the rule of the environment . i'm use cnn to solve this , the state representation be the image itself and it a q-learning algorithm a describe in dqn paper from deepmind . in the above situation i mention , wont the agent think due to ' move right ' action the state have change , which be not really the case ? and when remember the state transition ( s , a , r , s ' ) should i remember the actual action ' move right ' ( invalid ) or ' do nothing ' ( correct a per env ) ?rl agent's view of state transitions******rl agent's view of state transitions******Jan 18, 2018******3******CA
5******for instance , the title of this paper read : " sample efficient actor-critic with experience replay " . so , what do sample efficiency mean , and how be it achieve use importance sampling ?what is sample efficiency & importance sampling in reinforcement learning?******what is sample efficiency & importance sampling in reinforcement learning?******Feb 07, 2018******3******CA
1******in some atari game in the arcade learn environment ( ale ) , it be necessary to press once to start a game . because it may be difficult for a reinforcement learning ( rl ) agent to learn this , they may often waste a lot of time execute action that do nothing . therefore , i get the impression that some people hardcode their agent to press that button once when necessary . for example , in openai's baseline repository , this be implement use the wrapper . far down , in their ( which apply that wrapper among others ) , it be imply that deepmind tends to use this functionality in all of their publication . i have not be able to find a reference for this claim though . my question be : be it common in publish research ( by deepmind or others ) to use the functionality describe above ? i'd say that , if this be the case , it should be explicitly mention in these paper ( because it's important to know if hardcoded domain knowledge be add to a learning agent ) , but i have be unable to explicitly find this after look through a wide variety of paper . so , base on this , i'd be incline to believe the answer be " no " . the main thing that confuse me then be the implication ( without reference ) in the openai baseline repository that the answer would be " yes " .is it common in rl research with atari/ale to automatically press fire to start games?******is it common in rl research with atari/ale to automatically press fire to start games?******Feb 22, 2018******3******CA
1******i recently come across a quora post , where i saw the term " imagination learn " . it seem to be base on something call " imagination machine " ( the link be base on a guy's work profile a of now ; subject to change ) . the only thing that i could find on internet about it be this paper : imagination-augmented agent for deep reinforcement learning . ( but i'm not sure if it's relate to that concept . ) any idea on this would be appreciate .what is imagination learning and imagination machines?******what is imagination learning and imagination machines?******Feb 27, 2018******3******CA
4******a discuss in this thread , you can handle invalid move in reinforced learning by re-setting the probability of all illegal move to zero and renormalise the output vector . in back-propagation , which probability matrix should we use ? the raw output probability , or the post-processed vector ?how to deal with back-propagation when dealing with invalid moves in reinforced learning?******how to deal with back-propagation when dealing with invalid moves in reinforced learning?******Mar 01, 2018******3******CA
4******i've see numerous mathematical explanation of reward , v ( s ) value function , and return function . the reward provide an immediate return for be in a specific state . the good the reward , the good the state . a i understand it , it can be good to be in a low-reward state sometimes because we can accumulate more long term which be where the expect return function come in . an expected return , return or cummulative reward function effectively add up the reward from the current state to the goal state . this imply it's model-based . however it seem a value function do exactly the same ? be a value function a return function ? or be they different ?difference between expected return and value function in reinforcement learning******difference between expected return and value function in reinforcement learning******Mar 17, 2018******3******CA
5******i'm study reinforcement learning . it seem that " state " and " observation " mean exactly the same thing . they both capture the current state of the game . be there a difference between the two term ? be the observation maybe the state after the action have be take ?what is the difference between an observation and a state in reinforcement learning?******what is the difference between an observation and a state in reinforcement learning?******Apr 09, 2018******3******CA
1******semi gradient method work well in reinforcement learning , but what be the reason of not use the true gradient if it can be compute ? i try it on the cart pole problem with a deep q-network and it perform much bad than traditional semi gradient , be there a concrete reason for this ?why use semi-gradient instead of full gradient in rl problems, when using function approximation?******why use semi-gradient instead of full gradient in rl problems, when using function approximation?******Apr 24, 2018******3******CA
7******as far a i understand q-learning and policy gradient be the two major approach use to solve reinforcement learning ( rl ) problem . while q-learning aim to predict the reward of a certain action take in a certain state , policy gradient directly predict the action itself . however , both approach appear identical to me i . e . predict the maximum reward for an action ( q-learning ) be equivalent to predict the probability of take the action directly ( pg ) . be the difference in the way the loss be backpropagated ?q-learning vs policy gradients******q-learning vs policy gradients******Apr 28, 2018******3******CA
1******the basis of q-learning be recursive ( similar to dynamic programming ) , where only the absolute value of the terminal state be know . shouldn't it make sense to fee the model a great proportion of terminal state initially , to ensure that the predicted value of a step in terminal state ( zero ) be learn first ? will this make the network more likely to converge to the global optimum ?feeding a q-learning algorithms a greater fraction of terminal states******feeding a q-learning algorithms a greater fraction of terminal states******May 02, 2018******3******CA
0******i've look into policy gradient rl the last few month . a i find the topic quite interesting , i've be readings lot of paper about it . my aim be to write my master thesis in math about it . i already start out , the preliminary title be " technique for variance reduction in policy gradient reinforcement learn " . of course , i can sum up late result , but a master thesis ' aim should be to create sth . new , or apply sth . to a new setting . do anybody have an idea for a nice application ? it be my idea to write the thesis in ml . my professor be not that much into ml but be happy to advise and evaluate the thesis . advice highly appreciate !policy gradient rl / thesis topic******policy gradient rl / thesis topic******May 03, 2018******3******CA
2******in his lecture 5 of the course " reinforcement learn " , david silver introduce glie monte-carlo control . but why be it an on-policy control ? the sampling follow a policy π while improvement follow an ϵ-greedy policy , so isn't it an off-policy control ?why is glie monte-carlo control an on-policy control?******why is glie monte-carlo control an on-policy control?******May 22, 2018******3******CA
4******i've be read google's deepmind atari paper and i'm try to understand the concept of experience replay come up in a lot of other reinforcement learn paper ( particularly the alphago paper ) , so i want to understand how it work . below be some excerpt . first , we use a biologically inspired mechanism term experience replay that randomize over the data , thereby remove correlation in the observation sequence and smoothing over change in the data distribution . the paper then elaborate a follow ( i've take a screenshot , since there be a lot of mathematical symbol that be difficult to reproduce ): what be experience replay and what be it benefit in laymen's term ?understanding experience replay in reinforcement learning******understanding experience replay in reinforcement learning******May 30, 2018******3******CA
2******i've be read google's deepmind atari paper and i'm try to understand how to implement my question be that whether we update the parameter $ \ theta $ of function $ q $ once for all the sample of the minibatch or we do that for each sample of the minibatch separately ? accord to the follow code from this paper , it perform the gradient descent on loss term for the $ j $ - th sample . however , i have see other paper ( refer to this paper ) that say that we first calculate the sum of loss term for all sample of the minibatch and then perform the gradient descent on this sum of loss .implementing experience replay in reinforcement learning******implementing experience replay in reinforcement learning******May 30, 2018******3******CA
2******in a reinforcement learn model , state depend on the previous action choose . in the case in which some of the state - but not all - be fully independent of the action - but still obviously determine the optimal action - , how could we take these state variable into account ? if the problem be a multiarmed bandit problem ( where none of the action influence the state ) , the solution would be a contextual multiarmed bandit problem . though , if we need a " contextual reinforcement learn problem " , how can we approach it ? i can think of separate a continuous context into step , and create a reinforcement learn model for each of these step . then , be there any solution where these multiple rl model be use together , where each model be use for prediction and feedback proportionally to the closeness between the actual context and the context assign to the rl model ? be this even a good approach ?how to implement a contextual reinforcement learning model?******how to implement a contextual reinforcement learning model?******Jun 12, 2018******3******CA
2******in some implementation of off-policy q learn we need to know the action probability give by the behavior policy ( e . g . , if we want to use importance sample ) . in my case , i be use deep q-learning and select action use thompson sample . i implement this follow the approach in " what my deep model doesn't know ... " : i add dropout to my q-network and select action by perform a single stochastic forward pas through the q-network ( i . e . , with dropout enable ) and choose the action with the high q-value . so , how can i calculate when use thompson sample base on dropout ?action probability with thompson sampling in deep reinforcement learning******action probability with thompson sampling in deep reinforcement learning******Jun 15, 2018******3******CA
2******look at breakout : we know that the underlying world behaves like an mdp , because for the evolution of the system it just need to know which be the current state , i . e . position , speed and speed direction of the ball , position of the brick and the paddle etc . but consider only single frame a the state space we have a pomdp because we lack information about the dynamic [ 1 ] , [ 2 ] . question : what could happen if we wrongly assume that the pomdp be a mdp and do reinforcement learn with this assumption over the mdp ? obviously the question be more general , not limit to breakout and atari game . [ 1 ] [ 2 ]reinforcement learning over an mdp that is actually a pomdp******reinforcement learning over an mdp that is actually a pomdp******Jun 17, 2018******3******CA
1******i be currently explore multi-agent reinforcement learning . i have multiple agent that communicate with each other and a central service that maintain the environment state . the central service dispatch some information at regular interval to all the agent ( let call this information a energy ) . the information can be very different for all the agent . the agent on reception of this information select a particular action . the execution of the action should leave the agent as well a the environment in a positive state . the action require a limited amount of energy which might change on every timestep . if a agent do not have sufficient energy to it may request for energy from other agent . the other agent may grant or deny this request . if all the agent be able to successfully perform their action and leave the environment in a positive state they get a positive reward . a the environment be stochastic , where a agent's behavior be dependent on another agent can approximate q learn be use here ?can q-learning working in a multi agent environment where every agent learns a behaviour independently?******can q-learning working in a multi agent environment where every agent learns a behaviour independently?******Jun 18, 2018******3******CA
2******can anyone recommend a reinforcement learn algorithm for a multi agent environment . in my simplified example , i'm implement a q-learning system with different 10 agent . the agent compete for resource in store at different location by set a bid price for each item . all of the agent have different bid and pool budget of $ 100 . once the budget be reach the agent cannot buy any more that day . each agent will receive a reward if they buy an item . the goal would be to maximize the total amount of item buy between the agent . right now the agent don't communicate . can someone point me in the right direction for an algorithm that allow agent cooperation . thanksq learning with multiple agents design******q learning with multiple agents design******Jun 21, 2018******3******CA
3******in a recent paper data-efficient hierarchical reinforcement learning , o nachum , s gu , h lee , s levine , 2018 , a promising agent control technique call hierarchical reinforcement learning be introduce . it be some kind of layered policy for control ant-like robot in a maze . for example , the main controller be able to run sub-controllers and , and this allow the ant to move to a goal , even an obstacle be on the way . but there be something in the paper which i didn't understand : how to find the goal . accord to the paper , the lowlevel action “ move ” and “ push ” be equal to goal . and these goal have to be infer from demonstration . in the paper , they write : for generality , we develop a scheme where lower-level controller be supervise with goal that be learn and propose automatically by the higher-level controller . how exactly be the match between the observation and the goal state do ?finding goals in hierarchical reinforcement learning******finding goals in hierarchical reinforcement learning******Jun 23, 2018******3******CA
2******i've recently come across the client-server model , from my understanding , the client request the server for which the server respond with a response in this case both the request and response be vector . in reinforcement learn the agent communicate with the environment via an " action " for which the environment send a scalar reward signal . the " goal " be to maximize this scalar reward signal in long run . be there a more formal way to frame this problem such the agent search the internet for obtain more information about certain topic .analogy between reinforcement learning and webservers?******analogy between reinforcement learning and webservers?******Jun 26, 2018******3******CA
1******gradient in maximum entropy irl require to find the probability of expert trajectory give the reward function weight . this be do in the paper by calculate state visitation probability but i do not understand why we can ’ t just calculate the probability of a trajectory by sum up all the reward that be collect follow that trajectory ? the paper define the probability of a trajectory a exp ( r ( traj . ) / z . i do not understand why we have to solve mdp for calculate that .why do we have to solve mdp in each iteration of maximum entropy inverse reinforcement learning?******why do we have to solve mdp in each iteration of maximum entropy inverse reinforcement learning?******Jul 03, 2018******3******CA
1******i'm actually try to learn more about reinforcement learning but i've some trouble to find good resource . right now i'm in the condition where i'm not so good on the topic to fully understand the paper but i find the video on youtube too general . some blog's post have the good balance between complexity and content but be usually focus only on some application and don't give a good overview of the topic . i think that it's almost normal since reinforcement learning have only recently be in the spotlight . so , in this post , i'm look for a comprehensive list of moocs , book , tutorial and good resource for reinforcement learning .comprehensive list of moocs and books on reinforcement learning******comprehensive list of moocs and books on reinforcement learning******Jul 14, 2018******3******CA
2******i'm struggle with an inverse reinforcement learning problem which seem to appear quite often around the literature , yet i can't find any resource explain it . the problem be that of calculate the gradient of a boltzmann policy distribution over the reward weight theta : the theta be a linear parametrisation of the reward function , such that where phi ( s , a ) be feature of the state space . in the simplest of case , one could take , that be the feature space be just an indicator function of the state space . a lot of algorithm simply state to calculate the gradient , but that doesn't seem that trivial , and i'm not manage to infer from the bit of code i find online some of the paper use these kind of method be apprenticeship learn about multiple intention , babes-vroman et al map inference for bayesian inverse reinforcement learning , j.choi any help would be greatly appreciatedgradient of boltzmann policy over reward function******gradient of boltzmann policy over reward function******Jul 14, 2018******3******CA
3******i'm now read a book title a hands-on reinforcement learn with python , and the author explain the discount factor that be use in reinforcement learing to discount the future reward , with the following : a discount factor of 0 will never learn consider only the immediate reward ; similarly , a discount factor of 1 will learn forever look for the future reward , which may lead to infinity . so the optimal value of the discount factor lie between 0.2 to 0.8 . the author seem to be not go to explain further about the figure , but all the tutorial and explanation i have ever read write the optimal ( or at least widely use ) discount factor between 0.9 an 0.99 . this be the first time i have see such a low-figure discount factor . all the other explanation the author make regard the discount factor be the same a i have read so far . be the author correct here or do it depend on case ? if it be , then what kind of problem and / or situation should i set the discount factor as low a such figure at ? edit i just find the follow answer at quora : of course . a discount factor of 0 will never learn , meanwhile a factor near of 1 will only consider the last learning . a factor equal or great than 1 will cause the not convergence of the algorithm . value usually use be [ 0.2 , 0.8 ] edit : that be the learning factor . the discount factor only affect how you use the reward . for a good explanation : state-action-reward-state-action - wikipedia see influence of variable . i don't know what be write in the question a it in not visible in quora , but it seem that the 0.2 to 0.8 figure be use for learn factor , not discount factor . maybe the author be confuse with it ... ? i'm not sure what the learning factor be , though .can the optimal value of discount factor in deep reinforcement learning be between 0.2 to 0.8?******can the optimal value of discount factor in deep reinforcement learning be between 0.2 to 0.8?******Jul 22, 2018******3******CA
3******i want suggestion on literature on reinforcement learn algorithm that perform well with from the environment . what i mean by asynchronous feedback be , when an agent perform an action it get feedback ( reward or regret ) from the environment after sometime not immediately . i have only see algorithm with immediate feedback and asynchronous update . i don't know if literature on this problem exist . this be why i'm asking here . my application be fraud detection in banking , my understanding be when a fraud be detect it take 15-45 day for the system to flag it a a fraud sometimes until the customer complain the system doesn't know it fraud . how would i go about design a real time system use reinforcement learn to flag transaction that be fraud or normal . maybe my understanding be wrong , i'm learn on my own if someone could help me i would be grateful . edit : the reason i'm look at reinforcement learn instead of supervised learning be , it hard to get ground truth data in the banking scenario . fraudsters be always up-to-date or exceed the state of the art in fraud detection . so i've decide that reinforcement learning would be an optimal direction to look for solution to this problem .reinforcement learning with asynchronous feedback******reinforcement learning with asynchronous feedback******Jul 30, 2018******3******CA
2******i'm now learn about reinforcement learning , but i just find the word " trajectory " in this answer . however , i'm not sure what it mean . i read a few book on the reinforcement learning but none of them mention it . usually these introductionary book mention agent , environment , action , policy , and reward , but not " trajectory " . so , what do it mean ? accord to this answer over quora : in reinforcement learning terminology , a trajectory < span class = " math-container " > $ \ tau $ </span> be the path of the agent through the state space up until the horizon < span class = " math-container " > $ h $ </span> . the goal of an on-policy algorithm be to maximize the expected reward of the agent over trajectory . do it mean that the " trajectory " be the total path from the current state the agent be in to the final state ( terminal state ) that the episode finish at ? or be it something others ? ( i'm not sure what the " horizon " mean , either ) .what is a "trajectory" in reinforcement learning?******what is a "trajectory" in reinforcement learning?******Jul 31, 2018******3******CA
2******i'm confuse with the two terminology - action and policy - in reinforcement learning . as far a i know , the action be : it be what the agent make in a give state . however , the book i'm reading now ( hands-on reinforcement learn with python ) write the follow to explain policy : we define the entity that tell u what to do in every state a policy . now , i feel that the policy be the same a the action . so what be the difference between the two , and how can i use them apart correctly ?what is the difference between policy and action in reinforcement learning?******what is the difference between policy and action in reinforcement learning?******Aug 01, 2018******3******CA
4******i'm build a deep neural network to serve a the policy estimator in an actor-critic reinforcement learn algorithm for a continue ( not episodic ) case . i'm try to determine how to explore the action space . i have read through this text book by sutton and in section 13.7 he give one way to explore a continuous action space . in essence you train the policy model to give a mean and standard deviation a an output so you can sample a value from that gaussian distribution to pick an action . this just seem like the continuous action-space equivalent of an epsilon greedy policy . also , be there other continuous action space exploration strategy i should consider ? i've be do some research online and find some article relate to rl in robotics and find that the power and pi ^ 2 algorithm do something similar to what be in the textbook . be these , or other , algorithms " good " ( obviously depend on the problem be solve ) alternative to what be list in the textbook for continuous action-space problem ? i know that this question could have many answer , but i'm just look for a reasonably short list of option that people have use in real application that work .exploration strategies for reinforcement learning w/ continuous action space******exploration strategies for reinforcement learning w/ continuous action space******Aug 03, 2018******3******CA
4******in particular i would like to have a simple definition of environment and state.what be the difference between those two concept ? also i would like to know how the concept of model relates to the other two . there be a similar question difference between observation and state in reinforcement learning ? but be not exactly what i be look for . thank you .difference between state, model, and environment in reinforcement learning******difference between state, model, and environment in reinforcement learning******Aug 18, 2018******3******CA
5******i think i've see the expression " stationary data " , " stationary dynamic " and " stationary policy " , among others , in the context of reinforcement learning . what do it mean ? i think stationary policy mean that the policy do not depend on time , and only on state . but isn't that a unnecessary distinction ? if the policy depend on time and not only on the state , then strictly speak time should also be part of the state .what does "stationary" mean in the context of reinforcement learning?******what does "stationary" mean in the context of reinforcement learning?******Aug 20, 2018******3******CA
3******it seem i be a little confused about the optimal value ( v * ) and optimal action-value ( q * ) in reinforcement learning and just want some clarity because some blog i read on medium and github be inconsistent with literature . originally , i think the optimal action value , q * , represent you perform the action that maximize your current reward , and then act optimally thereafter . and the optimal value , v * , be the average q value in that state . meaning that if you're in this state , the average " goodness " be this . for example : if i be in a toy store and i can buy a pencil , yo-yo , or lego . q ( toy store , pencil ) = - 10 q ( toy store , yo-yo ) = 5 q ( toy store , lego ) = 50 and therefore my q * = 50 but my v * in this case be : v * = - 10 + 5 + 50 / 3 = 15 represent no matter what action i take , the average future project reward be 15 . and for advantage learning , my baseline would be 15 . so anything less than 0 be bad than average and anything above 0 be good than average . however , now i be read about how v * actually assume the optimal action in a give state , mean v * would be 50 in the above case . i be wonder which definition be correct . thanks in advance !in reinforcement learning, is the optimal value (v*) corresponding to performing the best action in a given state?******in reinforcement learning, is the optimal value (v*) corresponding to performing the best action in a given state?******Aug 24, 2018******3******CA
9******i'm cod a reinforcement learn model with a ppo agent thanks to the very good tensorforce library , build on top of tensorflow . the first version be very simple and i'm now dive into a more complex environment where all the action be not available at each step . let's say there be 5 action and their availability depend on an internal state ( which be define by the previous action and / or the new state / observation space ) : 2 action ( 0 and 1 ) be always available 2 action ( 2 and 3 ) be only available when the internal_state = = 0 1 action ( 4 ) be only available when the internal_state = = 1 hence , there be 4 action available when internal_state = = 0 and 3 action available when internal_state = = 1 . i'm thinking of a few possibility to implement that : change the action space at each step , depend on the internal_state . i assume this be nonsense . do nothing : let the model understand that choose an unavailable action have no impact . do - almost - nothing : impact slightly negatively the reward when the model choose an unavailable action . help the model : by incorporate an integer into the state / observation space that inform the model what's the internal_state value + bullet point 2 or 3 be there other way to implement this ? from your experience , which one would be the best ?how to implement a constrained action space in reinforcement learning?******how to implement a constrained action space in reinforcement learning?******Aug 29, 2018******3******CA
5******i be study reinforcement learning and the variant of it . i be start to get an understanding of how the algorithms work and how they apply to an mdp . what i don't understand be the process of define the state of the mdp . in most example and tutorial , they represent something simple like a square in a grid or similar . for more complex problem , like a robot learn to walk , etc . , how do you go about define those state ? can you use learn or classification algorithm to " learn " those state ?how to define states in reinforcement learning?******how to define states in reinforcement learning?******Aug 30, 2018******3******CA
3******i start teach myself about reinforcement learn a week ago and i have this confusion about the learning experience . let's say we have the game go . and we have an agent that we want to be able to play the game and win against anyone . but let's say this agent learn from play against one opponent , my question then be : wouldn't the agent ( after learn ) be able to play only with that opponent and win ? it estimate the value function of this specific behaviour only . would it be able to play as good with weak player ? how do you develop an agent that can estimate a value function that generalize against any behaviour and win ? self-play ? if yes , how do that work ?how can a reinforcement learning agent generalize if it is trained against only one opponent?******how can a reinforcement learning agent generalize if it is trained against only one opponent?******Sep 14, 2018******3******CA
2******follow up on my previous question use a hypothetical ai system to manage air flow use damper to achieve an optimal target of exactly equal airflow at a number of vent ; ( thank you for all the response to that question ) i be direct to " reinforcement learning . " in reinforcement learning , the system set some controllable variable and then determine the quality of the result of the dependent variable ( s ); use that " quality " to update the algorithm . in simple game this work fine because for each setting there be a single result . but , for the real world ( e . g . air flow system ) the result take some time to develop and there be no single precise " pair " result to the condition set . the flow change take time and even oscillate a bit a flow stabilize to a steady state . in practical system how be this " lag " account for ? how be the un-settled ( false ) result ignore ? how be this noise distinguish from exogenous factor ( un-controlled system input e . g . an open window expose to wind ) ?dealing with lags in reinforcement learning******dealing with lags in reinforcement learning******Oct 05, 2018******3******CA
4******i've be look at reinforcement learning , and specifically play around with create my own environment to use with the openai gym ai . i be use agent from the stable_baselines project to test with it . one thing i've notice in virtually all rl example be that there never seem to be any dropout layer in any of the network . why be this ? i have create an environment that simulate currency price and a simple agent , use dqn , that attempt to learn when to buy and sell . train it over almost a million timesteps take from a specific set of data consist of one month's worth of 5 - minute price data it seem to overfit a lot . if i then evaluate the agent and model against a different month's worth of data be performs abysmally . so sound like classic overfitting . but be there a reason why you don't see dropout layer in rl network ? be there other mechanism to try and deal with overfitting ? or in many rl example do it not matter ? e . g . there may only be one true way to the ultimate high score in the ' breakout ' game , so you might as well learn that exactly , and no need to generalise ? or be it deem that the chaotic nature of the environment itself should provide enough different combination of outcome that you don't need to have dropout layer ?why do you not see dropout layers on reinforcement learning examples?******why do you not see dropout layers on reinforcement learning examples?******Oct 07, 2018******3******CA
2******when extend reinforcement learn to the continuous state , continuous action case , we must use function approximators ( linear or non-linear ) to approximate the q-value . it be well know that non-linear function approximators , such a neural network , diverge aggressively . one way to help stabilize training be use reward clipping . because the temporal difference q-update be a bootstrapping method ( i . e . , use a previously calculate value to compute the current prediction ) , a very large previously calculate q-value can make the current reward relatively minuscule , thus make the current reward not impact the q-update , eventually lead the agent to diverge . to avoid this , we can try to avoid the large q-value in the first place by clip the reward between [ 1 , - 1 ] . but i have see some other people say that instead of clip the reward itself , we can instead clip the q-value between an interval . i be wonder which method be well for convergence , and under what assumption / circumstance . i be also wonder if there be any theoretical proof / explanation about reward / q-value clipping and which one be well .should the reward or the q value be clipped for reinforcement learning******should the reward or the q value be clipped for reinforcement learning******Oct 10, 2018******3******CA
1******sparse linear system be normally solve by use solver like minres , conjugate gradient , gmres . efficient preconditioning , i . e . , find a matrix p such that pax = pb be easy to solve then the original problem , can drastically reduce the computational effort to solve for x . however , precondition be normally problem specific and there be not one preconditioner that work well for every problem . i think this would be an interesting problem to apply rl , since there be certain norm ( e . g . condition number of matrix pa ) to measure if p be a good preconditioner , but i could not find any research in this field . be there a specific problem why rl could not be apply ?using reinforcement learning to find a preconditioner for linear systems of the form ax = b******using reinforcement learning to find a preconditioner for linear systems of the form ax = b******Oct 12, 2018******3******CA
0******i already know the basic of the basic of machine learning . e . g . : backpropagation , convolution , etc . first of let me explain reinforcement learn to make sure i grasp the concept correctly . in reinforcement learn a random-initialized network will first " play " / " do " a sequence of move in an environment . ( in this case a game ) . after that , it will receive a reward < span class = " math-container " > $ r $ </span> . furthermore a q-value get define by the engineer / hooby coder . this reward time the q-value < span class = " math-container " > $ q $ </span> to the power of the position < span class = " math-container " > $ n $ </span> of the action will be feed back use bp . so how do i know how slight chance in < span class = " math-container " > $ \ vec { w } $ </span> be change < span class = " math-container " > $ rq ^ n $ </span> ?how do i know how changes in the weights are changing the reward in reinforcement learning******how do i know how changes in the weights are changing the reward in reinforcement learning******Oct 16, 2018******3******CA
4******what be an agent in reinforcement learning ( rl ) ? i think it be not the neural network behind . what do the agent in rl exactly do ?what does the agent in reinforcement learning exactly do?******what does the agent in reinforcement learning exactly do?******Oct 17, 2018******3******CA
1******i be review a statement on the website for e regard structure exploration . structure exploration . some rl algorithm ( especially policy gradient ) initialize with random policy , which often manifest a random jitter on spot for a long time . this effect be mitigate in q-learning due to epsilon-greedy policy , where the max operation can cause the agent to perform some consistent action for a while ( e . g . hold down a left arrow ) . this be more likely to do something in a game than if the agent jitter on spot , a be the case with policy gradient . similar to q-learning , e do not suffer from these problem because we can use deterministic policy and achieve consistent exploration . where can i find source show that policy gradient initialize with random policy , whereas q-learning us epsilon-greedy policy ? also , what do " max operation " have to do with epsilon-greedy policy ?some rl algorithms (especially policy gradients) initialize with random policies, which often manifests as random jitter on spot for a long time?******some rl algorithms (especially policy gradients) initialize with random policies, which often manifests as random jitter on spot for a long time?******Oct 19, 2018******3******CA
0******how do i go about create a parkour agent which use deep rl . i have consider one approach wherein i can learn complex maneuver use imitation learning ( something like deepmimic or gail paper ) . and then use these learned physical maneuver to perform parkour trick .creating a parkour agent using deep reinforcement learning******creating a parkour agent using deep reinforcement learning******Oct 21, 2018******3******CA
2******i be not sure the name of this kind of problem , but anyway , the situation be a below . assign teacher into group and consider on each of their workload , availability etc . there be some other soft / hard constraint ( equality / inequality ) like each group should have at least 2 teacher everyone in the group have similar workload total workload in the group be below a certain value all be in different expertise and more ... i be try to build a sub-optimal solution to solve this problem . linear / non-linear programming seem not work for group problem . i be think of genetic algorithm or reinforcement learning . can this problem solve by use rl or drl ? i be try to define the group a state , and action include " assigntogroup " and " removefromgroup " . and any kind of idea or suggestion of how to solve this problem ? many thanksreinforcement learning to grouped scheduling optimisation problem******reinforcement learning to grouped scheduling optimisation problem******Nov 15, 2018******3******CA
1******be read the book title " reinforcement learn - an introduction by sutton and barto " and arrive at chapter 5 about monte carlo method i find myself quite confuse . one of the thing i don't understand be the need for a state-transition probability function when calculate the importance sample ratio for off-policy prediction . i understood so far that one of the main benefit of mc over dynamic programming ( dp ) be that one do not need to have a model of the state-transition probability for a system . or be this only the case for on-policy mc ?importance sampling for monte carlo reinforcement learning******importance sampling for monte carlo reinforcement learning******Nov 16, 2018******3******CA
