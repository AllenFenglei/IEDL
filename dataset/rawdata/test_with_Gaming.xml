<?xml version="1.0" encoding="utf-8"?>
<test>
	<row Id="1" PostTypeId="1" CreationDate="2017-06-28T23:14:43.333" Score="2" ViewCount="132" Body="&lt;p&gt;There is a lot of information on the internet about &lt;code&gt;image classification&lt;/code&gt; and &lt;code&gt;object identification&lt;/code&gt;. I want to know how I can extract (or create) geometric information from an image.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, if the image classifier can identify that there is a sphere in the image, how can i generate 3d vertices's and edges from that knowledge?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/UixLL.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/UixLL.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I want to find all the edges and points on these shapes&lt;/p&gt;&#xA;" OwnerUserId="7816" LastEditorUserId="7800" LastEditDate="2017-11-09T19:05:05.150" LastActivityDate="2018-02-10T19:28:42.657" Title="Identifying geometry in images" Tags="&lt;machine-learning&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="2" />
	<row Id="2" PostTypeId="2" ParentId="4752" CreationDate="2017-12-15T19:21:54.243" Score="2" Body="&lt;p&gt;To perform image recognition you have to find a way to represent an image with certain features.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One of the defining characteristics of a good image recognition algorithm are it's ability to detect salient regions, that is, regions which contain the most information&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is a lot of attention on deep learning for content-based image classification at the moment. You can achieve decent results by implementing deep learning having three or more layers of CNN's where each layer is responsible for extracting one or more feature of the image.&lt;/p&gt;&#xA;" OwnerUserId="10913" LastActivityDate="2017-12-15T19:21:54.243" CommentCount="2" />
	<row Id="3" PostTypeId="1" AcceptedAnswerId="1690" CreationDate="2016-08-18T17:15:44.240" Score="-1" ViewCount="100" Body="&lt;p&gt;Wolfram Language Image Identification Project launched an &lt;a href=&quot;https://www.imageidentify.com/&quot; rel=&quot;nofollow&quot;&gt;Image Identify site&lt;/a&gt; demo which returns the top predicted tags for the photos.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How does it work, briefly? I mean what type of learning vision technologies are used to analyze, recognize and understand the content of an image?&lt;/p&gt;&#xA;" OwnerUserId="8" LastEditorUserId="145" LastEditDate="2016-08-23T20:29:03.600" LastActivityDate="2016-08-23T20:29:03.600" Title="How does Wolfram's Image Identification Project work?" Tags="&lt;image-recognition&gt;&lt;deep-learning&gt;&lt;classification&gt;" AnswerCount="1" CommentCount="2" />
	<row Id="4" PostTypeId="1" CreationDate="2016-08-02T16:38:55.800" Score="15" ViewCount="210" Body="&lt;p&gt;Can a Convolutional Neural Network be used for pattern recognition in a problem domain where there are no pre-existing images, say by representing abstract data graphically? Would that always be less efficient?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://youtu.be/py5byOOHZM8?t=815&quot;&gt;This developer&lt;/a&gt; says current development could go further but not if there's a limit outside image recognition. &lt;/p&gt;&#xA;" OwnerUserId="46" LastEditorUserId="46" LastEditDate="2016-08-04T15:17:46.150" LastActivityDate="2016-09-07T14:56:38.193" Title="Is the pattern recognition capability of CNNs limited to image processing?" Tags="&lt;deep-network&gt;&lt;neural-networks&gt;&lt;image-recognition&gt;&lt;convolutional-neural-networks&gt;" AnswerCount="4" CommentCount="4" FavoriteCount="1" />
	<row Id="5" PostTypeId="1" AcceptedAnswerId="1688" CreationDate="2016-08-18T14:53:13.537" Score="-1" ViewCount="165" Body="&lt;p&gt;According to this &lt;a href=&quot;http://mashable.com/2014/01/06/pinterest-acquires-visualgraph/&quot; rel=&quot;nofollow&quot;&gt;article&lt;/a&gt;, Pinterest acquired VisualGraph, an image recognition and visual search technology startup.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How does Pinterest apply VisualGraph technology for machine vision, image recognition and visual search in order to classify the images?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In short, how do they predict the image categories? Based on what features?&lt;/p&gt;&#xA;" OwnerUserId="8" LastEditorUserId="145" LastEditDate="2016-08-18T15:05:17.923" LastActivityDate="2016-09-14T19:34:59.007" Title="How does Pinterest decipher what's on unmarked pictures and categorize them?" Tags="&lt;image-recognition&gt;&lt;classification&gt;&lt;computer-vision&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="1" />
	<row Id="6" PostTypeId="1" CreationDate="2016-09-15T20:36:18.530" Score="3" ViewCount="716" Body="&lt;p&gt;Are Convolutional Neural Networks summarily better than pattern recognition in all existing image processing libraries that don't use CNN's? Or are there still hard outstanding problems in image processing that seem to be beyond their capability?&lt;/p&gt;&#xA;" OwnerUserId="46" LastEditorUserId="10" LastEditDate="2016-10-07T17:31:23.663" LastActivityDate="2017-10-09T20:39:49.377" Title="Are Convolutional Neural Networks better than existing image recognition libraries that don't use CNNs?" Tags="&lt;image-recognition&gt;&lt;comparison&gt;&lt;convolutional-neural-networks&gt;" AnswerCount="3" CommentCount="1" FavoriteCount="2" />
	<row Id="7" PostTypeId="1" CreationDate="2017-10-05T04:21:32.313" Score="1" ViewCount="29" Body="&lt;p&gt;Image recognition can be used to classify images. But I wanted to find few parameters like height of person, his legs, his hand etc. Will CNN helpful for this type of output ?&lt;/p&gt;&#xA;" OwnerUserId="6212" LastActivityDate="2017-10-05T04:21:32.313" Title="Can Image Recognition used to find height of a person whole, torso, legs etc" Tags="&lt;convolutional-neural-networks&gt;&lt;image-recognition&gt;" AnswerCount="0" CommentCount="3" />
	<row Id="8" PostTypeId="2" ParentId="4752" CreationDate="2017-12-15T19:21:54.243" Score="2" Body="&lt;p&gt;To perform image recognition you have to find a way to represent an image with certain features.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One of the defining characteristics of a good image recognition algorithm are it's ability to detect salient regions, that is, regions which contain the most information&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is a lot of attention on deep learning for content-based image classification at the moment. You can achieve decent results by implementing deep learning having three or more layers of CNN's where each layer is responsible for extracting one or more feature of the image.&lt;/p&gt;&#xA;" OwnerUserId="10913" LastActivityDate="2017-12-15T19:21:54.243" CommentCount="2" />
	<row Id="9" PostTypeId="1" CreationDate="2018-03-10T11:26:54.217" Score="0" ViewCount="10" Body="&lt;p&gt;I have hundreds of .txt files. I need to get into each one of them and remove certain paragraphs that start with specific words but as a whole, are not exactly the same every time.&#xA;Is there an automatic way that can help me clean these parts out? If yes, what is it? &#xA;If not, is it easy/quick to create my own AI tool for this job? Assuming that I need to get this done very soon, does it take a lot of time to learn how to create an AI tool to get the job done for me?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks in Advance!&lt;/p&gt;&#xA;" OwnerUserId="13235" LastEditorUserId="9947" LastEditDate="2018-03-11T02:00:29.547" LastActivityDate="2018-03-11T02:00:29.547" Title="Automated way to clean lots of .txt files?" Tags="&lt;deep-learning&gt;&lt;automation&gt;" AnswerCount="0" CommentCount="1" />
	<row Id="10" PostTypeId="1" CreationDate="2016-08-02T21:25:25.313" Score="1" ViewCount="31" Body="&lt;p&gt;By default using &lt;a href=&quot;https://en.wikipedia.org/wiki/DeepDream&quot; rel=&quot;nofollow&quot;&gt;DeepDream&lt;/a&gt; technique you can creating a dreamlike image out of two different images.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is it possible to easily enhance this technique to generate one image out from three?&lt;/p&gt;&#xA;" OwnerUserId="8" LastActivityDate="2016-08-02T21:25:25.313" Title="Can DeepDream produce a &quot;dream&quot; from 3 images?" Tags="&lt;convolutional-neural-networks&gt;&lt;deepdream&gt;" AnswerCount="0" CommentCount="1" FavoriteCount="1" />
	<row Id="6130" PostTypeId="1" CreationDate="2018-04-21T03:54:58.987" Score="1" ViewCount="56" Body="&lt;p&gt;Everything from facial recognition to the google home is coming equiped with A.I and it is being widely used , If autonomously connected to the internet , will A.I pose a threat to privacy or will it endanger free will if used for surveillance with facial recognition , like in the movie 'Minority Report'&lt;/p&gt;&#xA;" OwnerUserId="15164" LastActivityDate="2018-04-21T03:54:58.987" Title="Will commercialisation and widespread use of A.I in security and surveillance and other household products threaten free will or endanger privacy?" Tags="&lt;machine-learning&gt;&lt;prediction&gt;&lt;self-driving&gt;&lt;facial-recognition&gt;" AnswerCount="0" CommentCount="5" />
	<row Id="5349" PostTypeId="1" AcceptedAnswerId="5351" CreationDate="2018-02-17T08:29:32.363" Score="2" ViewCount="40" Body="&lt;p&gt;i'm trying to identify numbers and letters in license plate. License plate images are taken at different lighting condtion and converted to gray image. My concern with type of data for training is:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Gray Image:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Since they are taken at different lighthing condition, gray image have different pixel intensity for same number. Which means, i have to get many training data for different lighting condition to train.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Edge Image:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They lack enough pixel information since only edge is white while others(background) are black. So i think they will be very weak for translational difference like shearing or shifting.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I want to get some information about which type of image is better for training number in different lighting condition. I wish to use edge image if they don't  differ much since i can prepare edge image right now.&lt;/p&gt;&#xA;" OwnerUserId="12090" LastActivityDate="2018-02-17T10:37:51.787" Title="In number classification using neural network, is training with edge image better than gray image?" Tags="&lt;neural-networks&gt;&lt;machine-learning&gt;&lt;image-recognition&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="1" />
	<row Id="5443" PostTypeId="1" CreationDate="2018-02-26T16:33:11.623" Score="1" ViewCount="25" Body="&lt;p&gt;Many of you have probably seen the turtle from LabSix that gets mistaken for a rifle in Google's InceptionV3 image classifier. I read &lt;a href=&quot;https://arxiv.org/pdf/1707.07397.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;the paper&lt;/a&gt; and I understand how they apply EOT to 2d images and on the individual pixel values, but I am still unsure how they implement the EOT algorithm to the 3d model. &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Are they using EOT to perturb the individual coordinates in the 3d model's mesh? Or are they perturbing images of a turtle and then printing the turtle from the images?&lt;/li&gt;&#xA;&lt;li&gt;How do they check the InceptionV3 output iteratively without having to 3d print the object each time and check the probabilities given?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Any examples that someone can point to would also be very helpful.&lt;/p&gt;&#xA;" OwnerUserId="12983" LastEditorUserId="12983" LastEditDate="2018-02-26T16:52:14.900" LastActivityDate="2018-02-26T16:52:14.900" Title="How to apply EOT algorithm to 3d model" Tags="&lt;neural-networks&gt;&lt;image-recognition&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="5461" PostTypeId="1" CreationDate="2018-02-28T11:48:37.810" Score="2" ViewCount="90" Body="&lt;p&gt;I'd like to generate subtitles for a silent film. Is there an open source project out there capable of creating captions based on a series of images (such as a scene from a movie)?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT: thanks for the comments below. To clarify, what i'm looking for is an algorithm which can generate a caption for a sequences of images within a movie  describing what happens in the sequence. This is for preliminary research, so accuracy is less important. &lt;/p&gt;&#xA;" OwnerUserId="13030" LastEditorUserId="13030" LastEditDate="2018-03-01T22:17:35.500" LastActivityDate="2018-11-30T05:01:55.350" Title="Create captions based on a series of images" Tags="&lt;image-recognition&gt;" AnswerCount="3" CommentCount="5" />
	<row Id="5818" PostTypeId="1" CreationDate="2018-03-28T09:36:33.223" Score="1" ViewCount="69" Body="&lt;p&gt;I am new to deep learning and computer vision. I have a problem where i use yolo algorithm (&lt;a href=&quot;https://pjreddie.com/&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://pjreddie.com/&lt;/a&gt;) to detect objects. In the original paper, they define the output to recognize 80 classes, but for my problem i just want to recognize human only. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So i change the final layer to only 1 neuron, and do the training process with transfer learning techniques (used pretrained weights for the cases of 80 classes, of course not use the final layer weights and these weights becomes random number for my problems). I feed only human data to the algorithm. However, i realize that after longer training, the model becomes worse. It starts to recognize other objects as human. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like to hear any advice from you guys, should i also feed non-human data to the model.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks&lt;/p&gt;&#xA;" OwnerUserId="14613" LastEditorUserId="14612" LastEditDate="2018-03-28T16:27:34.037" LastActivityDate="2018-03-31T09:24:56.200" Title="Extracting one class from a pretrained Convolutional Neural Network" Tags="&lt;deep-learning&gt;&lt;convolutional-neural-networks&gt;&lt;image-recognition&gt;&lt;computer-vision&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="0" />
	<row Id="5939" PostTypeId="1" CreationDate="2018-04-07T17:29:52.477" Score="8" ViewCount="82" Body="&lt;p&gt;With the growing ability to cheaply create fake pictures, fake soundbites, and fake video there becomes an increasing problem with recognizing what is real and what isn't. Even now we see a number of examples of applications that create fake media for little cost (see &lt;a href=&quot;https://en.wikipedia.org/wiki/Deepfake&quot; rel=&quot;nofollow noreferrer&quot;&gt;Deepfake&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/FaceApp&quot; rel=&quot;nofollow noreferrer&quot;&gt;FaceApp&lt;/a&gt;, etc.).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Obviously, if these applications are used in the wrong way they could be used to tarnish another person's image. Deepfake could be used to make a person look unfaithful to their partner. Another application could be used to make it seem like a politician said something controversial.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What are some techniques that can be used to recognize and protect against artificially made media? &lt;/p&gt;&#xA;" OwnerUserId="13088" LastEditorUserId="1581" LastEditDate="2018-10-31T19:56:24.773" LastActivityDate="2018-11-12T17:23:34.103" Title="What are some tactics for recognizing artificially made media?" Tags="&lt;machine-learning&gt;&lt;image-recognition&gt;&lt;pattern-recognition&gt;" AnswerCount="1" CommentCount="5" FavoriteCount="1" />
	<row Id="6005" PostTypeId="1" CreationDate="2018-04-11T18:00:17.490" Score="0" ViewCount="38" Body="&lt;p&gt;I have an image of a spatial graph, i.e. a network of roads or veins. I'm wondering whether there are some known methods to product a graph/adjacency matrix out of this? Probably a deep learning method?&lt;/p&gt;&#xA;" OwnerUserId="14890" LastActivityDate="2018-04-11T18:00:17.490" Title="Image of a network graph to an adjacency matrix" Tags="&lt;image-recognition&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="6042" PostTypeId="1" CreationDate="2018-04-13T18:54:52.583" Score="0" ViewCount="46" Body="&lt;p&gt;I am trying to copy &lt;a href=&quot;https://arxiv.org/pdf/1708.03307.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;this paper&lt;/a&gt;, in which cells are detected in images using alexnet with the last layer modified to output a compressed 1D vector representation of the 2D boolean mask of cell locations in the image. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've implemented the compression/decompression scheme, and now I'm trying to adapt a modified alexnet to the problem of mapping images to vectors. The input images are 1 channel 250x250. The output vectors have length 10000. I'm using pytorch. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is the model definition, modified to change output vector length and input number of channels: &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;class AlexNet(nn.Module):&#xA;&#xA;    def __init__(self,D_out=10000): #modified with D_out&#xA;        super(AlexNet, self).__init__()&#xA;        self.features = nn.Sequential(&#xA;            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2), #modified 1channel &#xA;            nn.ReLU(inplace=True),&#xA;            nn.MaxPool2d(kernel_size=3, stride=2),&#xA;            nn.Conv2d(64, 192, kernel_size=5, padding=2),&#xA;            nn.ReLU(inplace=True),&#xA;            nn.MaxPool2d(kernel_size=3, stride=2),&#xA;            nn.Conv2d(192, 384, kernel_size=3, padding=1),&#xA;            nn.ReLU(inplace=True),&#xA;            nn.Conv2d(384, 256, kernel_size=3, padding=1),&#xA;            nn.ReLU(inplace=True),&#xA;            nn.Conv2d(256, 256, kernel_size=3, padding=1),&#xA;            nn.ReLU(inplace=True),&#xA;            nn.MaxPool2d(kernel_size=3, stride=2),&#xA;        )&#xA;        self.classifier = nn.Sequential(&#xA;            nn.Dropout(),&#xA;            nn.Linear(256 * 6 * 6, 4096),&#xA;            nn.ReLU(inplace=True),&#xA;            nn.Dropout(),&#xA;            nn.Linear(4096, 4096),&#xA;            nn.ReLU(inplace=True),&#xA;            nn.Linear(4096, D_out), #modified with D_out &#xA;        )&#xA;&#xA;    def forward(self, x):&#xA;        x = self.features(x)&#xA;        x = x.view(x.size(0), 256 * 6 * 6)&#xA;        x = self.classifier(x)&#xA;        return x&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The training script is &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;model = AlexNet()&#xA;criterion = nn.MSELoss()&#xA;optimizer = optim.Adam(model.parameters(), lr=0.01)&#xA;&#xA;k = 30 #size of batch&#xA;N = 100 #number epochs&#xA;&#xA;train_loader = DataLoader(train_data, batch_size=k, shuffle=True) #data loader for training&#xA;losses = [] #track the losses &#xA;&#xA;for epoch in range(N): &#xA;    for i,(inputs,targets) in enumerate(train_loader): &#xA;&#xA;        #prepare batch&#xA;        inputs,targets = Variable(inputs), Variable(targets,requires_grad=False)&#xA;&#xA;        #zero gradients &#xA;        optimizer.zero_grad()&#xA;&#xA;        #calculate model prediction&#xA;        outputs = model(inputs)&#xA;&#xA;        #calculate loss&#xA;        loss = criterion(outputs,targets)&#xA;&#xA;        #backpropagate loss &#xA;        loss.backward()&#xA;        optimizer.step()&#xA;&#xA;        # print statistics&#xA;        print(loss.data[0])&#xA;        losses.append(loss.data[0])&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;(although once I see the loss decreasing on my local machine I'll move model and variables to gpu on a server)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have made a set of 1000 training images with 0 to 15 random splotches over the same cat image like this&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/I26WM.jpg&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/I26WM.jpg&quot; alt=&quot;a training image with random &amp;#39;cells&amp;#39;&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;and I have generated the compressed vector representations of the splotch locations (following method 2 from the paper if this matters). These vectors are 10000 elements long.. in fact the approximate cell locations are encoded with 20-fold redundancy in the vectors. Each sequential 500 elements approximately encodes all cell locations. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;When I attempt to train, the loss does not decrease. Here is the loss versus minibatch iteration: &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/YfCbA.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/YfCbA.png&quot; alt=&quot;loss versus minibatch iteration&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any pointers? I have tried multiple learning rates. So far I have only run this on my laptop cpu: have I not waited long enough to see a loss decrease? Am I missing something that renders this untrainable? Do I have a bug? Any comments appreciated&lt;/p&gt;&#xA;" OwnerUserId="14943" LastEditorUserId="14943" LastEditDate="2018-04-14T05:04:24.613" LastActivityDate="2018-04-14T05:04:24.613" Title="training modified alexnet to compressed sensing task: seeking pointers for training" Tags="&lt;deep-learning&gt;&lt;image-recognition&gt;" AnswerCount="0" CommentCount="7" />
	<row Id="6080" PostTypeId="1" CreationDate="2018-04-16T13:19:51.720" Score="1" ViewCount="25" Body="&lt;p&gt;Using a neural network the method seems to be that you end up with a probability for each possible outcome.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To predict the next frame in a monochrome movie of size 400x400 with 8 shades of gray, it seems like there seems to be: 8^(160000) possibilities.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the other had if you just predicted the probability for each pixel individually you would end up with some kind of image which gets progressively blurred.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Perhaps what you want is to generate a few possibilities that are none-the-less quite sharp. In a similar way to weather prediction(?)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So how would you go about designing a neural network that takes reads a movie and tries to predict the next frame?&lt;/p&gt;&#xA;" OwnerUserId="4199" LastActivityDate="2018-04-16T13:19:51.720" Title="Best way to predict future frame of movie or game?" Tags="&lt;neural-networks&gt;&lt;image-recognition&gt;&lt;prediction&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="6116" PostTypeId="1" CreationDate="2018-04-19T08:32:55.490" Score="3" ViewCount="318" Body="&lt;p&gt;I tried to build a neural network from scratch to build a cat or dog binary classifier using a sigmoid output unit. I seem to get the output value around 0.5(+/- 0.002) for every input. This seems really weird to me. Here's my code, Please let me know if there is a mistake in the implementation.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;def initialize_parameters_deep(layer_dims):&#xA;    l=len(layer_dims)&#xA;    parameters={}&#xA;    for l in range(1,len(layer_dims)):&#xA;        parameters['W'+str(l)]=np.random.randn(layer_dims[l],layer_dims[l-1])*0.01&#xA;        parameters['b'+str(l)]=np.zeros((layer_dims[l],1))&#xA;    return parameters&#xA;&#xA;def linear_forward(A,W,b):&#xA;    Z=np.dot(W,A)+b&#xA;    cache=(A,W,b)&#xA;    return Z,cache&#xA;&#xA;&#xA;def sigmoid(Z):&#xA;    A = 1/(1+np.exp(-Z))&#xA;    cache=Z&#xA;    return A, cache&#xA;&#xA;&#xA;def relu(Z):&#xA;    A = np.maximum(0,Z)&#xA;&#xA;    assert(A.shape == Z.shape)&#xA;&#xA;    cache = Z &#xA;    return A, cache&#xA;&#xA;def relu_backward(dA, cache):&#xA;    Z = cache&#xA;    dZ = np.array(dA, copy=True) # just converting dz to a correct object.&#xA;&#xA;    # When z &amp;lt;= 0, you should set dz to 0 as well. &#xA;    dZ[Z &amp;lt;= 0] = 0&#xA;&#xA;    assert (dZ.shape == Z.shape)&#xA;&#xA;    return dZ&#xA;&#xA;def sigmoid_backward(dA, cache):&#xA;    Z = cache&#xA;&#xA;    s = 1/(1+np.exp(-Z))&#xA;    dZ = dA * s * (1-s)&#xA;&#xA;    assert (dZ.shape == Z.shape)&#xA;&#xA;    return dZ&#xA;&#xA;&#xA;def linear_activation_forward(A_prev,W,b,activation):&#xA;    if(activation=='sigmoid'):&#xA;        Z,linear_cache=linear_forward(A_prev,W,b)&#xA;        A,activation_cache=sigmoid(Z)&#xA;    elif activation=='relu':&#xA;        Z,linear_cache=linear_forward(A_prev,W,b)&#xA;        A,activation_cache=relu(Z)&#xA;    cache=(linear_cache,activation_cache)&#xA;    return A,cache&#xA;&#xA;def L_model_forward(X,parameters):&#xA;    A=X&#xA;    L=len(parameters)//2&#xA;    caches=[]&#xA;    for l in range(1,L):&#xA;        A,cache=linear_activation_forward(A,parameters['W'+str(l)],parameters['b'+str(l)],'relu')&#xA;        caches.append(cache)&#xA;    AL,cache=linear_activation_forward(A,parameters['W'+str(L)],parameters['b'+str(L)],'sigmoid')&#xA;    caches.append(cache)&#xA;    return AL,caches&#xA;&#xA;def compute_cost(AL,Y):&#xA;    m=Y.shape[1]&#xA;    cost=-1/m*np.sum(np.multiply(np.log(AL),Y)+np.multiply(np.log(1-AL),1-Y))&#xA;    return cost&#xA;&#xA;def linear_backward(dZ,cache):&#xA;    A_prev,W,b=cache&#xA;    m=A_prev.shape[1]&#xA;    dW = np.dot(dZ,A_prev.T)/m&#xA;    db = np.sum(dZ,axis=1,keepdims=True)/m&#xA;    dA_prev = np.dot(W.T,dZ)&#xA;    return dA_prev,dW,db&#xA;&#xA;def linear_activation_backward(activation,dA_prev,cache):&#xA;    linear_cache,activation_cache=cache&#xA;    if activation=='sigmoid':&#xA;&#xA;        dZ=sigmoid_backward(dA_prev,activation_cache)&#xA;        dA_prev,dW,db=linear_backward(dZ,linear_cache)&#xA;    if activation=='relu':&#xA;        dZ=relu_backward(dA_prev,activation_cache)&#xA;        dA_prev,dW,db=linear_backward(dZ,linear_cache)&#xA;    return dA_prev,dW,db&#xA;&#xA;def L_model_backward(AL,Y,caches):&#xA;    L=len(caches)&#xA;    m = AL.shape[1]&#xA;    Y = Y.reshape(AL.shape)&#xA;    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))&#xA;&#xA;    grads={}&#xA;    current_cache=caches[-1]&#xA;    grads['dA'+str(L-1)],grads['dW'+str(L)],grads['db'+str(L)]=linear_activation_backward('sigmoid',dAL,current_cache)&#xA;&#xA;    for l in reversed(range(L-1)):&#xA;        current_cache=caches[l]&#xA;        dA_prev_temp, dW_temp, db_temp = linear_activation_backward('relu',grads['dA'+str(l+1)],current_cache)&#xA;        grads[&quot;dA&quot; + str(l)] = dA_prev_temp&#xA;        grads[&quot;dW&quot; + str(l + 1)] = dW_temp&#xA;        grads[&quot;db&quot; + str(l + 1)] = db_temp&#xA;    return grads&#xA;def Grad_Desc(parameters,grads,learning_rate):&#xA;    L=len(parameters)//2&#xA;    for l in range(L):&#xA;        parameters['W'+str(l+1)]=parameters['W'+str(l+1)]-learning_rate*grads['dW'+str(l+1)]&#xA;        parameters['b'+str(l+1)]=parameters['b'+str(l+1)]-learning_rate*grads['db'+str(l+1)] &#xA;    return parameters&#xA;&#xA;def L_layer_model(X,Y,learning_rate,num_iter,layer_dims):&#xA;    parameters=initialize_parameters_deep(layer_dims)&#xA;    costs=[]&#xA;    for i in range(num_iter):&#xA;        AL,caches=L_model_forward(X,parameters)&#xA;        cost=compute_cost(AL,Y)&#xA;        grads=L_model_backward(AL,Y,caches)&#xA;        parameters=Grad_Desc(parameters,grads,learning_rate)&#xA;        if i%100==0:&#xA;            print(cost)&#xA;            costs.append(cost)&#xA;    plt.plot(np.squeeze(costs))&#xA;def predict(X,parameters):&#xA;    AL,caches=L_model_forward(X,parameters)&#xA;    prediction=(AL&amp;gt;0.5)&#xA;    return AL,prediction&#xA;&#xA;L_layer_model(x_train,y_train,0.0075,12000,[12288,20,7,5,1])&#xA;prediction=predict(x_train,initialize_parameters_deep([12288,20,7,5,1])) &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="15128" LastEditorUserId="15122" LastEditDate="2018-04-19T18:54:40.377" LastActivityDate="2018-04-25T04:23:48.983" Title="Neural network returns about the same output(mean) for every input" Tags="&lt;neural-networks&gt;&lt;deep-learning&gt;&lt;image-recognition&gt;" AnswerCount="1" CommentCount="12" FavoriteCount="1" />
	<row Id="6137" PostTypeId="1" CreationDate="2018-04-22T08:17:57.023" Score="1" ViewCount="20" Body="&lt;p&gt;Previously I had trained a &lt;code&gt;Neural Network&lt;/code&gt;upon 20,000 character images. This &lt;code&gt;Neural Net&lt;/code&gt; generally works well, it uses &lt;code&gt;RGB- Hue, Saturation, Intensity&lt;/code&gt; feature set for training. However, there can be certain character images which have &lt;code&gt;RGB-HSI&lt;/code&gt; values that this &lt;code&gt;neural net&lt;/code&gt; has not seen before. Therefore I am looking forward to converting training data to &lt;code&gt;grayscale&lt;/code&gt; and use some feature set well suited for grayscale images.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So are there any good suggestion for extracting a feature set out of &lt;code&gt;grayscale&lt;/code&gt; images.&lt;/p&gt;&#xA;" OwnerUserId="15116" LastActivityDate="2018-04-22T08:17:57.023" Title="Feature set out of grayscale Images for training a neural network?" Tags="&lt;neural-networks&gt;&lt;image-recognition&gt;&lt;datasets&gt;&lt;artificial-neuron&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="6206" PostTypeId="1" CreationDate="2018-04-29T07:57:54.930" Score="3" ViewCount="89" Body="&lt;p&gt;I have a question about the training sequence regarding Neural Network recognition. Let's say an image has 28*28 pixels, which leads to 784 Input Nodes with various greyscale values and 10 output nodes, if the image shows a number 0-9. Then when the training data is used for a set of known pictures of numbers, the weights and hidden layers uses forward- and backpropagation to get get the proper hidden and weight layers for the known layer. However, doesn't a new training picture destroy the trained and balanced weights and nodes values? Because the weights and hidden nodes have been calibrated to recognize the former training picture?&#xA;Thank you for assistance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Kind regards&#xA;David&lt;/p&gt;&#xA;" OwnerUserId="15312" LastActivityDate="2018-08-27T19:01:21.473" Title="Neural Network training beginner question" Tags="&lt;neural-networks&gt;&lt;convolutional-neural-networks&gt;&lt;image-recognition&gt;&lt;training&gt;&lt;data-science&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="1" />
	<row Id="6526" PostTypeId="1" AcceptedAnswerId="6529" CreationDate="2018-05-27T16:05:17.947" Score="3" ViewCount="499" Body="&lt;p&gt;I'm currently working on license plate recognition. My system consist of 2 stage: (1) License Plate region extraction &amp;amp; (2) License Plate region recognition.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;I'm doing (1) with Raspberry pi 3 model b&lt;/strong&gt;. I find license plate candidate first by merging bounding boxes based on their similarity. In this way, i have only 1~7 license plate region proposals. And it took less than .3 seconds. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now i have to reduce number of region proposal to be around only 1~2 so that i can send these images to server to do job (2). For license plate extraction, I made my own classifier function in tensorflow and the code is below. It gets proposed license plate as input.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First, I resize all license plate to be [120, 60] and converted to gray image. And there are 2 classes: 'plate', 'non_plate'. For non_plate image, i collected various image that might appear in image as background. I have 181 images for 'plate' class and 56 images for 'non_plate' for now, i trained for about 3000 steps so far and current loss is .53 . &lt;/p&gt;&#xA;&#xA;&lt;p&gt;When i did prediction on test set,  i encountered problem that for some of plate image, it doesn't recognize license plate which is very obviously license plate image from my eyes. It is okay for me to wrongly recognize non plate image as plate but it is problem if it wrongly recognize plate as non_plate because it will not be sent to server to be fully recognized.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It happens like 10 out of 100 test images and this rate is far worse than i expected. I need help for adressing this problem. Would there be any improvement that i can make? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;(1) Is my training set too small to classify between license plate&#xA;    and non license plate? Or is number of steps is too small?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;(2) Is my graph structure bad?&lt;/strong&gt; I needed to have small graph&#xA;    structure for my raspberry pi to recognize less than 1 second. Could&#xA;    you suggest better structure if it is bad?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;(3) Is it bad to resize any proposed image to [120, 60] to be used&#xA;    as input for graph?&lt;/strong&gt; I think it loses some information. But isn't&#xA;    this close to roi pooling like used in fast rcnn?&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt; inputs=tf.reshape(features[FEATURE_LABEL],[-1,120 , 60 ,1],name=&quot;input_node&quot;) #120 x 60 x 1, which is gray&#xA;&#xA;conv1=tf.layers.conv2d(inputs=inputs,&#xA;                       filters=3,&#xA;                       kernel_size=[3,3],&#xA;                       padding='same',&#xA;                       activation=tf.nn.leaky_relu&#xA;                       )&#xA;#conv1 output shape: (batch_size,120,60,3)&#xA;&#xA;pool1=tf.layers.max_pooling2d(inputs=conv1,pool_size=[2,2],strides=2,padding='valid')&#xA;&#xA;#pool1 output shape: (batch_size,60,30,3)&#xA;&#xA;conv2=tf.layers.conv2d(inputs=pool1,filters=6,kernel_size=[1,1],padding='same',activation=tf.nn.leaky_relu)&#xA;&#xA;#conv2 output shape: (batch_size, 60,30,6)&#xA;&#xA;pool2=tf.layers.max_pooling2d(inputs=conv2,pool_size=[2,2],strides=2,padding='valid')&#xA;&#xA;#pool2 output shape: (batch_size, 30,15,6)&#xA;&#xA;conv3=tf.layers.conv2d(inputs=pool2,filters=9,kernel_size=[3,3],padding='same',activation=tf.nn.leaky_relu)&#xA;&#xA;#conv3 output shape: (batch_size, 30,15,9)&#xA;&#xA;pool3=tf.layers.max_pooling2d(inputs=conv3,pool_size=[2,2],strides=2,padding='valid')&#xA;&#xA;#pool3 output shape: (batch_size, 15,7,9)&#xA;&#xA;&#xA;#dense fully connected layer&#xA;pool2_flat=tf.reshape(pool3,[-1,15*7*9]) #flatten pool3 output to feed in dense layer&#xA;&#xA;dense1=tf.layers.dense(inputs=pool2_flat,units=120,activation=tf.nn.relu)&#xA;&#xA;logits=tf.layers.dense(dense1,2) #input for softmax layer&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/vHSZu.jpg&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/vHSZu.jpg&quot; alt=&quot;training non plate image example&quot;&gt;&lt;/a&gt;&#xA; [training non plate image example]&#xA;[&lt;img src=&quot;https://i.stack.imgur.com/EX3VO.png&quot; alt=&quot;training plate image example&quot;&gt;]&lt;a href=&quot;https://i.stack.imgur.com/EX3VO.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;4&lt;/a&gt;&#xA;[training plate image example. It is region proposed image]&lt;/p&gt;&#xA;" OwnerUserId="12090" LastEditorUserId="12090" LastEditDate="2018-05-27T16:50:50.263" LastActivityDate="2018-05-28T00:43:55.777" Title="Detecting license plate using tensorflow" Tags="&lt;convolutional-neural-networks&gt;&lt;image-recognition&gt;&lt;tensorflow&gt;&lt;python&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
	<row Id="6686" PostTypeId="1" AcceptedAnswerId="6688" CreationDate="2018-06-08T15:03:43.383" Score="3" ViewCount="97" Body="&lt;p&gt;I am reading a book about OpenCV, it speaks about some derivative of images like &lt;code&gt;sobel&lt;/code&gt;. I am confused about image derivative! What is derived from? How can we derived from an image? I know we consider an image(1-channel) as a n*m matrix with 0 to 255 intensity numbers. How can we derive from this matrix?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT: a piece of text of the book:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Derivatives   and Gradients&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;One   of  the most    basic   and important   convolutions    is  computing   derivatives&#xA;  (or   approximations  to  them).  There   are many    ways    to  do  this,   but only    a   few&#xA;  are   well    suited  to  a   given   situation.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;In    general,    the most    common  operator    used    to  represent   differentiation is  the&#xA;  Sobel derivative  operator.   Sobel&#xA;  operators exist   for any order   of  derivative  as  well    as  for mixed   partial&#xA;  derivatives   (e.g.,  ∂ 2 /∂x∂y).&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="9941" LastEditorUserId="9941" LastEditDate="2018-06-09T07:25:42.813" LastActivityDate="2018-06-18T02:50:23.553" Title="What does it mean &quot;derivative of an image&quot;?" Tags="&lt;image-recognition&gt;" AnswerCount="2" CommentCount="0" />
	<row Id="6707" PostTypeId="1" CreationDate="2018-06-11T12:51:07.997" Score="1" ViewCount="77" Body="&lt;p&gt;I would like to develop a machine learning algorithm, given two photos, that can decide which image is more &quot;artistic&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am thinking about somehow combining two images, giving it to a CNN, and get an output 0 (the first image is better) or 1 (the second image is better). Do you think this is a valid approach? Or could you suggest an alternative way for this? Also, I don't know how to combine two images.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit: Let me correct &quot;artistic&quot; as &quot;artistic according to me&quot;, but it doesn't matter, I am more interested in the architecture. You can even replace &quot;artistic&quot; with something objective. Let's say I would like to determine which photo belongs to a more hotter day.&lt;/p&gt;&#xA;" OwnerUserId="16201" LastEditorUserId="1671" LastEditDate="2018-06-13T17:04:48.873" LastActivityDate="2018-06-13T17:22:17.407" Title="Which photo is more artistic?" Tags="&lt;convolutional-neural-networks&gt;&lt;image-recognition&gt;&lt;art-aesthetics&gt;" AnswerCount="3" CommentCount="2" FavoriteCount="1" />
	<row Id="6750" PostTypeId="1" AcceptedAnswerId="6752" CreationDate="2018-06-14T06:23:57.040" Score="3" ViewCount="27" Body="&lt;p&gt;As I know, if we consider a 3*3 kernel, we should add a padding of 1px to the source image(if we want to have effect on whole of the image), then we start to put the kernel in upper-left side of the image and multiplying each element of kernel to corresponding pixel on image. Then we sum all the results and put it on the anchor point of kernel(usually center element). Then we should shift the kernel one step to right side and do these things again.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If I am right till here, I have a question about the summation results. I want to know: should we consider the replaced value of image in previously calculated summation and replaced in anchor point in new step of calculation or not?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I mean we must put the anchor point's result in source image and consider it in calculations of shifted kernel? Or we must put it in distance image and we don't consider these results when we shift the kernel on source image(It means don't replace the results on source image for next steps calculations)?&lt;/p&gt;&#xA;" OwnerUserId="9941" LastActivityDate="2018-06-14T07:01:03.110" Title="How to apply a kernel to an image?" Tags="&lt;image-recognition&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="6770" PostTypeId="1" CreationDate="2018-06-15T14:32:40.510" Score="6" ViewCount="80" Body="&lt;p&gt;I'm trying to detect the &lt;strong&gt;visual attention&lt;/strong&gt; area in a given image and crop the image into that area. For instance, given an image of any size and a rectangle of say LxW dimension as an input, I would like to crop the image to the most important visual attention area. I'm looking for a state of the art approach for that.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do we have any tools or SDK to implement that? Any piece of code or algorithm would really help.&lt;/p&gt;&#xA;" OwnerUserId="9053" LastActivityDate="2018-11-08T02:36:31.487" Title="Detect visual attention area in an image" Tags="&lt;machine-learning&gt;&lt;image-recognition&gt;&lt;algorithm&gt;&lt;computer-vision&gt;&lt;pattern-recognition&gt;" AnswerCount="3" CommentCount="3" FavoriteCount="2" />
	<row Id="6859" PostTypeId="1" CreationDate="2018-06-22T20:18:39.120" Score="2" ViewCount="314" Body="&lt;p&gt;I'm new to machine learning, so i figured I should look into google's tensor flow guides and I know how to code in JS so that's why I'm using tensorflow.js, there's and example in the guide that trains itslef to recognize handwritten numbers from the  MNIST handwriting dataset, I sort of understand what's going on in the code but since I'm very new to ML it's not a lot, I went through the code and saw that it didn't took image by image to train itself but it requests one sprite which contains all the images and then cuts it into what it needs, this makes sense from a performance point of view, but as this process is kind of abstract I don't understand what's really going on, I want to upload an image of my own and call the predictor of the model but I don't know how to do it, any help? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was thinking that drawing in a canvas of 28x28 a number might be very interesting as well instead of uploading an image, but I need to know how to test the model once it's trained with my own data.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The tutorial: &lt;a href=&quot;https://js.tensorflow.org/tutorials/mnist.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://js.tensorflow.org/tutorials/mnist.html&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="16078" LastActivityDate="2018-06-25T16:53:11.927" Title="How to load an image into tensorflow.js code which reads handwritten numbers and clasify them" Tags="&lt;machine-learning&gt;&lt;convolutional-neural-networks&gt;&lt;image-recognition&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="7018" PostTypeId="1" AcceptedAnswerId="7034" CreationDate="2018-07-04T13:50:25.157" Score="4" ViewCount="139" Body="&lt;ol&gt;&#xA;&lt;li&gt;What methods are used for facial recognition in public surveillance? Ideally, an answer would point to the software, algorithms or specifications being used.&lt;/li&gt;&#xA;&lt;li&gt;How can those be fooled?&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fake or disfigured face? To what extend would one need to employ artificial scars or moles, make-up or even a complete face mask?&lt;/li&gt;&#xA;&lt;li&gt;Will spectacles work? Sun glasses vs. normal ones?&lt;/li&gt;&#xA;&lt;li&gt;Will using a hat to hide a portion of a face work? How much needs to be hidden? Hair, forehead, eyes, nose or complete face?&lt;/li&gt;&#xA;&lt;li&gt;Blinding (not: destroying) a camera with laser or LEDS, provided the camera can be seen, and one can aim at it?&lt;/li&gt;&#xA;&lt;li&gt;What else?&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;Slightly related: Are there any other methods being used, such as clothes detection, gait detection, etc?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="16685" LastEditorUserId="1847" LastEditDate="2018-07-05T11:20:27.257" LastActivityDate="2018-07-11T18:11:47.610" Title="How good is facial recognition exployed in public surveillance" Tags="&lt;image-recognition&gt;&lt;facial-recognition&gt;" AnswerCount="2" CommentCount="2" />
	<row Id="7190" PostTypeId="1" CreationDate="2018-07-18T08:37:44.347" Score="4" ViewCount="105" Body="&lt;p&gt;Is there any project or example for a software identifying cars?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Situation: I got multiple angle shots in high resolution from a car. I want the algorithm to tell me &quot;This is a Mercedes SLK&quot; or &quot;This is a Toyota Prius&quot;.&#xA;I got a lot of high resolution data to train such an algorithm, but I presume a simple &quot;Put your data in TensorFlow and see what happens.&quot; is not enought.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I had stumbled upon &lt;a href=&quot;https://ai.stackexchange.com/questions/3282/identifying-cars-using-deep-learning&quot;&gt;Identifying cars using deep learning&lt;/a&gt; , but this is not what I meant.&lt;/p&gt;&#xA;" OwnerUserId="6736" LastEditorUserId="9062" LastEditDate="2018-07-18T18:11:50.760" LastActivityDate="2018-07-18T18:11:50.760" Title="Identifying car model via deep learing" Tags="&lt;deep-learning&gt;&lt;convolutional-neural-networks&gt;&lt;image-recognition&gt;&lt;tensorflow&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="2" />
	<row Id="7200" PostTypeId="1" CreationDate="2018-07-19T08:55:08.907" Score="1" ViewCount="63" Body="&lt;p&gt;What AI concepts, topologies&lt;sup&gt;1&lt;/sup&gt;, algorithms, or SaaS can be used to recognize a person eating a chocolate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For this question, image recognition draws from a real time feed, validating each of these steps in sequence:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Using a camera app, the user begins recording.&lt;/li&gt;&#xA;&lt;li&gt;The user focuses on the subject's face, at which time the app attempts to recognize the person&lt;sup&gt;2&lt;/sup&gt;&lt;/li&gt;&#xA;&lt;li&gt;Person holds a single piece of chocolate (i.e M&amp;amp;Ms) to the camera lens, at which time the app attempts to recognize it.&lt;/li&gt;&#xA;&lt;li&gt;The user puts the chocolate into their mouth, chews, and swallows, at which time the app attempts to recognize that AS AN ACTION.&lt;/li&gt;&#xA;&lt;li&gt;The app gives a completion message indicating success or failure.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;I understand that we can use real time recognition for each step, but I don't know if there are concepts proposed or tested to validate the scene as a sequence or any of the three recognition steps individually.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The app should invalidate the scene if the subject is swapped with another subject, if the subject does not swallow the chocolate, or there is some other deviation from the expected sequence above.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;[1] By topology in this context is meant the standard mathematical meaning of the term applied to the higher level connections that are likely needed to recognize sequences of actions.  In this sense, the use of the term topology is not at the level dimensions of neuron layers or convolution kernels.  Since process topology is normally considered prior to considering library dependencies or deployment concerns, the term topology is more appropriate than architecture in this question.  (First things first.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;[2] I've already identified SaaS options for facial recognition.&lt;/p&gt;&#xA;" OwnerUserId="16975" LastEditorUserId="4302" LastEditDate="2018-07-24T11:50:04.047" LastActivityDate="2018-07-24T11:50:04.047" Title="Steps recognition" Tags="&lt;image-recognition&gt;&lt;concepts&gt;&lt;action-recognition&gt;&lt;topology&gt;" AnswerCount="0" CommentCount="5" />
	<row Id="7277" PostTypeId="1" CreationDate="2018-07-24T15:01:27.323" Score="1" ViewCount="18" Body="&lt;p&gt;Anyone here know if the image-recognition/text-recognition/etc features of Google Vision API use the same trained models as the image-recognition/text-recognition/etc of Firebase's ML kit? If they don't which one do you think is better?  &lt;em&gt;(I've tried, and failed, to find the answer on the web.)&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I realize Google owns both of them, but one would think that if both are essentially the same, then this fact would be stated very clearly throughout multiple channels on the Internet. &lt;em&gt;(It's not.)&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I do believe at least the text-recognition is the same, because both use OCR. But I'm unsure about the image detection aspect.&lt;/p&gt;&#xA;" OwnerUserId="17080" LastEditorUserId="1671" LastEditDate="2018-07-24T20:00:55.887" LastActivityDate="2018-07-24T20:00:55.887" Title="Difference in trained models between GCP's Google Vision and Firebase's ML kit?" Tags="&lt;machine-learning&gt;&lt;image-recognition&gt;&lt;computer-vision&gt;&lt;software-evaluation&gt;&lt;google&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="7302" PostTypeId="1" CreationDate="2018-07-27T07:25:09.473" Score="0" ViewCount="61" Body="&lt;p&gt;I have created an ANN in Python (without libs). On beginning, it had been learned in target of solve linear problems like distinguishing between negative and positive numbers, where the layer widths were [1, 2, 1]. I have decided to learn recognizing small digits saved as 20x20 black &amp;amp; white PNG files. Now the array of layer widths is:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;[1200, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 10]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I tried other similar ones....  With the above array of layer widths training took 8 hours (NN had seen &lt;strong&gt;600.000&lt;/strong&gt; images from 5000 images of learning set) and when I look at results, each output is equal about 10%-15%. Nothing is certain.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://github.com/mvxxx/NNMV&quot; rel=&quot;nofollow noreferrer&quot;&gt;This code is a core of my NN&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;and that is main code:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;net = nnmv.NeuralNetwork()&#xA;    net.createNew([1200,100,100,100,100,100,100,100,100,100,100,100,100,10],0.15,0.07)&#xA;    for step in range(0,1000):&#xA;        for i in range(0,500):&#xA;            for number in range(0,10):&#xA;                print(&quot;Currently learning: &quot;,number,'x',i,&quot; in step: &quot;,step)&#xA;                pixels = list(Image.open(&quot;judgment/&quot;+str(number)+'x'+str(i)+&quot;.png&quot;).convert(&quot;RGB&quot;).getdata())&#xA;                output = list()&#xA;                for itr in range(0,number):&#xA;                    output.append(0)&#xA;                output.append(1)&#xA;                for itr in range(0,9-number):&#xA;                    output.append(0)&#xA;                net.teach(Stuff.reorganisePixelData(pixels),output)&#xA;                print(&quot;Error: &quot;,net.calculateError(output))&#xA;        Saver.Saver().save(net, &quot;digitrecognizer&quot;)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;There is 1200 inputs because there are 400 pixels and each pixel is saved in RGB model. &#xA;&lt;strong&gt;Stuff.reorganisePixelData:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;def reorganisePixelData(pixels):&#xA;    output = []&#xA;    for i in range(0,len(pixels)):&#xA;        output.append(pixels[i][0])&#xA;        output.append(pixels[i][1])&#xA;        output.append(pixels[i][2])&#xA;    return output&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;What have I to do? Add or remove layers, change some or all of the layer widths? Or something in concept of learning?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My error calculator prints error like &lt;strong&gt;0.30203135930914193&lt;/strong&gt;, and it changes only a bit.&lt;/p&gt;&#xA;" OwnerUserId="17132" LastEditorUserId="4302" LastEditDate="2018-08-12T02:49:26.557" LastActivityDate="2018-11-02T22:00:36.813" Title="What ANN layer widths support the learning of digit recognition?" Tags="&lt;neural-networks&gt;&lt;image-recognition&gt;&lt;hidden-layers&gt;" AnswerCount="1" CommentCount="4" />
	<row Id="7371" PostTypeId="1" CreationDate="2018-08-01T09:56:43.227" Score="4" ViewCount="87" Body="&lt;p&gt;I am currently working on a project to classify snake types separately using an image of the snake. I need to train a module to classify snake images, but the problem is there are only a small number of images available for some snake types. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What is the best approach to train a neural network for image classification using a small data set?&lt;/p&gt;&#xA;" OwnerUserId="17220" LastEditorUserId="2193" LastEditDate="2018-08-02T01:28:18.007" LastActivityDate="2018-08-02T01:28:18.007" Title="Image Classification" Tags="&lt;neural-networks&gt;&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;convolutional-neural-networks&gt;&lt;image-recognition&gt;" AnswerCount="2" CommentCount="0" />
	<row Id="7470" PostTypeId="1" CreationDate="2018-08-08T06:17:27.707" Score="6" ViewCount="77" Body="&lt;p&gt;From &lt;a href=&quot;http://proceedings.mlr.press/v48/santoro16.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;Meta-Learning with Memory-Augmented Neural Networks&lt;/a&gt; in section 4.1:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;To reduce the risk of overfitting, we performed data augmentation by&#xA;  randomly translating and rotating character images. We also created&#xA;  new classes through 90◦, 180◦ and 270◦ rotations of existing data.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I can maybe see how rotations could reduce overfitting by allowing the model to generalize better. But if augmenting the training images through rotations prevents overfitting, then what is the purpose of adding new classes to match those rotations? Wouldn't that cancel out the augmentation? &lt;/p&gt;&#xA;" OwnerUserId="17373" LastEditorUserId="1671" LastEditDate="2018-08-08T21:24:13.147" LastActivityDate="2018-08-09T09:50:31.003" Title="How does rotating an image and adding new 'rotated classes' prevent overfitting?" Tags="&lt;image-recognition&gt;&lt;datasets&gt;&lt;overfitting&gt;" AnswerCount="2" CommentCount="1" />
	<row Id="7672" PostTypeId="1" AcceptedAnswerId="7766" CreationDate="2018-08-22T03:29:14.083" Score="4" ViewCount="106" Body="&lt;p&gt;A dataset is given which contains textual data (year, number of rooms, location) and visual data (an jpeg image of the house). The neural network has the task to predict the price of the property. As an example, the training dataset consists of some values of a computer game simulation (a city simulation) and the aim is to determine the housing price for new unseen real estate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem is, that that the number of pictures in the input dataset is fluctuating. Sometimes no images are given and sometimes more. That means the image recognition engine must form a sublayer in the overall neural network. It is some kind of aggregation problem to transform first visual data into a textual description of the image and aggregate it then with the other textual information.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;original message:&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So suppose that you have a real estate appraisal problem. You have some structured data, and some images exterior of home, bedrooms, kitchen, etc. The number of pictures taken is variable per observational unit, i.e. the house.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I understand the basics of combining an image processing neural net with tabular data for a single image. You chop off the final layer and feed in the embeddings of the image to your final model.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How would one deal with variable number of images? Where your unit of observation can have between zero and infinity images (theoretically no upper bound on number of images in observation)?&lt;/p&gt;&#xA;" OwnerUserId="17646" LastEditorUserId="11571" LastEditDate="2018-08-22T13:13:42.657" LastActivityDate="2018-09-16T14:07:02.137" Title="Predicting housing values with neural network (was: Variable Number of Inputs to Neural Networks)" Tags="&lt;deep-learning&gt;&lt;image-recognition&gt;" AnswerCount="2" CommentCount="4" />
	<row Id="7676" PostTypeId="1" CreationDate="2018-08-22T09:32:28.397" Score="1" ViewCount="54" Body="&lt;p&gt;For my university project, I am planning to build an automated customer service machine. One which recognizes when someone approaches the camera according to says hello, etc. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, I am planning to add simple speech recognition and language processing features. So my question is. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What kind of camera would be suitable? Is there any particular model that you recommend. I was thinking of cameras used for amazon go(as an example).&lt;/p&gt;&#xA;" OwnerUserId="17651" LastEditorUserId="17651" LastEditDate="2018-08-23T02:28:45.740" LastActivityDate="2018-08-23T02:28:45.740" Title="Cameras for automatic customer service machine" Tags="&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;image-recognition&gt;&lt;hardware-evaluation&gt;&lt;open-ai&gt;" AnswerCount="0" CommentCount="5" ClosedDate="2018-08-22T17:20:23.667" />
	<row Id="7715" PostTypeId="1" CreationDate="2018-08-25T21:24:00.783" Score="4" ViewCount="35" Body="&lt;p&gt;I’m training a network to do image classification on zoo animals. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I’m a software engineer and not an ML expert, so I’ve been retraining Google’s Inception model and the latest models is trained using Google AutoML Vision.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The network performs really well, but I have trouble with images of animals that I don’t want any labels for. Basically I would like images of those animals to be classified as unknowns or achieve low scores. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I do have images of the animals that I don’t want labels for and I tried putting them all into one “nothing” label together with images I’ve collected of the animals habitats without any animals. This doesn’t really yield any good results though. The network performs for the labeled animals but ends up assigning one of those labels to the other animals as well. Usually with a really high score as well. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have 14 labels and 10.000 images. I should also mention that the “nothing” label ends up having a lot of images compared to the actual labels. Those images are not included in the 10.000.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there any tricks to achieve better results with this? Should I create multiple labels for the images in the “nothing” category maybe?&lt;/p&gt;&#xA;" OwnerUserId="17725" LastActivityDate="2018-08-28T01:47:10.400" Title="Optimizing image recognition results for unknown labels" Tags="&lt;neural-networks&gt;&lt;convolutional-neural-networks&gt;&lt;image-recognition&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="7801" PostTypeId="1" CreationDate="2018-09-03T09:05:44.930" Score="0" ViewCount="17" Body="&lt;p&gt;How to find a picture of specific cat graffiti from my photo library, which is so huge that I tired scrolling. The graffiti is very simple - it is just a black silhouette on a white wall - I can almost draw it by hand.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Either use name to picture matching with pretrained networks or use some generic contour recognition and matching if there is any. I lack practice a lot, so what is the recommended approach for setup to search images by name or &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am long interested to try AI, but never had any real task at hand, so this is my first experience - I watched lectures by Andrew Ng, and they are quite good if you need the math and modules. I'd like to avoid going into much math details and concentrate more on usability, but any good math insights are welcome.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The library is currently in Google Photos, but it doesn't matter - I can setup any pipeline for feeding photos. The missing part is AI processing block. If you can point me the best practice to download and use pretrained network for the task, or there are some user level modules to reuse, I would be happy to try and report on progress.&lt;/p&gt;&#xA;" OwnerUserId="17898" LastActivityDate="2018-09-03T09:05:44.930" Title="Searching (google) photo library with AI" Tags="&lt;image-recognition&gt;&lt;getting-started&gt;&lt;pattern-recognition&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="7899" PostTypeId="1" AcceptedAnswerId="7931" CreationDate="2018-09-09T22:20:04.963" Score="2" ViewCount="59" Body="&lt;p&gt;Image Captioning is a hot research topic in the AI community. There are considerable image captioning models for research usage such as NIC, Neural Talk 2 etc. But can these research models be used for commercial purpose? Or we should build much more complex structured ones for commercial usage? Or if we can make some improvements based these models to meet the business applications situation? If so, what improvements should we take? Are there any existing commercial Image Captioning applications can be referenced?&lt;/p&gt;&#xA;" OwnerUserId="14948" LastActivityDate="2018-09-12T06:23:18.653" Title="How to build a commercial image captioning system?" Tags="&lt;deep-learning&gt;&lt;image-recognition&gt;&lt;natural-language-processing&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="7900" PostTypeId="1" CreationDate="2018-09-10T02:08:14.790" Score="1" ViewCount="77" Body="&lt;p&gt;For my university project, I am planning to build a face recognition/ occupation recognition programme. However, rather than using the existing Haar cascade(for age and gender) I am planning to use Face API which seems far more accurate than the former. My question is is it possible to somehow combine my trained data for Haar cascade(for occupation) with Face API since Face API doesn't have the option to recognize occupation(such as students/office workers from their appearance)?&lt;/p&gt;&#xA;" OwnerUserId="17651" LastEditorUserId="17651" LastEditDate="2018-09-10T04:05:39.353" LastActivityDate="2018-11-11T12:01:30.373" Title="Occupation detection using Face API" Tags="&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;convolutional-neural-networks&gt;&lt;image-recognition&gt;&lt;python&gt;" AnswerCount="1" CommentCount="6" />
	<row Id="8034" PostTypeId="1" CreationDate="2018-09-19T07:21:47.930" Score="2" ViewCount="44" Body="&lt;p&gt;In physics, there are a lot of graphs, such as 'velocity vs time' , 'time period vs length' and so on. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let's say I have a sample set of points for a 'velocity vs time' graph. I draw it by hand, rather haphazardly, on a canvas. This drawn graph on the canvas is then provided to the computer. By computer I mean AI. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I want it to sort of beautify my drawn graph, such as straightening the lines, making the curves better, adding the digits on axes and so on. In other words, I want it to give me a better version of my drawn graph which I can readily use in, say, a word document for a report.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;a) Is it possible/plausible to do this?&#xA;b) Are there any APIs available that can already do this? (Don't want to reinvent the wheel)&#xA;c) Any recommendations/suggestions to make the idea possible by altering it somehow?&lt;/p&gt;&#xA;" OwnerUserId="18361" LastEditorUserId="1581" LastEditDate="2018-09-19T18:53:19.690" LastActivityDate="2018-09-19T18:53:19.690" Title="How can I use A.I/Image Processing to construct mathematical graphs from drawing?" Tags="&lt;image-recognition&gt;" AnswerCount="0" CommentCount="2" />
	<row Id="8196" PostTypeId="1" CreationDate="2018-10-01T05:30:04.247" Score="0" ViewCount="23" Body="&lt;p&gt;I'm currently working on tumor detection project using dicom images as I'm beginner in it currently having a difficulty in segmenting each part in image and giving each segment a new colour.&lt;/p&gt;&#xA;" OwnerUserId="18661" LastActivityDate="2018-10-01T06:53:25.823" Title="How image segmentation actually works?" Tags="&lt;image-recognition&gt;&lt;matlab&gt;" AnswerCount="1" CommentCount="2" />
	<row Id="8254" PostTypeId="1" CreationDate="2018-10-04T06:25:15.123" Score="1" ViewCount="26" Body="&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/GX7lT.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/GX7lT.png&quot; alt=&quot;in figure 18 showing the part which have tumor and other one is the actual DICOM Image&quot;&gt;&lt;/a&gt;As i'm beginner in image processing,having difficulty in segmenting all the parts in dicom image.currently i'm applying watershed algorithm but it segment only that part that have tumor.i  have to segment all parts in image. which algorithm will be helpful to perform this task?&lt;/p&gt;&#xA;" OwnerUserId="18661" LastEditorUserId="18661" LastEditDate="2018-10-04T10:50:46.403" LastActivityDate="2018-11-03T13:00:26.777" Title="how to segment each part in dicom image?" Tags="&lt;image-recognition&gt;&lt;matlab&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="8591" PostTypeId="1" CreationDate="2018-10-23T22:22:35.900" Score="1" ViewCount="24" Body="&lt;p&gt;I am developing an image search engine. The engine is meant to retrieve wrist watches based on the input of the user. I am using SIFT descriptors to index the elements in the database and applying Euclidean distance to get the most similar watches. I feel like this type of descriptor is not the best since watches have a similar structure and shape. Right now, the average difference between the best and worst matches is not big enough (15%)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've been thinking of adding colour to the descriptor, but I'd like to hear other suggestions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;BR,&#xA;SV&lt;/p&gt;&#xA;" OwnerUserId="19266" LastEditorUserId="7800" LastEditDate="2018-10-24T23:31:21.897" LastActivityDate="2018-11-24T22:02:30.543" Title="What is a good descriptor for similar objects?" Tags="&lt;image-recognition&gt;&lt;computer-vision&gt;&lt;feature-selection&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="8613" PostTypeId="1" CreationDate="2018-10-25T07:50:28.110" Score="1" ViewCount="28" Body="&lt;p&gt;I saw when browsing we can use data augmentation for creating a dataset for face recognition. The augmented images may include inverted, tilted or distorted faces. Do the model detect the face from the inverted image. When I tried my model cant able to detect any inverted or tilted faces.&lt;/p&gt;&#xA;" OwnerUserId="17058" LastEditorUserId="17058" LastEditDate="2018-10-26T06:32:22.170" LastActivityDate="2018-10-26T07:40:16.527" Title="How can we use data augmentation for creating data set for face recognition and will the inverted faces on augmented images detected?" Tags="&lt;image-recognition&gt;&lt;facial-recognition&gt;" AnswerCount="1" CommentCount="2" />
	<row Id="8615" PostTypeId="1" CreationDate="2018-10-25T10:12:34.790" Score="2" ViewCount="49" Body="&lt;p&gt;Which possibilities exist to evaluate the visual reasoning capabilities of neural networks in the field of image recognition?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are there methods to measure the ability of machine reasoning?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Or something more specific: Is it possible to measure if a network understood the concept of a car / a cat / a human without using the classification accuracy.&lt;/p&gt;&#xA;" OwnerUserId="16634" LastEditorUserId="17221" LastEditDate="2018-10-26T19:14:17.280" LastActivityDate="2018-10-26T21:43:52.173" Title="How to measure the reasoning capabilities of neural networks" Tags="&lt;convolutional-neural-networks&gt;&lt;image-recognition&gt;&lt;reasoning&gt;" AnswerCount="1" CommentCount="3" FavoriteCount="2" />
	<row Id="8616" PostTypeId="1" CreationDate="2018-10-25T13:28:23.067" Score="2" ViewCount="33" Body="&lt;p&gt;I loaded a neural network model trained with Caffe by other people in OpenCV. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The model should detect the presence of a car in a single parking spot outputting the probability of it being free/occupied.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The model was trained with images all belonging to the same parking area, taken at different hours of day and with different light conditions. Images were taken by different cameras but the cameras are all of the same model (raspberry cameras).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I tried to run the model with a few images some of them taken from their dataset and other downloaded from google.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The images taken from their dataset are correctly classified while the ones taken from google are not correctly classified.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My question is: is it possible to deploy a NN model trained with images all coming from a single parking area in another parking area? Is not such a model for parking detection occupancy supposed to generalize independently from the location where training images have been taken?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you know about an already existing trained model that works good please let me know.&lt;/p&gt;&#xA;" OwnerUserId="12959" LastEditorUserId="12959" LastEditDate="2018-10-26T07:54:35.637" LastActivityDate="2018-10-26T07:54:35.637" Title="Influence of location on a Neural Network trained for parking detection occupancy" Tags="&lt;neural-networks&gt;&lt;image-recognition&gt;&lt;classification&gt;&lt;training&gt;" AnswerCount="1" CommentCount="2" />
	<row Id="8679" PostTypeId="1" CreationDate="2018-10-30T03:32:48.643" Score="0" ViewCount="25" Body="&lt;p&gt;Take training image classification model as an example, when there is limited amount of data, it is not uncommon to augment data by randomly rotating image data but I often see the resulting image is rotated to a degree that part of the area that is normally unseen or out of canvas of image appear black in color. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In practice, the target image to be detected wouldn't look like that. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If these kind of augmented images are introduced to training data,&#xA;would it be any negative impact on the resulting model?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The following picture is an example of the kind of image I am talking about.&#xA;&lt;a href=&quot;https://i.stack.imgur.com/cM689.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/cM689.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="19404" LastActivityDate="2018-10-30T03:32:48.643" Title="Is there any negative impact on classification model if training image data is rotated out of canvas?" Tags="&lt;deep-learning&gt;&lt;image-recognition&gt;&lt;classification&gt;&lt;datasets&gt;" AnswerCount="0" CommentCount="2" />
	<row Id="8759" PostTypeId="1" CreationDate="2018-11-03T14:16:16.313" Score="0" ViewCount="9" Body="&lt;p&gt;Wasn't really sure on which forum to post my question, I thought it fitted well in here, so:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have different versions of some same creature (an old one and a most recent one, actually), and since yesterday I was writting an algorithm which was supposed to guess what color in new one was in the older one.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now that my algorithm is complete, I can affirm it doesn't work, so I came here to see if what I'm trying to do is possible (sure it is, but maybe there already is some tool or algorithm around here I'm simply not aware of) ; I think it might have something to do with &lt;code&gt;pattern recognition&lt;/code&gt;, but I hope not since my couple of images are never the same images with different rgb, usually the movement of the creature ~nearly~ is the same but sometimes it's designed with a different motion.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hope I was clear, here's an example of an &lt;a href=&quot;https://i.stack.imgur.com/scn8f.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;old&lt;/a&gt; image and its corresponding &lt;a href=&quot;https://i.stack.imgur.com/IM87r.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;new&lt;/a&gt; image.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also my algorithm was not really smart, basically it retrieved colors from &lt;code&gt;oldVersionImage&lt;/code&gt; and &lt;code&gt;newVersionImage&lt;/code&gt; and told me which one were corresponding, but sometimes an orange-&gt;red wasn't detected because another matching couple had been detected whereas this last color's couple was matching pretty well but in reality colors were not linked.&lt;/p&gt;&#xA;" OwnerUserId="19551" LastActivityDate="2018-11-03T14:16:16.313" Title="Find links between colors of an old image and its corresponding new image representing the same object" Tags="&lt;image-recognition&gt;&lt;pattern-recognition&gt;" AnswerCount="0" CommentCount="1" />
	<row Id="8846" PostTypeId="1" CreationDate="2018-11-08T05:34:22.210" Score="1" ViewCount="27" Body="&lt;p&gt;There are some fields of Computer Vision that are similar to Artificial Intelligence. For example, pattern recognition and path tracking. Based on these similarities, can we say that the Computer Vision is a part of Artificial Intelligence?&lt;/p&gt;&#xA;" OwnerUserId="19656" LastEditorUserId="1847" LastEditDate="2018-11-08T10:00:00.910" LastActivityDate="2018-11-08T10:00:00.910" Title="Are Computer Vision and Digital Image Processing part of Artificial Intelligence?" Tags="&lt;machine-learning&gt;&lt;image-recognition&gt;&lt;computer-vision&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="9020" PostTypeId="1" CreationDate="2018-11-17T13:57:52.170" Score="0" ViewCount="10" Body="&lt;p&gt;I have 2 new collections of images, for example(just for example) cucumbers and tomatoes. I want to get 3 probabilities. Prob if img is a tomato, cucumbers, and the third prob for any another object. So I want to know if cucumber or tomato on image( and what exactly ), or if there is something else. BUT this is the key, I haven't good collection of the third group - random objects, and I want to use transfer learning and existing trained NN like Res50. How can I add 2 new group in a trained NN? Maybe I should calculate cosine distance between encoded outputs of NN on the last layer before softmax layer?  &lt;/p&gt;&#xA;" OwnerUserId="13067" LastActivityDate="2018-11-17T13:57:52.170" Title="How to add 2 new classes to trained Res50 Net(Keras)" Tags="&lt;convolutional-neural-networks&gt;&lt;image-recognition&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="9030" PostTypeId="1" CreationDate="2018-11-17T19:53:45.473" Score="0" ViewCount="7" Body="&lt;p&gt;Lets say we have a data-set of all cats and we have to identify the cat breed based on given test image. As, the two different cat breeds have visual similarity can we use existing networks (VGG, ImageNet, GoogleNet) to solve this problem?&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Should faceNet be applied here? As, the problem is similar to face detection where face characteristics of two different people are same yet it can correctly recognize a person.&lt;/li&gt;&#xA;&lt;li&gt;What if with visual similarity in data-set we have only few example of each class? Like for a problem (random) we have good amount of data but for each class we have only few examples.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Is there any model that can be applied here?&lt;/p&gt;&#xA;" OwnerUserId="19966" LastActivityDate="2018-11-17T20:32:31.510" Title="Image prediction model when data-set classes have visual similarity" Tags="&lt;neural-networks&gt;&lt;convolutional-neural-networks&gt;&lt;image-recognition&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="9078" PostTypeId="1" CreationDate="2018-11-20T15:46:37.783" Score="0" ViewCount="76" Body="&lt;p&gt;I'm working in a company that opens restaurants in enterprises.&#xA;Every day at lunch, we want our clients to be able to scan their trays, sothat the food is detected automatically thanks to AI / image recognition.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Technically speaking, we have a number of food items that grows over time in our database, but everyday there are about 30 items available at the same time in the restaurant. About 5 items are changing each day (for example, the main dish changes, but the bottle of water is always the same).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This means, when the client go to the till to pay, the client will place the tray by himself, the camera will take photos of the tray and will try to identify different items separetely among the 30 items available this day.&#xA;Clients pay per food article, which means we don't need to track the weight or the quantity in the main dish.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have absolutely no experience in AI/ML and don't know how to start for my need, I'm a web developer.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Which tool should I look at first? &lt;/li&gt;&#xA;&lt;li&gt;Which skill do I need to acquire? I mean, are there easy to use high level libraries , or do I need to learn ML from scratch?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;First I was thinking of Amazon Recognition or Google Vision but It seems to be made for recognizing ANY food item among their own database. My need seems easier since I just need to recognize several items on a tray among 30 known items.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks a lot for your help.&lt;/p&gt;&#xA;" OwnerUserId="20067" LastEditorUserId="1671" LastEditDate="2018-11-20T20:42:39.530" LastActivityDate="2018-11-22T10:39:05.353" Title="Which AI tool for food recognition?" Tags="&lt;machine-learning&gt;&lt;image-recognition&gt;&lt;computer-vision&gt;&lt;software-evaluation&gt;" AnswerCount="1" CommentCount="6" FavoriteCount="2" />
	 <row Id="9163" PostTypeId="1" CreationDate="2018-11-25T22:06:31.570" Score="1" ViewCount="18" Body="&lt;p&gt;for a school project I have been given a dataset containing images of plants and weeds. The goal is to detect when there is a weed in the pictures. The training and validation sets have already been created by our teachers, however they probably didn't have enough images for both so they &quot;photoshopped&quot; some weeds in some of the training pictures.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here are examples of images with the weed label in the training set:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/PSlqn.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/PSlqn.png&quot; alt=&quot;weed label in the training set&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In some cases, the &quot;photoshopped&quot; weed is hard to detect, and no shape resembling a weed is clearly visible like in this picture (weed at the very bottom, near the middle):&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/7GwrR.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/7GwrR.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And here is an example of an image with the weed label in the validation set:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/SSFkA.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/SSFkA.png&quot; alt=&quot;weed label in the validation set&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How would I go about preprocessing the training set so that a CNN trained on it would perform well on the validation set? I was thinking of applying a low-pass filter to the rough edges of the photoshopped images so that the network doesn't act as an edge detector, but it doesn't seem very robust. Should I manually select the best images from the training set? Thank you!&lt;/p&gt;&#xA;" OwnerUserId="20198" LastEditorUserId="20198" LastEditDate="2018-11-25T22:31:09.303" LastActivityDate="2018-11-25T22:31:09.303" Title="How to preprocess a modified dataset so that a fitted CNN makes correct predictions on an un-modified version of the dataset?" Tags="&lt;convolutional-neural-networks&gt;&lt;image-recognition&gt;&lt;datasets&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="2037" PostTypeId="1" AcceptedAnswerId="2044" CreationDate="2016-09-29T14:21:57.723" Score="1" ViewCount="457" Body="&lt;p&gt;I understand how a neural network can be trained to recognise certain features in an image (faces, cars, ...), where the inputs are the image's pixels, and the output is a set of boolean values indicating which objects were recognised in the image and which weren't.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I don't really get is, when using this approach to detect features and we detect a face for example, how we can go back to the original image and determine the location or boundaries of the detected face. How is this achieved? Can this be achieved based on the recognition algorithm, or is a separate algorithm used to locate the face? That seems unlikely since to find the face again, it needs to be recognised in the image, which was the reason of using a NN in the first place.&lt;/p&gt;&#xA;" OwnerUserId="2522" LastActivityDate="2017-08-28T10:41:30.590" Title="When using neural networks to detect features in an image, how can locate that specific feature in the original image?" Tags="&lt;neural-networks&gt;&lt;deep-learning&gt;&lt;convolutional-neural-networks&gt;&lt;computer-vision&gt;" AnswerCount="3" CommentCount="1" />
	<row Id="4671" PostTypeId="1" CreationDate="2017-12-06T09:09:36.967" Score="1" ViewCount="28" Body="&lt;p&gt;I am trying to build a neural network suitable to measure similarity between pairs of images. In particular I am interested in shoes. I have a query image (e.g. a shoe that I just took a picture of) and I want to find similar shoes in a database (several thousands of images).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I tried using MAC feature (e.g. max pool over the entire spacial dimension on last (or some other) convolution layer of say VGG16) (here is a link to a paper &lt;a href=&quot;https://arxiv.org/pdf/1511.05879.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://arxiv.org/pdf/1511.05879.pdf&lt;/a&gt;). The two MAC vectors are compared using cosine similarity. That works, but among the top matches there are always a few very strange shoes (e.g when I submit a query image with a boot I find sandals among other boots with extremely high similarity score).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What would be a better way of doing that? Something more robust to finding shoes similar in shape to the query image. Thanks!&lt;/p&gt;&#xA;" OwnerUserId="11417" LastActivityDate="2017-12-06T09:09:36.967" Title="Similarity of images (CBIR) with CNN features" Tags="&lt;convolutional-neural-networks&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="11" PostTypeId="1" CreationDate="2016-12-07T04:47:00.043" Score="2" ViewCount="87" Body="&lt;p&gt;I am working on a project, wherein I take input from the user as free text and try to relate the text to what the user might mean. I have tried &lt;strong&gt;Stanford NLP&lt;/strong&gt; which tokenizes the text into tokens, but I am not able to categorize the input. For example, the user might be greeting someone or sharing some problem he is facing. In case he is sharing some problem I need to categorize the problem as well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can someone help me with from where should I start?&lt;/p&gt;&#xA;" OwnerUserId="4088" LastEditorUserId="1807" LastEditDate="2016-12-07T17:23:07.330" LastActivityDate="2017-01-12T12:27:07.703" Title="Can I categorise the user input which I get as free text?" Tags="&lt;nlp&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="1494" PostTypeId="1" AcceptedAnswerId="1497" CreationDate="2016-08-09T14:17:50.773" Score="0" ViewCount="161" Body="&lt;p&gt;I would like to know what kind of dataset I need (to prepare) for training the network to recognize the spelling mistakes in individual words for English text.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given the large database of words, having correct one for each incorrect. What kind of input is more efficient for that tasks? Is it using one input per each letter, syllable, whole word or I should use different pattern syllable?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then the input should be incorrect word, output correct, and if the word doesn't need correction, then both input and output should be the same. Is that the right approach?&lt;/p&gt;&#xA;" OwnerUserId="8" LastActivityDate="2016-08-09T20:13:44.400" Title="Training network to detect spelling mistakes" Tags="&lt;deep-learning&gt;&lt;datasets&gt;&lt;language-processing&gt;" AnswerCount="2" CommentCount="3" />
	<row Id="12" PostTypeId="1" CreationDate="2017-02-03T16:14:09.547" Score="4" ViewCount="176" Body="&lt;p&gt;I am researching Natural Language Processing (NLP) to develop a NL Question Answering. Answering part is already developed. So question remains, along with the questions regarding the algorithms.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Final product should be able to: - User can ask a question in NL - Question gets translated to a MDX query, which generates a script regarding dimensions of the cube.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How can I translate a Natural Language Question to a MDX query? Outcome of question results in answer of a calculation. E.g. ‘ How many declarations were done by employee1?’ or ‘Give me the quantities for Sales’&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks in advance!&lt;/p&gt;&#xA;" OwnerUserId="5219" LastActivityDate="2017-02-04T14:58:45.733" Title="How can I convert an input Natural Language QA to a MDX q" Tags="&lt;nlp&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="2" />
	<row Id="13" PostTypeId="1" CreationDate="2017-04-05T18:32:59.777" Score="2" ViewCount="64" Body="&lt;p&gt;I was just curious if there are any particular studies or projects done with NLP in the last 5 or so years (breakthroughs in parsing, sentiment analysis, discourse analysis, speech recognition) that you guys think are specifically influential. I'm looking at the history of NLP (and by extension, machine learning) and starting in the 1950s with the Georgetown–IBM experiment. If anyone has any relevant recommendations, they'd be appreciated.&lt;/p&gt;&#xA;" OwnerUserId="6477" LastActivityDate="2017-04-05T18:32:59.777" Title="Recommendations for research: Influential NLP projects of the last 5 years" Tags="&lt;machine-learning&gt;&lt;research&gt;&lt;natural-language&gt;&lt;nlp&gt;" AnswerCount="0" CommentCount="2" FavoriteCount="1" />
	<row Id="14" PostTypeId="1" CreationDate="2017-12-16T18:51:09.517" Score="3" ViewCount="246" Body="&lt;p&gt;Capsule Networks seem to be a good solution for problems, which make up hierarchical complexity ( ( (eyes, nose, ears -&gt; face); (fingers, nails, palm -&gt; hand) ) -&gt; human). NLP domain is a very clear hierarchical complexity problem, because there are words, sentences, paragraphs and chapters, whose meaning change based on the style of lower levels.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there any research papers or software tools on Capsule Networks and NLP, which I should be aware of? Is there related research papers, which have been investigating hierarchical complexity within the domain of NLP, which could be easily translated to Capsule Network?&lt;/p&gt;&#xA;" OwnerUserId="11626" LastEditorUserId="11626" LastEditDate="2017-12-18T11:52:47.350" LastActivityDate="2018-01-19T18:15:08.177" Title="Has Capsule Networks or similar systems been used for NLP?" Tags="&lt;neural-networks&gt;&lt;nlp&gt;" AnswerCount="1" CommentCount="3" FavoriteCount="2" />
	<row Id="15" PostTypeId="1" AcceptedAnswerId="1345" CreationDate="2016-08-03T09:01:05.790" Score="14" ViewCount="176" Body="&lt;p&gt;Identifying sarcasm is considered as one of the most difficult open-ended problems in the domain of ML and NLP.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, was there any considerable research done in that front? If yes, then what is the accuracy like? Please also explain the NLP model briefly.&lt;/p&gt;&#xA;" OwnerUserId="101" LastActivityDate="2016-08-05T04:52:42.947" Title="What research has been done in the domain of &quot;Identifying sarcasm in text&quot;?" Tags="&lt;natural-language&gt;&lt;research&gt;" AnswerCount="2" CommentCount="2" FavoriteCount="5" />
	<row Id="16" PostTypeId="1" CreationDate="2016-08-03T10:14:49.743" Score="4" ViewCount="53" Body="&lt;p&gt;Text summarization is a long-standing research problem that was &lt;em&gt;&quot;ignited&quot;&lt;/em&gt; by Luhn in 1958. However, a half century later, we still came nowhere close  to solving this problem (abstractive summarization). The reason for this might be because researchers are resorting to statistical (and sometimes linguistic) methods to find &amp;amp; extract the most salient parts of the text.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is summarization problem solvable using AI (neural networks to be precise)? &lt;/p&gt;&#xA;" OwnerDisplayName="user220" LastEditorDisplayName="user220" LastEditDate="2016-08-04T06:13:13.763" LastActivityDate="2018-01-05T03:55:00.837" Title="Can abstractive summarization be achieved using neural networks?" Tags="&lt;neural-networks&gt;&lt;natural-language&gt;&lt;text-summarization&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="17" PostTypeId="1" CreationDate="2016-11-11T23:04:19.753" Score="9" ViewCount="365" Body="&lt;p&gt;In programming languages, there is a set of grammar rules which govern the construction of valid statements and expressions. These rules help in parsing the programs written by the user.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can there ever be a functionally complete set of grammar rules which can parse any statement in English (locale-specific) &lt;strong&gt;accurately&lt;/strong&gt; and which can be possibly implemented for use in AI-based projects?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know that there are a lot of NLP Toolkits available online, but they are not that effective. Most of them are trained using specific corpuses which sometimes fail to infer some complex correlations between various parts of an expression.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In other words, what I am asking is that if it is possible for a computer to parse a well-versed sentence written in English as if it were parsed by an adult English-speaking human?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT:&#xA;If it cannot be represented using simple grammar rules, what kind of semantic structure can be used to generalize it?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT2: This &lt;a href=&quot;https://www.eecs.harvard.edu/shieber/Biblio/Papers/shieber85.pdf&quot; rel=&quot;noreferrer&quot;&gt;paper&lt;/a&gt; proves the absence of context-freeness in natural languages. I am looking for a solution, even if it is too complex.&lt;/p&gt;&#xA;" OwnerUserId="3592" LastEditorUserId="3592" LastEditDate="2016-11-16T19:24:23.503" LastActivityDate="2017-01-16T14:20:16.013" Title="Can the English language ever be generalized using a set of grammar rules?" Tags="&lt;ai-design&gt;&lt;natural-language&gt;&lt;nlp&gt;&lt;language-processing&gt;" AnswerCount="4" CommentCount="2" FavoriteCount="1" />
	<row Id="18" PostTypeId="1" CreationDate="2017-04-05T18:32:59.777" Score="2" ViewCount="64" Body="&lt;p&gt;I was just curious if there are any particular studies or projects done with NLP in the last 5 or so years (breakthroughs in parsing, sentiment analysis, discourse analysis, speech recognition) that you guys think are specifically influential. I'm looking at the history of NLP (and by extension, machine learning) and starting in the 1950s with the Georgetown–IBM experiment. If anyone has any relevant recommendations, they'd be appreciated.&lt;/p&gt;&#xA;" OwnerUserId="6477" LastActivityDate="2017-04-05T18:32:59.777" Title="Recommendations for research: Influential NLP projects of the last 5 years" Tags="&lt;machine-learning&gt;&lt;research&gt;&lt;natural-language&gt;&lt;nlp&gt;" AnswerCount="0" CommentCount="2" FavoriteCount="1" />
	<row Id="19" PostTypeId="1" CreationDate="2017-04-06T06:52:45.150" Score="10" ViewCount="240" Body="&lt;p&gt;It seems that most projects attempt to teach the AI to learn individual, specific languages.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It occurs to me that there are relations in written and spoken words and phrases across languages - most of use have a much easier time learning more languages after we learn a second language, and we start to understand the relations between words and phrases in different languages.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Has anyone attempt to train an AI to learn &lt;em&gt;all&lt;/em&gt; languages?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Wouldn't this potentially be a much simpler problem than trying to teach an AI a single, specific language with all of the specifics and details of that single language? Since you're actually omitting a lot of related data in other languages from the training set?&lt;/p&gt;&#xA;" OwnerUserId="6485" LastActivityDate="2017-04-06T08:48:55.790" Title="Has anyone attempted to train an AI to learn all languages?" Tags="&lt;natural-language&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="2" />
	<row Id="20" PostTypeId="1" CreationDate="2017-07-22T08:24:30.650" Score="1" ViewCount="57" Body="&lt;p&gt;I want to produce a bot in Python that automatically generates short football summaries from Whoscored data. For my first stage I generate the articles with different sentence templates and lots of rules where the data is used.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now I want to move to the next stage and start looking into NLP and more advanced NLG. I already scraped numerous articles to create a corpus. How should I move on and do next? Any advice would be much appreciated as I'm new in this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks!&lt;/p&gt;&#xA;" OwnerUserId="8601" LastActivityDate="2017-07-22T08:24:30.650" Title="Advanced NLG - robot journalist" Tags="&lt;machine-learning&gt;&lt;natural-language&gt;" AnswerCount="0" CommentCount="0" FavoriteCount="1" />
	<row Id="21" PostTypeId="1" AcceptedAnswerId="5273" CreationDate="2018-02-10T03:28:13.393" Score="1" ViewCount="54" Body="&lt;p&gt;I'm wondering if these 2 specific programs already exist and if not how hard would it be to write them:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;A program that would figure out (by only &quot;reading&quot; large amounts of texts in human language 1 and 2) which words in second language have the same meaning as a word in first language.  You would give for input texts in both languages and for output you would get for every word in first language a list of words in second language that are most similar to it with a probability that they mean the same thing. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;A program that would figure out which words have the most similar meaning by analyzing large amounts of texts in one human language.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;I'm planning on writing these two programs and it would be nice if I could get existing programs that do this so that I could compare results of my program to those of existing programs.&lt;/p&gt;&#xA;" OwnerUserId="12251" LastActivityDate="2018-02-11T02:47:14.710" Title="Existing programs that find out words with same meanings" Tags="&lt;machine-learning&gt;&lt;natural-language&gt;&lt;nlp&gt;" AnswerCount="2" CommentCount="5" />
	<row Id="5353" PostTypeId="1" CreationDate="2018-02-17T11:08:12.603" Score="1" ViewCount="100" Body="&lt;p&gt;The more I think about machine learning the more I realize the importance of finding similarities by using analogies as a way of learning.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If I want to categorize words into hierarchical tree this method would work I think, if not tell me why?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Find two sentences that contain same words but their order is different and some words can also be different.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Find another two such sentences.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Evaluate strength of analogy between these 4 sentences.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The stronger it is the more probability that words mean similar thing, that they belong to same category. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;When you learn categories you can do analogies on abstract sentences that contain these found categories and in this manner you can build hierarchy of categories.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Deer eats grass.&#xA;...is to...&#xA;Man eats deer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;as &#xA;Cow eats grass&#xA;is to&#xA;?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If we can find sentence Man eats cow.&#xA;being used in texts that we analyze then we have confirmed that cow and deer belong to category&#xA;Animals that eat grass and that human eats them.&lt;/p&gt;&#xA;" OwnerUserId="12251" LastEditorUserId="1671" LastEditDate="2018-02-18T21:42:43.747" LastActivityDate="2018-02-18T21:42:43.747" Title="Analogies and similarity" Tags="&lt;machine-learning&gt;&lt;natural-language-processing&gt;&lt;theory&gt;&lt;computational-linguistics&gt;" AnswerCount="0" CommentCount="4" FavoriteCount="2" />
	<row Id="5392" PostTypeId="1" AcceptedAnswerId="5406" CreationDate="2018-02-22T08:08:59.070" Score="4" ViewCount="58" Body="&lt;p&gt;I am absolutely new in AI area.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like to know how to mathematically/logically represent the &lt;strong&gt;sense&lt;/strong&gt; of sentences like:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;The cat drinks milk.&#xA;&#xA;Sun is yellow.&#xA;&#xA;I was at work yesterday.&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;So that it could be converted to computer understandable form and analysed algorithmically.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any clue?&lt;/p&gt;&#xA;" OwnerUserId="12907" LastEditorUserId="9947" LastEditDate="2018-02-22T22:06:50.683" LastActivityDate="2018-02-23T15:37:27.007" Title="Represent sense/meaning of sentences mathematically" Tags="&lt;natural-language-processing&gt;&lt;sentience&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="1" />
	<row Id="5517" PostTypeId="1" CreationDate="2018-03-04T22:39:31.653" Score="3" ViewCount="165" Body="&lt;p&gt;I am seeking the information for this kind of chatbot architecture : There are two chatbots. One plays the role of teacher, and another is a student who is learning. The goal is to test the student's quality, and to improve the student's ability.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I didn't find much reference. There are :&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://Bottester:%20Testing%20Conversational%20Systems%20with%20Simulated%20Users&quot; rel=&quot;nofollow noreferrer&quot;&gt;Bottester: Testing Conversational Systems with Simulated Users&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And the &lt;a href=&quot;http://parl.ai/static/docs/basic_tutorial.html#&quot; rel=&quot;nofollow noreferrer&quot;&gt;ParlAI&lt;/a&gt;, a python-based platform for enabling dialog AI research has the notion of &quot;Teacher agent&quot;, which seems to be what I am looking for.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Of course, we also have deep reinforcement learning which might be related.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I prefer to have some classical references for this approach to chatbots.&#xA;Currently, reinforcement learning is not in my consideration.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Constructing two chatbots talking to each other, like what Facebook did, is not what I want. Because in this case, both of them are student agents.&lt;/p&gt;&#xA;" OwnerUserId="13118" LastActivityDate="2018-05-17T07:25:12.400" Title="Two chatbots - One teaches another" Tags="&lt;natural-language-processing&gt;&lt;chat-bots&gt;" AnswerCount="2" CommentCount="3" FavoriteCount="2" />
	<row Id="5536" PostTypeId="1" AcceptedAnswerId="7554" CreationDate="2018-03-06T10:35:34.890" Score="3" ViewCount="253" Body="&lt;p&gt;I'm training Seq2Seq model on OpenSubtitles dialogs - &lt;a href=&quot;http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;Cornell-Movie-Dialogs-Corpus&lt;/a&gt;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My work based on the following papers (but currently I'm not implemented Attention yet):&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1409.3215&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;em&gt;Sequence to Sequence Learning with Neural Networks, Sutskever et al. 2014&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1506.05869&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;em&gt;A Neural Conversational Model, Vinyals, Le, 2015&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The &lt;code&gt;loss&lt;/code&gt; I received is quite high and sucked in variation &lt;code&gt;~6.4&lt;/code&gt; after 3 epoches. The model predicts the most common words with some times other not significant words (but 99.99% is just 'you'):&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I’ve experimented with 128 - 2048 hidden units and with 1 or 2 or 3 LSTM layers per &lt;code&gt;encoder&lt;/code&gt; and &lt;code&gt;decoder&lt;/code&gt;. The outcomes are more or less the same.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;SEQ1: yeah man it means love respect community and the dollars too the package the unk end&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;SEQ2: but how did you get unk 82 end&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;PREDICTION: promoting 16th dashboard be of the the the you you you you you you you you you you you you you you you you you you you you you you you you&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I'm using here &lt;code&gt;greedy&lt;/code&gt; prediction, meaning - after I receive &lt;code&gt;logit&lt;/code&gt; I do &lt;code&gt;argmax(..)&lt;/code&gt; on all its value for first-3 mini-batch-elements (here I present only first element). For convenient - &lt;code&gt;SEQ1&lt;/code&gt; and &lt;code&gt;SEQ2&lt;/code&gt; are also printed - to know the actual dialog which was presented to the model.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The pseudo-code of my architecture looks like this (I'm using Tensorflow 1.5):&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;seq1 = tf.placeholder(...)&#xA;seq2 = tf.placeholder(...)&#xA;&#xA;embeddings = tf.Variable(tf.random_uniform([vocab_size, 100],-1,1))&#xA;&#xA;seq1_emb = tf.nn.embedding_lookup(embeddings, seq1)&#xA;seq2_emb = tf.nn.embedding_lookup(embeddings, seq1)&#xA;&#xA;encoder_out, state1 = tf.nn.static_rnn(BasicLSTMCell(), seq1_emb)&#xA;decoder_out, state2 = tf.nn.static_rnn(BasicLSTMCell(), seq2_emb,&#xA;                                                        initial_state=state_1)&#xA;logit = Dense(decoder_out, use_bias=False)&#xA;&#xA;crossent = tf.nn.saparse_softmax_cross_entropy_with_logits(logits=logit, &#xA;                                                         labels=target)&#xA;crossent = mask_padded_zeros(crossent)&#xA;loss = tf.reduce_sum(crossent) / number_of_words_in_batch&#xA;&#xA;train = tf.train.AdamOptimizer(learning_rate=0.00002).minimize(loss) &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I'm also wonder if I pass well &lt;code&gt;state1&lt;/code&gt; to &lt;code&gt;decoder&lt;/code&gt;, which in general looks like this:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;# reshape in pseudocode: state1 = state[1:]&#xA;new_state1 = []&#xA;for lstm in state1:&#xA;    new_lstm = []&#xA;    for gate in lstm:&#xA;        new_lstm.append(gate[1:])&#xA;    new_state1.append(tuple(new_lstm))&#xA;state1 = tuple(new_state1)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Should I use some projection layer between states of &lt;code&gt;encoder&lt;/code&gt; and &lt;code&gt;decoder&lt;/code&gt; ?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;So if &lt;code&gt;seq1&lt;/code&gt; has 32 words, &lt;code&gt;seq2&lt;/code&gt; has 31 (since we will not predict nothing after the last word, which is the tag &lt;code&gt;&amp;lt;END&amp;gt;&lt;/code&gt;).&lt;/p&gt;&#xA;" OwnerUserId="12691" LastEditorUserId="4302" LastEditDate="2018-10-08T12:15:27.360" LastActivityDate="2018-10-08T12:15:27.360" Title="Seq2Seq dialogs predicts only most common words like `you` after couple of epoches" Tags="&lt;neural-networks&gt;&lt;natural-language-processing&gt;&lt;tensorflow&gt;&lt;recurrent-neural-networks&gt;&lt;lstm&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="1" />
	<row Id="5652" PostTypeId="1" CreationDate="2018-03-12T18:50:49.307" Score="2" ViewCount="62" Body="&lt;p&gt;I'm new to AI development and am looking for a quality algorithm (potentially nlp?) implementation proved against US legal texts.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Obviously some training would need to be done, but I've found little to no online references to go on when it comes to running assessment against US legal documents.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My goal is to use an algorithm to discover potential issues in long and complex legal texts, or associated (groups) of legal texts which bind one or more related entities (people or corporations) to potentially conflicting clauses.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Just a pointer in some kind of direction would be helpful.&lt;/p&gt;&#xA;" OwnerUserId="13043" LastActivityDate="2018-03-12T18:50:49.307" Title="NLP proved against US legal texts" Tags="&lt;neural-networks&gt;&lt;ai-design&gt;&lt;natural-language-processing&gt;&lt;legal&gt;" AnswerCount="0" CommentCount="4" FavoriteCount="1" />
	<row Id="5727" PostTypeId="1" CreationDate="2018-03-18T08:37:24.300" Score="0" ViewCount="29" Body="&lt;p&gt;When you read a big book, I think humans constantly summarize or model the content of the book to the point where they have read and understand the upcoming text with that summarization as a context. Also, it is not feasible/effective to understand a line in the book, the true meaning of which can only be understood based on what was mentioned in the book 100 pages earlier, except if you summarize and feedback that information in an LSTM or some other recurrent neural network.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Has anyone tried this approach in mainstream NLP research before?&lt;/p&gt;&#xA;" OwnerUserId="3015" LastEditorUserId="9947" LastEditDate="2018-03-19T20:22:08.410" LastActivityDate="2018-03-19T20:22:08.410" Title="Did anyone model NLP system on top of text summarization problem?" Tags="&lt;natural-language-processing&gt;&lt;text-summarization&gt;" AnswerCount="0" CommentCount="1" />
	<row Id="5874" PostTypeId="1" CreationDate="2018-04-03T16:33:54.950" Score="5" ViewCount="96" Body="&lt;p&gt;Can we define the feeling of the human through conversations with an AI? Something like a &quot;confessional,&quot; disregarding human possibilities to lie.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Below, I have the categories joyful, sadness, anger, fear and affection. For each category, there are several words that can be in the texts that refer to it.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Joy:&lt;/strong&gt; &lt;strong&gt;(&lt;/strong&gt; cheerful, happy, confident, happy, satisfied, excited, interested, dazzled, optimistic, relieved, euphoric, drunk, witty, good &lt;strong&gt;)&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Sadness:&lt;/strong&gt; &lt;strong&gt;(&lt;/strong&gt; sad, desperate, displeased, depressed, bored, lonely, hurt, desolate, meditative, defrauded, withdrawn, pitying, concentrated, depressed, melancholic, nostalgic &lt;strong&gt;)&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Anger:&lt;/strong&gt; &lt;strong&gt;(&lt;/strong&gt; aggressive, critical, angry, hysterical, envious, grumpy, disappointed, shocked, exasperated, frustrated, arrogant, jealous, agonized, hostile, vengeful &lt;strong&gt;)&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Fear:&lt;/strong&gt; &lt;strong&gt;(&lt;/strong&gt; shy, frightened, fearful, horrified, suspicious, disbelieving, embarrassed, embarrassed, shaken, surprised, guilty, anxious, cautious, indecisive, embarrassed, modest &lt;strong&gt;)&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Affection:&lt;/strong&gt; &lt;strong&gt;(&lt;/strong&gt; loving, passionate, supportive, malicious, dazzled, glazed, homesick, embarrassed, indifferent, curious, tender, moved, hopeful &lt;strong&gt;)&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Flow Example&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Phrase 1:&lt;/strong&gt; &quot;I'm very happy! It concludes college.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Categorization 1:&lt;/strong&gt;&#xA; - Joy &lt;strong&gt;(+1)&lt;/strong&gt;&#xA; - Sadness &lt;strong&gt;(-1)&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Phrase 2:&lt;/strong&gt; &quot;I'm sad, my mother passed away.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Categorization 2:&lt;/strong&gt;&#xA; - Sadness &lt;strong&gt;(+1)&lt;/strong&gt;&#xA; - Joy &lt;strong&gt;(-1)&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Phrase 3:&lt;/strong&gt; &quot;I met a girl, but I was ashamed.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Categorization 3:&lt;/strong&gt;&#xA; - Fear &lt;strong&gt;(+1)&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this a clever way to follow and / or improve, or am I completely out of the way?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I see that there is a Google product that creates parsing according to the phrases. I do not know how it works, because I like to recreate the way I think it would work.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Remembering that this would not be the only way to categorize the phrase. This would be the first phase of the analysis. I can also identify the subject of the sentence, so we would know if the sadness is from the creator of the message or from a third party, in most cases.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.nltk.org/book/ch08.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;NLTK&lt;/a&gt; &lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://github.com/text-machine-lab/sentimental&quot; rel=&quot;nofollow noreferrer&quot;&gt;Sentiment Analysis Python Example&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="7800" LastEditorUserId="7800" LastEditDate="2018-04-05T18:53:30.830" LastActivityDate="2018-04-18T09:38:43.747" Title="Sentiment Analysis" Tags="&lt;natural-language-processing&gt;&lt;sentiment-analysis&gt;" AnswerCount="3" CommentCount="7" FavoriteCount="3" />
	<row Id="6143" PostTypeId="1" CreationDate="2018-04-23T18:36:23.620" Score="0" ViewCount="131" Body="&lt;p&gt;The choice of the number of embedding dimensions (N) seems to generally be determined empirically (i.e. trial-and-error) for a given corpus and use case. Typical ranges used seem to be anywhere from 50-1000.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there any more rigorous way to select a near-optimal N than simply executing and evaluating over a series of possible choices for N? I'm thinking specifically of some heuristic that takes into account some measurable aspects of corpus or use case.&lt;/p&gt;&#xA;" OwnerUserId="13360" LastActivityDate="2018-04-23T18:36:23.620" Title="Optimizing the number of embedding dimensions for word2vec" Tags="&lt;natural-language-processing&gt;&lt;word2vec&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="6144" PostTypeId="1" CreationDate="2018-04-23T18:58:09.750" Score="2" ViewCount="29" Body="&lt;p&gt;Word2vec assigns an N-dimensional vector (a dimensional reduction, really) to given words. It turns out that, at least with a number of canonical examples, vector arithmetic seems to work intuitively. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;king + woman - man = queen&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;These terms are all N-dimensional vectors. So, what we really might have (numbers made up and N=3 here) is:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;king(0,1,2) + woman(1,1,0) - man(2,2,2) = queen(-1,0,0)&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this (contrived) example, the last dimension (king/man=2, queen/woman=0) suggests a semantic concept of gender. Aside from semantics, a given dimension could &quot;mean&quot; a part of speech, first letter, or really any feature or set of features that the algorithm might have latched onto. However, any perceived &quot;meaning&quot; of a single dimension might well just be a  simple coincidence.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The question: if we picked out only a single dimension, does that dimension itself convey some predictable or determinable information? Or is this purely a &quot;random&quot; artifact of the algorithm, with only the full N-dimensional vector distances mattering?&lt;/p&gt;&#xA;" OwnerUserId="13360" LastActivityDate="2018-04-24T04:13:45.413" Title="Do individual dimensions in vector space have meaning?" Tags="&lt;natural-language-processing&gt;&lt;wordvector&gt;&lt;word2vec&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="6216" PostTypeId="1" AcceptedAnswerId="6221" CreationDate="2018-04-30T23:58:24.823" Score="1" ViewCount="49" Body="&lt;p&gt;I have an approximately 90,000 row dataset that has information of social media profiles which has columns for biography, follower count, language spoken, name, username and the &lt;strong&gt;label (to identify whether the profile is that of an influencer, brand or news and media)&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Task: I have to train a model that predicts the label. I then need to produce a confidence interval for each prediction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As I have never come across a problem like this, I am just after some suggestions of what models I should be using for a situation like this? I am thinking Natural Language Processing (NLP), but not sure. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, for NLP (if a suitable method), any codes or advice to help me implement for the first time on Python would be greatly appreciated! Thanks in advanced&lt;/p&gt;&#xA;" OwnerUserId="15011" LastEditorUserId="4302" LastEditDate="2018-10-08T12:11:41.813" LastActivityDate="2018-10-08T12:11:41.813" Title="Recommended Modelling Technique for Influencer Marketing Scenario" Tags="&lt;training&gt;&lt;natural-language-processing&gt;&lt;sentiment-analysis&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="1" />
	<row Id="6216" PostTypeId="1" AcceptedAnswerId="6221" CreationDate="2018-04-30T23:58:24.823" Score="1" ViewCount="49" Body="&lt;p&gt;I have an approximately 90,000 row dataset that has information of social media profiles which has columns for biography, follower count, language spoken, name, username and the &lt;strong&gt;label (to identify whether the profile is that of an influencer, brand or news and media)&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Task: I have to train a model that predicts the label. I then need to produce a confidence interval for each prediction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As I have never come across a problem like this, I am just after some suggestions of what models I should be using for a situation like this? I am thinking Natural Language Processing (NLP), but not sure. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, for NLP (if a suitable method), any codes or advice to help me implement for the first time on Python would be greatly appreciated! Thanks in advanced&lt;/p&gt;&#xA;" OwnerUserId="15011" LastEditorUserId="4302" LastEditDate="2018-10-08T12:11:41.813" LastActivityDate="2018-10-08T12:11:41.813" Title="Recommended Modelling Technique for Influencer Marketing Scenario" Tags="&lt;training&gt;&lt;natural-language-processing&gt;&lt;sentiment-analysis&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="1" />
	<row Id="6414" PostTypeId="1" AcceptedAnswerId="6458" CreationDate="2018-05-14T20:43:22.980" Score="1" ViewCount="34" Body="&lt;p&gt;I am looking to extract the central theme of news headline using NLP/ Text-mining, any references in this direction is of great help.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example: Inputs:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;BRIEF-Dynasil Corporation Of America Reports Q2 EPS Of $0.08&lt;/p&gt;&#xA;&#xA;&lt;p&gt;China's night-owl retail investors leverage up to dominate oil futures trade&lt;/p&gt;&#xA;&#xA;&lt;p&gt;outputs:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Reports&lt;/p&gt;&#xA;&#xA;&lt;p&gt;oil futures&lt;/p&gt;&#xA;" OwnerUserId="15638" LastActivityDate="2018-05-18T15:32:39.787" Title="Are there any references of nlp/text mining techniques for Identifying the theme of News headlines" Tags="&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;natural-language-processing&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="1" />
	<row Id="6524" PostTypeId="1" AcceptedAnswerId="6566" CreationDate="2018-05-27T15:47:36.650" Score="2" ViewCount="79" Body="&lt;p&gt;I have to read a lot of papers, and I thought that I can use an A.I. to read them and summarize them. Maybe find one that can understand what the papers are talking about it seems a lot to ask.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think I can use natural language processing. Is it the right choice?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm sorry, but I'm new in A.I. and I don't know much about it.&lt;/p&gt;&#xA;" OwnerUserId="4920" LastEditorUserId="4302" LastEditDate="2018-10-08T11:56:59.767" LastActivityDate="2018-10-08T11:56:59.767" Title="How can I build an AI with NLP that reads and understands documents?" Tags="&lt;natural-language-processing&gt;" AnswerCount="1" CommentCount="4" />
	<row Id="6527" PostTypeId="1" AcceptedAnswerId="6569" CreationDate="2018-05-27T16:33:37.543" Score="2" ViewCount="184" Body="&lt;p&gt;There are many books, courses, etc. out there, but not sure which path to take. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So what would be the most effective way (shortest) to learn natural language processing online?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;p.s. I mean learning fundamentals, not how to use existing libraries or services.&lt;/p&gt;&#xA;" OwnerUserId="15902" LastActivityDate="2018-05-30T08:02:41.030" Title="What is the most effective way to learn natural language processing online?" Tags="&lt;neural-networks&gt;&lt;natural-language-processing&gt;" AnswerCount="2" CommentCount="2" FavoriteCount="3" />
	<row Id="6662" PostTypeId="1" CreationDate="2018-06-05T15:21:05.840" Score="3" ViewCount="52" Body="&lt;p&gt;I know some people will try to crucify me for asking such question here, since it's too generic, but ill give it a shot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So basically what I'm after in trying to find if there any tools exist (simply white papers are welcome too) for creating chatbots based on a plain text corpus, so that questions could be asked about it. That is, there is some textual data (like articles), but there are no question, answer pairs to train a conventional model with, like seq2seq. I understand that there are ways to achieve this by using tools to extract intents,entities from a question and match it with paragraphs, articles (based on indexes and topics), but to my understanding this creates more of a NLP search bot, rather than a chatbot, which provides answers in conversation-like manner.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks in advance.&lt;/p&gt;&#xA;" OwnerUserId="16074" LastActivityDate="2018-11-01T11:00:27.617" Title="What existing tools are out there for creating chatbots from a plain text corpus and without having question, answer pairs?" Tags="&lt;machine-learning&gt;&lt;natural-language-processing&gt;&lt;chat-bots&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="6672" PostTypeId="1" CreationDate="2018-06-06T07:53:29.787" Score="2" ViewCount="50" Body="&lt;p&gt;I am working on a task where I am required to automate the customer service request channel. The process is quite typical. A customer queries about a product via email, the person on the front channel checks emails, forwards it to the relevant department and then answer is provided.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem is that customer query can be about one of hundreds of devices listed. Each device has its own pdf documentation which is quite extensive. Finding the right pdf and then finding the right section where information could be listed is really a tedious process and wastes a lot of time. Sometimes the information is not even listed and answer has to be improvised by product specialist (the last part hints me about reinforcement learning, what do you guys think).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I want to achieve is that this whole tedious and repetitive process is automated and may be if possible, the model learns over time as well. The task output is quite open ended as well. Different approaches and models can be tried out (like chatbots and etc). Rapid failure is highly appreciated here.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Below mentioned are some more details:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Database:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I have customers queries about devices in the form of emails.&lt;/li&gt;&#xA;&lt;li&gt;PDF documentation of devices. The documentations are quite extensive.&lt;/li&gt;&#xA;&lt;li&gt;I also happen to have some excel files where some sample queries and sample answers are listed. But since queries can be of very dynamic nature, it doesn't seem like a classification problem (to me at least).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I have googled quite a lot about the topic but mostly what I get are topics like 'How AI will transform the customer service' and then something more specific to NLP and a lot of company ads etc. So far what I have understood from online surfing is that possible approaches need to use NLP library (Nltk) in Python and do some topic modelling for documentation and for email. Still how I approach the whole task is not clear to me. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I want from you guys is that maybe guide me how this task can be achieved step by step. I am not looking for any code! Just which methods can be used and how the problem can be approached. Right now, I don't know where to start and how to approach it.&lt;/p&gt;&#xA;" OwnerUserId="16093" LastEditorUserId="9947" LastEditDate="2018-09-05T12:55:20.553" LastActivityDate="2018-09-05T17:20:03.403" Title="Implementing AI/ML in customer service" Tags="&lt;neural-networks&gt;&lt;machine-learning&gt;&lt;reinforcement-learning&gt;&lt;natural-language-processing&gt;&lt;python&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="6965" PostTypeId="1" CreationDate="2018-06-30T17:37:49.283" Score="2" ViewCount="131" Body="&lt;p&gt;My question is that is there any general idea on how humans solve jumbled words? I know many people will say we match it against a commonly used words checklist mentally, but it is kind of vague. Is there any theory on this and how might an AI learn to do the same?&lt;/p&gt;&#xA;" OwnerUserId="9947" LastActivityDate="2018-06-30T18:23:40.640" Title="Can AI solve jumbled words?" Tags="&lt;natural-language-processing&gt;&lt;world-knowledge&gt;" AnswerCount="1" CommentCount="3" />
	<row Id="7144" PostTypeId="1" CreationDate="2018-07-13T18:17:09.933" Score="2" ViewCount="32" Body="&lt;p&gt;I'm looking to write an AI that will be able to extract in text references from standards documents to assist human research.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My use case is extracting the identifying numbers, for example, &quot;AR 25-2&quot;, along with the title of the document &quot;Information Assurance&quot; so that a human can gather all the related research on a contract at once, instead of having to keep track of references while they're reading through the document.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have a pretty good idea of where to gather the names of these documents for training, I'm planning on 'scraping' a few repositories for different categories of these documents. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What kind of model should I use to get the best results?&lt;/p&gt;&#xA;" OwnerUserId="16853" LastEditorUserId="4302" LastEditDate="2018-10-08T12:47:11.887" LastActivityDate="2018-10-08T12:47:11.887" Title="Extracting referenced documents" Tags="&lt;natural-language-processing&gt;&lt;automation&gt;" AnswerCount="0" CommentCount="3" />
	<row Id="7217" PostTypeId="1" CreationDate="2018-07-20T10:19:25.900" Score="1" ViewCount="22" Body="&lt;p&gt;This is actually something I have been researching a bit on my own.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Most movie scripts can be structurally analysed by using writing theory such as &lt;a href=&quot;http://dramatica.com/theory/book/theme&quot; rel=&quot;nofollow noreferrer&quot;&gt;Dramatica&lt;/a&gt;. Dramatica is based upon hierarchy of concepts, which can be topic modeled. The hierarchy of topic models would seem to work very well with the Dynamic Routing algorithm of Capsule Networks.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have been working with computational creativity problems in narrative generation. The state of the art methods use Partial Order Causal Link Planners, but they depend on propositional logic. Alonzo Church presented the &lt;a href=&quot;https://en.wikipedia.org/wiki/Extensional_context&quot; rel=&quot;nofollow noreferrer&quot;&gt;Superman dilemma&lt;/a&gt; (Louis Lane does not know that Clark Kent is Superman, but Superman knows, that he is Clark Kent) and invented Intensional Logic as a solution; the basic idea is, that if we do not know the context of the narrative, the meaning is always in superposition and can only be understood through entangled meanings from the background story. So in a sense propositional logic is limited by classic information theory constraints, while Church's logic can take a quantum information theoretic approach. I do not believe that classic information theory can resolve narrative analysis problems. So basicly the meaning of a narrative collapses (the superposition gets resolved) by using the hierarchical narrative structure and what we know before hand.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So my intuition would be following:&#xA;-We can use Dramatica and potentially other narrative theories (hierarchical metamemetics, reverse SCARF etc.) to create a hierarchical network like ImageNet, but for narratives.&#xA;-We can build conceptual topic models. Dramatica has hierarchy of 4-16-64-64 concepts and annotated data exists already.&#xA;-When using hundreds of topic models, there will be a lot of false positives. However, the superposition of the topic models can be collapsed by using the hierarchical levels and some other dramatic analytics.&#xA;-By using the Dynamic Routing of Capsule Networks, we might be able to build a system, which could determine a narrative interpretation of the full story, which would make most sense by using the concept hierarchy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I tried to prove my intuition, but unfortunately Dramatica only has 300 movies analysed and I was able to find scripts of only 10 of them; not enough data.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, there are other hierarchical ontologies out there and other narrative structures; could the same intuition be used for political news for example?&lt;/p&gt;&#xA;" OwnerUserId="11626" LastActivityDate="2018-07-20T10:19:25.900" Title="Would Capsule Neworks and Topic Modeling used together make sense?" Tags="&lt;natural-language-processing&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="7235" PostTypeId="1" CreationDate="2018-07-21T09:02:49.037" Score="1" ViewCount="57" Body="&lt;p&gt;I am learning AI and trying out my first real life AI application.&#xA;What I am trying to do is taking as an input various sentences, and then classifying the sentences into one of X number of categories based on keywords, and 'action' in the sentence. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The keywords are, for example, Merger, Acquisition, Award, product launch etc. so in essence I am trying to detect if the sentence in question talks about a merger between two organizations, or an acquisition by an organisation, a person or a organization winning an award, or launching of a new product etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To do this, I have made custom models based on the basic NLTK package model, for each keyword, and trying to improve the classification by dynamically tagging/updating the models with related keywords, synonyms etc to improve the detection capability. Also, given a set of sentences, I am presenting the user with the detected categorization and asking whether its correct or wrong, and if wrong, what is the correct categorization, and also identify the entities (company names,person names, product names, etc).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So the object is to first classify the sentence into a category, and additionally, detect the named entities in the sentence, based on the category.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The idea is, to be able to automatically re-train the models based on this feedback to improve its performance over time, and to be able to retrain with as less manual intervention as possible. For the sake of this project, we can assume that user feedback would be accurate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem I am facing is that NLK is allowing fixed length entities while training, so for example a two word award is being detected as two awards. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What should be my approach to solve this problem? Is there a better NLU (even a commercial one) which can address this problem? It seems to me that this would be a common AI problem, and I am missing something basic. Would love you guys to have an input on this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks.&lt;/p&gt;&#xA;" OwnerUserId="17028" LastEditorUserId="1671" LastEditDate="2018-07-23T20:17:54.067" LastActivityDate="2018-07-23T20:17:54.067" Title="Sentence classification and named identity detection with automatic retraining" Tags="&lt;training&gt;&lt;natural-language-processing&gt;&lt;getting-started&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="7246" PostTypeId="1" CreationDate="2018-07-22T12:19:16.267" Score="0" ViewCount="37" Body="&lt;p&gt;I want to use NLP for semantic retrieval. I am new to this field. Can anyone suggest toolkit or tutorial to learn and implement NLP from scratch.&lt;/p&gt;&#xA;" OwnerUserId="17049" LastActivityDate="2018-07-22T12:19:16.267" Title="NLP for semantic retrieval" Tags="&lt;machine-learning&gt;&lt;classification&gt;&lt;natural-language-processing&gt;&lt;semantics&gt;" AnswerCount="0" CommentCount="2" />
	<row Id="7601" PostTypeId="1" CreationDate="2018-08-16T14:57:13.340" Score="6" ViewCount="89" Body="&lt;p&gt;If you taught an AI to understand sentences through usual neural network techniques.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then could you being to teach it things with sentences such as &quot;ants are small&quot;, &quot;the sky is blue&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;i.e. if you fed it that sentence and the neural network says this is 99% likely to be a properly formed sentence. Then where would it store this sentence for future use? This would be a kind of one-shot learning after it learnt how to learn.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Could you use some sort of gated architecture?&lt;/p&gt;&#xA;" OwnerUserId="4199" LastEditorUserId="1581" LastEditDate="2018-08-17T20:52:21.110" LastActivityDate="2018-08-20T21:01:02.073" Title="Can you teach an AI through sentences?" Tags="&lt;neural-networks&gt;&lt;natural-language-processing&gt;" AnswerCount="1" CommentCount="3" FavoriteCount="1" />
	<row Id="7655" PostTypeId="1" CreationDate="2018-08-20T21:31:23.160" Score="1" ViewCount="17" Body="&lt;p&gt;I want to do some sequence to sequence modelling on source data that looks like this:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;/-0.013428/-0.124969/-0.13435/0.008087/-0.269241/-0.36849/&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;with target data that looks like this:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;Dont be angry with the process youre going through right now&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Both are of indeterminate lengths, and the lengths of target and source data aren't the same. What I'd like to do is have a prediction model where I can input similar numbers and have it generate texts based on the target training data.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I started off doing character level s2s, but the output of the model is too nonsensical even at 2-5k epochs. So I've been looking into word level s2s and NMT, but the tutorials always assume strings of text as the target and source, and I keep running into roadblocks trying to preprocess the text, when all the tutorials assume a certain syntax/set of characters. This is my first try at ML, and some of the tutorials really throw me out with the text preprocessing requirements.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Am I going down the right avenue looking at word level/NMT stuff? And is there a tutorial I've missed for something like what I'm trying to build?&lt;/p&gt;&#xA;" OwnerUserId="17611" LastActivityDate="2018-08-20T21:31:23.160" Title="Sequence to sequence machine learning / NMT - converting numbers into words" Tags="&lt;natural-language-processing&gt;&lt;tensorflow&gt;&lt;keras&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="7678" PostTypeId="1" CreationDate="2018-08-22T15:10:12.507" Score="1" ViewCount="27" Body="&lt;p&gt;The term paraphrasing is used for converting input text into output text with small modifications on the semantic level. Paraphrasing is used by managers to distribute work items to employees. It is a certain form of communication which is hard to formalize.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From the management literature it is know that so called workflow management systems are implemented as groupware servers. They are storing and forward messages in the intranet of a company. The question is: is it possible to combine both? That means to paraphrase incoming messages of a company and distribute the messages to sub-departments? In theory, this would replace traditional managers, but I'm not sure. Perhaps it would make sense to test out the hypothesis first on the Enron dataset, which is a corpus of the e-mail fulltext of 158 employees in a large company.&lt;/p&gt;&#xA;" OwnerUserId="11571" LastActivityDate="2018-08-22T15:10:12.507" Title="Can semantic paraphrasing be used for a workflow management system?" Tags="&lt;machine-learning&gt;&lt;natural-language-processing&gt;&lt;voice-recognition&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="7747" PostTypeId="1" AcceptedAnswerId="7752" CreationDate="2018-08-28T23:10:23.383" Score="2" ViewCount="85" Body="&lt;p&gt;In the domain of natural language processing, a textgenerator is able to produce pseudo random output. The most famous one is SCIgen which was used to generate fake-science papers. The inner working of SCIgen is known, a so called context-free grammar was used which was parametrized by a random generator. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For the purpose of layout formatting, the “Lorem ipsum” text is used, which is a dummy pattern, generated by software. The inner working is unclear. I've seen many &quot;Lorum ispum&quot; generators on the web, and not only &quot;lorum ispum&quot;, there is also &quot;bacon ispum&quot;, &quot;space ispum&quot;... So how do these generators generate the text?&lt;/p&gt;&#xA;" OwnerUserId="17801" LastEditorUserId="16909" LastEditDate="2018-08-29T11:25:27.700" LastActivityDate="2018-08-29T21:26:04.417" Title="How does the 'Lorum ispum' generator work?" Tags="&lt;natural-language-processing&gt;&lt;text-summarization&gt;" AnswerCount="2" CommentCount="2" FavoriteCount="0" />
	<row Id="7880" PostTypeId="1" AcceptedAnswerId="7883" CreationDate="2018-09-07T22:39:06.603" Score="3" ViewCount="40" Body="&lt;p&gt;Is there an accepted way in NLP to parse conjunctions (and/or) in a sentence?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;By following the example below; how would I parse,&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;&quot;I drink orange juice if its the weekend or if its late and I\'m tired.&quot;&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Into,&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;[ &#xA;  [&quot;its the weekend&quot;]], &#xA;  [&quot;its late&quot;, &quot;I\'m tired&quot;] &#xA;]&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Implying an action will be taken when one of the above elements at the 1st level of depth is true.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know when I hear the sentence that it means &lt;code&gt;&quot;its the weekend&quot; OR (&quot;its late&quot; AND &quot;I\'m tired&quot;)&lt;/code&gt;, but how could this be determined computationally?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can an existing python/other library do this?&lt;/p&gt;&#xA;" OwnerUserId="10623" LastEditorUserId="1581" LastEditDate="2018-11-28T21:21:33.523" LastActivityDate="2018-11-28T21:21:33.523" Title="How to parse conjunctions in Natural Language Processing in Python" Tags="&lt;natural-language-processing&gt;&lt;python&gt;&lt;computational-linguistics&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="7977" PostTypeId="1" AcceptedAnswerId="7978" CreationDate="2018-09-14T14:44:09.633" Score="1" ViewCount="71" Body="&lt;p&gt;I would like to have a chat to talk on a personal plan enough to pass the Turing test.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I got to study some &lt;strong&gt;natural language processing (NLP)&lt;/strong&gt; but some that usually hide a lot of mechanical, so I think they are also much more sensitive than words and get phrases more fluid.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem is that I do not even have the idea to start. I did some testing with a NLP &lt;strong&gt;chatterbot&lt;/strong&gt; library for &lt;strong&gt;python&lt;/strong&gt;, but I do not know if it's possible to join PLN to Networks or how to use a neural network and I can not even use python or if I have to use a specific language.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In addition, I am using the book &lt;strong&gt;Artificial Intelligence - Russell and Norvig&lt;/strong&gt; as the basis for the article and I would like recommend me others.&lt;/p&gt;&#xA;" OwnerUserId="18233" LastActivityDate="2018-09-14T15:41:48.153" Title="How to make a chatbot with NLP and Neural" Tags="&lt;neural-networks&gt;&lt;natural-language-processing&gt;&lt;python&gt;&lt;chat-bots&gt;" AnswerCount="1" CommentCount="3" />
	<row Id="8013" PostTypeId="1" AcceptedAnswerId="8020" CreationDate="2018-09-17T04:44:46.687" Score="1" ViewCount="42" Body="&lt;p&gt;I'm training a language model with &lt;code&gt;5000&lt;/code&gt; vocabularies using a single &lt;code&gt;M60 GPU&lt;/code&gt; (w/ actually usable memory about 7.5G). &#xA;&lt;br&gt;The number of tokens per batch is about &lt;code&gt;8000&lt;/code&gt;, and the hidden dimension to the softmax layer is &lt;code&gt;512&lt;/code&gt;. So, if I understand correctly, fully-connected (softmax) layer theoretically consumes &lt;code&gt;5000*8000*512*4=81.92GB&lt;/code&gt; for a forward pass (4 is for float32).&#xA;&lt;br&gt;But the GPU performed the forward and backward passes without any problem, and it says the GPU memory usage is less than &lt;code&gt;7GB&lt;/code&gt; in total. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I used PyTorch. What's causing this? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT: To be clearer, the input to the final fc layer (256x5000 matrix) is of size [256, 32, 256]. &lt;/p&gt;&#xA;" OwnerUserId="18298" LastEditorUserId="18298" LastEditDate="2018-09-17T17:22:59.283" LastActivityDate="2018-09-17T18:35:57.343" Title="Calculation of GPU memory consumption on softmax layer doesn't match with the empirical result" Tags="&lt;neural-networks&gt;&lt;natural-language-processing&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="8126" PostTypeId="1" AcceptedAnswerId="8134" CreationDate="2018-09-24T21:35:10.663" Score="1" ViewCount="38" Body="&lt;p&gt;Within a piece of text, I'm trying to detect who did what to whom. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For instance, in the following sentences:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;CV hit IV. CV was hit by IV.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I'd like to know who hit whom.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I can't remember what this technique is called. Thanks for any help!&lt;/p&gt;&#xA;" OwnerUserId="18501" LastActivityDate="2018-09-25T09:03:37.953" Title="Looking for NLP technique and drawing a blank" Tags="&lt;natural-language-processing&gt;&lt;computational-linguistics&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="8341" PostTypeId="1" CreationDate="2018-10-10T09:14:46.177" Score="0" ViewCount="45" Body="&lt;p&gt;If there is given a one paragraph as a input and it extract a string from the  paragraph,within a predefined range (i.e. a string that starts with three letters that a always fixed and ends with five numbers like &quot;XXX12345&quot; that  numbers are varies between [0-9], etc).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have been struggling where to begin on this or if I am even going in the right direction for considering Machine/Deep learning to try to do this.&#xA;should i use NLTK ?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;I already make this by using python regular expression&lt;/strong&gt; but i want to know how to make this prgram using &lt;strong&gt;machine or deep learning.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Please Help!&lt;/p&gt;&#xA;" OwnerUserId="18912" LastActivityDate="2018-10-10T09:14:46.177" Title="Extract particular pattern from the given text/paragraph using machine or deep learning" Tags="&lt;neural-networks&gt;&lt;deep-learning&gt;&lt;natural-language-processing&gt;&lt;python&gt;" AnswerCount="0" CommentCount="8" FavoriteCount="0" />
	<row Id="8345" PostTypeId="1" CreationDate="2018-10-10T20:38:33.697" Score="1" ViewCount="22" Body="&lt;p&gt;I'm trying to build a chat analysis that could identify the intent of check price.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Has any kind of preset intent list to train my chatbot already been done ?&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Data: A data set for &quot;check price&quot; intent's. Like &quot;How much are ____&quot;&lt;/li&gt;&#xA;&lt;li&gt;Context:I looking for a data set to train a intent recognization for check price at chat bot. Exemple: If some one ask for a product price. I want to tag this is as check price intent . For that I am trainning a intent recognition.&lt;/li&gt;&#xA;&lt;li&gt;Region: Prefirencal the whole globe,but for start could be only at English&lt;/li&gt;&#xA;&lt;li&gt;License:Could both payed or free&lt;/li&gt;&#xA;&lt;li&gt;Non-answers: I didnt find nothing like a dataset for intent&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="18925" LastEditorUserId="18925" LastEditDate="2018-10-15T11:21:24.453" LastActivityDate="2018-10-15T11:21:24.453" Title="Preset Intent list" Tags="&lt;natural-language-processing&gt;&lt;datasets&gt;&lt;chat-bots&gt;" AnswerCount="0" CommentCount="2" />
	<row Id="8360" PostTypeId="1" CreationDate="2018-10-11T19:13:45.250" Score="1" ViewCount="57" Body="&lt;p&gt;I'm working on a project,whereby; one of the actors is &quot;Teacher&quot; and it's role will be, insert the course name, outcomes of skills, then insert the question, student degree and automatically will be connected with appropriate skill through the natural language processing (NLP) analysis student degree. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;What algorithm should I used in Natural Language Processing to connect the question to the appropriate skill (text comparison)? &lt;/p&gt;&#xA;" OwnerUserId="18955" LastEditorUserId="1581" LastEditDate="2018-10-30T17:09:23.763" LastActivityDate="2018-10-30T17:09:23.763" Title="Question in NLP" Tags="&lt;natural-language-processing&gt;&lt;algorithm&gt;" AnswerCount="1" CommentCount="4" />
	<row Id="8367" PostTypeId="1" CreationDate="2018-10-12T06:04:40.683" Score="2" ViewCount="39" Body="&lt;p&gt;There are some predefined categories( Overview, Data Architecture,Technical Details, Applications etc). The requirement is to classify the input text of paragraphs into their resp. category. I cant use any pretrained word embeddings (Word2Vec,Glove) because the data entered is not in general English ( talking about dogs, environment etc) but pure technical (How does a particular program orks, steps to download anaconda etc). Don't have any data available in internet to train as well. Anything that understands semantic-surface-level of a sentence will work&lt;/p&gt;&#xA;" OwnerUserId="18963" LastActivityDate="2018-10-16T12:24:44.130" Title="How to find the category of a technical text on a surface-semantic-level" Tags="&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;natural-language-processing&gt;&lt;python&gt;&lt;semantics&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="8377" PostTypeId="1" CreationDate="2018-10-13T08:55:43.150" Score="1" ViewCount="21" Body="&lt;p&gt;The need for semantic cognition in relation to natural language in computers is ever appearing in real problems in the field of AI.  We can note a substantial increase in related posted in StackExchange and other web locations.  This need is radically increasing for several reasons.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Recent advances in voice recognition and synthesis covers converting syntax back and forth into the audio domain, but the resulting talk with humans is meaningless on the computer side, whether the computer is speaking or listening.&lt;/li&gt;&#xA;&lt;li&gt;Many businesses went paperless years and now have thousands of documents that can't be easily indexed.&lt;/li&gt;&#xA;&lt;li&gt;The AI talk in public media has led to a funding increase for all of its sub-fields so technical people are talking, reading, and writing more about semantics because they are because they are doing those things more for anything AI related.&lt;/li&gt;&#xA;&lt;li&gt;Senior level business people, for the same reason as the technical people, are looking to stay at the forefront of technology and things like chatbots and command driven products are an appealing option.  (This will be the question in a moment.)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;AI researcher and linguist Roger Schank explains case based reasoning in a way that has become his signature: A story telling type of thought experiment.  He writes: &lt;sup&gt;1&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The story is that I was complaining to a friend that my wife didn't cook steak the way I liked it &amp;ndash; she always overcooked it.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;My friend said, &quot;Well, that reminds me of the time I couldn't get my hair cut as short as I wanted it, thirty years ago in England.&quot;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The question I ask is, How does such reminding happen, and why does it happen?  The &quot;how&quot; is obvious. What are the connections between the steak and the haircut? If you look at it on a conceptual level, there's an identical index match: We each asked somebody who had agreed to be in a service position to perform that service, and they didn't do it the way we wanted it.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;There are a number of questions you can ask.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;First, how do we construct such indices? Obviously, my friend constructed such an index in order to find, in his own mind, the story that had the same label.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Second, why do you construct them? And the answer is that you're trying to understand the universe and you need to match incoming events to past experiences. This is something I call &quot;case-based reasoning.&quot;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;The idea that you would then make that match obviously has a purpose. It's not hard to understand what the purpose would be; the purpose is learning. Because how would you learn from new experiences otherwise?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Consider now the state of technology and the increasing funding, senior level management attention, and growing technical expertise, resulting in an industrial robots that respond to and respond with voice.  This is no longer the domain of science fiction.  It is a need toward which current technology is moving with diligence and passion.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The following Schank-ian thought experiment, where the match occurs without case-based reasoning, shows the hole in current AI system design.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;An industrial robot is melting down a defective metal part to recycle the metal as part of a materials cost reduction policy.  When the operation is complete and the metal is properly added back into the production stream, the recycling engineer says, &quot;And that's a wrap,&quot; referring to the task is complete from the movie shooting scenario.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;A week later, the robot is working in another department.  The department director has bought a piece of gold jewelry for his wife to celebrate their twentieth anniversary.  The robot enters his office, he hands the robot the gift and says, &quot;Please wrap this.&quot;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;That the gift ends up in the production line for gold plated electronic contacts on the factory floor is because the computer in the robot does NOT use case based reasoning in a way that reduces risk of loss.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How can current technology be used to not only deliver understanding but also avoid misunderstanding?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Consider that Schank is likely correct, that memory is largely the storage and indexing of these conceptual cases.  Consider the input to be processed is a continuous sequence of linguistic elements&lt;sup&gt;2&lt;/sup&gt; as the input (originating from a voice recognition deep learner already in place) and the output is a list of matching cases that are analogs, scored by how likely they match the meaning intended by the speaker.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It would be a later task to decide how to assess risks associated with execution based on each of the meanings and ask the speaker what they meant if the meaning is ambiguous and the risk of executing based on a misunderstanding is high.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What convolution networks, attention based learners, rules engines, fuzzy logic containers, deep Q-learners, or other components can successfully store Schank's cases and retrieve them based solely on the meaning of streams of linguistic elements?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Recall what Schank wrote above:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;&quot;If you look at it on a conceptual level, there's an identical index match: We each asked somebody who had agreed to be in a service position to perform that service, and they didn't do it the way we wanted it.&quot;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;How does one store that concept and retrieve it?&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Semantics of natural language &amp;mdash; is AI capable hardware and software now developed enough to realize it?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Footnotes&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;[1] The Third Culture: Beyond the Scientific Revolution, John Brockman, Simon &amp;amp; Schuster, 1995, &lt;a href=&quot;https://www.edge.org/documents/ThirdCulture/q-Ch.9.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;chapter 9&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;[2] Linguistic elements may be words, prefixes, endings of words, or word groups that have a meaning across the language space.  Examples:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;gold (just a normal word)&lt;/li&gt;&#xA;&lt;li&gt;-ing (to indicate the continuous tense of many verbs and is therefore an independent linguistic element)&lt;/li&gt;&#xA;&lt;li&gt;screw gun (jargon that operates as a word pair with a meaning different than if the words are taken as separate linguistic elements)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="4302" LastActivityDate="2018-10-13T08:55:43.150" Title="Semantics of natural language — is AI capable hardware and software now developed enough to realize it?" Tags="&lt;ai-design&gt;&lt;natural-language-processing&gt;&lt;chat-bots&gt;&lt;topology&gt;&lt;semantics&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="8569" PostTypeId="1" CreationDate="2018-10-22T01:27:58.513" Score="0" ViewCount="19" Body="&lt;p&gt;(Maybe related : &lt;a href=&quot;https://ai.stackexchange.com/questions/8511/usefulness-of-dropout-for-non-overfitting-network/8513#8513&quot;&gt;Usefulness of Dropout for non-overfitting network&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My neural network does not overfit.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Using Data augmentation in a non-overfitting network can increase its accuracy ?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Note : I'm asking this question in the NLP area, where Data augmentation is not trivial. I'm thinking about back-translation. The augmented data might not be of similar quality, which can hurt the accuracy (I guess ?).&lt;/em&gt;&lt;/p&gt;&#xA;" OwnerUserId="18852" LastEditorUserId="1581" LastEditDate="2018-11-01T17:42:18.447" LastActivityDate="2018-11-01T17:42:18.447" Title="Usefulness of Data augmentation for non-overfitting network [NLP]" Tags="&lt;natural-language-processing&gt;&lt;datasets&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="8680" PostTypeId="1" CreationDate="2018-10-30T10:39:08.117" Score="1" ViewCount="21" Body="&lt;p&gt;&lt;strong&gt;I would like to create an NPC engine for games which are in a fantasy context&lt;/strong&gt; like Lord of the Rings, Warcraft, Skyrim, Dragon Age etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This engine should be able to &lt;strong&gt;determine the polarity of the given sentence&lt;/strong&gt; (positive/negative/neutral) and should also be able to tag the words (part-of-speech tagging, but that's not relevant now).&#xA;&lt;strong&gt;The problem is that I cannot find a dataset which&lt;/strong&gt; I can teach my AI with, so that &lt;strong&gt;fits into the fantasy context&lt;/strong&gt;.&#xA;As an example for Lord of the Rings, there are characters like Sauron which are negative, but there's a ton of expressions too in a fantasy world which cannot be found in a general dataset.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Therefore, &lt;strong&gt;I would like to ask if you could suggest to take dataset(s)&lt;/strong&gt; which contain expressions, even better names in a fantasy context.&#xA;It doesn't matter which fantasy universe does it take.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thank you!&lt;/p&gt;&#xA;" OwnerUserId="19441" LastEditorUserId="19441" LastEditDate="2018-10-30T10:57:50.280" LastActivityDate="2018-11-03T02:20:27.260" Title="Searching for dataset in specifix context for NLP, sentiment analysis" Tags="&lt;natural-language-processing&gt;&lt;datasets&gt;&lt;sentiment-analysis&gt;" AnswerCount="1" CommentCount="3" />
	<row Id="8898" PostTypeId="1" CreationDate="2018-11-10T03:38:04.040" Score="1" ViewCount="10" Body="&lt;p&gt;The problem statement: Mapping from a vector space representation onto a tree structure.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Possible solution: Given a word vector as input, produce a path in the tree from the root down to the node that most closely matches that vector.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The path would be a variable length string composed from a finite set of symbols.  The variable length output leads me towards long short-term memory (LSTM) models.  But I've never built a complete LSTM model before.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The understanding gap: My vector inputs are already dense representations.  Specifically, I'm working with GloVe right now.  But the output path symbols would require a different encoding, correct?  How can I structure/train the necessary encoder-decoder pair so that it can handle both word vectors and these path symbols as input while still being able to produce path symbols as output?&lt;/p&gt;&#xA;" OwnerUserId="19703" LastActivityDate="2018-11-10T03:38:04.040" Title="Learning Tree Paths when Given Vectors" Tags="&lt;neural-networks&gt;&lt;natural-language-processing&gt;&lt;lstm&gt;&lt;wordvector&gt;&lt;long-short-term-memory&gt;" AnswerCount="0" CommentCount="0" FavoriteCount="1" />
	<row Id="8944" PostTypeId="1" CreationDate="2018-11-12T17:00:32.700" Score="0" ViewCount="14" Body="&lt;p&gt;Grammatical induction is the art of learning a grammar from training data. We have a domain-specific-language for example a Python dialect and should create for that dialect a grammar which is able to parse the language. Parsing means, to identify for new sourcecode samples if they are valid and which tokens has which meaning. To make things more complicated the language is not a programming language but the input in a textadvanture. That means, the grammar should learn what the internal parser is doing. Additionally, the language has a meaning. That means, the user types in a sentence and at as result the avatar on the screen moves in a direction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the literature such task is called Grammar induction, because the grammar is not there and must be find from scratch. Additional the link between the language and the actions on the screen are needed. I know this is a very complicated task and it is not possible to explain this in detail. So my question goes only into the direction of a submodul of the overall system. Before it is possible to iterate a grammar some datastructure is needed to store the grammar. How can i do this? Do I need the ANTLR syntax for a grammar, can i store a grammar as a graph, as a Lisp list tree or in a SQL database? In every case, the idea is not to program the grammar by hand in software, but to iterate with a solver over possible grammars according to the input stream which is an unknown language.&lt;/p&gt;&#xA;" OwnerUserId="11571" LastActivityDate="2018-11-12T17:00:32.700" Title="Datastructure for grounded grammar induction" Tags="&lt;natural-language-processing&gt;&lt;genetic-programming&gt;" AnswerCount="0" CommentCount="0" FavoriteCount="1" />
	<row Id="8958" PostTypeId="1" CreationDate="2018-11-13T17:22:08.943" Score="1" ViewCount="31" Body="&lt;h3&gt;(Un-original) idea:&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;Wouldn't it be cool if we could fact-check using an algorithm that could understand a whole bunch of documents (e.g. scientific papers) as higher-order logic?&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;Question:&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;What work has been done on this to date?&lt;/p&gt;&#xA;&#xA;&lt;h3&gt;What I've got so far:&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;(1) I seem to recall there being prior work to create a subset of English (I think intended for use in scientific writing) that could be easily interpreted by an algorithm. This doesn't quite get us to the algorithm described above (as it's restricted to a subset of English) - but seems pertinent.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(2) Once parsed, I guess a resolution algorithm like that in &lt;a href=&quot;https://en.wikipedia.org/wiki/Prolog&quot; rel=&quot;nofollow noreferrer&quot;&gt;Prolog&lt;/a&gt; could be used to check wether a fact (presumably also inputted as a logical statement) contradicts the logic of the documents?&lt;/p&gt;&#xA;" OwnerUserId="19864" LastActivityDate="2018-11-14T09:29:04.163" Title="Possible to translate generic English-language document into higher-order logic?" Tags="&lt;natural-language-processing&gt;&lt;logic&gt;" AnswerCount="2" CommentCount="2" />
	<row Id="8999" PostTypeId="1" CreationDate="2018-11-16T11:47:11.507" Score="1" ViewCount="20" Body="&lt;p&gt;There are 4 kinds of adverbs :&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Adverbs of Manner. For example, slowly, quietly&lt;/li&gt;&#xA;&lt;li&gt;Adverbs of Place. For example, there, far&lt;/li&gt;&#xA;&lt;li&gt;Adverbs of Frequency. For example, everyday, often&lt;/li&gt;&#xA;&lt;li&gt;Adverbs of Time. For example, now, first, early&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;nltk, spacy and textblob only tag a token as an adverb without specifying which kind it is.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are there any libraries which tag including the type of adverb?&lt;/p&gt;&#xA;" OwnerUserId="19962" LastEditorUserId="1847" LastEditDate="2018-11-16T12:16:36.087" LastActivityDate="2018-11-16T15:09:19.593" Title="How to know which kind of adverb in NLP Parts of Speech (POS) tagging?" Tags="&lt;natural-language-processing&gt;" AnswerCount="2" CommentCount="1" />
	<row Id="9016" PostTypeId="1" CreationDate="2018-11-17T13:00:53.227" Score="2" ViewCount="89" Body="&lt;p&gt;The domain of emergency call for clogged pipelines has to do with taking a call and managing the reaction of plumber departments. It is mostly a group oriented communication situation between the caller, the first level call taker, the second level dispatcher and external stations in the back office. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;From a linguistic point of view, there are different kind of speech acts available. For example paraphrasing which is the repetition of previous speech with own words, or counter-speech which is criticizing something said before. Modeling all the different social roles, their usage of speech acts and make the overall decision process transparent is a difficult task. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've searched a bit for existing papers about the subject, but it seems that the domain wasn't explored yet. My question is: Is it possible to create some kind of chatbot population which talks to each other back and forth and is able to simulate an emergency dispatching task which includes conflicts between the operators and contrasting point of views about how to handle a certain situation under resource limitations?&lt;/p&gt;&#xA;" OwnerUserId="11571" LastEditorUserId="1847" LastEditDate="2018-11-17T14:32:14.960" LastActivityDate="2018-11-27T10:11:07.590" Title="How to model a plumber dispatcher with Artificial Intelligence?" Tags="&lt;natural-language-processing&gt;&lt;game-ai&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="9122" PostTypeId="1" CreationDate="2018-11-23T13:28:36.467" Score="0" ViewCount="16" Body="&lt;p&gt;I am relatively new to recurrent neural networks and it seems like a vast domain. So I want to get my initial footing right. There seems to be a whole lot of applications in this field, but the first I encountered and the one that many articles seem to be claiming as essential for other applications is Language Models. I find that I am not too clear with some ideas and intuitions in this area. Rather than a set of questions, I thought it would be better if I lay out the flow of ideas as understood by me. Where I am not sure ,I have left it as a question. And I hope that all the wrong ideas are pointed out. I would love to learn it correct the first time around rather than having to unlearn and re-learn later. It is quite a long question and I apologize in advance for that.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let us say, the task is to train from a corpus of text and generate new text or predict text(in search suggestions kind of applications)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let us say, I am using a vocabulary of one-hot vectors (not word embeddings). Now this means I convert each word in my dataset into a one-hot vector, with a one at the position the word occurs in the vocabulary. I now proceed in 2 parts:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Step 1: Pass the first timestep word into the first timestep of the RNN. This will calculate a vector giving probabilities of output ( a vector of same length as vocabulary, with each entry being a probability of the next word being the word corresponding to that index position in the dictionary). Let us call this y_pred. It will also calculate a cell vector which is passed into the next timestep to give a certain &quot;Memory aspect&quot; to the RNN. The correct next word is actually a one hot vector that we have as a label in our training data. We now input this &quot;correct next word&quot; as our training data says into the next timestep and use this as well as the cell output of the previous timestep to calculate a prediction for the next(3rd word). Now we calculate the error or cost, which is a measure of how much y_pred as predicted by the neural network is off from the next word as we have in the training data. We now train the weights to minimise this cost.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Step 2: Having trained the weights, we feed in a dummy input in the first timestep (say a vector of zeros), the RNN now predicts a vector where the entry in each index being the probability of the next word to be the word in the vocabulary at that index position.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Am I correct till this point? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If yes, here is where I seem to be losing the trail,&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We now take this yhat and we now choose the input to the next timestep as a one hot vector with a one in the index position, say i, where this i is obtained by randomly choosing an index with probability of each index being chosen given by the vector ypred? Am I first correct in assuming we pass a one hot vector into the next timestep? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;We know get the ypred of the second timestep and this is again sampled like before and we repeat this till we reach an end of sample.Thus we get a generated sequence. This idea can be generalized to generating characters, music, texts and so on. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now why are we using a sample of randomly chosen, probability weighted, indices when we can just pass the one with the maximum probability to the next time step? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also how do we make a real time sequence predictor? For example, predicting search queries as text is entered. I feel we should first train the model on the proper sentences and then as a word is entered we predict words in the next time step by taking the next word that the model predicts has maximum probability and then, the next word, and so on. When the actual second word is entered by the user, we now take this as the input to the second timestep and get the most probable sentence that the model predicts and so on.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is this an okay idea?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, let us say that instead of working with an alphabetical position corpus, I am working with a word embedding. I understand the idea behind this as giving the vector representations of words a way to contain some meaning.This allows the network to perform well on words encountered in real time working, that was not present in the training text as the vector is similar to more common words that belong to (atleast, to some approximation) the same class.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now a word embedding of a word has entries that are values allowed to take any range? Or are they usually conformed to lie within 0 to 1 or -1 to 1?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Okay. So now is the neural network predicting at each timestep a vector of probabilites, or a vector of values, which the network thinks is a word embedding representing a word which it believes is most likely to occur next? If it is probabilities then I dont understand what they represent. If it is the other case, then how do we get the word itself? The embedding matrix need not necessarily contain a vector of these exact values. Do we then measure the distance(sum of squares of differences of each entry) between this vector and every vector in the embedding matrix and get the smallest one? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Okay. Now how do we proceed generating ?Here, there seems to be really only two way of sampling. That is to pass this vector y_pred as input to the next timestep or pass the vector from the embedding matrix which we identified to have minimum distance from y_pred? That is the actual word which we think the network is trying to convey to us.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks in advance! &lt;/p&gt;&#xA;" OwnerUserId="17143" LastActivityDate="2018-11-23T13:28:36.467" Title="Language Models RNN" Tags="&lt;neural-networks&gt;&lt;natural-language-processing&gt;&lt;ai-basics&gt;&lt;recurrent-neural-networks&gt;&lt;wordvector&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="9141" PostTypeId="1" AcceptedAnswerId="9166" CreationDate="2018-11-24T13:44:39.893" Score="0" ViewCount="36" Body="&lt;p&gt;I am a new learner in NLP. I am interested in the sentence generating task. As far as I am concerned, one state-of-the-art method is the &lt;a href=&quot;https://github.com/karpathy/char-rnn&quot; rel=&quot;nofollow noreferrer&quot;&gt;CharRNN&lt;/a&gt;, which uses RNN to generate a sequence of words.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, BERT has come out several weeks ago and is very powerful. Therefore, I am wondering whether this task can also be done with the help of BERT? I am a new learner in this field, and thank you for any advice!&lt;/p&gt;&#xA;" OwnerUserId="20170" LastActivityDate="2018-11-26T01:01:44.943" Title="Can BERT be used for sentence generating tasks?" Tags="&lt;neural-networks&gt;&lt;deep-learning&gt;&lt;natural-language-processing&gt;" AnswerCount="1" CommentCount="2" />
	<row Id="9179" PostTypeId="1" CreationDate="2018-11-26T13:12:13.263" Score="2" ViewCount="31" Body="&lt;p&gt;I am learning to create a dialogue system. The various parts of such a system are Intent classifier, slot filling, Dialogue state tracking (DST), dialogue policy optimization and NLG.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;While reading &lt;a href=&quot;https://storage.googleapis.com/pub-tools-public-publication-data/pdf/44018.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;this&lt;/a&gt; paper on DST, I found out that a discriminative  sequence model of DST can identify goal constraints, fill slots and maintain state of the conversation. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does this mean that now I dont need to create an intent classifier and slot filling models separately as the tasks are already being done by this DST? Or I am misunderstanding both the things and they are separate?&lt;/p&gt;&#xA;" OwnerUserId="19244" LastEditorUserId="19244" LastEditDate="2018-11-26T14:19:21.107" LastActivityDate="2018-11-27T20:31:33.160" Title="Does an advanced Dialogue state tracking eliminate the need of intent classifier and slot filling models in dialogue systems/ chatbots?" Tags="&lt;neural-networks&gt;&lt;machine-learning&gt;&lt;natural-language-processing&gt;&lt;recurrent-neural-networks&gt;&lt;chat-bots&gt;" AnswerCount="1" CommentCount="4" />
	<row Id="9187" PostTypeId="1" CreationDate="2018-11-26T17:34:44.853" Score="0" ViewCount="14" Body="&lt;p&gt;I am looking for methods/techniques I can use to generate a set of similar questions based on a base question. The generated questions should be answered by the exact same answer to the base question.&#xA;For example if the base question is &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;What is the address of the restaurant?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Generated questions&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Where is the restaurant located?&lt;/li&gt;&#xA;&lt;li&gt;Can you give me the location of the restaurant?&lt;/li&gt;&#xA;&lt;li&gt;Whats the address of the restaurant (I understand this bit hard since new words are introduced)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;How can I come up with a generic model which can take a question as an input and generate a set of similar questions?&lt;/p&gt;&#xA;" OwnerUserId="20218" LastActivityDate="2018-11-26T17:34:44.853" Title="How to use AI to generate similar questions from a base question?" Tags="&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;ai-design&gt;&lt;natural-language-processing&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="9191" PostTypeId="1" CreationDate="2018-11-26T20:56:12.613" Score="1" ViewCount="13" Body="&lt;p&gt;Let's say we have 2 blocks of text, where there are some similarities as in 2 interpretations of the same story. Is there any solution that would recognize these consistencies and ultimately be able to recreate a story with all the details of each?&lt;/p&gt;&#xA;" OwnerUserId="20223" LastActivityDate="2018-11-26T20:56:12.613" Title="Intelligent Text Combination" Tags="&lt;natural-language-processing&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="9215" PostTypeId="1" CreationDate="2018-11-27T16:08:24.887" Score="0" ViewCount="12" Body="&lt;p&gt;I constantly see Latent Dirichlet Allocation (LDA) as a go to technique for topic modelling. It performs okay-ish, but ignores word context and (subjectively) seems outdated. Has anyone implemented something like an LSTM with LDA to retain sentence information? What other approaches with neural nets could be a good fit for topic modelling?&lt;/p&gt;&#xA;" OwnerUserId="20244" LastActivityDate="2018-11-27T16:08:24.887" Title="Did anyone try topic modelling with neural nets?" Tags="&lt;neural-networks&gt;&lt;natural-language-processing&gt;&lt;recurrent-neural-networks&gt;&lt;lstm&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="9248" PostTypeId="1" CreationDate="2018-11-29T08:18:19.443" Score="0" ViewCount="24" Body="&lt;p&gt;We want to figure out the connection between people, based on their speech.&#xA;Assume, that a conversation is a poetry with lines belongs to characters. There are a lot of poetries and the lines are mixed. Now we want to define a conversation to which each line belongs to. &#xA;We assume, that people in a conversation use similar words (their dictionaries should be similar). It means that there is a correlation between words of person A and words belongs to person B, and we could detect a connection between the peoples which had a conversation. What are the next steps for content understanding after NLP?&#xA;Can some of you advise us about the field of study and tools/libraries, which are dealing with content processing? Maybe, some of you know good articles or online resources, which can help us to dive into this field.&lt;/p&gt;&#xA;" OwnerUserId="20267" LastEditorUserId="1671" LastEditDate="2018-11-29T22:22:11.477" LastActivityDate="2018-11-29T22:22:11.477" Title="Content analysis tools" Tags="&lt;natural-language-processing&gt;&lt;software-evaluation&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="2920" PostTypeId="1" CreationDate="2017-03-04T18:27:37.373" Score="4" ViewCount="420" Body="&lt;p&gt;I am looking for a solution that I can use with identifying cars.&#xA;So I have a database with images of cars. About 3-4 per car. What I want to do is upload a picture to the web of car(Picture taken with camera/phone) and then let my pc recognize the car. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Example: &#xA;Lets say I have these 2 pictures in my database(Mazda cx5)(I can only upload 2 links at max. atm. but you get the idea).&#xA;&lt;a href=&quot;https://i.stack.imgur.com/NsLow.png&quot; rel=&quot;noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/NsLow.png&quot; alt=&quot;First car&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now I am going to upload this picture of a mazda cs5 to my web app:&#xA;&lt;a href=&quot;https://i.stack.imgur.com/psHD6.png&quot; rel=&quot;noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/psHD6.png&quot; alt=&quot;Picture of mazda cs5&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now I want an AI to recognize that this picture is of an Mazda CX5 with greyish color. I have looked on the net and found 2 interesting AI's I can use:&#xA;Tensorflow and Clarifai, but I don't know if these are going to work so my question to you what would be my best bet to go with here?&lt;/p&gt;&#xA;" OwnerUserId="5837" LastActivityDate="2017-07-04T17:30:04.077" Title="Image recognition" Tags="&lt;image-recognition&gt;&lt;tensorflow&gt;" AnswerCount="2" CommentCount="0" FavoriteCount="1" />
	<row Id="3528" PostTypeId="1" AcceptedAnswerId="3531" CreationDate="2017-06-22T13:35:38.667" Score="8" ViewCount="3952" Body="&lt;p&gt;Which one would you recommend for a first approach to deep learning? I'm a neuroscience student trying for the first time computational approaches, if that matters.&lt;/p&gt;&#xA;" OwnerUserId="8015" LastActivityDate="2018-01-04T05:07:55.510" Title="Tensorflow vs Keras vs ... to begin with deep learning?" Tags="&lt;deep-learning&gt;&lt;tensorflow&gt;&lt;neurons&gt;&lt;keras&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="3" />
	<row Id="4250" PostTypeId="1" CreationDate="2017-10-11T16:01:18.823" Score="2" ViewCount="85" Body="&lt;p&gt;I was going through &quot;&lt;a href=&quot;https://www.tensorflow.org/tutorials/wide_and_deep&quot; rel=&quot;nofollow noreferrer&quot;&gt;Wide &amp;amp; Deep Learning&lt;/a&gt;&quot; tensorflow tutorial &amp;amp; it's quite simply explained the process. But I missed few of the things. If someone can please explain them to me, it will be of great help:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1) Why &lt;code&gt;occupation&lt;/code&gt; and &lt;code&gt;native_country&lt;/code&gt; we are using &lt;code&gt;tf.feature_column.categorical_column_with_hash_bucket&lt;/code&gt; and again using &lt;code&gt;tf.feature_column.embedding_column&lt;/code&gt;?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2) Why in &lt;code&gt;tf.feature_column.embedding_column&lt;/code&gt;, we are taking &lt;code&gt;dimension=8&lt;/code&gt;, even though they have more unique values?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;3) Why we are using &lt;code&gt;crossed_columns&lt;/code&gt; variables? In the document there's an explaination given. But I'm not fully understanding it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The questions might sound silly, but I'm not sure of the answers to these questions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thank you!&lt;/p&gt;&#xA;" OwnerUserId="9664" LastEditorUserId="7550" LastEditDate="2017-10-12T06:42:08.630" LastActivityDate="2017-10-12T06:42:08.630" Title="Wide &amp; Deep Learning Explanation" Tags="&lt;neural-networks&gt;&lt;tensorflow&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="5685" PostTypeId="1" CreationDate="2018-03-14T19:49:36.747" Score="0" ViewCount="78" Body="&lt;p&gt;I am interested in using Keras / Tensorflow to self-train a neural net how to behave in a random environment with real-time feedback from a series of sensors. That probably sounded confusing, so let me give an example. As a learning exercise I'm attempting to teach a simple network how to play the classic 'Snake' game  by inputting the snake's distance to food, walls, and itself and reducing the output to 4 neurons representing moving UP, DOWN, RIGHT, or LEFT - taking whichever returns the highest value as the next movement of the snake. I am essentially trying to recreate &lt;a href=&quot;https://www.youtube.com/watch?v=3bhP7zulFfY&quot; rel=&quot;nofollow noreferrer&quot;&gt;this&lt;/a&gt; video, but instead of a genetic algorithm with many models I would like to have a single model continually learn and adapt (re-spawning and continuing on deaths) based on the results from initially random movement.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So on to methodology, my thought is to use a weighted loss function to attribute higher positive weights to actions that result in gaining points (moving towards food and eating it) and attribute negative weights to actions that result in death (e.g. hitting walls / hitting itself) or avoiding the food. Conceptually I can see how this would work, and I'm tempted to code my own weighted activation function to try it out, but I am wondering if anything like this already exists in Keras / Tensorflow. I have heard of weighted activation functions being implemented, but I couldn't find any examples of training with 'negative data', i.e. training the network what &lt;em&gt;not&lt;/em&gt; to do.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As for what I've done so far, I have basically reproduced the above linked video. I have a snake program setup to input the according data to a densely connected network with 12 input neurons, 8 hidden neurons, and 4 output neurons. The output of the network controls the snake's next movement as desired, and currently I built an evaluation function to determine how well the snake is doing at every step and a basic genetic algorithm which takes this evaluation to slowly work towards a better network. This works okay, not quite as well as in the video (which I attribute to my reduced number of neurons, sensors, and probably inferior evaluation function), but it eventually seems to get the idea of seeking food and not dying.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So does anyone have any thoughts on training with weighted loss functions, maybe good sources to checkout for information, and more specifically any implementation of training negative correlations? I feel like a real-time self-learning network that learns by doing must have a way of evaluating and adapting to negative results, but I am also pretty new to neural networks so if there is another standard way of achieving what I'm describing I'm open to suggestions!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks!&lt;/p&gt;&#xA;" OwnerUserId="13315" LastActivityDate="2018-03-14T19:49:36.747" Title="Training with unbalanced positive *and negative* data" Tags="&lt;neural-networks&gt;&lt;tensorflow&gt;&lt;keras&gt;&lt;real-time&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="5739" PostTypeId="1" CreationDate="2018-03-19T01:35:47.950" Score="0" ViewCount="24" Body="&lt;p&gt;Say you follow a tutorial on the tensorflow website for a wide and deep model (&lt;a href=&quot;https://www.tensorflow.org/tutorials/wide_and_deep&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://www.tensorflow.org/tutorials/wide_and_deep&lt;/a&gt;)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I create a model based on the US census data to predict whether or not an individual will make more or less than \$50k given a number of features like age, education, profession, etc. I've been able to create the model as well as create a predictor that uses the model just fine. But is there a way to see what features tensorflow is &quot;weighing&quot; more than others? For instance, does it weigh a higher education more than someones age? (i.e. if someone has a PHD and is 26 years old, is the model more likely to say they make more than \$50k vs someone who has an associates degree and is 55 years old?)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm using a DNNLinearCombinedClassifier if it matters to this question.&lt;/p&gt;&#xA;" OwnerUserId="11667" LastEditorUserId="32" LastEditDate="2018-08-10T15:13:48.670" LastActivityDate="2018-08-10T15:13:48.670" Title="Being able to see how tensorflow &quot;weighs&quot; features in classifier" Tags="&lt;neural-networks&gt;&lt;tensorflow&gt;" AnswerCount="0" CommentCount="2" />
	<row Id="6158" PostTypeId="1" CreationDate="2018-04-24T18:44:36.500" Score="2" ViewCount="295" Body="&lt;p&gt;To start, let me just say that I am very new to tensorflow and Machine Learning in general. But, as part of my learning project I am trying to adapt the tensorflow wide and deep model to generate movie recommendations. However, the part I'm getting stuck on is handling multiple values for a categorical column. Below is a sample of how a couple of rows in my CSV look like.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;    ID,Genres,Tags,Rating,Recommendations&#xA;    ----------------------------------------&#xA;    1,genre1:genre2:genre3,tag1:tag3,4.3,44&#xA;    2,genre2:genre3,tag1:tag5,3.7,22&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The Genres and Tags column have multiple categorical values. I have looked at &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/string_split&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;code&gt;tf.string_split&lt;/code&gt;&lt;/a&gt; to parse the strings and return a &lt;code&gt;SparseTensor&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Once I have parsed my delimited string values into &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/SparseTensor&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;code&gt;SparseTensor&lt;/code&gt;&lt;/a&gt;, what do I do with? If I want to create &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;code&gt;categorical_column_with_vocabulary_file&lt;/code&gt;&lt;/a&gt;, how does the &lt;code&gt;SparseTensor&lt;/code&gt; interact with it? Is that even the correct step? Should the &lt;code&gt;SparseTensor&lt;/code&gt; be converted into a something before I can create a &lt;code&gt;categorical_column_*&lt;/code&gt;? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am just not sure how to train the Wide and Deep model when you have multiple categorical values for a single column. Some people have suggested that I use each 'Genre' as its own column and encode it using One-Hot, but it is not realistic for me to do this, because there could be 100s of genres and tags in the data.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any help on this matter would be welcome. Thank you!!&lt;/p&gt;&#xA;" OwnerUserId="15220" LastActivityDate="2018-11-24T10:01:45.317" Title="How do you handle multiple categorical values in a single column for wide_deep model in tensorflow?" Tags="&lt;neural-networks&gt;&lt;deep-learning&gt;&lt;tensorflow&gt;&lt;python&gt;&lt;linear-regression&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="3" />
	<row Id="6330" PostTypeId="1" AcceptedAnswerId="6340" CreationDate="2018-05-10T01:01:42.800" Score="0" ViewCount="32" Body="&lt;p&gt;From &lt;a href=&quot;https://stackoverflow.com/questions/36370129/does-tensorflow-use-automatic-or-symbolic-gradients&quot;&gt;https://stackoverflow.com/questions/36370129/does-tensorflow-use-automatic-or-symbolic-gradients&lt;/a&gt;, I understood TensorFlow requires all the operations in the Graph to be explicit formulas (instead of black-boxes, such as raw python functions) to do Automatic Differentiation. Then it will do some kind of Gradient Descent based on that to minimization.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm wondering, since it already know all the explicit formulas, can it directly find out the minimum by examining the equation itself? Like computing the points where gradient is zero or do not exist, then do some kind of processing to find out the minimum.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I found it is simple to do this &quot;symbolic minimization&quot; above with few variables such as minimizing &lt;code&gt;Σ(a_i - v)^2&lt;/code&gt; where &lt;code&gt;v&lt;/code&gt; is the trainable variable an &lt;code&gt;a_i&lt;/code&gt; are all the training samples. I'm not sure is there a general way though.&lt;/p&gt;&#xA;" OwnerUserId="15546" LastActivityDate="2018-05-10T09:31:36.480" Title="Can TensorFlow minimize &quot;symbolically&quot;" Tags="&lt;tensorflow&gt;&lt;optimization&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="6345" PostTypeId="1" CreationDate="2018-05-10T19:53:12.393" Score="1" ViewCount="130" Body="&lt;p&gt;I am trying to implement CNN using tensorflow on temporal accelrometer signal. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I have signal values segmented on every 10ms (200 samples). &lt;/li&gt;&#xA;&lt;li&gt;I want to perform 1-D convolution (&lt;code&gt;tf.nn.conv1d(x,W,stride=1,padding='VALID')&lt;/code&gt;) &lt;/li&gt;&#xA;&lt;li&gt;Convolution window size is 20 samples and stride of 1 with 32 features and Valid padding&lt;/li&gt;&#xA;&lt;li&gt;I want to apply Max-Pooling with window size of 10 samples &lt;code&gt;tf.nn.max_pool(x,ksize=[1,1,10,1],strides= [1,1,2,1],padding='VALID')&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;But i am getting errors regarding dimensions of tensors. Any suggestions on how can i set filter size and stride for booth convolution and max-pooling&lt;/p&gt;&#xA;" OwnerUserId="15565" LastActivityDate="2018-05-10T19:53:12.393" Title="How to set Stride,Filter size in Tensorflow for 1-D signals?" Tags="&lt;tensorflow&gt;&lt;python&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="6383" PostTypeId="1" CreationDate="2018-05-12T16:33:34.113" Score="6" ViewCount="440" Body="&lt;p&gt;I am pretty much a beginner in Tensorflow and simply follow a tutorial. There is no problem with my code, but I have a question regarding the output&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;accuracy: 0.95614034&#xA;accuracy_baseline: 0.6666666&#xA;auc: 0.97714674&#xA;auc_precision_recall: 0.97176754&#xA;average_loss: 0.23083039&#xA;global_step: 760&#xA;label/mean: 0.33333334&#xA;loss: 6.578666&#xA;prediction/mean: 0.3428335&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;I would like to know what does &quot;prediction/mean&quot; and &quot;label/mean&quot; represent?&lt;/p&gt;&#xA;" OwnerUserId="15593" LastEditorUserId="2193" LastEditDate="2018-05-14T17:53:10.930" LastActivityDate="2018-10-11T22:00:14.413" Title="Meaning of evaluation metrics in Tensorflow" Tags="&lt;neural-networks&gt;&lt;tensorflow&gt;&lt;python&gt;&lt;artificial-neuron&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
	<row Id="6488" PostTypeId="1" CreationDate="2018-05-22T09:49:42.907" Score="5" ViewCount="781" Body="&lt;p&gt;I used the example at - &lt;a href=&quot;https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/5_DataManagement/tensorflow_dataset_api.py&quot; rel=&quot;noreferrer&quot;&gt;https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/5_DataManagement/tensorflow_dataset_api.py&lt;/a&gt; - to create my own classification model. I used different data but the basic outline of datasets was used. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It was important for my data type to shuffle the data and then create the training and testing sets. The problem however comes as a result of the shuffling.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When I train my model with the shuffled train set I get a +- 80% accuracy for train and +- 70% accuracy for the test set. I then want to input all the data (i.e. the set that made the training and test set) into the model to view the fully predicted output of this data set that I have. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If this data set is shuffled as the training and testing set was I get an accuracy of around 77% which is as expected but then if I input the unshuffled data (as I required to view the predictions) I get a 45% accuracy. How is this possible?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I assume it's due to the fact that the model is learning incorrectly and that it learns that the order of the data points plays a role in the predicting of those data points. But this shouldn't be happening as I am simply trying to (like the mnist example) predict each data point separately. This could be a mini-batch training problem.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So I ask, in the example mentioned above, using data sets and batches to train, does the model learn from the average of all the data points in the mini-batch or does it think one mini-batch is one data point and learn in that manner (which would mean order matters of the data)?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Or if there are any other suggestions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks &lt;/p&gt;&#xA;" OwnerUserId="15789" LastActivityDate="2018-10-13T12:36:19.760" Title="TensorFlow batch learning" Tags="&lt;deep-learning&gt;&lt;training&gt;&lt;tensorflow&gt;" AnswerCount="3" CommentCount="1" />
	<row Id="7935" PostTypeId="1" CreationDate="2018-09-12T12:05:11.227" Score="4" ViewCount="256" Body="&lt;p&gt;I am making a machine learning program for time series data analysis and using NEAT could help the work. I started to learn TensorFlow not long ago but it seems that the computational graphs in TensorFlow are usually fixed. Is there tools in TensorFlow to help build a dynamically evolving neural network? Or something like PyTorch would be a better alternative? Thanks.&lt;/p&gt;&#xA;" OwnerUserId="18102" LastEditorUserId="10135" LastEditDate="2018-10-18T03:14:37.643" LastActivityDate="2018-10-18T03:14:37.643" Title="Can neuro-evolution of augmenting topologies (NEAT) neural networks be built in TensorFlow?" Tags="&lt;python&gt;&lt;tensorflow&gt;&lt;neat&gt;&lt;programming-languages&gt;&lt;topology&gt;" AnswerCount="2" CommentCount="0" />
	<row Id="8188" PostTypeId="1" AcceptedAnswerId="8191" CreationDate="2018-09-30T17:52:52.947" Score="4" ViewCount="2869" Body="&lt;p&gt;I made my first neural net in C++ without any libraries. It was a net to recognize numbers from the MNIST dataset. In a 784 - 784 - 10 net with sigmoid function and 5  epochs with each 60000 samples, it took about 2 hours to train. It was probably slow anyways, because I trained it on a laptop and I used classes for Neurons and Layers.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To be honest, I've never used Tensor Flow, so I wanted to know how the performance of my net would be compared to the same in Tensor Flow. Not to specific but just a rough aproximation.&lt;/p&gt;&#xA;" OwnerUserId="17103" LastActivityDate="2018-10-01T09:51:46.657" Title="How fast is TensorFlow compared to self written neural nets?" Tags="&lt;neural-networks&gt;&lt;tensorflow&gt;" AnswerCount="2" CommentCount="0" FavoriteCount="2" />
	<row Id="8578" PostTypeId="1" CreationDate="2018-10-22T09:31:20.077" Score="0" ViewCount="51" Body="&lt;p&gt;The Levenshtein algorithm and some ratio and proportion may handle this use case.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Based on the pre-defined sequence of statements, such as &quot;I have a dog&quot;, &quot;I own a car&quot; and many more, I must determine if an another input statement such as &quot;I have a cat&quot; is the same or how much percentage does the input statement is most likely equal to the pre-defined statements.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;For Example:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Predefined statements: &quot;I have a dog&quot;, &quot;I own a car&quot;, &quot;You think you are smart&quot;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Input statements and results:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;I have a dog - 100% (because it has exact match), I have a cat - ~75% (because it was almost the same except for the animal, think - ~10% (because it was just a small part of the third statement), bottle - 0% (because it has no match at all)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;The requirement is that TensorFlow be used rather than Java, which is the language I know, so any help with what to look at to get started would be helpful.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My plan was to use the predefined statements as the train_data, and to output only the accuracy during the prediction, but i don't know what model to use, please help thanks! even just guide me with the architecture and I will try to implement it, thanks in advance!&lt;/p&gt;&#xA;" OwnerUserId="19229" LastEditorUserId="18663" LastEditDate="2018-10-26T18:47:04.143" LastActivityDate="2018-11-25T19:01:05.190" Title="Tensorflow - finding the right model on my use case" Tags="&lt;ai-design&gt;&lt;tensorflow&gt;&lt;getting-started&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="7749" PostTypeId="1" AcceptedAnswerId="7750" CreationDate="2018-08-29T08:01:14.643" Score="3" ViewCount="50" Body="&lt;p&gt;Tensorflow/Lucid is able to visualize what a &quot;channel&quot; of a layer of a neural network (image recognition, Inception-v1) responds to. Even after studying the tutorial, the source code, the three research papers on lucid and comments by the authors on Hacker News, I'm still not clear on how &quot;channels&quot; are supposed to be defined and individuated. Can somebody shed some light on this? Thank you.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://github.com/tensorflow/lucid&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://github.com/tensorflow/lucid&lt;/a&gt; &lt;br/&gt;&#xA;&lt;a href=&quot;https://news.ycombinator.com/item?id=15649456&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://news.ycombinator.com/item?id=15649456&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="17807" LastEditorUserId="17221" LastEditDate="2018-08-29T16:49:18.313" LastActivityDate="2018-08-29T16:55:14.630" Title="What exactly does &quot;channel&quot; refer to in tensorflow/lucid?" Tags="&lt;tensorflow&gt;&lt;computer-vision&gt;" AnswerCount="1" CommentCount="4" />
	<row Id="3861" PostTypeId="1" AcceptedAnswerId="3866" CreationDate="2017-08-22T13:45:38.643" Score="4" ViewCount="532" Body="&lt;p&gt;I wonder on the following concept: a given neural network gets two audio input (preferably music) and gives a real number between 0 and 1 which describes &quot;similarity&quot; between the second and the first track.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As far as my understanding of neural networks go, the problem fits the concept of NNs, as pattern recognition in music can help determine similarities and discrepancies in audio, see voice recognition.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, due to the nature of long and complex inputs, and the vague nature of learning datasets (how similar, for instance, Diana Ross: It's your move, and the vaporwave legend Floral Shoppe exactly are? 0.9? 0.6? other?), such a network would be extremely slow and convoluted.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is it possible today to build and train such a model? If yes, how would it look like?&lt;/p&gt;&#xA;" OwnerUserId="1270" LastActivityDate="2017-08-23T14:56:34.697" Title="Is music/sound similarity comparison feasible on neural networks?" Tags="&lt;neural-networks&gt;&lt;deep-learning&gt;&lt;pattern-recognition&gt;&lt;voice-recognition&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
	<row Id="5551" PostTypeId="1" CreationDate="2018-03-07T04:23:28.307" Score="0" ViewCount="31" Body="&lt;p&gt;Let us for these purposes say with are working with any feed forward neural network.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let us also say, that we know beforehand that certain portion of our dataset arsignificantly more impactful or important to our underlying representation. Is there anyway to add that “weighting” to our data?&lt;/p&gt;&#xA;" OwnerUserId="9608" LastActivityDate="2018-03-09T09:29:08.607" Title="A way to give more weight to particular data?" Tags="&lt;training&gt;&lt;datasets&gt;" AnswerCount="2" CommentCount="3" />
	<row Id="84" PostTypeId="1" CreationDate="2016-08-02T16:55:37.050" Score="8" ViewCount="149" Body="&lt;p&gt;Some programs do exhaustive searches for a solution while others do heuristic searches.  For example, in chess, the search for the best next move tends to be more exhaustive in nature whereas in go, the search for the best next move tends to be more heuristic in nature due to the much larger search space.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is the technique of brute force exhaustive searching for a good answer considered to be AI or is it generally required that heuristic algorithms be used before being deemed AI?  If so, is the chess playing computer beating a human professional seen as a meaningful milestone?&lt;/p&gt;&#xA;" OwnerUserId="55" LastEditorUserId="8" LastEditDate="2016-08-09T18:57:04.447" LastActivityDate="2018-02-20T13:10:31.087" Title="Are methods of exhaustive search considered to be AI?" Tags="&lt;gaming&gt;&lt;search&gt;&lt;chess&gt;&lt;heuristics&gt;" AnswerCount="5" CommentCount="2" />
	<row Id="1492" PostTypeId="1" AcceptedAnswerId="1495" CreationDate="2016-08-09T12:00:06.583" Score="0" ViewCount="429" Body="&lt;p&gt;We can read on wiki page that in March 2016 AlphaGo AI lost its game (1 of 5) to Lee Sedol, a professional Go player. One &lt;a href=&quot;http://www.bbc.co.uk/news/technology-36558829&quot; rel=&quot;nofollow&quot;&gt;article&lt;/a&gt; cite says:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;AlphaGo lost a game and we as researchers want to explore that and find out what went wrong. We need to figure out what its weaknesses are and try to improve it.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Have researchers already figured it out what went wrong?&lt;/p&gt;&#xA;" OwnerUserId="8" LastEditorUserId="130" LastEditDate="2016-08-09T15:45:35.477" LastActivityDate="2016-08-09T15:45:35.477" Title="Why did AlphaGo lose its Go game?" Tags="&lt;gaming&gt;&lt;deepmind&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="1" />
	<row Id="1815" PostTypeId="1" CreationDate="2016-08-31T14:13:18.663" Score="9" ViewCount="124" Body="&lt;p&gt;I want to start with a scenario that got me thinking about how well MCTS can perform:&#xA;Let's assume there is a move that is not yet added to the search tree. It is some layers/moves too deep. But if we play this move the game is basically won. However let's also assume that &lt;em&gt;all&lt;/em&gt; moves that could be taken instead at the given game state are very very bad. For the sake of argument let's say there are 1000 possible moves and only one of them is good (but very good) and the rest is very bad. Wouldn't MCTS fail to recognize this and &lt;em&gt;not&lt;/em&gt; grow the search tree towards this move and also rate this subtree very badly? &#xA;I know that MCTS eventually converges to minimax (and eventually it will build the whole tree if there is enough memory). Then it should know that the move is good even though there are many bad possiblities. But I guess in practice this is not something that one can rely on.&#xA;Maybe someone can tell me if this is a correct evaluation on my part.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Apart from this special scenario I'd also like to know if there are other such scenarios where MCTS will perform badly (or extraordinary well). &lt;/p&gt;&#xA;" OwnerUserId="1949" LastActivityDate="2017-06-04T16:40:40.950" Title="Monte Carlo Tree Search: What kind of moves can easily be found and what kinds make trouble?" Tags="&lt;gaming&gt;&lt;monte-carlo-search&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="2117" PostTypeId="1" AcceptedAnswerId="2181" CreationDate="2016-10-11T01:09:20.780" Score="1" ViewCount="504" Body="&lt;p&gt;I'm interested mostly in the application of AI in gaming; in case this adjusts the way you answer, but general answers are more than welcome as well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was reading up on Neural Networks and combining them with Genetic Algorithms; my high-level understanding is that the Neural Networks are used to produce a result from the inputs, and the Genetic Algorithm is employed to constantly adjust the weights in the Neural Network until a good answer is found.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The concept of a Genetic Algorithm randomly mutating the weights on the inputs to a Neural Network makes sense to me; but I don't understand where this would be applied in respect to gaming.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, if I had some simple enemy AI that I want to have adapt to the players play-style, is this a good opportunity to implement the AI as a Genetic-Algorithm combined with a Neural Network?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With these different suitable applications, how does one go about deciding how to encode the problem in such a way that it can be mutated by the Genetic Algorithm and serve as suitable on/off inputs to a Neural Network (actually, are Neural Networks always designed as on off signals?)?&lt;/p&gt;&#xA;" OwnerUserId="2819" LastActivityDate="2016-10-19T14:34:23.680" Title="What sort of game problems can Neural-Networks and Genetic Algorithms solve, and how are they typically implemented?" Tags="&lt;neural-networks&gt;&lt;gaming&gt;&lt;genetic-algorithms&gt;" AnswerCount="3" CommentCount="0" />
	<row Id="2176" PostTypeId="1" CreationDate="2016-10-18T15:45:23.340" Score="1" ViewCount="583" Body="&lt;p&gt;I am creating a snake game in Unity and I would like to implement AI snakes that wander around the globe while avoiding collision with the other snakes on the globe, and if possible I would also like to make the AI snakes purposefully trap other snakes so that the other snakes would collide and die. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/aQ61J.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/aQ61J.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The AI snakes must meet the following requirements:  &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They must move in a certain way. A snake is controlled by a user using the arrow keys on a keyboard, therefor I would also like the AI snakes to move using this form of input.&lt;/li&gt;&#xA;&lt;li&gt;The AI snakes must move on a sphere&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;As I know, creating Artificial Intelligence is not an easy task and I would like to know if there are some open source projects that I can use for accomplishing this task.&lt;/p&gt;&#xA;" OwnerUserId="3105" LastActivityDate="2016-10-20T11:56:55.070" Title="How to create an AI snake for a video game?" Tags="&lt;gaming&gt;" AnswerCount="4" CommentCount="3" FavoriteCount="1" />
	<row Id="2555" PostTypeId="1" AcceptedAnswerId="2556" CreationDate="2016-12-27T14:47:59.430" Score="2" ViewCount="118" Body="&lt;p&gt;With tools like open AI will we be able to teach an AI to build its own decks? build a deck from a limited pool? or draft? evaluate the power level of a card? &lt;/p&gt;&#xA;" OwnerUserId="4466" LastActivityDate="2016-12-28T00:21:53.347" Title="How close are we to having an AI that can play Magic: The Gathering objectively well?" Tags="&lt;gaming&gt;&lt;training&gt;" AnswerCount="1" CommentCount="3" />
	<row Id="4048" PostTypeId="1" CreationDate="2017-09-17T20:12:20.860" Score="4" ViewCount="1117" Body="&lt;p&gt;I am currently writing an engine to play a card game, as there is no engine yet for this particular game.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am hoping to be able to introduce a neural net to the game afterwards, and have it learn to play the game.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm writing the engine in such a way that is helpful for an AI player. There are choice points, and at those points, a list of valid options is presented. Random selection would be able to play the game (albeit not well).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have learned a lot about neural networks (mostly NEAT and HyperNEAT) and even built my own implementation. I am still unsure how best build an AI that can take into account all the variables in one of these types of games. Is there a common approach? I know that Keldon wrote a good AI for RftG which has a decent amount of complexity, I am not sure how he managed to build such an AI.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any advice? Is it feasible? Are there any good examples of this? How were the inputs mapped?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT: I have looked online and learned how neural networks work and usually how they pertain to image recognition or steering a simple agent. I'm not sure if or how I would apply it to making selections with cards which have a complex synergy. Any direction towards what I should be looking into would be greatly appreciated.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;About the game: The game is similar to Magic: The Gathering. There is a commander which has health and abilities. Players have an energy pool which they use to put minions and spells on the board. Minions have health, attack values, costs, etc. Cards also have abilities, these are not easily enumerated. Cards are played from the hand, new cards are drawn from a deck. These are all aspects it would be helpful for the neural network to consider. &lt;/p&gt;&#xA;" OwnerUserId="9660" LastEditorUserId="1671" LastEditDate="2018-03-05T19:43:41.283" LastActivityDate="2018-03-06T16:10:26.510" Title="Teach a Neural Network to play a card game" Tags="&lt;neural-networks&gt;&lt;machine-learning&gt;&lt;gaming&gt;&lt;neat&gt;" AnswerCount="3" CommentCount="3" FavoriteCount="2" />
	<row Id="4672" PostTypeId="1" CreationDate="2017-12-06T19:00:23.507" Score="0" ViewCount="219" Body="&lt;p&gt;Can an AI learn to play chess if you give it nothing but &quot;the goal is to win&quot; as starting criteria? If not, what is the minimum information the AI would need to be &quot;seeded&quot; with in order to learn to play chess?  What techniques could be used to create an AI that learns to play chess independently? &lt;/p&gt;&#xA;" OwnerUserId="7801" LastEditorUserId="33" LastEditDate="2017-12-11T20:13:41.930" LastActivityDate="2017-12-29T07:31:46.447" Title="Can an AI learn how to play chess without instructions?" Tags="&lt;gaming&gt;&lt;game-ai&gt;&lt;chess&gt;&lt;combinatorial-games&gt;" AnswerCount="6" CommentCount="2" />
	<row Id="5432" PostTypeId="1" AcceptedAnswerId="5434" CreationDate="2018-02-25T16:28:49.717" Score="1" ViewCount="72" Body="&lt;p&gt;If the game had a variable speed and was essential in evolution/gaining score(IDK AI terminologies). Would the AI be able to figure out when to slow down and speed up?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If it is able to solve the problem or complete the level, will it have an equation to relating acceleration, or perhaps a number on when to speed up and down. What if the game environment was dynamic?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Can you even teach math to an AI?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;PS: I'm not sure if I should ask separate question?&lt;/p&gt;&#xA;" OwnerUserId="8433" LastActivityDate="2018-02-26T17:41:03.490" Title="Can a game AI learn the concept of acceleration?" Tags="&lt;machine-learning&gt;&lt;game-ai&gt;" AnswerCount="2" CommentCount="0" />
	<row Id="5619" PostTypeId="1" CreationDate="2018-03-10T13:03:40.733" Score="0" ViewCount="11" Body="&lt;p&gt;I'm developing a millitary game and I want soldiers to place themselves in specific order, when commander orders. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;How can I do this? Should agents learn somehow how to achieve given order or there exist other way?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm new in AI, so I do not really know how can I accomplish my goal. &#xA;Thanks for every advice.&lt;/p&gt;&#xA;" OwnerUserId="13237" LastActivityDate="2018-03-10T22:08:54.690" Title="Placing agents in a specific order on demand" Tags="&lt;machine-learning&gt;&lt;game-ai&gt;" AnswerCount="1" CommentCount="2" />
	<row Id="3345" PostTypeId="1" CreationDate="2017-05-19T18:38:45.073" Score="6" ViewCount="1340" Body="&lt;p&gt;I'm wondering how to train a neural network for a round based board game like, tic-tac-toe, chess, risk or any other round based game.&#xA;Getting the next move by inference seems to be pretty straight forward, by feeding the game state as input and using the output as the move for the current player.&#xA;However training an AI for that purpose doesn't appear to be that straight forward, because:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;There might not be a rating if a single move is good or not, so training of single moves doesn't seem to be the right choice&lt;/li&gt;&#xA;&lt;li&gt;Using all game states (inputs) and moves (outputs) of the whole game to train the neural network, doesn't seem to be the right choice as not all moves within a lost game might be bad&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;So I'm wondering how to train a neural network for a round based board game?&#xA;I would like to create a neural network for tic-tac-toe using tensorflow.&lt;/p&gt;&#xA;" OwnerUserId="7321" LastActivityDate="2017-11-14T21:32:55.480" Title="How to train a neural network for a round based board game?" Tags="&lt;training&gt;&lt;tensorflow&gt;&lt;game-ai&gt;" AnswerCount="3" CommentCount="0" FavoriteCount="2" />
	<row Id="5570" PostTypeId="1" CreationDate="2018-03-08T06:10:00.340" Score="1" ViewCount="29" Body="&lt;p&gt;In two player games, the exact value of the evaluation function doesn't matter as long as it's bigger for better positions. However, for learning, it's customary when it does change when the best move gets made. This way, the learning can minimize the difference between the directly computed value &lt;code&gt;f(0, p)&lt;/code&gt; of a position &lt;code&gt;p&lt;/code&gt; and the value obtained from &lt;code&gt;n&lt;/code&gt; step minimax &lt;code&gt;f(n, p)&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I'm missing here is a way to direct the evaluation function to actually winning. For example, a &lt;em&gt;perfect&lt;/em&gt; evaluation function for a won position in chess would always return &lt;code&gt;+1&lt;/code&gt; without any hint how to progress towards checkmate. In a chess variant without the fifty-move limit, it could play useless turns forever.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I guess, this is a rather theoretical problem as we won't ever have such a good function, but I wonder &lt;em&gt;if there's a way to avoid it&lt;/em&gt;?&lt;/p&gt;&#xA;" OwnerUserId="12053" LastActivityDate="2018-03-08T07:53:38.680" Title="Game AI evaluation function and making progress towards winning" Tags="&lt;reinforcement-learning&gt;&lt;gaming&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="3345" PostTypeId="1" CreationDate="2017-05-19T18:38:45.073" Score="6" ViewCount="1340" Body="&lt;p&gt;I'm wondering how to train a neural network for a round based board game like, tic-tac-toe, chess, risk or any other round based game.&#xA;Getting the next move by inference seems to be pretty straight forward, by feeding the game state as input and using the output as the move for the current player.&#xA;However training an AI for that purpose doesn't appear to be that straight forward, because:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;There might not be a rating if a single move is good or not, so training of single moves doesn't seem to be the right choice&lt;/li&gt;&#xA;&lt;li&gt;Using all game states (inputs) and moves (outputs) of the whole game to train the neural network, doesn't seem to be the right choice as not all moves within a lost game might be bad&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;So I'm wondering how to train a neural network for a round based board game?&#xA;I would like to create a neural network for tic-tac-toe using tensorflow.&lt;/p&gt;&#xA;" OwnerUserId="7321" LastActivityDate="2017-11-14T21:32:55.480" Title="How to train a neural network for a round based board game?" Tags="&lt;training&gt;&lt;tensorflow&gt;&lt;game-ai&gt;" AnswerCount="3" CommentCount="0" FavoriteCount="2" />
	<row Id="3345" PostTypeId="1" CreationDate="2017-05-19T18:38:45.073" Score="6" ViewCount="1340" Body="&lt;p&gt;I'm wondering how to train a neural network for a round based board game like, tic-tac-toe, chess, risk or any other round based game.&#xA;Getting the next move by inference seems to be pretty straight forward, by feeding the game state as input and using the output as the move for the current player.&#xA;However training an AI for that purpose doesn't appear to be that straight forward, because:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;There might not be a rating if a single move is good or not, so training of single moves doesn't seem to be the right choice&lt;/li&gt;&#xA;&lt;li&gt;Using all game states (inputs) and moves (outputs) of the whole game to train the neural network, doesn't seem to be the right choice as not all moves within a lost game might be bad&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;So I'm wondering how to train a neural network for a round based board game?&#xA;I would like to create a neural network for tic-tac-toe using tensorflow.&lt;/p&gt;&#xA;" OwnerUserId="7321" LastActivityDate="2017-11-14T21:32:55.480" Title="How to train a neural network for a round based board game?" Tags="&lt;training&gt;&lt;tensorflow&gt;&lt;game-ai&gt;" AnswerCount="3" CommentCount="0" FavoriteCount="2" />
	<row Id="4984" PostTypeId="1" AcceptedAnswerId="4985" CreationDate="2018-01-13T03:48:19.280" Score="3" ViewCount="39" Body="&lt;p&gt;I have some episodic datasets extracted from a turn-based RTS game in which the current actions leading to the next state doesn’t determine the final solution/outcome of the episode. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The learning is expected to terminate at a final state/termination condition (when it wins or losses) for each episode and then move on to the next number of episodes in the dataset. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have being looking into Q learning, Monte Carlo and SARSA but I am confused about which one is best applicable. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If any of the mentioned algorithm is implemented, can a reward of zero be given in preliminary states before termination state of each episodes at which it will be rewarded with a positive/negative (win/loss) value?&lt;/p&gt;&#xA;" OwnerUserId="12081" LastActivityDate="2018-01-13T20:28:09.730" Title="Which Reinforcement Learning algorithms are efficient for episodic problems?" Tags="&lt;reinforcement-learning&gt;&lt;game-ai&gt;&lt;unsupervised-learning&gt;&lt;monte-carlo-search&gt;&lt;q-learning&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="4990" PostTypeId="1" CreationDate="2018-01-13T16:20:28.183" Score="1" ViewCount="48" Body="&lt;p&gt;I play a racing game called Need For Madness ( some gameplay: &lt;a href=&quot;https://www.youtube.com/watch?v=NC5uFZ-t0A8&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://www.youtube.com/watch?v=NC5uFZ-t0A8&lt;/a&gt; ). NFM is a racing game, where the player can choose different cars and race and crash the other cars, and you can play on different tracks too. The game has a fixed frame rate, so you can assume that the same sequence of button presses will always arrive at the exact same position, rotation, velocity, etc. of the car.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I want to make a bot which could race faster than I can. What would be the best way to go about doing this? Is this problem even suited for deep learning?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was thinking I could train a neural network where the input would be the current world state (position of the player, position of the checkpoints you have to through and all the obstacles), and the output would be an array of booleans, one for each button. During a race, I could then keep forward propagating from the input to the booleans. However, I'm not so sure what I would do after the race is over. How do I back propagate after the race to make the NN be less likely to make bad moves?&lt;/p&gt;&#xA;" OwnerUserId="12091" LastEditorUserId="1671" LastEditDate="2018-01-17T00:41:47.397" LastActivityDate="2018-01-17T00:41:47.397" Title="How to teach an AI to race optimally in a racing game?" Tags="&lt;neural-networks&gt;&lt;deep-learning&gt;&lt;game-ai&gt;&lt;pathfinding&gt;" AnswerCount="0" CommentCount="2" FavoriteCount="1" />
	<row Id="5067" PostTypeId="1" CreationDate="2018-01-19T11:32:39.073" Score="2" ViewCount="89" Body="&lt;p&gt;I am currently writing an engine to play a card game and I would like for an ANN to learn how to play the game. The game is currently playable, and I believe for this game a deep-recurrent-Q-network with a reinforcement learning approach is the way to go. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, I don't know what type of layers I should use, I found some examples of Atari games solved through ANN, but their layers are CNN (convolutional), which are better for image processing. I don't have an image to feed the NN, only a state composed of a tensor with cards in the player's own hand and cards on the table. And the output of the NN should be a card or the action 'End Turn'.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm currently trying to use TensorFlow but I'm open to any library that can work with NN. Any type of help or suggestion would be greatly appreciated!      &lt;/p&gt;&#xA;" OwnerUserId="12217" LastEditorUserId="12217" LastEditDate="2018-01-23T14:25:09.793" LastActivityDate="2018-02-22T15:16:48.663" Title="What layers to use in a Neural Network for card game" Tags="&lt;neural-networks&gt;&lt;deep-learning&gt;&lt;reinforcement-learning&gt;&lt;tensorflow&gt;&lt;game-ai&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
	<row Id="5169" PostTypeId="1" CreationDate="2018-01-28T07:56:26.750" Score="1" ViewCount="107" Body="&lt;p&gt;A human player plays limited games compared to a system that undergoes millions of iterations. Is it really fair to compare AlphaGo with the world #1 player when we know experience increases with the increase in number of games played?&lt;/p&gt;&#xA;" OwnerUserId="12394" LastEditorUserId="1671" LastEditDate="2018-01-30T23:52:47.607" LastActivityDate="2018-02-02T08:27:22.170" Title="Is it fair to compare AlphaGo with a Human player?" Tags="&lt;game-ai&gt;&lt;philisophy&gt;&lt;alphago&gt;" AnswerCount="4" CommentCount="1" />
	<row Id="1320" PostTypeId="1" AcceptedAnswerId="1324" CreationDate="2016-08-04T15:25:37.293" Score="1" ViewCount="129" Body="&lt;p&gt;Artificial intelligence is present in many games, both current and older games. How can such intelligence understand what to do? I mean, how can it behave like a human in a game, allowing you to play against itself, or that AI plays against itself?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In games like Age of Empires, for example.&lt;/p&gt;&#xA;" OwnerUserId="173" LastEditorUserId="145" LastEditDate="2016-08-09T20:36:48.157" LastActivityDate="2016-08-13T03:12:52.877" Title="How does artificial intelligence work in games?" Tags="&lt;gaming&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="2" ClosedDate="2016-08-15T14:22:03.317" />
	<row Id="4937" PostTypeId="1" CreationDate="2018-01-07T16:07:12.053" Score="-1" ViewCount="41" Body="&lt;p&gt;There is more information recently that AlphaZero has been trained to be the best chess program after 4 hours of learning (in chess). I am wondering how the AI network could have been modeled for this program?&lt;/p&gt;&#xA;" OwnerUserId="11994" LastEditorUserId="1671" LastEditDate="2018-01-07T21:25:00.477" LastActivityDate="2018-01-08T01:04:52.253" Title="How the AI network can be modeled for AlphaZero?" Tags="&lt;deep-learning&gt;&lt;ai-design&gt;&lt;game-ai&gt;&lt;combinatorial-games&gt;" AnswerCount="2" CommentCount="5" />
	<row Id="5174" PostTypeId="1" CreationDate="2018-01-28T09:53:44.280" Score="2" ViewCount="42" Body="&lt;p&gt;I read about minimax, then alpha-beta pruning and then about iterative deepening. Iterative deepening coupled with alpha-beta pruning proves to quite efficient as compared alpha-beta alone.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have implemented a game agent that uses iterative deepening with alpha-beta pruning. Now I want to beat myself. What can I do to go deeper? Like alpha-beta pruning cut the moves, what other small change could be implemented that can beat my older AI?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My aim to go deeper than my current AI. If you want to know about the game, here is a brief summary:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are two players, four game pieces and a 7-by-7 grid of squares. At the beginning of the game, the first player places both the pieces on any two different squares. From that point on, the players alternate turns moving both the pieces like a Queen in chess (any number of open squares vertically, horizontally, or diagonally). When the piece is moved, the square that was previously occupied is blocked. That square can not be used for the remainder of the game. The piece can not move through blocked squares. The first player who is unable to move any one of the queens loses.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So my aim is to cut the unwanted nodes and search deeper.&lt;/p&gt;&#xA;" OwnerUserId="12384" LastEditorUserId="1671" LastEditDate="2018-01-30T23:48:58.257" LastActivityDate="2018-03-09T18:16:52.280" Title="What else can boost iterative deepening with alpha beta pruning?" Tags="&lt;game-ai&gt;&lt;combinatorial-games&gt;&lt;combinatorics&gt;" AnswerCount="3" CommentCount="1" />
	<row Id="2980" PostTypeId="1" AcceptedAnswerId="2981" CreationDate="2017-03-14T14:26:07.403" Score="8" ViewCount="858" Body="&lt;p&gt;I want to create an AI which can play five-in-a-row/gomoku. As I mentioned in the title I want to use Reinforcement Learning for this. I use Policy Gradient method namely REINFORCE with baseline. For the value and policy function aproximation I use a Neural Network. It has convolutional and fully connected layers. All of the layers, except for the output, are shared. The policy's output layer has 8x8=64(the size of the board) output unit and softmax on them. So it is stochastic. But what if the network produces a very high probability for an invalid move? An invalid move is when the agent wants to check a square which has one &quot;X&quot; or &quot;O&quot; in it. I think it can stuck in that game state. Could you recommend any solution for this problem?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My gusse: Use Actor-Critic method. For an invalid move, give a negative reward and pass the turn to the opponent.&lt;/p&gt;&#xA;" OwnerUserId="6019" LastEditorUserId="1671" LastEditDate="2017-12-22T17:40:38.947" LastActivityDate="2018-01-12T03:49:42.523" Title="How to handle invalid moves in Reinforcement Learning?" Tags="&lt;machine-learning&gt;&lt;reinforcement-learning&gt;&lt;game-ai&gt;&lt;combinatorial-games&gt;" AnswerCount="3" CommentCount="0" FavoriteCount="1" />
	<row Id="4095" PostTypeId="1" CreationDate="2017-09-23T16:32:35.447" Score="3" ViewCount="45" Body="&lt;p&gt;After reading this &lt;a href=&quot;https://pure.york.ac.uk/portal/files/13014166/CowlingPowleyWhitehouse2012.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;paper&lt;/a&gt; about Monte Carlo methods for imperfect information games with elements of uncertainty, I couldn't understand the application of determinization step in &lt;a href=&quot;https://gist.github.com/kjlubick/8ea239ede6a026a61f4d&quot; rel=&quot;nofollow noreferrer&quot;&gt;author's implementation&lt;/a&gt; of the algorithm for Knockout game.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Determinization is defined as transformation from instance of imperfect information game to instance of perfect one. It means that all players should see the cards of each other after the determinization step. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why can't the players see the cards of each other in the code above?&lt;/p&gt;&#xA;" OwnerUserId="9797" LastEditorUserId="1671" LastEditDate="2017-09-25T17:32:31.247" LastActivityDate="2017-09-25T17:32:31.247" Title="Determinization step in Information Set Monte Carlo Tree Search" Tags="&lt;monte-carlo-search&gt;&lt;combinatorial-games&gt;&lt;imperfect-information&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="4482" PostTypeId="1" AcceptedAnswerId="4483" CreationDate="2017-11-10T15:54:48.073" Score="7" ViewCount="233" Body="&lt;p&gt;I invented a chess-like boardgame and I built an engine so that it can play autonomously. The engine is basically a decision tree. It's composed by:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;A search function that at each node finds all possible legal moves&lt;/li&gt;&#xA;&lt;li&gt;An evaluation function that assigns a numerical value to the board position (positive means first players is gaining the upper hand, negative means the second player is winning instead)&lt;/li&gt;&#xA;&lt;li&gt;An alphabeta pruning negamax algorithm&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;The main problem about this engine is that the optmization of the evaluation function is really tricky. I don't know which factors to consider and which weights to put. The only way I see to improve the engine is to iterate games trying each time different combinations of factors and weights. However it computationally seems a very tough feat (Can I backpropagate without using deeplearning?).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like to use reinforcement learning to make the engine improve by playing against itself. I have been reading about the topic but I am still quite confused.&#xA;What other reward is there in a game a part the win-or-lose output (1 or 0)?&#xA;If I use other rewards, like the output from the evaluation function at each turn, how can I implement it? How do I modify the evaluation function to give better rewards iteration after iteration?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am new in this field, so let me know if I'm misunderstanding any part of the process.  All input is appreciated!&lt;/p&gt;&#xA;" OwnerUserId="10813" LastEditorUserId="1671" LastEditDate="2017-11-12T22:34:04.263" LastActivityDate="2017-11-12T22:34:04.263" Title="Reinforcement learning without neural network" Tags="&lt;reinforcement-learning&gt;&lt;game-ai&gt;&lt;game-theory&gt;&lt;combinatorial-games&gt;&lt;negamax&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="2" />
	<row Id="4497" PostTypeId="1" CreationDate="2017-11-12T07:03:09.540" Score="2" ViewCount="88" Body="&lt;p&gt;I am trying to find a good evaluation function for a game with:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A 7x7 tile board&lt;/li&gt;&#xA;&lt;li&gt;2 players, given equal number(&gt;=3 currently undetermined) of &lt;em&gt;stones&lt;/em&gt;&#xA;placed randomly on the tiles&lt;/li&gt;&#xA;&lt;li&gt;A turn is consisted of a player moving a &lt;em&gt;stone&lt;/em&gt; owned by that player, vertically or horizontally but &lt;em&gt;not&#xA;diagonally&lt;/em&gt; to a very next tile of itself&lt;/li&gt;&#xA;&lt;li&gt;A player loses when out of moves: a player is out of moves when every&#xA;&lt;em&gt;stone&lt;/em&gt; that player owns, has its very next tiles, except not for diagonals necessarily,  occupied either by the board edge or other&#xA;&lt;em&gt;stones&lt;/em&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Right now my evaluation function's return value increases:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;if the total moves available to the player is increasing&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;and/or&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;average distance to the middle tile of the board is decreasing&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Question:&lt;/strong&gt; Is there a better strategy? or how can I improve my evaluation function?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="10843" LastEditorUserId="10843" LastEditDate="2017-11-12T22:32:00.190" LastActivityDate="2018-02-12T14:27:16.537" Title="Evaluation Function for a Go like game" Tags="&lt;ai-design&gt;&lt;algorithm&gt;&lt;heuristics&gt;&lt;go&gt;&lt;combinatorial-games&gt;" AnswerCount="2" CommentCount="1" />
	<row Id="4725" PostTypeId="1" AcceptedAnswerId="4727" CreationDate="2017-12-12T12:14:09.153" Score="7" ViewCount="187" Body="&lt;p&gt;Currently I'm doing a project that's about creating an AI to play the game Gomoku (It's like tic tac toe, but played on a 15*15 board and requires 5 in a row to win). I have already successfully implemented a perfect tic tac toe AI using Q learning and having game states/actions stored in a table, but for a 15*15 board the possible game states become too large too implement this project.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My question is, should I use neural networks or genetic algorithms for this problem? And more specifically, how should I implement this?&lt;/p&gt;&#xA;" OwnerUserId="11537" LastActivityDate="2017-12-13T18:13:30.030" Title="Neural networks vs Genetic algorithms in games like Tic Tac Toe?" Tags="&lt;neural-networks&gt;&lt;machine-learning&gt;&lt;genetic-algorithms&gt;&lt;combinatorial-games&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="2" />
	<row Id="1358" PostTypeId="1" AcceptedAnswerId="1361" CreationDate="2016-08-05T07:03:50.110" Score="12" ViewCount="258" Body="&lt;p&gt;I have heard about this concept in a Reddit post about Alpha Go. I have tried to go through the paper and the article, but could not really make sense of the algorithm.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, can someone give an easy-to-understand explanation of how the Monte-Carlo search algorithm work and how is it being used in building game-playing AI bots?&lt;/p&gt;&#xA;" OwnerUserId="101" LastEditorUserId="101" LastEditDate="2017-05-16T04:33:03.233" LastActivityDate="2017-05-16T04:33:03.233" Title="How does &quot;Monte-Carlo search&quot; work?" Tags="&lt;gaming&gt;&lt;monte-carlo-search&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="4" />
	<row Id="1485" PostTypeId="1" AcceptedAnswerId="1523" CreationDate="2016-08-09T09:01:52.373" Score="1" ViewCount="61" Body="&lt;p&gt;For example I would like to implement transparent AI in the RTS game which doesn't offer any AI API (like old games), and I'd like to use image recognition algorithm for detecting the objects which can talks to another algorithm which is responsible for the logic.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given I'd like to use two neural networks, what are the approaches to setup the communication between them? Is it just by exporting result findings of the first algorithm (e.g. using CNN) with list of features which were found on the screen, then use it as input for another network? Or it's more complex than that, or I need to have more than two networks?&lt;/p&gt;&#xA;" OwnerUserId="8" LastEditorUserId="8" LastEditDate="2016-08-09T18:57:43.590" LastActivityDate="2016-08-10T11:24:13.367" Title="How to separate image recognition from logic?" Tags="&lt;neural-networks&gt;&lt;convolutional-neural-networks&gt;&lt;gaming&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="5570" PostTypeId="1" CreationDate="2018-03-08T06:10:00.340" Score="2" ViewCount="147" Body="&lt;p&gt;In two player games, the exact value of the evaluation function doesn't matter as long as it's bigger for better positions. However, for learning, it's customary when it does change when the best move gets made. This way, the learning can minimize the difference between the directly computed value &lt;code&gt;f(0, p)&lt;/code&gt; of a position &lt;code&gt;p&lt;/code&gt; and the value obtained from &lt;code&gt;n&lt;/code&gt; step minimax &lt;code&gt;f(n, p)&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I'm missing here is a way to direct the evaluation function to actually winning. For example, a &lt;em&gt;perfect&lt;/em&gt; evaluation function for a won position in chess would always return &lt;code&gt;+1&lt;/code&gt; without any hint how to progress towards checkmate. In a chess variant without the fifty-move limit, it could play useless turns forever.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I guess, this is a rather theoretical problem as we won't ever have such a good function, but I wonder &lt;em&gt;if there's a way to avoid it&lt;/em&gt;?&lt;/p&gt;&#xA;" OwnerUserId="12053" LastActivityDate="2018-08-05T11:54:31.857" Title="Game AI evaluation function and making progress towards winning" Tags="&lt;reinforcement-learning&gt;&lt;gaming&gt;" AnswerCount="2" CommentCount="0" />
	<row Id="5833" PostTypeId="1" AcceptedAnswerId="5834" CreationDate="2018-03-29T04:16:23.857" Score="5" ViewCount="180" Body="&lt;p&gt;When Google researchers created AlphaGo, how did they simulate the game of Go? If I wanted to take the same approach to other games, like Risk, how would I go about coding the rules of the game? Is there a programming package, book, or general technique for coding the rules of a game for deep learning?&lt;/p&gt;&#xA;" OwnerUserId="14631" LastActivityDate="2018-04-06T06:04:48.497" Title="How does one code the rules of a boardgame for deep learning?" Tags="&lt;deep-learning&gt;&lt;gaming&gt;&lt;alphago&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="1" />
	<row Id="5919" PostTypeId="1" CreationDate="2018-04-06T06:09:29.033" Score="1" ViewCount="178" Body="&lt;p&gt;When training on large neural network, how to deal with the case that the gradients are too small to have any impact?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;FYI, I have an RNN, which has multiple LSTM cells and each cell has hundreds of neurons. Each training data has thousands of steps, so the RNN would unroll thousands of times. When I print out all gradients, they are very small, like e-20 of the variable values. Therefore the training does not change the variable values at all. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;BTW, I think this is not an issue of vanishing gradients. Note that the gradients are uniformly small from the beginning to the end.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any suggestion to overcome this issue?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thank!&lt;/p&gt;&#xA;" OwnerUserId="14816" LastActivityDate="2018-08-12T03:01:46.073" Title="Too small gradient on large neural network" Tags="&lt;gaming&gt;" AnswerCount="2" CommentCount="3" />
	<row Id="6748" PostTypeId="1" CreationDate="2018-06-14T02:44:04.580" Score="3" ViewCount="161" Body="&lt;p&gt;I'm a professional game developer investigating the potential for using reinforcement learning to build strategy game AI opponents that have more creative behavior compared to traditional techniques like behavior trees. I have a few questions I've bolded below, any thoughts would be helpful, and could save me from pursuing dead ends.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I created a very boring and tiny game as a test case. Two players each control a fleet of ships, each ship has health and can fire on one other ship each turn dealing some damage. The player and his opponent assigns orders to their respective ships, telling them which target to attack, and then the turn is resolved. Ships with 0 health are removed from the board. The player that loses all their ships first loses the game.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Assuming I was using TensorFlow, at a very high level I need to:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A) Create a training program that outputs a trained graph to a file. The training program will need to map gamestates into tensors, feed the tensors through the graph to produce actions, execute actions on the gamestate to generate a new state, and evaluate the reward function for the new state. Repeat a bunch.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;B) Take the graph created in #1, load it at the game runtime, and use the graph to generate intelligent actions from real gamestates during the Player vs AI match.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As soon as I started digging into TensorFlow, questions immediately came up, and now I'm not quite sure if there is a more appropriate library to do this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I) TensorFlow has a High Level python API, and a Low Level C++ API. Most games are built in C++, and thus using a C++ or C API is preferable, it makes integration with the game much simpler. In principle we could use pybind or some other scheme for sending state from C++ to Python and back again, but that's not ideal. &#xA;&lt;strong&gt;Question 1: How much do I lose by using the low level API specifically for reinforcement learning, compared to the high level API?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;II) Platforms. 99.9% of the time, PC/Console games are developed in Windows environments, and so having Tensorflow work in Windows is critical. From my googling, Tensorflow just &lt;em&gt;barely&lt;/em&gt; supports building in Windows using CMake, though it requires some finagling. More worryingly are other platforms:&#xA;&lt;strong&gt;Question 2: What hope is there of running the TensorFlow library on consoles like XboxOne, Playstation 4, or the Switch? I imagine this would require manually porting the entire source :(&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;III) TensorFlow is big, and it seems you need to basically link all of it to ship with the game.&#xA;&lt;strong&gt;Question 3: Is there any way to get a slimmed down &quot;Runtime TensorFlow&quot; library that is only capable of loading a graph and transforming states into actions?&lt;/strong&gt;&#xA;It seems like if the answer was yes, it might also be easier to port this smaller runtime version to more platforms. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Question 4: Should I even be using TensorFlow for this? Is there perhaps something more suitable?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks again if you read all that, I'm eager to start tinkering, but would like to set off in the right direction.&lt;/p&gt;&#xA;" OwnerUserId="16265" LastEditorUserId="1671" LastEditDate="2018-06-14T21:23:18.807" LastActivityDate="2018-06-14T21:23:18.807" Title="Reinforcement Learning in Commercial Strategy Games" Tags="&lt;reinforcement-learning&gt;&lt;tensorflow&gt;&lt;game-ai&gt;&lt;getting-started&gt;&lt;gaming&gt;" AnswerCount="0" CommentCount="2" />
	<row Id="8403" PostTypeId="1" AcceptedAnswerId="8404" CreationDate="2018-10-14T09:05:08.993" Score="3" ViewCount="35" Body="&lt;p&gt;I'm making a Connect Four game using the typical minimax + alpha-beta pruning algorithms. I just implemented a Transposition Table, but my tests tell me the TT only helps 17% of the time. By this I mean that 17% of the positions my engine comes across in its calculations can be automatically given a value (due to the position being calculated previously via a different move order).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For most games, is this figure expected? To me it seems very low, and I was optimistically hoping for the TT to speed up my engine by around 50%. It should be noted though that on each turn in the game, I reset my TT (since the evaluation previously assigned to each position is inaccurate due to lower depth back then).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know that the effectiveness of TT's are largely dependent on the game they're being used for, but any ballparks of how much they speed up common games (chess, go, etc) would be helpful.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT - After running some more tests and adjusting my code, I found that the TT sped up my engine to about 133% (so it took 75% as much time to calculate). This means those 17% nodes were probably fairly high up in the tree, since not having to calculate the evaluation of these 17% sped up things by 33%. This is definitely better, but my question still remains on whether this is roughly expected performance of a typical TT.&lt;/p&gt;&#xA;" OwnerUserId="16917" LastEditorUserId="16917" LastEditDate="2018-10-14T13:25:32.393" LastActivityDate="2018-10-14T13:29:50.357" Title="Transposition table is only used for roughly 17% of the nodes - is this expected?" Tags="&lt;game-ai&gt;&lt;search&gt;&lt;gaming&gt;&lt;minimax&gt;&lt;efficiency&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="5169" PostTypeId="1" CreationDate="2018-01-28T07:56:26.750" Score="2" ViewCount="153" Body="&lt;p&gt;A human player plays limited games compared to a system that undergoes millions of iterations. Is it really fair to compare AlphaGo with the world #1 player when we know experience increases with the increase in number of games played?&lt;/p&gt;&#xA;" OwnerUserId="12394" LastEditorUserId="1671" LastEditDate="2018-04-14T02:44:25.220" LastActivityDate="2018-04-14T08:23:57.840" Title="Is it fair to compare AlphaGo with a Human player?" Tags="&lt;philosophy&gt;&lt;game-ai&gt;&lt;alphago&gt;" AnswerCount="5" CommentCount="1" />
	<row Id="5172" PostTypeId="2" ParentId="5169" CreationDate="2018-01-28T09:48:34.213" Score="2" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;Is it fair to compare AlphaGo with a Human player?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Depends on the purpose of the comparison.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If we are comparing ability to win a game of Go, then yes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If we are comparing learning ability, then &lt;em&gt;maybe&lt;/em&gt;. It depends on the task. AlphaGo and systems like it are capable of learning only in well-described limited domains. There may be an analogy with sensory learning (it might even be possible in theory to take a small piece of brain tissue and run an algorithm similar to AlphaGo's learning process on it). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In general, the approach used by AlphaGo and other reinforcement learning successes is &quot;trial-and-error plus function approximation&quot;. It seems analogous to perception and motor skills, such as object recognition or riding a bike, as opposed to reasoning skills and games as humans play them, which goes through many more cognitive and conscious layers that have no real analog in a RL system like AlphaGo.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;A human player plays limited games compared to a system that undergoes millions of iterations&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;This is an advantage of a machine to learn this kind of task. It would equally apply in other simulated environments with simple rules. If your goal is to have the most skilled and optimal navigation of such a domain, the implication now is that you would not train a human expert through years of study, but to write the simulator and train an AlphaGo-like machine. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is no different a comparison than deciding cars and roads are better solutions to long distance travel for the general population than walking or horses and carts. It doesn't matter what underlies the advantage of one over the other, the assessment is cost/benefit, which resolves to a single comparable number. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It would, however, be wrong to assess AlphaGo as a better general-purpose learning engine than a human. The fact that humans do not have to work fully through millions of simulations in full detail is important. It means that something about how humans learn is still not covered by learning machines. &lt;a href=&quot;https://arxiv.org/abs/1604.00289&quot; rel=&quot;nofollow noreferrer&quot;&gt;Some of these things are understood and being discussed&lt;/a&gt; - such as the ability to focus intuitively on important aspects of what to learn, the ability to reason about the environment, learning analogously or transfer learning from other domains.&lt;/p&gt;&#xA;" OwnerUserId="1847" LastEditorUserId="1847" LastEditDate="2018-01-28T11:28:12.230" LastActivityDate="2018-01-28T11:28:12.230" CommentCount="0" />
	<row Id="5195" PostTypeId="2" ParentId="5169" CreationDate="2018-01-31T00:08:14.873" Score="0" Body="&lt;p&gt;If you read through the abstracts of Chess AI papers, it is often pointed out that humans &quot;search&quot; the Chess game tree much more efficiently than computers, which was why it was so hard to beat the top humans in Chess for so many years.  (The human efficiency may have to do with intuition and judgement, which are difficult to replicate. &quot;Confidence levels&quot; for AI evaluations is one method of addressing these issues, as is &quot;&lt;a href=&quot;https://en.wikipedia.org/wiki/Monte_Carlo_tree_search&quot; rel=&quot;nofollow noreferrer&quot;&gt;monte carlo&lt;/a&gt;&quot;.  But it's also important to note that humans are far more limited in the depth and breadth of their &quot;searches&quot;, which is why, now that we have the right algorithms, humans can no longer win.)  &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Is it fair?  &lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Perhaps the more salient question is:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;&lt;strong&gt;Is it useful to compare AlphaGo to a human player?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;It most certainly is, because it tells us that we have is sometimes termed a &quot;strong-narrow AI&quot; that can outperform a human in a single task. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why AlphaGo beating &lt;a href=&quot;https://en.wikipedia.org/wiki/Lee_Sedol#Match_against_AlphaGo&quot; rel=&quot;nofollow noreferrer&quot;&gt;Lee Sedol&lt;/a&gt; was a big deal is the complexity of Go, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Computational_complexity_theory#Intractability&quot; rel=&quot;nofollow noreferrer&quot;&gt;intractability&lt;/a&gt; of the Go game tree, and the fact that computers were previously ineffective against high-level human Go players.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This human vs. AI evaluation doesn't strictly fall under the &quot;Turing Test&quot; (&lt;a href=&quot;https://en.wikipedia.org/wiki/Turing_test&quot; rel=&quot;nofollow noreferrer&quot;&gt;Imitation Game&lt;/a&gt;), it does fall squarely under the maxim of &lt;a href=&quot;https://en.wikipedia.org/wiki/Protagoras#Relativism&quot; rel=&quot;nofollow noreferrer&quot;&gt;Protagoras&lt;/a&gt; that &quot;Man is the measure of all things.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This is critical because intelligence is a spectrum, and gauging strength of intelligence, in the context of intractable problems &lt;em&gt;(problems that cannot be fully solved due to their size)&lt;/em&gt; is a function of relative strength of two agents, whether human or AI.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This relative assessment is all we have, and all we may ever have for certain sets of problems.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem with humans is not that we're not clever, but that our minds have cognitive limitations.  So to tackle certain problems, intelligent machines are useful.&lt;/p&gt;&#xA;" OwnerUserId="1671" LastEditorUserId="1671" LastEditDate="2018-02-01T19:24:03.093" LastActivityDate="2018-02-01T19:24:03.093" CommentCount="0" />
	<row Id="5206" PostTypeId="2" ParentId="5169" CreationDate="2018-02-01T13:46:03.393" Score="0" Body="&lt;p&gt;There is no such thing as fairness when comparing. You define a measure for performance and then compare the values of the measure.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One sensible measure for playing the game of GO is the 'Number of games won', regardless of any investment in the development of the system, computational or sample efficiency. AlphaGo is currently at the top by this measure.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another sensible measure could be 'Number of games won under a restriction on sample efficiency during training'. As others pointed out, such a measure could be much more favorable for humans.&lt;/p&gt;&#xA;" OwnerUserId="12483" LastEditorUserId="12483" LastEditDate="2018-02-02T08:27:22.170" LastActivityDate="2018-02-02T08:27:22.170" CommentCount="0" />
	<row Id="5169" PostTypeId="1" CreationDate="2018-01-28T07:56:26.750" Score="2" ViewCount="153" Body="&lt;p&gt;A human player plays limited games compared to a system that undergoes millions of iterations. Is it really fair to compare AlphaGo with the world #1 player when we know experience increases with the increase in number of games played?&lt;/p&gt;&#xA;" OwnerUserId="12394" LastEditorUserId="1671" LastEditDate="2018-04-14T02:44:25.220" LastActivityDate="2018-04-14T08:23:57.840" Title="Is it fair to compare AlphaGo with a Human player?" Tags="&lt;philosophy&gt;&lt;game-ai&gt;&lt;alphago&gt;" AnswerCount="5" CommentCount="1" />
	<row Id="5174" PostTypeId="1" CreationDate="2018-01-28T09:53:44.280" Score="4" ViewCount="713" Body="&lt;p&gt;I read about minimax, then alpha-beta pruning and then about iterative deepening. Iterative deepening coupled with alpha-beta pruning proves to quite efficient as compared alpha-beta alone.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have implemented a game agent that uses iterative deepening with alpha-beta pruning. Now I want to beat myself. What can I do to go deeper? Like alpha-beta pruning cut the moves, what other small change could be implemented that can beat my older AI?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My aim to go deeper than my current AI. If you want to know about the game, here is a brief summary:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are two players, four game pieces and a 7-by-7 grid of squares. At the beginning of the game, the first player places both the pieces on any two different squares. From that point on, the players alternate turns moving both the pieces like a Queen in chess (any number of open squares vertically, horizontally, or diagonally). When the piece is moved, the square that was previously occupied is blocked. That square can not be used for the remainder of the game. The piece can not move through blocked squares. The first player who is unable to move any one of the queens loses.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So my aim is to cut the unwanted nodes and search deeper.&lt;/p&gt;&#xA;" OwnerUserId="12384" LastEditorUserId="1671" LastEditDate="2018-01-30T23:48:58.257" LastActivityDate="2018-04-08T19:57:53.713" Title="What else can boost iterative deepening with alpha beta pruning?" Tags="&lt;game-ai&gt;&lt;combinatorial-games&gt;&lt;combinatorics&gt;" AnswerCount="3" CommentCount="2" FavoriteCount="1" />
	<row Id="5224" PostTypeId="2" ParentId="5174" CreationDate="2018-02-03T05:19:53.603" Score="1" Body="&lt;p&gt;To make boost iterative deepening with alpha-beta pruning you can use the &#xA;SSS* Search algorithm, its a best first strategy algorithm. The SSS* Algorithm can improve the time efficiency of the overall algorithm but it increases the space complexity.&#xA;I am linking the wiki to it &lt;a href=&quot;https://en.wikipedia.org/wiki/SSS*&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://en.wikipedia.org/wiki/SSS*&lt;/a&gt;&#xA;I will update the answer as soon as i get a better solution.&lt;/p&gt;&#xA;" OwnerUserId="11651" LastEditorUserId="1641" LastEditDate="2018-03-09T18:16:52.280" LastActivityDate="2018-03-09T18:16:52.280" CommentCount="0" />
	<row Id="5574" PostTypeId="2" ParentId="5174" CreationDate="2018-03-08T09:16:23.443" Score="1" Body="&lt;p&gt;First thing you're going to want to add is probably a &lt;a href=&quot;https://en.wikipedia.org/wiki/Transposition_table&quot; rel=&quot;nofollow noreferrer&quot;&gt;Transposition Table&lt;/a&gt;, as also suggested by SmallChess.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Afterwards, I'd look into &lt;a href=&quot;https://chessprogramming.wikispaces.com/Aspiration+Windows&quot; rel=&quot;nofollow noreferrer&quot;&gt;Aspiration Search&lt;/a&gt; and/or &lt;a href=&quot;https://chessprogramming.wikispaces.com/Principal%20Variation%20Search&quot; rel=&quot;nofollow noreferrer&quot;&gt;Principal Variation Search&lt;/a&gt; (also see &lt;a href=&quot;https://www.ics.uci.edu/~eppstein/180a/990202b.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;this page&lt;/a&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then I'd look into things like the &lt;a href=&quot;https://en.wikipedia.org/wiki/Killer_heuristic&quot; rel=&quot;nofollow noreferrer&quot;&gt;Killer Move Heuristic&lt;/a&gt;, and maybe also see if you can simply implement existing parts of your engine more efficiently (e.g. use &lt;a href=&quot;https://chessprogramming.wikispaces.com/Bitboards&quot; rel=&quot;nofollow noreferrer&quot;&gt;bitboards&lt;/a&gt; for your state representation).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Other than all of that, the &lt;a href=&quot;https://chessprogramming.wikispaces.com/&quot; rel=&quot;nofollow noreferrer&quot;&gt;chess programming wiki&lt;/a&gt; probably has lots of other interesting pages as well.&lt;/p&gt;&#xA;" OwnerUserId="1641" LastActivityDate="2018-03-08T09:16:23.443" CommentCount="0" />
	<row Id="5220" PostTypeId="1" AcceptedAnswerId="5222" CreationDate="2018-02-02T22:41:35.850" Score="1" ViewCount="244" Body="&lt;p&gt;The match got a lot of press, and I doubt anyone is surprised that Alpha Zero crushed Stockfish.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;See: &lt;a href=&quot;https://www.chess.com/news/view/google-s-alphazero-destroys-stockfish-in-100-game-match&quot; rel=&quot;nofollow noreferrer&quot;&gt;AlphaZero Destroys Stockfish in 100 Game Match&lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;To me, what's really salient is that &lt;em&gt;&quot;much like humans, AlphaZero searches fewer positions that its predecessors. The paper claims that it looks at &quot;only&quot; 80,000 positions per second, compared to Stockfish's 70 million per second.&quot;&lt;/em&gt;  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For those who remember Matthew Lai's &lt;a href=&quot;https://arxiv.org/pdf/1509.01549.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;GiraffeChess&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;However, it is interesting to note that the way computers play chess is very different from how&#xA;  humans play. While both humans and computers search ahead to predict how the game will go on,&#xA;  humans are much more selective in which branches of the game tree to explore. Computers, on the&#xA;  other hand, rely on brute force to explore as many continuations as possible, even ones that will be&#xA;  immediately thrown out by any skilled human. In a sense, the way humans play chess is much more&#xA;  computationally efficient - using Garry Kasparov vs Deep Blue as an example, Kasparov could not&#xA;  have been searching more than 3-5 positions per second, while Deep Blue, a supercomputer with&#xA;  480 custom ”chess processors”, searched about 200 million positions per second &lt;a href=&quot;https://arxiv.org/pdf/1509.01549.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;1&lt;/a&gt; to play at&#xA;  approximately equal strength (Deep Blue won the 6-game match with 2 wins, 3 draws, and 1 loss).&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;How can a human searching 3-5 positions per second be as strong as a computer searching 200&#xA;  million positions per second? And is it possible to build even stronger chess computers than what&#xA;  we have today, by making them more computationally efficient? Those are the questions this&#xA;  project investigates.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;[Lai was tapped by DeepMind as a researcher last year]&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But what I'm interested in at the moment is the decision speed in these matches:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;- What was the average time to make a move in the AlphaZero vs. Stockfish match?&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="1671" LastActivityDate="2018-02-03T02:34:14.947" Title="What was the average decision speed pf Alpha Zero in the recent Stockfish match?" Tags="&lt;game-ai&gt;&lt;chess&gt;&lt;alphazero&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="5222" PostTypeId="2" ParentId="5220" CreationDate="2018-02-03T02:34:14.947" Score="1" Body="&lt;p&gt;No, &lt;strong&gt;ALL&lt;/strong&gt; computer chess experts were surprised about the outcomes of the match. If you require references, please start a new question.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Your question is simple...&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1712.01815.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://arxiv.org/pdf/1712.01815.pdf&lt;/a&gt;&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;... We evaluated the fully trained instances of AlphaZero against Stockfish, Elmo and the previous&#xA;  version of AlphaGo Zero (trained for 3 days) in chess, shogi and Go respectively, playing&#xA;  100 game matches at tournament time controls of one minute per move ...&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;One minute per move. Stockfish would use the one minute if there is more than a single legal move, otherwise it'd move immediately. So the average time for a move for Stockfish is about &lt;strong&gt;57s to 60s&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is no source code for AlphaZero. However, it's hard to believe the system wouldn't take advantage of the minute it was given. The expected time for AlphaZero should be also &lt;strong&gt;57s to 60s&lt;/strong&gt;.&lt;/p&gt;&#xA;" OwnerUserId="6014" LastActivityDate="2018-02-03T02:34:14.947" CommentCount="3" />
	<row Id="5256" PostTypeId="1" CreationDate="2018-02-08T14:39:26.087" Score="3" ViewCount="110" Body="&lt;p&gt;So, I am trying to create an AI to handle the construction layout of a real time strategy game like Age of Empires II. The process has too many steps to be handled effectively by brute force, but also has enough structural requirements that it also cannot just be done randomly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Assuming a limited area to work with, which can be represented by tiles, the AI must be able to place several structures within the area. A layout once fully created can be given a score based on the pathable distance between certain structures as well as a few other factors. If paths between certain structures become completely blocked, the AI has failed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The starting area that is defined by tiles is also random in nature, containing a few predefined elements that the AI cannot control, which include randomly placed terrain and resource nodes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know this problem case has been quite vague, but the actual question relates to the type of AI that would best fit solving this issue. I currently have an algorithm that runs through what it believes are the best few results in a series of steps trying to create the most optimal layout, but it fails with many starting layouts, which require manual adjustments to the AI before it can process them properly. Even then, it is just an approximation at best, since it starts out assuming that the steps I gave it to check contain the most optimal layout.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is an example of what a finished layout might look like. It doesn't state which colors are which objects, but it might help in determining what type of AI I should be looking at using.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/oyJ62.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/oyJ62.png&quot; alt=&quot;screeps example&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="12607" LastEditorUserId="12607" LastEditDate="2018-02-08T15:10:17.527" LastActivityDate="2018-11-06T02:00:39.567" Title="RTS Construction Layout AI" Tags="&lt;algorithm&gt;&lt;game-ai&gt;&lt;prediction&gt;&lt;game-theory&gt;&lt;path-planning&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="5257" PostTypeId="2" ParentId="5256" CreationDate="2018-02-08T17:47:24.783" Score="1" Body="&lt;p&gt;Because the OP was a bit longer, I made a small mindmap to illustrate the topic and a possible answer. At first, the problem is called “Walling” and is described in the literature in the context of the “Starcraft AI” challenge. The question was, where to place buildings to win the game. A possible answer to the problem has to do with formalization of knowledge. Usually, the human player is aware what a good layout is, and he also knows where to place his units. The question is only how to express this knowledge in sourcecode.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In my opinion the answer is called “Computer based training”. CBT is a technology, not with the aim to program an AI, but to formalize knowledge in a game for training human players. The idea is, that a human player plays the walling game, and while he is doing so he learns to take the right decision. From the standpoint of AI it is important, that every CBT game has an evaluation algorithm which is often called a tutorial mode. This is done in cases. For example, in case 1 the player learns how to use a given terrain, in case 2 how to protect the structures and so forth. So my recommendation is, at first create a computer-based training game as a tutorial for human-players, and use the formalized knowledge in step 2 for building the AI for “Starcraft AI walling”.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/RWsEF.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/RWsEF.png&quot; alt=&quot;RTSmindmapwalling&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="11571" LastActivityDate="2018-02-08T17:47:24.783" CommentCount="2" />
	<row Id="5338" PostTypeId="1" CreationDate="2018-02-16T12:21:49.247" Score="2" ViewCount="113" Body="&lt;p&gt;Any small application based on real world application of AI which can be done easily at home for a beginner who is trying to make use of his basic programming skills into AI at the beginning level. &lt;/p&gt;&#xA;" OwnerUserId="12780" LastEditorUserId="1671" LastEditDate="2018-02-16T17:32:16.760" LastActivityDate="2018-02-16T20:36:01.557" Title="Can anyone suggest a small application based on an Artificial Intelligence which can be done by a beginner in AI?" Tags="&lt;game-ai&gt;&lt;ai-basics&gt;&lt;applications&gt;&lt;getting-started&gt;&lt;python&gt;" AnswerCount="2" CommentCount="3" FavoriteCount="2" />
	<row Id="5342" PostTypeId="2" ParentId="5338" CreationDate="2018-02-16T17:42:35.670" Score="5" Body="&lt;p&gt;This is fairly boilerplate advice, but, since you're brand new to AI, I'd personally suggest writing a classical Tic-Tac-Toe AI, ideally using &lt;a href=&quot;https://en.wikipedia.org/wiki/Minimax&quot; rel=&quot;noreferrer&quot;&gt;minimax&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I suggest this because &lt;a href=&quot;http://www.flyingmachinestudios.com/programming/minimax/&quot; rel=&quot;noreferrer&quot;&gt;minimax is fundamental to AI&lt;/a&gt;, and there are many webpages devoted to this subject, such as &lt;a href=&quot;https://medium.freecodecamp.org/how-to-make-your-tic-tac-toe-game-unbeatable-by-using-the-minimax-algorithm-9d690bad4b37&quot; rel=&quot;noreferrer&quot;&gt;How to make your Tic Tac Toe game unbeatable by using the minimax algorithm&lt;/a&gt; and &lt;a href=&quot;https://www.neverstopbuilding.com/blog/2013/12/13/tic-tac-toe-understanding-the-minimax-algorithm13&quot; rel=&quot;noreferrer&quot;&gt;Tic Tac Toe: Understanding the Minimax Algorithm&lt;/a&gt;.  (Google search for &quot;Tic-tac-toe&quot; and &quot;minimax&quot; will yield a plethora of other sites.  I'd also recommend looking at this minimax page from Stanford: &quot;&lt;a href=&quot;https://cs.stanford.edu/people/eroberts/courses/soco/projects/2003-04/intelligent-search/minimax.html&quot; rel=&quot;noreferrer&quot;&gt;Strategies and Tactics for Intelligent Search&lt;/a&gt;&quot;.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I recommend this approach as a good basic primer.  The real cutting-edge work is being done in Machine Learning and Neural Networks, and for that reason, it's probably more important than ever to have some basic grounding in classical AI before you start dipping your toe in that pond.&lt;/p&gt;&#xA;" OwnerUserId="1671" LastActivityDate="2018-02-16T17:42:35.670" CommentCount="5" />
	<row Id="5345" PostTypeId="2" ParentId="5338" CreationDate="2018-02-16T20:24:15.443" Score="1" Body="&lt;p&gt;I will assume you talk about applied AI (in generalized/strong AI we have nothing yet to program :-). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can look at any university course of introduction to AI and see its chapters and the program examples they use ( start by programming without any theory is not a way ).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;By example, one common issue on this kind of courses is path finding, using for it algorithms as A* algorithm and applying them to games as Hanoi Towers. This kind of knowledge is a must for any activity in AI. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Standford link provided by @DukeZhou is a good example of one of theses courses, just I suggest start it from first chapter instead of go directly to minmax. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Later on, you can jump to more advanced concepts, as recognition/classification and its common approaches: k-nearest/k-means, decision networks, neural nets, ... .  &lt;/p&gt;&#xA;" OwnerUserId="12630" LastEditorUserId="12630" LastEditDate="2018-02-16T20:36:01.557" LastActivityDate="2018-02-16T20:36:01.557" CommentCount="1" />
	<row Id="5619" PostTypeId="1" CreationDate="2018-03-10T13:03:40.733" Score="1" ViewCount="41" Body="&lt;p&gt;I'm developing a millitary game and I want soldiers to place themselves in specific order, when commander orders. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;How can I do this? Should agents learn somehow how to achieve given order or there exist other way?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm new in AI, so I do not really know how can I accomplish my goal. &#xA;Thanks for every advice.&lt;/p&gt;&#xA;" OwnerUserId="13237" LastActivityDate="2018-03-11T13:11:08.140" Title="Placing agents in a specific order on demand" Tags="&lt;machine-learning&gt;&lt;game-ai&gt;" AnswerCount="2" CommentCount="3" />
	<row Id="5623" PostTypeId="2" ParentId="5619" CreationDate="2018-03-10T22:08:54.690" Score="1" Body="&lt;p&gt;I agree with the commenters.  I think the easiest way to do this in some programming language is to say:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;soldiers[] = {tom,sam,sue,larry}&#xA;&#xA;define function fallIn(){&#xA;    facing = getcommanderfacing()&#xA;    commanderpos = getcommanderpos()&#xA;    dist = 1 //stand one foot away&#xA;&#xA;    for(int i = 0; i&amp;lt;soldiers.length, i++{&#xA;        //set them to a distance behind the commander, facing the same direction &#xA;        soldier[i].navigateTo(commanderpos - facing*dist*(i+1), facing)&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Unless I misunderstood, this should be a pretty easy problem.  If you have to worry about collision with objects, you might tell them to follow the commander's path if he's moving or if he's not, find the position closest to the one they want that doesn't leave them in a wall.  Pathfinding can be a complex problem to get right, but even that doesn't necessarily depend on ai.&lt;/p&gt;&#xA;" OwnerUserId="13243" LastActivityDate="2018-03-10T22:08:54.690" CommentCount="0" />
	<row Id="5628" PostTypeId="2" ParentId="5619" CreationDate="2018-03-11T13:11:08.140" Score="0" Body="&lt;p&gt;The assumption that the problem is a difficult AI problem is right. Solving the problem is only possible with different topics in AI. The first task is the natural language parser, which converts a text-message into an action. Problem #2 is a high-level symbolic planning problem, which can be described with the PDDL language. And the third problem is to transform the output of the PDDL solver into lowlevel actions which are executed by the agents.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Realizing such a pipeline is not a trivial task and can be done with a cognitive architecture. Some addons for Unity3d brings a ready-to-run software within, but it is also possible to program it from scratch with object-oriented programming. A first step would be to describe the choreography problem with PDDL and set constraints. &lt;a href=&quot;http://icaps17.icaps-conference.org/workshops/KEPS/proceedingsKEPS.pdf#page=13&quot; rel=&quot;nofollow noreferrer&quot;&gt;A PDDL Representation for Contradance Composition&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="11571" LastActivityDate="2018-03-11T13:11:08.140" CommentCount="1" />
	<row Id="5794" PostTypeId="1" CreationDate="2018-03-24T20:12:28.483" Score="1" ViewCount="97" Body="&lt;p&gt;I have implemented multiple MCTS based AI players for the Love Letter game (&lt;a href=&quot;https://en.wikipedia.org/wiki/Love_Letter_(card_game)&quot; rel=&quot;nofollow noreferrer&quot;&gt;rules&lt;/a&gt;). It is a 2-4 players zero sum card game where players make alternating moves. I am struggling with how to properly conduct experiments for estimating AI player strength against human players: &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;In 2 player game where one of the players is AI bot&lt;/li&gt;&#xA;&lt;li&gt;In 4 player game where one (or multiple) of players is AI bot&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="14534" LastActivityDate="2018-03-26T18:50:41.867" Title="How to estimate the AI player's strength in multiplayer game?" Tags="&lt;game-ai&gt;&lt;monte-carlo-tree-search&gt;" AnswerCount="1" CommentCount="3" />
	<row Id="5796" PostTypeId="2" ParentId="5794" CreationDate="2018-03-25T09:13:30.940" Score="2" Body="&lt;p&gt;The following are extremely simple ways of tackling this problem.&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;A very simple way&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;It can simply be&lt;br/&gt;&#xA;&lt;code&gt;strength of AI&lt;/code&gt;=&lt;code&gt;(# of games won)&lt;/code&gt;/&lt;code&gt;(total # of games)&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;In case data for each move is available&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Something like&lt;br/&gt;&#xA;&lt;code&gt;score per game&lt;/code&gt;=&lt;code&gt;# of correct decisions&lt;/code&gt;/&lt;code&gt;total number of decisions&lt;/code&gt;.&lt;br/&gt;&#xA;Then&lt;br/&gt;&#xA;&lt;code&gt;strength of AI&lt;/code&gt;=&lt;code&gt;sum(score per game)&lt;/code&gt;/&lt;code&gt;total # of games&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;If each move/decision has a score associated with it&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;then you do&lt;br/&gt;&lt;code&gt;score per move&lt;/code&gt;=&lt;code&gt;scored points by taking a decision&lt;/code&gt;/&lt;code&gt;maximum possible score&lt;/code&gt;.&lt;br/&gt;&#xA;then&lt;br/&gt;&#xA;&lt;code&gt;score per game&lt;/code&gt;=&lt;code&gt;sum(score per move)&lt;/code&gt;/&lt;code&gt;total # of moves&lt;/code&gt;&lt;br/&gt;&#xA;and finally,&lt;br/&gt;&#xA;&lt;code&gt;strength of AI&lt;/code&gt;=&lt;code&gt;sum(score per game)&lt;/code&gt;/&lt;code&gt;total # of games&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;How to choose optimal number of games to play?&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;It depends on your requirements. If you want to report your AI's strength in percentage of the games it played correct to 1 decimal place (for example, this AI won 95.1%) then 10000 is an optimal number of games your AI needs to play. Suppose your AI won 9508 games out of 10000 then you will have 95.08% strength of AI. To be able to correctly round it to 1 decimal place you need to have an additional decimal place so that you can quote the strength of you AI with reasonable confidence, in this case 95.1%.&lt;/p&gt;&#xA;" OwnerUserId="12957" LastEditorUserId="12957" LastEditDate="2018-03-26T05:54:52.317" LastActivityDate="2018-03-26T05:54:52.317" CommentCount="7" />
	<row Id="5810" PostTypeId="1" CreationDate="2018-03-27T13:19:29.650" Score="2" ViewCount="500" Body="&lt;p&gt;I'm currently having troubles to win against a random bot playing the Schieber Jass game. It is a imperfect card information game. (famous in switzerland &lt;a href=&quot;https://www.schieber.ch/&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://www.schieber.ch/&lt;/a&gt;) &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The environement I'm using is on Github &lt;a href=&quot;https://github.com/murthy10/pyschieber&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://github.com/murthy10/pyschieber&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To get a brief overview of the Schieber Jass I will describe the main characteristics of the game.&#xA;The Schieber Jass consists of four players building two teams.&#xA;At the beginning every player gets randomly nine cards (there are 36 cards).&#xA;Now there are nine rounds and every player has to chose one card every round. Related to the rules of the game the &quot;highest card&quot; wins and the team gets the points.&#xA;Hence the goal is to get more points then your opponent team.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are several more rules but I think you can image how the game should roughly work.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now I'm trying to apply a DQN approach at the game.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To my attempts:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I let two independent reinforcement player play against two random players&lt;/li&gt;&#xA;&lt;li&gt;I design the input state as a vector (one hot encoded) with 36 &quot;bits&quot; for every player and repeated this nine times for every card you can play during a game.&lt;/li&gt;&#xA;&lt;li&gt;The output is a vector of 36 &quot;bits&quot; for every possible card.&lt;/li&gt;&#xA;&lt;li&gt;If the greedy output of the network suggest an invalid action I take the action with the highest probability of the allowed actions&lt;/li&gt;&#xA;&lt;li&gt;The reward is +1 for winning, -1 for losing, -0.1 for a invalid action and 0 for an action which doesn't lead to a terminal state&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;My question:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Would it be helpful to use a LSTM and reduce the input state?&lt;/li&gt;&#xA;&lt;li&gt;How to handle invalid moves?&lt;/li&gt;&#xA;&lt;li&gt;Do you have some good ideas for improvements? (like Neural-Fictitious Self-Play or something similar)&lt;/li&gt;&#xA;&lt;li&gt;Or is this the whole approach absolute nonsense?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="14587" LastEditorUserId="14587" LastEditDate="2018-06-18T14:32:08.663" LastActivityDate="2018-06-18T14:32:08.663" Title="How to use DQN to handle an imperfect but complete information game?" Tags="&lt;reinforcement-learning&gt;&lt;game-ai&gt;&lt;q-learning&gt;&lt;imperfect-information&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="1" />
	<row Id="5870" PostTypeId="2" ParentId="5810" CreationDate="2018-04-02T20:22:46.973" Score="3" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;Would it be helpful to use a LSTM and reduce the input state?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I'd bet, no. LSTM is more complicated and harder to learn, while the input is 4 * 9 * 36 bits is still rather limited.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, you may want to aggregate the information somehow, e.g., add additional bits informing about what cards were already played (no matter when). This information is redundant, but by providing it, you may save the network quite some learning.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;At the same time, you may want to use symmetries (all colors but trumps are equivalent and the therefore the weights should be the same).&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;How to handle invalid moves?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;That's simple: There are no invalid moves. The network provides 36 outputs of how much it wants to play a given card. You simply take the one valid card having the greatest output value. You don't try to make the network learn what moves are valid as this is neither needed nor helpful.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Do you have some good ideas for improvements? (like Neural-Fictitious Self-Play or something similar)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I can't tell. But it should matter at the moment. First make you network clearly beat the random players, then you can look for more. Or start with Self-Play, as you want probably have both for comparison.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Or is this the whole approach absolute nonsense?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I don't think so, but ... (see below)&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;I design the input state as a vector (one hot encoded) with 36 &quot;bits&quot; for every player&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;This doesn't sound good. Every player has 9 of 36 cards and so should be the encoding. A player doesn't know the cards of other players.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The reward is +1 for winning, -1 for losing,&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;In most card games I know, it matters by how much you win (unlike e.g., in Go). Even when it doesn't matter, using this information at the early learning stages is IMHO useful.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;-0.1 for a invalid action and&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Drop the invalid action. Just transform anything the network produces to a valid action, add no penalty (as written above).&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;... 0 for an action which doesn't lead to a terminal state&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;All action but the last one lead to a non-terminal state. You can use some Temporal Difference Learning or use the fact that the game has a small fixed number of moves and reward/punish all actions takes in a the whole game.&lt;/p&gt;&#xA;" OwnerUserId="12053" LastActivityDate="2018-04-02T20:22:46.973" CommentCount="1" />
	<row Id="5889" PostTypeId="1" CreationDate="2018-04-04T06:11:51.267" Score="2" ViewCount="34" Body="&lt;p&gt;It is possible to use case-based reasoning for forward simulation in Mario AI, this is explained by &lt;a href=&quot;https://www.cc.gatech.edu/~riedl/pubs/ijcai17.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;Game engine learning from video&lt;/a&gt; They are using features: &lt;/p&gt;&#xA;&#xA;&lt;p&gt;distance, velocity and position&lt;/p&gt;&#xA;&#xA;&lt;p&gt;to predict following game-frames like in a physics engine. What my problem with the paper is, that the “learned game engine” seems to be working autonomously. That means, the human operator is out of the loop, he is not changing the cases manually and he is not involved in predicting the future. Is it possible to make an interactive forward simulation? For example, the game-engine asks the operator what will happen if Mario jumps over the wall.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What i do not understand is how to design the GUI-interface in such a situation, because the number of possible reactions of the game-engine to a situation is endless, and to make the simulation interactive the user would click very fast on some buttons. For example, if the desired framerate is 30fps, should the user define all the parameters in a timestep of 1/30 seconds?&lt;/p&gt;&#xA;" OwnerUserId="11571" LastActivityDate="2018-04-04T06:11:51.267" Title="Interactive forward simulation" Tags="&lt;game-ai&gt;" AnswerCount="0" CommentCount="1" />
	<row Id="5890" PostTypeId="1" CreationDate="2018-04-04T09:13:15.360" Score="3" ViewCount="146" Body="&lt;p&gt;I am trying to find out what are some good learning strategies for Deep Q-Network with opponents. Let's consider the well known game Tic-Tac-Toe as an example:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;How should an opponent be implemented to get good and fast improvements?&lt;/li&gt;&#xA;&lt;li&gt;Is it better to play against a random player or a perfect player or should the opponent be a DQN player as well?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="14587" LastEditorUserId="1671" LastEditDate="2018-04-04T17:36:15.333" LastActivityDate="2018-04-04T17:36:15.333" Title="What are good learning strategies for Deep Q-Network with opponents?" Tags="&lt;reinforcement-learning&gt;&lt;game-ai&gt;&lt;q-learning&gt;&lt;self-play&gt;&lt;perfect-play&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="2" />
	<row Id="5893" PostTypeId="2" ParentId="5890" CreationDate="2018-04-04T14:05:51.500" Score="2" Body="&lt;p&gt;In a two player zero-sum game (if I win, you lose and vice-versa), then you can have a simple and efficient solution learning from self-play.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;How should an opponent be implemented to get good and fast improvements?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;You don't need to think in terms of agent vs opponent, instead think in terms of coding both the players' goals into a single Q function. Score +1 if player A wins, -1 if player B wins, and zero for a draw. It is then player A's goal to maximise the score and player B's goal to minimise the score.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can then implement and learn &lt;em&gt;both&lt;/em&gt; player strategies in the same self-play learning session and same Q function, using minimax. In practice that means where in Q learning you generally pick the maximising action on next state to bootstrap Q values, in a &lt;em&gt;minimax&lt;/em&gt; variant, you pick maximising or minimising action depending on whose turn it is. Otherwise the Q learning algorithm is the same as normal. &lt;a href=&quot;https://github.com/neilslater/game_playing_scripts/blob/master/tictactoe_q.py&quot; rel=&quot;nofollow noreferrer&quot;&gt;I have implemented this, but not for DQN, just for tabular Q-learning&lt;/a&gt; - feel free to learn from, copy and/or re-use any part of that code.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Is it reasonable to play against a random player, a perfect player or should the opponent be a DQN player as well?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;The Q learner will learn to optimise against whichever player you make it play against. Against a random player, it will not necessarily learn to play well, just well enough to defeat the randomness. It may even make deliberate mistakes - such as not blocking a winning line - knowing it has a better chance to win due to random opponent.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Against a perfect player is possible with tic tac toe (because you can construct such a player), although there might be gaps in the trained Q values - game states never seen - which mean that an imperfect opponent could actually defeat the trained agent! In practice this does not scale to more complex unsolved games, because no perfect players exist.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another DQN player should work fine. You would end up with two agents, each specialising in playing one player's turns. This is less efficient than a single minimax-based player, but no expected problems. It may be a preferred choice for some games, especially if they are not zero-sum.&lt;/p&gt;&#xA;" OwnerUserId="1847" LastEditorUserId="1847" LastEditDate="2018-04-04T14:18:44.970" LastActivityDate="2018-04-04T14:18:44.970" CommentCount="4" />
	<row Id="5891" PostTypeId="1" AcceptedAnswerId="5892" CreationDate="2018-04-04T12:36:54.207" Score="4" ViewCount="1003" Body="&lt;p&gt;To provide a bit of context, I'm a software engineer &amp;amp; game enthusiast (card games specially). The thing is I've always been interested in AI oriented to games. In college, I programmed my own Gomoku AI so i'm a bit familiar with the basic concepts of AI game oriented and have read books &amp;amp; articles about Game Theory as well. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;My issue comes when I try to analyze AI's for &lt;strong&gt;Imperfect Information&lt;/strong&gt; games like (Poker, Magic the gathering, Hearthstone, etc). In most cases when I found an AI for Hearthstone, it was either some sort of Monte Carlo or MinMax strategy. I honestly think although it might even provide some decent results it will still be always quite flat and linear since it doesn't take into account what deck the opponent is playing and almost always tries to follow the same game-plan, since it will not change based on tells your opponent might give away via cards played (hint that a human would catch). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like to know if using Neural Networks would be more better than just using a raw evaluation of board state + hands + Hp each turn without taking into account learning about possible threads the opponent might have, how to deny the opponent the best plays he could make, etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My intuition tells me that this is way harder and far more complex.&#xA;Is that the only reason the NN method is not used?Has there been any research to prove how much efficiency edge would be between those 2 approaches? &lt;/p&gt;&#xA;" OwnerUserId="14769" LastEditorUserId="9947" LastEditDate="2018-04-04T12:58:23.100" LastActivityDate="2018-04-04T13:35:42.850" Title="Why most imperfect information games usually use non machine learning AI?" Tags="&lt;machine-learning&gt;&lt;game-ai&gt;&lt;imperfect-information&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="1" />
	<row Id="5892" PostTypeId="2" ParentId="5891" CreationDate="2018-04-04T13:35:42.850" Score="3" Body="&lt;p&gt;A heuristic search using MCTS + minimax + alphabeta pruning is a highly efficient AI planning process. What the AI techniques of reinforcement learning (RL) plus neural networks (NNs) typically add to this is a way to establish better heuristics.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;My intuition tells me that this is way harder and far more complex. &lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;It's not actually that much more complex in concept. Replace the hand-coded heuristic with a learning engine, e.g. DQN or AC3. Train the learning engine from human expert play examples and/or from self play.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It &lt;em&gt;is&lt;/em&gt; harder though, because there are many things that can go wrong with an NN-based estimator in a RL context. You will need to make many experiments with different hyper-parameters of the learning engine. For complex games, you may have to invest many 100s of hours of training, which you might want to compare against the end result of a similar amount of time spent refining expert heuristic systems.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For imperfect information games, you may also want to use something that can learn an internal state representation. That could be some kind of explicit belief state that you maintain like an expert system, or something that attempts to learn a good representation, such as an RNN (e.g. LSTM). This may not be necessary for a first try at an agent though, since the MCTS search will make up for &lt;em&gt;some&lt;/em&gt; inadequacies of low accuracy heuristics.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Is that the only reason the NN method is not used?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Up until quite recently, approaches using RL and NN were far harder to find examples of outside of academic machine learning research, and there were not any pre-written frameworks for LSTM or e.g. AC3. In the last few years, RL and NN frameworks have started to appear making an AI self-learning approach far more approachable. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would expect that many hobby-level coders considering game-playing AI nowadays would seriously take a look at RL and NNs in order to &lt;em&gt;learn&lt;/em&gt; robust heuristics for their game projects. However, the &quot;traditional&quot; search-based methods still work in conjunction with these for a completed agent. &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Has there been any research to prove how much efficiency edge would be between those 2 approaches?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;For card games, I am not aware of any specific research, although I am just a hobbyist, yet to write any specific game engine more complex than tic-tac-toe.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For perfect information board games, &lt;a href=&quot;https://en.wikipedia.org/wiki/AlphaZero&quot; rel=&quot;nofollow noreferrer&quot;&gt;the chess playing variant of AlphaZero&lt;/a&gt; demonstrates applicability of RL+NN self-play approach versus &quot;traditional&quot; heuristics plus search (represented by Stockfish). However, the framing of the tournament has been criticised as unfair to Stockfish, so it is not necessarily an open-and-shut case that RL is strictly better.&lt;/p&gt;&#xA;" OwnerUserId="1847" LastActivityDate="2018-04-04T13:35:42.850" CommentCount="0" />
	<row Id="6102" PostTypeId="1" CreationDate="2018-04-18T12:01:49.907" Score="10" ViewCount="206" Body="&lt;p&gt;Imagine a game where it is a black screen apart from a red pixel and a blue pixel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given this game to a human, they will first see that pressing the arrow keys will move the red pixel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The next thing they will try is to move the red pixel onto the blue pixel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Give this game to an AI and it will randomly move the red pixel until a million tries later it accidentally moves onto the blue pixel to get a reward.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the AI had some concept of distance between the red and blue pixel it might try to minimise this distance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Without actually programming in the concept of distance, if we take the pixels of the game can we calculate a number(s) such as &quot;entropy&quot; or suchlike that would be lower when pixels are far apart than when close together? It should work with other configurations of pixels. Such as a game with three pixels where one is good and one is bad. Just to give the neural network more of a sense of how the screen looks?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then give the NN a goal such as try and minimise the entropy of the board as well as try to get rewards.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there anything akin to this in current research?&lt;/p&gt;&#xA;" OwnerUserId="4199" LastEditorUserId="10135" LastEditDate="2018-10-18T10:44:59.717" LastActivityDate="2018-10-18T10:44:59.717" Title="Can a neural network work out the concept of distance?" Tags="&lt;neural-networks&gt;&lt;game-ai&gt;&lt;path-planning&gt;&lt;teaching-concepts&gt;" AnswerCount="4" CommentCount="2" />
	<row Id="6108" PostTypeId="2" ParentId="6102" CreationDate="2018-04-18T16:45:34.437" Score="1" Body="&lt;h1&gt;Answer&lt;/h1&gt;&#xA;&#xA;&lt;p&gt;I'm going to take your question at face value, and go really deep into this topic. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Yes, they can. The typical human mind can. But consider the human mind. Millions, if not &lt;em&gt;billions&lt;/em&gt;, of neurons. In fact, one can consider distance as a human concept, simply a theory developed from interactions with the world. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Therefore, given a year or two, with a ton of neurons on your hand, you could replicate this scenario. That is if your computer is as parallel as the human mind. The short explanation is that the human mind is very parallel.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, it would be simpler to calculate the distance with a program, not an AI, and simply feed the result to the AI that would make the decisions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Consider the amount of time you have spent looking at a screen. If you can tell the (approximate) distance between two pixels, so can a Neural Network, as you are one. However, add the amount of time you have spent alive and learning into the equation, and it becomes a disaster. &lt;/p&gt;&#xA;&#xA;&lt;h2&gt;Further reading&lt;/h2&gt;&#xA;&#xA;&lt;h3&gt;The human brain is parallel&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;This is a result of the fact that all of the neurons in the human brain are independent of each other. They can run &lt;em&gt;true simultaneous&lt;/em&gt; actions, thus making the action of interpreting images and such much easier, as blocks of neurons can &quot;think&quot; independent of the operations of the others, limiting what would be &quot;lag&quot; to a minuscule amount.&lt;/p&gt;&#xA;" OwnerUserId="14723" LastActivityDate="2018-04-18T16:45:34.437" CommentCount="0" />
	<row Id="6110" PostTypeId="2" ParentId="6102" CreationDate="2018-04-18T17:33:12.647" Score="1" Body="&lt;p&gt;You can create AI to &quot;see&quot; as a human. As you said, giving the human the keys, he will click randomly. He just needs to know which keys he presses that brings him closer to other objects on the screen. I think the basics of an AI is object recognition. I would try to create a script to map the screen objects of the game. There are legal examples in Python.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would try to follow a path like this:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Make the AI ​​understand that by clicking the arrows or the WASD and it is in the context GAME, the object that move pixels according to the direction, represents the main author (the player).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;In parallel: map all boundaries of the region and index different objects within that region to automatically have the coordinate domain and object distance. AI needs to SEE (stream) the game and through images to categorize objects. Do you understand what I mean?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;In parallel: The AI ​​needs to be aware of all texts and information that is on the screen (all mapped, remember?). You need to understand when a text changes or something different happens. For example: whenever he returns to the initial position of each phase, whenever he has a count, what happens when the cout reaches zero or a common number that generates another type of change.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;He needs to understand what is repeated at every &quot;respawn&quot;. You also need to understand what &quot;respawn&quot; is. Maybe a certain map position on every map it returns whenever a count on the screen ends. Or when it comes up against a certain type of object (mapped object)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;To be honest, if you want to create a super intelligent robot, you can go following all the steps that go through the heads of different humans, or the best humans, or the rules of each game. But sometimes it's easier to build specific bots to perform specific tasks. It depends on what you want to do&lt;/p&gt;&#xA;" OwnerUserId="7800" LastActivityDate="2018-04-18T17:33:12.647" CommentCount="2" />
	<row Id="8475" PostTypeId="2" ParentId="6102" CreationDate="2018-10-17T01:32:11.473" Score="1" Body="&lt;p&gt;We can break down the problem as follows:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First, if you have two points on a plane and feed the coordinates of those points to a neural network (e.g., a vector &lt;span class=&quot;math-container&quot;&gt;$&amp;lt; x_0, y_0, x_1, y_1 &amp;gt;$&lt;/span&gt;) and and train it on a label thats the actual distance (e.g., &lt;span class=&quot;math-container&quot;&gt;$ \sqrt{(x_0 - y_0)^2 + (x_1-y_1)^2} $&lt;/span&gt;), it should be able to learn this relationship with arbitrarily close accuracy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Next, if you have an image similar to what you describe, and feed that through a different neural network (e.g., a CNN), and as labels you used the the points of the two dots (once again &lt;span class=&quot;math-container&quot;&gt;$&amp;lt; x_0, y_0, x_1, y_1 &amp;gt;$&lt;/span&gt;), then it should be able to learn that relationship with arbitrarily close accuracy once again.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Of course, there's no reason to do this in two separate neural network, so we can just combine the two end-to-end have a model that takes the image as input and the distance as output.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This model would need to be trained on labeled data, however, so you'd either need to generate the data yourself or label images.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But if you wanted it to learn the notion of closing a distance in a less supervised way, you'd need to use reinforcement learning. In this case, you'd have to setup an environment that incentivises the agent to reduce the distance. This could be as simple as gaining reward if an action reduces the distance.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another approach would be to incentivise the agent using future reward. That is, it's reward doesn't just come from the results of the next immediet state, but there's also contributions from the next possible state, and the one after that, and so on. This is the idea behind Deep Q-Learning, and I implement a simple example (very similar to what you're describing) &lt;a href=&quot;https://github.com/nathanmargaglio/DQN/blob/master/Basic%20Env.ipynb&quot; rel=&quot;nofollow noreferrer&quot;&gt;in this notebook&lt;/a&gt;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, now the question is: has this implementation done something other than randomly moving around until it follows a path to success?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In your example, you talk about rewarding the agent when it lands on the goal. But in what I described, it gained reward by moving closer to the goal (either through the Q-Function or directly from the environment). It is able to do so by learning some abstract idea of distance (which can be illustrated in the supervised version).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When a human learns this, it's for the same exact reason: the human is gaining a reward for moving in that direction through a sense of future rewards.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'd say that, given enough training and data, reinforcement learning could learn this concept with ease. As far as other rewards being present on the board (e.g., &quot;minimise the entropy of the board as well as try to get rewards&quot;), you need to think about what it is you're asking. Would you rather the agent minimize distance or maximize reward? Cause, in general, it can't do both. If you're looking for some balance between the two, then really you're just redefining the reward to also consider the distance. &lt;/p&gt;&#xA;" OwnerUserId="19080" LastActivityDate="2018-10-17T01:32:11.473" CommentCount="0" />
	<row Id="6125" PostTypeId="1" AcceptedAnswerId="6127" CreationDate="2018-04-20T10:49:59.647" Score="1" ViewCount="60" Body="&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/IzJ5Q.jpg&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/IzJ5Q.jpg&quot; alt=&quot;Picture&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So I know that 'h' and 'f' will be pruned, but I'm not sure about 'k' and 'l'.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When we visit 'j', technically there is no need for us to visit 'k' and 'l' because there are 2 options:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;one or two of them might be higher than 8 ('j') &lt;/li&gt;&#xA;&lt;li&gt;both of them less than 8 &lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;But no matter what, the decision of the max(root) will not change, the max will choose the right side no matter what 'k' and 'l' are, because the right side will either be 8 or 9, which is still higher than 4 (returned value from left side)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;so will alpha beta prune 'k' and 'l' or not? if not, then it means alpha beta is not &quot;optimal&quot; overall right? considering it will not prune all the unnecessary paths.&lt;/p&gt;&#xA;" OwnerUserId="12782" LastEditorUserId="12782" LastEditDate="2018-04-20T13:57:30.063" LastActivityDate="2018-06-19T17:49:50.150" Title="Which edges of this tree will be pruned by Alpha-beta pruning?" Tags="&lt;ai-design&gt;&lt;game-ai&gt;&lt;logic&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="6127" PostTypeId="2" ParentId="6125" CreationDate="2018-04-20T16:36:58.253" Score="1" Body="&lt;p&gt;If you prune k and L then you could miss the optimal solution. Assume L=9, if you prune L then the value of the tree is 8. If you don't prune L then the value of the tree is 9. Now I will try and address what I think your actual question is&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;But no matter what, the decision of the max(root) will not change, the max will choose the right side no matter what 'k' and 'l' are, because the right side will either be 8 or 9, which is still higher than 4 (returned value from left side).&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;From this sentence it seems like you don't care about the value of the tree, you only want to find the optimal first move based on alpha beta. You are correct in saying that the correct first move will always contain the right most child of the root, but oftentimes that is not the only information we want. Sometimes we want to know the value of the tree as well or what the complete correct path is, but if we had pruned k and L we would not know these.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Edit: I have changed all 'L's to uppercase, because lower case 'L' looks to much like uppercase 'i'&lt;/p&gt;&#xA;" OwnerUserId="13088" LastActivityDate="2018-04-20T16:36:58.253" CommentCount="2" />
	<row Id="6205" PostTypeId="1" CreationDate="2018-04-29T01:34:48.543" Score="3" ViewCount="429" Body="&lt;p&gt;I am currently getting into Deep Learning and would like to set up an environment for training an Artificial Neural Network or NEAT to play simple video games on NES (Mario etc.) and SNES ( Donkey Kong Country etc.), using TensorFlow/TFLearn in Python.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I started off with OpenAI gym environment and there is actually a super-mario environment for gym on github, which I fail to install as Gym-pull is not available anymore and latest gym package doesn't even have scoreboard folder (I am on windows 10, conda environment).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Now, what would be the best way to set up a solid training environment that will be similar to OpenAI gym in terms of simplicity?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Unfortunately OpenAI universe isn't compatible with Windows 10 atm, and I really don't want to get a different setting like ubuntu environment to make it work. I would like to stay in win10.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If someone could guide me for suggested setup or refer me to articles/ documentation where similar things have been done in win10 python env. for NES/SNES, I would be extremely grateful! I assume an emulator with python API (perhaps Nintaco?) is a way to go? How would I then get the 'observation output', I would need to scan the live pixel output of the game, which I am not sure how to do.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Regards,&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Mark&lt;/p&gt;&#xA;" OwnerUserId="15310" LastEditorUserId="15310" LastEditDate="2018-04-29T01:47:58.480" LastActivityDate="2018-10-12T10:00:33.187" Title="Training AI to play NES/SNES games on NN python" Tags="&lt;deep-learning&gt;&lt;game-ai&gt;&lt;python&gt;&lt;q-learning&gt;&lt;neat&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="6212" PostTypeId="1" CreationDate="2018-04-30T08:18:27.573" Score="0" ViewCount="66" Body="&lt;p&gt;Let's assume a common game scenario of several characters in a combat arena. Each character has different strengths and weaknesses. The arena has traps and tools. Suppose the characters had only very basic moves such as step in a direction, shoot, climb, duck, pick up item,  use item, drag heavy object. Each move has a chance of success  based on the context (e.g. range to target). What AI, machine learning, or evolutionary approach could be used to generate personalized tactics for each character based on repeated runs of the scenario?&lt;/p&gt;&#xA;" OwnerUserId="15322" LastActivityDate="2018-06-04T20:30:27.903" Title="Developing character tactics via repeated trials" Tags="&lt;game-ai&gt;&lt;problem-solving&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="1" />
	<row Id="6224" PostTypeId="2" ParentId="6212" CreationDate="2018-05-01T12:47:15.267" Score="0" Body="&lt;p&gt;There are a few ways to tackle this. You could make an AI that is simply a series of IF statements, or you could actually make an AI that would actually take in the situation and come up with a sensible solution.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;IF Approach - You make a series of IF statements that come up with a sensible action to execute. This is the method that Minecraft uses. The resulting action were recorded from some of the best players.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;True AI - Have your Character execute random actions and learn the consequences of them. The, train it to execute various actions for certain scenarios.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The main difference between these two approaches is that IF statements have a constant and predictable behavior, while the AI approach has a very bad startup value but ends up improving over time.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is no &quot;best&quot; method, it is up to you to choose one or the other or a mix of both.&lt;/p&gt;&#xA;" OwnerUserId="14723" LastActivityDate="2018-05-01T12:47:15.267" CommentCount="2" />
	<row Id="6230" PostTypeId="2" ParentId="6212" CreationDate="2018-05-01T17:59:49.283" Score="1" Body="&lt;p&gt;The first step is to increase the abstraction level of the game. Instead of storing the game characters with absolute position on a pixel level, a text-adventure-like layer above the game has to be established. In the literature this concept is called “knowledge containers” and is described under the topic of case-based reasoning. Now, it is possible to record the repeated trials with a RDF-based vocabulary, and it is also possible to run machine learning algorithm for feature detection against the game-logs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Unfortunately, the high-level textadventure like game-description has to be grounded to the original game. That means, if one of the player is doing a low level move, this has to be converted into the vocabulary of the knowledge-container. For the game Wargus some literature is available, the Darmok2 AI-engine can play other Real time strategy games with this approach. The Darmok2 AI engine was written in Java and is not available as sourcecode. The system is documented in  &lt;a href=&quot;https://www.cs.utexas.edu/~katie/Struck09.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;Learning from Human Demonstrations for Real-Time Case-Based Planning&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;textual case-based reasoning&quot; can be seen in action at &lt;a href=&quot;https://www.youtube.com/watch?v=wh3yEFWcFlo&quot; rel=&quot;nofollow noreferrer&quot;&gt;Artificial Intelligence plays puzzle game (Solomon's key)&lt;/a&gt; Which algorithm was used in the example is unknown. From the screenshot i would guess it is a cognitive architecture, perhaps SOAR or ACT-R.&lt;/p&gt;&#xA;" OwnerUserId="11571" LastEditorUserId="11571" LastEditDate="2018-05-05T19:36:20.037" LastActivityDate="2018-05-05T19:36:20.037" CommentCount="3" />
	<row Id="6279" PostTypeId="1" AcceptedAnswerId="6283" CreationDate="2018-05-05T13:30:41.473" Score="1" ViewCount="90" Body="&lt;p&gt;I was wondering if it is possible to train an AI that can play outdoor games like cricket, badminton etc. I am new to AI, so if this question is dumb please bear it.&lt;/p&gt;&#xA;" OwnerUserId="15441" LastActivityDate="2018-05-06T08:58:15.150" Title="Developing an AI to play outdoor games" Tags="&lt;training&gt;&lt;game-ai&gt;" AnswerCount="2" CommentCount="2" />
	<row Id="6283" PostTypeId="2" ParentId="6279" CreationDate="2018-05-06T01:00:37.523" Score="1" Body="&lt;p&gt;Yes it is possible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A group of Chinese college students and teachers made a &lt;a href=&quot;https://www.youtube.com/watch?v=BRVdwINXpMI&quot; rel=&quot;nofollow noreferrer&quot;&gt;robot that plays badminton&lt;/a&gt;.  I am sure someone will make a robot that can play cricket and other outside games.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/O4qxK.jpg&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/O4qxK.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Although not an outdoor game, &lt;a href=&quot;https://www.youtube.com/watch?v=IXyKLDNzGGI&quot; rel=&quot;nofollow noreferrer&quot;&gt;Omron made a robot named Forpheus that plays ping pong&lt;/a&gt;.  There is also a &lt;a href=&quot;https://www.youtube.com/watch?v=ARbNmCu04Ko&quot; rel=&quot;nofollow noreferrer&quot;&gt;robot that plays the sport of curling&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is an annual event called the &lt;a href=&quot;https://www.youtube.com/watch?v=G9uFIBGSkMg&quot; rel=&quot;nofollow noreferrer&quot;&gt;RoboCup&lt;/a&gt; where robot teams compete in indoor soccer on a scaled down level.  They don't look like they will be beating humans in the next couple of years but it is interesting to watch.  Their web site is: &lt;a href=&quot;http://www.robocup.org/&quot; rel=&quot;nofollow noreferrer&quot;&gt;http://www.robocup.org/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/bwW6c.jpg&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/bwW6c.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are a few challenges that remain to be resolved for robots to play humans in sports.  The biggest one is self-contained power that will last long enough to play a game.  It takes a lot of power to move a human scaled robot and run its electronics, sensors, and computers.  Other challenges are dexterity and agility.  There have been some advances in these areas as this &lt;a href=&quot;https://www.youtube.com/watch?v=8vIT2da6N_o&quot; rel=&quot;nofollow noreferrer&quot;&gt;video&lt;/a&gt; shows.&lt;/p&gt;&#xA;" OwnerUserId="5763" LastEditorUserId="5763" LastEditDate="2018-05-06T01:24:46.663" LastActivityDate="2018-05-06T01:24:46.663" CommentCount="0" />
	<row Id="6286" PostTypeId="2" ParentId="6279" CreationDate="2018-05-06T08:58:15.150" Score="0" Body="&lt;p&gt;AI is best expressed as an autonomous agent, it could be a robot or a piece of software, An agent is anything that perceives things (perhaps imperfectly) about its environment and can then make a decision to execute some actions which will have some (perhaps unpredictable) effect on the environment.&lt;br&gt;&#xA;&lt;a href=&quot;https://i.stack.imgur.com/ezKet.jpg&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/ezKet.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;agents will maintain some internal representation of what they believe the world looks like. As new information arrives, they can update those beliefs and select the best action in response to their beliefs about the state of the world. &lt;a href=&quot;https://dataskeptic.com/blog/episodes/2018/the-agent-model-of-intelligence&quot; rel=&quot;nofollow noreferrer&quot;&gt;The Agent Model of Intelligence&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To change your perspective on AI, check &lt;a href=&quot;http://gym.openai.com/&quot; rel=&quot;nofollow noreferrer&quot;&gt;&quot;OpenAI Gym&quot;&lt;/a&gt;, its a platform for reinforcement learning research released by OpenAI On April 27, 2016.&lt;/p&gt;&#xA;" OwnerUserId="11911" LastActivityDate="2018-05-06T08:58:15.150" CommentCount="0" />
	<row Id="6445" PostTypeId="1" CreationDate="2018-05-18T00:54:06.063" Score="-1" ViewCount="36" Body="&lt;p&gt;For speedrunning purposes, I am trying to train a neural network to identify human-executable ways to manipulate pseudo-RNG (in Pokemon Red, for the interested). The game runs at sixty frames per second, and the linear-congruential PRNG updates every frame, while many frames are unlikely to be relevant to the manipulation (and so should contain no actions from the neural net). Any given manipulation is likely to last 30sec-2min, and the advancement rate of the PRNG can change depending on location in the game-world.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have some experience with coding AI/deep-learning. I've made some programs using Multilayer Perceptron and IndRNN approaches. From what I can tell, IndRNN or A3C would be my best bets. I'm not expert enough to know the correct approach, though, or to know if the dimensionality of the problem makes it outright unfeasible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1) Is this problem reasonably solvable with NN/deep learning?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2) What approach would you recommend to tackle it?&lt;/p&gt;&#xA;" OwnerUserId="15711" LastEditorUserId="2193" LastEditDate="2018-05-18T13:18:48.840" LastActivityDate="2018-05-18T17:01:40.630" Title="Teaching a NN to manipulate pseudoRNG over a long time scale?" Tags="&lt;neural-networks&gt;&lt;game-ai&gt;&lt;recurrent-neural-networks&gt;&lt;learning-algorithms&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="6449" PostTypeId="2" ParentId="6445" CreationDate="2018-05-18T04:02:59.533" Score="0" Body="&lt;p&gt;The point of pseudoRNG is to be unmodable and unpredictable, making it hard to train an AI to learn. It would more likely be useful and more efficient to have the equation that the game uses for generation available, so that you can manually make the check, or to just have a list of the loop if the pseudoRNG is based on the time elapsed.&lt;/p&gt;&#xA;" OwnerUserId="6989" LastEditorUserId="2193" LastEditDate="2018-05-18T17:01:40.630" LastActivityDate="2018-05-18T17:01:40.630" CommentCount="1" />
	<row Id="6715" PostTypeId="1" CreationDate="2018-06-11T19:55:35.770" Score="5" ViewCount="138" Body="&lt;p&gt;A few months ago I made a simple game that is similar to the dinosaur game in Google Chrome - you jump over obstacles, or don't jump over levitating obstacles, and jump to collect bitcoins, which can be placed at 5 different heights. I used a very lightweight NN written by NYU professor Dan Shiffman, and within a few days the game and AI were done, starting off with a population of 200 jumpers, and a genetic algorithm (fitness function (points are given for avoiding obstacles and gathering bitcoins) and mutation), and it worked as it should.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, this was only when the bitcoins and obstacles were not near each other, which I've been struggling with ever since. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, I made a &quot;training ground&quot; where I put first a levitating obstacle, then a grounded one, and then a bitcoin after it, and then a bitcoin above a fourth grounded obstacle, and no matter how many times and how long I'd leave it to train, I'd always end up with identical behavior:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The first 3 obstacles are properly avoided, the first bitcoin is collected, and then jumpers would jump too early, land before the fourth &quot;bitcoin&quot; obstacle, and jump again, always crashing at almost the same place (across all generations, so even if I'd restart the training, they crash at the same place in the obstacle, with a deviation of a few pixels up or down).&#xA;I added multilayer support to the NN, no improvements.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Today I replaced the NN with tensorflow.js, and I am getting identical behaviour.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My inputs are:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;distance to next obstacle  &lt;/li&gt;&#xA;&lt;li&gt;altitude of next obstacle  &lt;/li&gt;&#xA;&lt;li&gt;distance to next star  &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;(for simplicity I removed the altitude of stars from the input, and keep them at a constant altitude)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have 2 hidden layers (5 and 6 neurons), and 1 neuron in the output, which determines if the jumper should jump.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My only idea is that a neuron that decides when to jump because of the obstacle activates alongside the neuron that decides when to jump because of the bitcoin, their weights are summed up and a decision to jump too early is made. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'll give somewhat of a (maybe bad) analogy: &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If it takes you 1 month to prepare an exam, then, if you have 2 exams on the same day, you will start preparing them 2 months earlier. That logic works in this case, but not in my AI.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the initial &quot;toy neural network&quot; I even added 8 layers of 12 neurons each, which I think is overkill for this case.&#xA;In tf.js I used both sigmoid and relu activation functions.&#xA;No matter what I did, no improvement.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Hope someone has an idea where I'm going wrong.&lt;/p&gt;&#xA;" OwnerUserId="16214" LastEditorUserId="16214" LastEditDate="2018-06-11T20:25:43.113" LastActivityDate="2018-11-14T15:02:25.450" Title="Issue with simple game AI" Tags="&lt;reinforcement-learning&gt;&lt;tensorflow&gt;&lt;game-ai&gt;" AnswerCount="1" CommentCount="3" FavoriteCount="1" />
	<row Id="7534" PostTypeId="2" ParentId="6715" CreationDate="2018-08-12T22:41:17.893" Score="0" Body="&lt;p&gt;The issue is likely in how you estimate wellness, how the error function is constructed and from what data, since you have used two known good pieces of software and probably known good derivatives for your activation functions.  The second most likely is in now the components of wellness is aggregated.  Summing squares is sometimes not representative of a solid aggregation strategy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm a bit confused about the game for three reasons.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Stars enter the description without telling us whether they are not obstacles, are obsticles, or the only obstacles&lt;/li&gt;&#xA;&lt;li&gt;At one point bitcoins collection is the objective and obstacles are the challenge and at another point bitcoins are obstacles themselves&lt;/li&gt;&#xA;&lt;li&gt;Your inputs have distance but not direction (Is this 2-D game?)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Based on textual hints, I'm going to assume five simple things, and you can correct any misconceptions I list.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Collecting all bitcoins is part of the objective&lt;/li&gt;&#xA;&lt;li&gt;Running into bitcoins mid-jump is considered a crash&lt;/li&gt;&#xA;&lt;li&gt;There is some radial tolerance to landing in at a bitcoin location with some imprecision&lt;/li&gt;&#xA;&lt;li&gt;There are other things to crash into&lt;/li&gt;&#xA;&lt;li&gt;Your outputs are jump magnitude and direction&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I see that when the bitcoins are not in the vicinity of other things, the net can be trained effectively to jump to them, but when in the vicinity of other things, the training converges on a behavior that repeatedly fails prior to completion.  I'm assuming that the failure location is not 100% repeatable because the genetic algorithm has a pseudo-random seed that changes.  Again, correct me if I misunderstand in my piecing together the scenario.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One should consider the possibility that the distance to non-bitcoin obstacles is part of the error function and the difference between the jump destination and the bitcoin is also part of the error function.  (This second one is why I prefer to call the error contour a wellness measure.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the bitcoin incentive does not seem to be the crash cause, in that, had the other obstacle been moved, the bitcoin would have been collected, then the first of the two wellness criteria needs a higher order contribution from the distance to the other obstacle.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are two simple functional forms that come to mind, which could be tried that increase the alarm represented in back propagation when the probability of collision is heightened to more effectively train against collision.  Both involve determining the direct jump line to the nearest bit coin and the distance from that line to its nearest other obstacle; call that x.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;$x^y$, where $y &amp;gt; 1.0$&lt;/li&gt;&#xA;&lt;li&gt;$e^{kx}$&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="4302" LastEditorUserId="4302" LastEditDate="2018-08-16T13:16:30.807" LastActivityDate="2018-08-16T13:16:30.807" CommentCount="0" />
	<row Id="6748" PostTypeId="1" CreationDate="2018-06-14T02:44:04.580" Score="3" ViewCount="161" Body="&lt;p&gt;I'm a professional game developer investigating the potential for using reinforcement learning to build strategy game AI opponents that have more creative behavior compared to traditional techniques like behavior trees. I have a few questions I've bolded below, any thoughts would be helpful, and could save me from pursuing dead ends.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I created a very boring and tiny game as a test case. Two players each control a fleet of ships, each ship has health and can fire on one other ship each turn dealing some damage. The player and his opponent assigns orders to their respective ships, telling them which target to attack, and then the turn is resolved. Ships with 0 health are removed from the board. The player that loses all their ships first loses the game.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Assuming I was using TensorFlow, at a very high level I need to:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A) Create a training program that outputs a trained graph to a file. The training program will need to map gamestates into tensors, feed the tensors through the graph to produce actions, execute actions on the gamestate to generate a new state, and evaluate the reward function for the new state. Repeat a bunch.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;B) Take the graph created in #1, load it at the game runtime, and use the graph to generate intelligent actions from real gamestates during the Player vs AI match.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As soon as I started digging into TensorFlow, questions immediately came up, and now I'm not quite sure if there is a more appropriate library to do this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I) TensorFlow has a High Level python API, and a Low Level C++ API. Most games are built in C++, and thus using a C++ or C API is preferable, it makes integration with the game much simpler. In principle we could use pybind or some other scheme for sending state from C++ to Python and back again, but that's not ideal. &#xA;&lt;strong&gt;Question 1: How much do I lose by using the low level API specifically for reinforcement learning, compared to the high level API?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;II) Platforms. 99.9% of the time, PC/Console games are developed in Windows environments, and so having Tensorflow work in Windows is critical. From my googling, Tensorflow just &lt;em&gt;barely&lt;/em&gt; supports building in Windows using CMake, though it requires some finagling. More worryingly are other platforms:&#xA;&lt;strong&gt;Question 2: What hope is there of running the TensorFlow library on consoles like XboxOne, Playstation 4, or the Switch? I imagine this would require manually porting the entire source :(&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;III) TensorFlow is big, and it seems you need to basically link all of it to ship with the game.&#xA;&lt;strong&gt;Question 3: Is there any way to get a slimmed down &quot;Runtime TensorFlow&quot; library that is only capable of loading a graph and transforming states into actions?&lt;/strong&gt;&#xA;It seems like if the answer was yes, it might also be easier to port this smaller runtime version to more platforms. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Question 4: Should I even be using TensorFlow for this? Is there perhaps something more suitable?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks again if you read all that, I'm eager to start tinkering, but would like to set off in the right direction.&lt;/p&gt;&#xA;" OwnerUserId="16265" LastEditorUserId="1671" LastEditDate="2018-06-14T21:23:18.807" LastActivityDate="2018-06-14T21:23:18.807" Title="Reinforcement Learning in Commercial Strategy Games" Tags="&lt;reinforcement-learning&gt;&lt;tensorflow&gt;&lt;game-ai&gt;&lt;getting-started&gt;&lt;gaming&gt;" AnswerCount="0" CommentCount="2" />
	<row Id="6953" PostTypeId="1" CreationDate="2018-06-29T14:31:57.610" Score="6" ViewCount="551" Body="&lt;p&gt;I am learning about Monte Carlo algorithms and struggling to understand the following:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;If simulations are based on random moves, how can the modeling of the opponent's behavior work well?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;For example, if I have a node with 100 children, 99 of which lead to an instant WIN, whereas the last one leads to an instant LOSS.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In reality, the opponent would never play any of the 99 losing moves for him (assuming they are obvious as they are the last moves), and would always play the winning one. But the Monte Carlo algorithm would still see this node as extremely favorable (99/100 wins for me), because it sees each of the 100 moves as equally probable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is my understanding wrong, or does it mean that in most games such situations do not occur and randomness is a good approximation of opponent behavior?&lt;/p&gt;&#xA;" OwnerUserId="16597" LastEditorUserId="1641" LastEditDate="2018-09-22T18:14:58.670" LastActivityDate="2018-09-22T18:14:58.670" Title="Why does Monte Carlo work when a real opponent's behavior may not be random" Tags="&lt;game-ai&gt;&lt;search&gt;&lt;monte-carlo-tree-search&gt;" AnswerCount="3" CommentCount="1" FavoriteCount="1" />
	<row Id="6954" PostTypeId="2" ParentId="6953" CreationDate="2018-06-29T15:09:03.767" Score="0" Body="&lt;p&gt;I will point out that the Monte Carlo Tree Search algorithm does not make completely random moves. Instead it usually uses some metric to balance between exploration and exploitation when deciding which branch to search (see Upper Confidence Bound and others).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That being said, you are correct in that a specific line of play which is incredibly troublesome may not be seen and could cause Monte Carlo to make a major mistake. This may have been a cause of AlphaGo losing to Lee Sedol in game 4.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;A disadvantage is that, faced in a game with an expert player, there may be a single branch which leads to a loss. Because this is not easily found at random, the search may not &quot;see&quot; it and will not take it into account. It is believed that this may have been part of the reason for AlphaGo's loss in its fourth game against Lee Sedol. In essence, the search attempts to prune sequences which are less relevant. In some cases, a play can lead to a very specific line of play which is significant, but which is overlooked when the tree is pruned, and this outcome is therefore &quot;off the search radar&quot;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="13088" LastEditorUserId="13088" LastEditDate="2018-06-29T15:38:49.243" LastActivityDate="2018-06-29T15:38:49.243" CommentCount="0" />
  	<row Id="6955" PostTypeId="2" ParentId="6953" CreationDate="2018-06-29T15:30:27.467" Score="1" Body="&lt;p&gt;First, we need to distinguish plain &lt;strong&gt;Monte-Carlo&lt;/strong&gt; from &lt;strong&gt;Monte-Carlo Tree Search&lt;/strong&gt;. They're different things. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Monte-Carlo search&lt;/strong&gt;, in the context of game AI search algorithms, is typically understood to mean that we search randomly many times, and average the results, and nothing else. If this is all we're doing, then yes, your understanding is correct. This is also sometimes referred to as &quot;plain Monte-Carlo (search)&quot; or &quot;pure Monte-Carlo (search)&quot;, to make it explicitly clear that we're not doing any tree search as in Monte-Carlo Tree Search (sometimes when we just say &quot;Monte-Carlo&quot; in the context of game AI, people will automatically assume Monte-Carlo Tree Search, due to how popular it is).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Monte-Carlo Tree Search&lt;/strong&gt; does a lot more than just that though. It gradually builds up a search tree (through the &lt;em&gt;Expansion&lt;/em&gt; step), and within that search tree (which is growing over time), it uses a much more sophsticated strategy for traversal than pure random (the &lt;em&gt;Selection&lt;/em&gt; step). &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;For example suppose i have a node with 100 children, 99 of which leading to an instant WIN, and the last one leading to an instant LOSS.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Suppose that this node you're talking about, the one with those 100 children, is relatively close to the root node. Then, it is likely that it and all 100 of its children will end up &quot;growing into the search tree&quot; that is slowly built up by the Expansion step. Once they have been added to the search tree, the Selection step will make sure that the vast majority of further iterations visiting this part of the tree will select the instant loss (assuming the opponent is to move in this node). &lt;em&gt;In the limit&lt;/em&gt; (after an infinite amount of search time), this bias towards selecting the loss node will be so large that the average evaluation tends to the (correct) minimax evaluation.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Another way to view the idea of evaluation through many random sequences of play is the following; the idea is that if we're in a very strong position, a good game state, then we're more likely to win than to lose if both players start playing at random. Consider, for example, a game of chess where Player 1 has many pieces left, and Player 2 only has a few pieces left. Imagine both players were to play completely at random from that game state onwards. On average, which player would you expect to win more often? Probably Player 1. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;When we're considering game states that are still far away from terminal states, this basic idea tends to work relatively well. Obviously not always correct, it's still a heuristic, but it can kind of work. When we're already very close to a terminal state that can be reached through one highly specific sequence of play, yeah, we might miss that through random actions; this is where we need the more informed policy of the &lt;em&gt;Selection&lt;/em&gt; step.&lt;/p&gt;&#xA;" OwnerUserId="1641" LastEditorUserId="1641" LastEditDate="2018-08-21T08:33:55.060" LastActivityDate="2018-08-21T08:33:55.060" CommentCount="5" />
  	<row Id="7111" PostTypeId="2" ParentId="6953" CreationDate="2018-07-11T03:10:45.763" Score="1" Body="&lt;p&gt;&lt;strong&gt;The Two Questions&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Why does Monte Carlo work when a real opponent's behavior may not be random?&lt;/li&gt;&#xA;&lt;li&gt;If simulations are based on random moves, how can the modeling of the opponent's behavior work well?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Directed Graphs Over Trees&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Games (or game-like strategic scenarios) should not be represented as trees.  If the process paths being represented have the Markov property in that each decision lacks knowledge of history, a particular game state can be approached by more than one path, and there may be cyclic paths where a game state is revisited.  Trees have neither feature.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is best to use directed graph structures to think about these problems.  The state of a game is a vertex and vertices are connected by unidirectional edges.  This is normally drawn as shapes connected by arrows.  When two arrows enter one shape or there is a closed path, it is not a tree.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;The Scenario Outlined in the Question&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the case of the scenario outline in this question, there is a vertex representing a game state with 100 outgoing edges representing possible moves for player A.  Ninety-nine of the edges lead to an obvious instant game win for A.  Exactly one leads to an obvious instant game win for B.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Playing back the game to prior to the traversal of the incoming edge to the vertex before the final move, it cannot be assumed that game play allowed player B the same 100 options.  Even if the same 100 were available to B, they would not necessarily be of similar value from B's perspective when deciding that previous move.  More than likely, B will have had a different set of outgoing edges from which to choose, bearing little or no obvious resemblance to A's subsequent options.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any game where this is not true, where the options remain constant, would be trivial even in comparison with tic-tack-toe.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;The Monte Carlo Approach and Its Algorithm Development&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Regarding the specification of a singular Monte Carlo algorithm, it does not exist.  Goodfellow, Bengio, &amp;amp; Courville correctly state in their &lt;em&gt;Deep Learning&lt;/em&gt;, 2016, that Monte Carlo algorithms (not a singular algorithm) draw a normally correct conclusion but with a non-deterministic occurrence of incorrect conclusion. There are varieties of approach details and associated algorithms in the literature.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Cross-entropy (CE) method proposed by Rubinstein in 1997&lt;/li&gt;&#xA;&lt;li&gt;Continuation multilevel Monte Carlo algorithm; Collier, Haji–Ali, von Schwerin, &amp;amp; Tempone; 2000&lt;/li&gt;&#xA;&lt;li&gt;Sequential Monte Carlo algorithm; Drovandi, McGree, &amp;amp; Pettitt; 2012&lt;/li&gt;&#xA;&lt;li&gt;Distributed consensus approach from Bayes and Big Data: The Consensus Monte Carlo Algorithm; Scott1, Blocker, Bonassi, Chipman, George, &amp;amp; McCulloch; 2014&lt;/li&gt;&#xA;&lt;li&gt;Hamiltonian Monte Carlo, a Markov chain based algorithm designed to avoid, &quot;The random walk behavior and sensitivity to correlated parameters;&quot; Hoffman &amp;amp; Gelman; 2014&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;There are several more.  All attempt to use chaotic perturbation to minimize duration and resource consumption of decisioning by approximating a Monte Carlo simulation from a Bayesian posterior distribution.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The simulation of stochastic nature is usually, in these approaches, accomplished by the injection of a chaotic sequence from a pseudo random number generator.  They are generally not truly stochastic because acquiring entropy from within a digital system is another bottleneck presenting immense difficulties, but that's an entirely tangential topic.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Direct Answer to the Question&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To correct the misconception in the question, this use of chaotic perturbation does not equalize the selection of moves (represented by edges in the game-play's directed graph).  The probabilities of success for each available option are still roughly calculated and followed, but only roughly so because of the psuedo-noise injected by design.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;These disturbances in the application of pure optimization achieve time and resource thrift for the majority of game states (represented by vertices) but concurrently sacrifice some reliability.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;An Overview of Why the Sacrifice Works&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The introduction of chaotic perturbations, mentioned above, modifies the conditions of the optimization search through the achievement of two very specific gains.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Faster coverage of the contour being searched by increasing entropy (being less organized by adding synthetic Brownian motion) across the set of trials.&lt;/li&gt;&#xA;&lt;li&gt;Avoidance of local minima in convergence by being less presumptuous about the contour being searched (slightly less reliant on gradient and curvature hints).&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;This is true of both reinforced networks (containing real time feedback during actual use) or pre-trained networks of the supervised training type (with labelled data) or unsupervised training where convergence is determined by fixed criteria.&lt;/p&gt;&#xA;" OwnerUserId="4302" LastEditorUserId="4302" LastEditDate="2018-08-04T01:24:01.653" LastActivityDate="2018-08-04T01:24:01.653" CommentCount="7" />
	<row Id="6959" PostTypeId="1" AcceptedAnswerId="6960" CreationDate="2018-06-29T19:51:58.097" Score="2" ViewCount="59" Body="&lt;p&gt;I built a simple HTML game. In this game the goal is to click when the blue ball is above the red ball. If you hit, you get 1 point, if you miss, you lose 1 point. With each hit, the blue ball moves faster. &lt;a href=&quot;https://codepen.io/iazzetta/pen/BVxzyr&quot; rel=&quot;nofollow noreferrer&quot;&gt;You can test the game here&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/5L5pQ.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/5L5pQ.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Without using machine learning, I would easily solve this problem by just clicking when the X, Y of the blue ball was on the X, Y of the red ball. Regardless of the time, knowing the positions of the 2 elements I could solve the problem of the game.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;However, if I wanted to create an AI to solve this problem, could I?&#xA;  How would it be? I'd really like to see the AI randomly wandering&#xA;  until it's perfect.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;h2&gt;My way to solve the problem&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;I click many times and watch score. If score down, add to bad_positions. If actual position in bad_positions, not click. At first he misses many times, then starts to hit eternally. &lt;strong&gt;This is machine learning? Deep learning? Just a bot?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;var bad_positions = [];&#xA;function train(){&#xA;  var pos = $ball.offset().left;&#xA;  var last_score = score;&#xA;  if (!bad_positions.includes(pos)) {&#xA;   $('#hit').click();&#xA;    if (score &amp;lt; last_score){&#xA;      bad_positions.push(pos)&#xA;    } &#xA;  }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="7800" LastEditorUserId="7800" LastEditDate="2018-06-29T20:24:08.943" LastActivityDate="2018-06-29T21:36:48.500" Title="How to use Machine Learning with simple games?" Tags="&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;game-ai&gt;&lt;javascript&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="1" />
	<row Id="6960" PostTypeId="2" ParentId="6959" CreationDate="2018-06-29T21:36:48.500" Score="1" Body="&lt;p&gt;You have implemented a simple &lt;a href=&quot;https://getstream.io/blog/introduction-contextual-bandits/&quot; rel=&quot;nofollow noreferrer&quot;&gt;contextual bandit&lt;/a&gt; solver, which is a machine learning algorithm. A few details may be different from a full implementation, but the key elements are:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;A choice of actions (click hit or don't click hit)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;A reward signal that can be observed after each action (+1 for a hit, 0 for nothing happens, -1 for an attack which misses)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;An observable state which affects the reward achievable (the position of the blue ball). For a contextual bandit, the state is not influenced by the action taken. This is true here.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;One thing that is different about your problem from a classic contextual bandit is that the next state &lt;em&gt;is&lt;/em&gt; predictable from the current state (whilst in a pure bandit problem it should be entirely random). However, that's not too important to your problem here, and your solver is definitely following a contextual bandit approach.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Your solver tests the score from trying different actions in each state, and narrows down the best action to take in each state. Your implementation is simple and &quot;greedy&quot; for a contextual bandit solver. A more typical solution would maintain an average result for each action and have a rule for how to explore actions in each state, so it could test whether results were reliable (this is very helpful with non-deterministic scenarios where bandit solvers are more often used).&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;With each hit, the blue ball moves faster&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Unless you somehow limit the reaction time of the agent, this is not relevant to how you write the solver. You &lt;em&gt;could&lt;/em&gt; change the rules affecting the agent to make it relevant in the same way as it would be for a human, e.g. deciding to click means the click happens 0.1 seconds later, and the state can include observations of position just now and several 0.02 seconds going back.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In general, if you want to take this further, with more complex games and still learning how to control agent actions, you could look at simple reinforcement learning agents, such as Q-learning. If you are interested in the underlying theory of agents like this, then a good (and free) introductory text is &lt;a href=&quot;http://incompleteideas.net/book/the-book-2nd.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;Sutton &amp;amp; Barto &quot;Reinforcement Learning: An Introduction&quot;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1847" LastActivityDate="2018-06-29T21:36:48.500" CommentCount="2" />
	<row Id="7051" PostTypeId="1" AcceptedAnswerId="7492" CreationDate="2018-07-06T14:42:14.027" Score="4" ViewCount="122" Body="&lt;p&gt;I'm attempting to create an AI for a card game using reinforcement learning.  The basics of the game are that you can have (theoretically) up to 35 cards in your hand, you can also have to up to 35 cards 'in play' and so can your opponent.  In normal play you would have ~6 cards in your hand and maybe ~3 each in play.  There are roughly 300 unique cards in total.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How should I represent the game state for the input and how should I represent the action to take in the output?&lt;/p&gt;&#xA;" OwnerUserId="16724" LastEditorUserId="16724" LastEditDate="2018-07-06T15:02:21.843" LastActivityDate="2018-08-08T22:00:58.383" Title="Representing inputs and outputs for a card game neural network" Tags="&lt;neural-networks&gt;&lt;reinforcement-learning&gt;&lt;game-ai&gt;" AnswerCount="1" CommentCount="2" />
	<row Id="7492" PostTypeId="2" ParentId="7051" CreationDate="2018-08-08T22:00:58.383" Score="1" Body="&lt;p&gt;Assuming there's no ordering to the hand (i.e. it doesn't matter what order cards were added to it), then a reasonable approach is to use one input neuron for the number of each kind of card that is present in a player's hand. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You don't describe how the game is played, but a common approach for extracting actions is to have one output neuron for each possible action. To select an action, you would pick the one corresponding to the neuron with the highest output response to a given input.&lt;/p&gt;&#xA;" OwnerUserId="16909" LastActivityDate="2018-08-08T22:00:58.383" CommentCount="0" />
	<row Id="7159" PostTypeId="1" CreationDate="2018-07-16T15:37:24.917" Score="11" ViewCount="2584" Body="&lt;p&gt;I am currently new to artificial intelligence but I am very intrigued by it. I am currently researching three algorithms, namely:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Minimax, Alpha-beta pruning and Monte Carlo tree search.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As you may have figured out, these are all tree search algorithms. My question is simple. How do I choose which algorithm is best for something like a checkers board game?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;N.B.&#xA;The reason why I only chose these three algorithms was due to time I have available in understanding them. From a little research, I found that these algorithms are basically interweaved into the minimax algorithm. So if I can understand one, then the other two will just fall into place.&lt;/p&gt;&#xA;" OwnerUserId="16906" LastEditorUserId="1671" LastEditDate="2018-07-24T20:52:25.617" LastActivityDate="2018-07-24T20:52:25.617" Title="How do I choose which algorithm is best for something like a checkers board game?" Tags="&lt;game-ai&gt;&lt;minimax&gt;&lt;alpha-beta-pruning&gt;&lt;monte-carlo-tree-search&gt;" AnswerCount="5" CommentCount="0" FavoriteCount="2" />
	<row Id="7160" PostTypeId="2" ParentId="7159" CreationDate="2018-07-16T16:09:33.520" Score="1" Body="&lt;p&gt;I you have to choose between Minimax and Alpha-Beta pruning you should choose Alpha-beta. It is more efficient and fast because it can prune a substantial part of your exploration tree. But you need to order the actions from the best to the worst depending on max or min point of view, so the algorithm can quickly realize if the exploration is necessary. &lt;/p&gt;&#xA;" OwnerUserId="15949" LastActivityDate="2018-07-16T16:09:33.520" CommentCount="0" />
  	<row Id="7161" PostTypeId="2" ParentId="7159" CreationDate="2018-07-16T16:56:27.287" Score="2" Body="&lt;p&gt;Playing chess with a blind search algorithm like Monte Carlo tree search is a very good idea, because it helps to raise the energy consumption of your 64 core workstation. Using the maximum capacity of a cpu and ignoring any possible kind of heuristics is a best practice method in proofing real scientific progress. One advantage of Minimax in contrast to the Monte Carlo algorithm is, that Minimax has a Nash equilibrium which makes it well suited for a mathematical terminology and an abstract introduction into game theory. This helps to focus away from the original problem (how to play chess) into a more general discussion about zero-sum games and payoff matrix. The third strategy on your list (alpha beta-prunning) sounds also well suited for running a server farm under maximum load without ever finding out the best move.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My advice is similar to your own perception: if you have understood the minimax strategy, all the other algorithm are much easier to implement. And minimax is the right choice, if you're planning to stay away from rules of thumb which are implemented as a symbolic planner in LISP.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/pq2hu.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/pq2hu.png&quot; alt=&quot;Minimax algorithm&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="11571" LastActivityDate="2018-07-16T16:56:27.287" CommentCount="0" />
  	<row Id="7165" PostTypeId="2" ParentId="7159" CreationDate="2018-07-16T18:31:16.950" Score="13" Body="&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;None of these algorithms are practical for modern work, but they are good places to start pedagogically. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;You should always prefer to use Alpha-Beta pruning over bare minimax search.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;You should prefer to use some form of heuristic guided search if you can come up with a useful heuristic. Coming up with a useful heuristic usually requires a lot of domain knowledge.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;You should prefer to use Monte Carlo Tree search when you lack a good heuristic, when computational resources are limited, and when mistakes will not have outsize real-world consequences.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;More Details:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In minimax search, we do not attempt to be very clever. We just use a standard dynamic programming approach. It is easy to figure out the value of difference moves if we're close to the end of the game (since the game will end in the next move, we don't have to look very far ahead). Similarly, if we know what our opponent will do in the last move of the game, it's easy to figure out what we should do in the second last move. Effectively we can treat the second last move as the last move of a shorter game. We can then repeat this process. Using this approach is certain to uncover the best strategies in a standard extensive-form game, but will require us to consider every possible move, which is infeasible for all but the simplest games.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alpha-Beta pruning is a strict improvement on Minimax search. It makes use of the fact that some moves are obviously worse than others. For example, in chess, I need not consider any move that would give you the &lt;em&gt;opportunity&lt;/em&gt; to put me in checkmate, even if you could do other things from that position. Once I see that a move might lead to a lose, I'm not going to bother thinking about what else might happen from that point. I'll go look at other things. This algorithm is also certain to yield the correct result, and is faster, but still must consider most of the moves in practice.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are two common ways you can get around the extreme computational cost of solving these kinds of games exactly:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;Use a Heuristic (A* search is the usual algorithm for pedagogical purposes, but Quiescence search is a similar idea in 2 player games). This is just a function that gives an &lt;em&gt;estimate&lt;/em&gt; of the value of a state of the game. Instead of considering all the moves in a game, you can just consider moves out to some finite distance ahead, and then use the value of the heuristic to judge the value of the states you reached. If your heuristic is consistent (essentially: if it always &lt;em&gt;overestimates&lt;/em&gt; the quality of states), then this will still yield the correct answer, but with enormous speedups in practice.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Use Rollouts (like Monte Carlo Tree Search). Basically, instead of considering every move, run a few thousand simulated games between players acting randomly (this is faster than considering all possible moves). Assign a value to states equal to the average win rate of games starting from it. This may not yield the correct answer, but in some kinds of games, it performs reliably. It is often used as an extension of more exact techniques, rather than being used on its own.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;" OwnerUserId="16909" LastEditorUserId="16909" LastEditDate="2018-07-16T21:31:59.717" LastActivityDate="2018-07-16T21:31:59.717" CommentCount="9" />
  	<row Id="7167" PostTypeId="2" ParentId="7159" CreationDate="2018-07-16T19:07:25.377" Score="5" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;N.B The reason why I only chose these three algorithms was due to time I have available in understanding them. From a little research, I found that these algorithms are basically interweaved into the minimax algorithm. So if I can understand one then the other two will just fall into place.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Given this context, I would recommend starting out with Minimax&lt;/strong&gt;. Of the three algorithms, Minimax is the easiest to understand.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Alpha-Beta&lt;/strong&gt;, as others have mentioned in other answers, is a strict improvement on top of Minimax. Minimax is basically a part of the Alpha-Beta implementation, and a good understanding of Alpha-Beta requires starting out with a good understanding of Minimax anyway. If you happen to have time left after understanding and implementing Minimax, I'd recommend moving on to Alpha-Beta afterwards and building that on top of Minimax. Starting out with Alpha-Beta if you do not yet understand Minimax doesn't really make sense.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Monte-Carlo Tree Search&lt;/strong&gt; is probably a bit more advanced and more complicated to really, deeply understand. In the past decade or so, MCTS really has been growing to be much more popular than the other two, so from that point of view understanding MCTS may be more &quot;useful&quot;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The connection between Minimax and MCTS is less direct/obvious than the connection between Minimax and Alpha-Beta, but there still is a connection at least on a conceptual level. &lt;strong&gt;I'd argue that having a good understanding of Minimax first is still beneficial before diving into MCTS&lt;/strong&gt;; in particular, understanding Minimax and its flaws/weak points can provide useful context / help you understand why MCTS became &quot;necessary&quot; / popular.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;To conclude, in my opinion:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Alpha-Beta is strictly better than Minimax, but also strongly related / built on top of Minimax; so, start with Minimax, go for Alpha-Beta afterwards if time permits&lt;/li&gt;&#xA;&lt;li&gt;MCTS has different strengths/weaknesses, is often better than Alpha-Beta in &quot;modern&quot; problems (but not always), a good understanding of Minimax will likely be beneficial before starting to dive into MCTS&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1641" LastActivityDate="2018-07-16T19:07:25.377" CommentCount="5" />
  	<row Id="7172" PostTypeId="2" ParentId="7159" CreationDate="2018-07-17T00:55:46.777" Score="1" Body="&lt;p&gt;The selection from among those and others mentioned in other answers to the question is important, yes, and there are conceptual overlaps, but those are not algorithms.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Minimax, Alpha-beta pruning, Monte Carlo tree search are approaches to dealing with the spanning trees of the graphs associated with Markov chains to find an optimum next move based on metrics derived from vertices and edges.  There are many potential algorithms that could realize each approach in software.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The best approaches and the best algorithms to realize them depend on many things.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Dimensions of the data paths&lt;/li&gt;&#xA;&lt;li&gt;Hardware utilization options exposed through the operating system, cluster, and language employed&lt;/li&gt;&#xA;&lt;li&gt;Desired performance criteria and priorities&lt;/li&gt;&#xA;&lt;li&gt;Time requirements&lt;/li&gt;&#xA;&lt;li&gt;Skill and knowledge of the development team&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Although many frameworks available in Python, Java, and other languages will provide ways to overlap concepts and rapid prototype, you cannot just learn one and the others will fall into place.  You can hack through to a working solution for your current problem, but if you want to develop the ability to reliably create reliable software, there are no such shortcuts.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In my experience, the thing to start with is neither of the three.  It is the commitment to diligence and thoughtfulness in ML software development.  If we, as engineers and researchers do not commit to this, then the unreliability of smart systems we create will, in 50 years, rival the unreliability of cell phone connections.  We could, to the detriment of safety and economic stability, exceed the maintainability issues characteristic of much of the middle tier software in production today.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I encourage those entering into this powerful and future-critical field to aim much higher than that.&lt;/p&gt;&#xA;" OwnerUserId="4302" LastActivityDate="2018-07-17T00:55:46.777" CommentCount="0" />
	<row Id="7173" PostTypeId="1" AcceptedAnswerId="7177" CreationDate="2018-07-17T01:17:14.057" Score="1" ViewCount="72" Body="&lt;p&gt;AI became superior to the best human players in chess around 20 years ago (when the 2nd Deep Blue match concluded). However, it took until 2016 for an AI to beat the Go world chess champion, and this feat required heavy machine learning.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My question is why was/is Go a harder game for AIs to master than Chess? I assume it has to do with Go's enormous branching factor; on a 13x13 board it is 169, while on a 19x19 board it is 361. Meanwhile, Chess typically has a branching factor of around 30.&lt;/p&gt;&#xA;" OwnerUserId="16917" LastActivityDate="2018-07-17T07:33:41.057" Title="Why was Go a harder game for an AI to master than Chess?" Tags="&lt;game-ai&gt;&lt;chess&gt;&lt;branching-factors&gt;&lt;go&gt;&lt;decision-tree&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="7177" PostTypeId="2" ParentId="7173" CreationDate="2018-07-17T07:33:41.057" Score="2" Body="&lt;p&gt;The branching factor is important, as it limits the effectiveness of search.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, the branching factor in chess is already too high to effectively search without techniques that reduce the size of the search space. Even with millions of tests per second, a computer can only check a small fraction of the possible future games in order to find results in its favour. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;One key factor is heuristics - approximate measures of the value of each game state. A good heuristic can guide and improve search by orders of magnitude. There are some effective heuristics possible in chess, from weighted values of the pieces in play, scores for areas of the board that a position controls etc. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Heuristics for Go are much harder to find. &lt;a href=&quot;https://webdocs.cs.ualberta.ca/~mmueller/ps/goeval.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;Here's a sample paper from a few years ago that makes an attempt&lt;/a&gt;, there are several similar ones available online. Although plenty of options have been tried, and many were partially successful, none managed to bring the quality of computer play up to the standard of best human players. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;One of the major achievements of AlphaGo was training a neural network that had good position evaluation - the &quot;value network&quot;. The technology that made generating this approximate function of board game positions possible was deep learning, which has been developed very strongly since about 2010. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is still possible a more analytical heuristic approach could be found that challenges deep learning models driven by self-play reinforcement learning on more raw board data. However, in some regards the reverse has been shown, with &lt;a href=&quot;https://en.wikipedia.org/wiki/AlphaZero&quot; rel=&quot;nofollow noreferrer&quot;&gt;AlphaZero taking the same learning technique into chess&lt;/a&gt; and demonstrating its effectiveness against &quot;old school&quot; tuned expert heuristics.&lt;/p&gt;&#xA;" OwnerUserId="1847" LastActivityDate="2018-07-17T07:33:41.057" CommentCount="1" />
	<row Id="7180" PostTypeId="1" CreationDate="2018-07-17T13:34:55.370" Score="4" ViewCount="185" Body="&lt;p&gt;Imagine the fictitious scenario in a role playing game (RPG) where the non-playing characters (NPCs) within the RPG are conscious of their own surrounding and consider the developer to be god.  The people inside can also live a normal life in that they can create new life, eat, die, and perform other functions humans experience.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Will this qualify them to be an AI?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Will the children of the NPCs qualify as an AI?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Might this be realized in the future?&lt;/p&gt;&#xA;" OwnerUserId="14371" LastEditorUserId="4302" LastEditDate="2018-07-27T18:18:43.870" LastActivityDate="2018-07-27T23:57:38.077" Title="What if there's a game where all the AI people actually lived?" Tags="&lt;game-ai&gt;&lt;game-theory&gt;&lt;theory&gt;&lt;soft-question&gt;&lt;artificial-consciousness&gt;" AnswerCount="4" CommentCount="1" FavoriteCount="1" />
	<row Id="7183" PostTypeId="2" ParentId="7180" CreationDate="2018-07-17T15:03:10.813" Score="1" Body="&lt;p&gt;&lt;strong&gt;Yes&lt;/strong&gt;, a baby can be considered an AI. Will this be our future? &lt;strong&gt;I don't know&lt;/strong&gt;. That is exactly what some people are looking for, to create an AI that can live. We have several AIs that each time more surprises us. But none of them question their own existence, none of them wants to know or require attention from their god (developer) because of their reflections. I believe that what we create today can be equated with a mosquito of our real life: a brainless &quot;being&quot; that performs simple actions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The cool thing about believing in such a future with Artificial Intelligence is that we do not have to repeat our mistakes. We do not need an AI evolving according to age, it can be born with a superintelligence, knowing everything, learning only new things that are not foreseen.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some humans (and I) have a passion for the human, for every detail and imperfection, and dream of re-creating something as mysterious and complex as through an AI. It seems something impossible, some believe that it would be impossible only because who created us would be a perfect being (god). But others (me) do not stop at this issue, and continue the quest to create an AI with some characteristics of the human, such as: feelings, reflecting on one's own acts, ...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But all this, as far as I know, is surreal and only projection of our mind. It is already something interesting, for creating new challenges for humanity.&lt;/p&gt;&#xA;" OwnerUserId="7800" LastActivityDate="2018-07-17T15:03:10.813" CommentCount="0" />
  	<row Id="7184" PostTypeId="2" ParentId="7180" CreationDate="2018-07-17T15:06:33.150" Score="0" Body="&lt;p&gt;I think it is a very good idea to populate the whole universe with AI characters, because this helps to spread out singularity faster. In the literature the concept is called swarm or &lt;a href=&quot;https://en.wikipedia.org/wiki/Crowd_simulation&quot; rel=&quot;nofollow noreferrer&quot;&gt;crowd simulation&lt;/a&gt;, because many AI individuals are working together in the same environment. This concept shouldn't be misinterpreted as multi-agent system, because this is a blackboard like architecture which is active in one individual. The appropriate term is swarm simulation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If the individuals are able to recognize the developer of the environment as god, depends on their conciseness level. This is a scale to measure the intelligence. It starts with zero, goes to animal AI, human level AI and at the maximum it is super-human universal AI which understands everything. The scale is called ConsScale and determines the level of Machine Consciousness. &lt;a href=&quot;http://www.conscious-robots.com/consscale/levels.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;Level 7&lt;/a&gt; means, that the AI robot can recognize themself as an AI.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/RiX34.jpg&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/RiX34.jpg&quot; alt=&quot;sitting on a stone&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="11571" LastEditorUserId="1671" LastEditDate="2018-07-17T17:04:49.950" LastActivityDate="2018-07-17T17:04:49.950" CommentCount="0" />
  	<row Id="7187" PostTypeId="2" ParentId="7180" CreationDate="2018-07-17T18:58:23.600" Score="0" Body="&lt;p&gt;This is a standard trope in science fiction, although more common is the idea of transferring minds from real people into a virtual environment.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Right now, such an idea is still firmly in science fiction. We don't know a few things:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;What consciousness is in detail. There are various educated guesses and philosophical stances, but none have been seriously verified.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;What the minimal environment is that can support consciousness. This is important because simulating more complex environments is more computationally expensive. There is a &lt;strong&gt;huge&lt;/strong&gt; gulf between capabilities of current computers and something that could simulate reality to the level of granularity that we can experience and manipulate it (let alone to the depth that we can scientifically investigate). &lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Will this consider them to be an AI?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Assuming you can solve the caveats above, then yes, perhaps even a &quot;&lt;a href=&quot;https://en.wikipedia.org/wiki/Artificial_general_intelligence#Relationship_to_%22strong_AI%22&quot; rel=&quot;nofollow noreferrer&quot;&gt;Strong AI&lt;/a&gt;&quot; in the domain of the game, but not a human-equivalent &lt;a href=&quot;https://en.wikipedia.org/wiki/Artificial_general_intelligence&quot; rel=&quot;nofollow noreferrer&quot;&gt;AGI&lt;/a&gt; (depending on the complexity of the environment).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you mixed a current RPG game with some agents driven by our current best game-playing bots, and improved them so that they are able to solve problems within the game - e.g. in World of Warcraft, or perhaps in Minecraft - then you would have something as advanced or better than any current &quot;narrow AI&quot; that solves points scoring or adversarial games. You would be justified in calling it &quot;AI&quot;, if OpenAI and Deep Mind can call their achievements &quot;AI&quot;. However, it seems unlikely such agents would be much like your imagined simulated people - having consciousness etc.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Would this be real in the future?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Depends on the constraints faced by researchers. To get to an imagined point where this is possible, we have to extrapolate current trends on computing power and advances in understanding goal-driven AI and self-awareness. There is a range of opinions on how likely this is, how much power is required etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is a compelling idea, and unlike say faster-than-light travel, there are no widely-accepted theoretical limits that prevent it. &lt;/p&gt;&#xA;" OwnerUserId="1847" LastActivityDate="2018-07-17T18:58:23.600" CommentCount="0" />
  	<row Id="7309" PostTypeId="2" ParentId="7180" CreationDate="2018-07-27T23:57:38.077" Score="0" Body="&lt;p&gt;The question can be extended further:  What if the NPCs were smart enough to design digital systems capable of housing a game much like the one they are in?  This would not be recursion in the sense of ancestors and descendants within a species, but actual recursion in the domain of speciation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Working backward, how can we know for sure that we aren't God's RPG, and, more importantly, what difference would there be between that scenario and the ancient middle eastern conceptualization of the monotheistic creation?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The bidirectionality of this scenario was examined on the screen by writer-director David Cronenberg in his 1999 film eXistenZ, staring Jude Law, Jennifer Jason Leigh, and Ian Holm (recommended).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Regarding the sub-question, &quot;Will this qualify them to be an AI?&quot; that depends on two things.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;How one defines intelligence, a somewhat slippery word to define &lt;sup&gt;1&lt;/sup&gt;&lt;/li&gt;&#xA;&lt;li&gt;What facilities and propensities are imbued into the hardware and software that bring the NPCs to artificial life.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Regarding whether the children of the NPCs qualify as AI, definitively yes if the parents qualify and the children are adequate replicas or artificially genetic improvements.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Might this be realized in the future?  That depends on a number of things.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Will the earth avert global extinction events?&lt;/li&gt;&#xA;&lt;li&gt;Will humanity accidentally exterminate itself? &lt;sup&gt;2&lt;/sup&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Some call all of this science fiction or Futurism.  I do not.  Such things are gradually developing and have been for at least the duration of my life.  I've been an interested spectator in this very real drama.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;[1] The philosophic question of whether super-human intelligence humans can't possess is a prerequisite to characterizing human intelligence is well represented in cybernetic literature reaching as far back as Charles Babbage and perhaps further in the early biochemical interests of Abu Mūsā Jābir ibn Hayyān.  Defining what intelligence means is more than looking at functional MRIs or running tests in Python.  If we define intelligence as the ability to collaborate, ants and even bacteria may be more intelligent than humans.  If we define intelligence as the ability to efficiently construct artifices of benefit to the species, bees exceed humans.  Humans can determine mathematically that hexagonal rooms are 1.7 times more efficient than square rooms in terms of construction materials, but is it intelligence that, having determined that ratio centuries ago, humans continue to waste materials on square rooms?  We don't see bacteria, ants, or bees shooting narcotics either.  In some respects, by some definitions of intelligence, humans would qualify as the dominant morons of all terrestrial life forms.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;[2] &quot;Darwin's dice have rolled badly for Earth. The human species is, in a word, an environmental abnormality. Perhaps a law of evolution is that intelligence usually extinguishes itself.&quot; &amp;mdash; Harvard U Professor 1955 and Pulitzer Prize winner for General Nonfiction, New York Times Magazine, May 30th, 1993, &lt;em&gt;Is Humanity Suicidal?&lt;/em&gt;&lt;/p&gt;&#xA;" OwnerUserId="4302" LastActivityDate="2018-07-27T23:57:38.077" CommentCount="0" />
	<row Id="7231" PostTypeId="1" CreationDate="2018-07-20T23:38:25.483" Score="4" ViewCount="117" Body="&lt;p&gt;I know that they are quite alot of optimizations for alpha-beta pruning but what does it mean exactly:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1) Does it mean that these optimized algorithms are to be integrated into the alpha-beta algorithm or&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2) Does it mean that these optimizations are completely new algorithms in that they have got nothing to do the alpha-beta algorithms?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the note of alpha beta optimizations, I have come across a lot of optimizations like Iterative deepening, Principal variation Search, Quiescence search and many more. My second question is the optimizations listed above are found in the site &quot;&lt;a href=&quot;https://chessprogramming.wikispaces.com/Search&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://chessprogramming.wikispaces.com/Search&lt;/a&gt;&quot;, but this site groups these algorithms into 4 categories namely, Mandatory, Selectivity, Scout and friends and lastly Alpha-beta goes best-first. Does this mean that alpha-beta algorithm is split into four areas and that they are specialized optimization algorithms for each area? This is really confusing me. How do I even begin to decide which optimized algorithm to pick?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I advise people to visit this site:&#xA;&lt;a href=&quot;http://www.fierz.ch/strategy2.htm&quot; rel=&quot;nofollow noreferrer&quot;&gt;http://www.fierz.ch/strategy2.htm&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;not, &lt;a href=&quot;https://chessprogramming.wikispaces.com/Search&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://chessprogramming.wikispaces.com/Search&lt;/a&gt;, this website to beginners like myself is just too distracting with all of its links on each page. This just becomes too overwhelming for a beginner to understand.&lt;/p&gt;&#xA;" OwnerUserId="16906" LastEditorUserId="16906" LastEditDate="2018-07-22T15:22:11.593" LastActivityDate="2018-07-22T15:22:11.593" Title="Alpha-beta pruning algorithms optimizations" Tags="&lt;game-ai&gt;&lt;minimax&gt;&lt;alpha-beta-pruning&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="7236" PostTypeId="2" ParentId="7231" CreationDate="2018-07-21T10:05:43.973" Score="1" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;1) Does it mean that these optimized algorithms are to be integrated into the alpha-beta algorithm or&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;2) Does it mean that these optimizations are completely new algorithms in that they have got nothing to do the alpha-beta algorithms?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Most of them are extensions of the Alpha-Beta pruning algorithm. For example, Iterative Deepening is almost the same as Alpha-Beta pruning, but automatically keeps repeating the algorithm with gradually-increasing depth limits until some time limit is reached, rather than just running once for a pre-determined depth limit.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Principal Variation Search also still uses Alpha-Beta as a basis, but performs many searches with significantly smaller &lt;code&gt;[alpha, beta]&lt;/code&gt; windows than the standard Alpha-Beta pruning algorithm.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In most cases, these extensions would start out from an existing Alpha-Beta implementation, and build from there with some adaptations in the code. This is not necessarily the case for all of those extensions though, just for most. For example, Transposition Tables are kind of a separate extension that could be plugged into vanilla Minimax, or Alpha-Beta, or Principal Variation Search, or whatever you're using.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;My second question is the optimizations listed above are found in the site &quot;&lt;a href=&quot;https://chessprogramming.wikispaces.com/Search&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://chessprogramming.wikispaces.com/Search&lt;/a&gt;&quot;, but this site groups these algorithms into 4 categories namely, Mandatory, Selectivity, Scout and friends and lastly Alpha-beta goes best-first. Does this mean that alpha-beta algorithm is split into four areas and that they are specialized optimization algorithms for each area?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Those four categories are not mutually exclusive, they're more like... broad &quot;flavours&quot;. What they list under Obligatory are some of the more basic extensions that any programmer should probably look into first if they were developing a chess-playing program. The other category are different &quot;flavours&quot;, different &quot;broad ideas&quot;. For example, everything listed under &quot;Selectivity&quot; is about searching &quot;interesting&quot; or &quot;exciting&quot; parts of the search tree deeper than &quot;less interesting&quot; or &quot;boring&quot; parts. Many of those ideas could be used regardless of whether you're using Alpha-Beta, Iterative Deepening, or PVS, and probably all could be combined with Transposition Tables as well.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;How do I even begin to decide which optimized algorithm to pick?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;This is really really difficult to decide just based on the names. In theory, which algorithm is the &quot;best&quot; will also highly depend on your specific game, and maybe even hardware. And, in many cases it's not even a choice between mutually exclusive parts; different ideas can be combined with each other in different ways.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The only solution here is really just to do lots of reading, lots of research, try implementing different things to better understand them.&lt;/p&gt;&#xA;" OwnerUserId="1641" LastActivityDate="2018-07-21T10:05:43.973" CommentCount="0" />
	<row Id="7254" PostTypeId="1" CreationDate="2018-07-23T09:05:00.573" Score="1" ViewCount="55" Body="&lt;p&gt;Games like checkers have compulsory moves. In checkers for instance, if there's a jump available a player must take it over any non-jumping move.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My question is, if jumps are compulsory will there still be a need for quiescence search?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My thinking is that I can develop an implementation of quiescence search that first checks whether jumps are available. If there are then it can skip all non-jumping moves. If there's only one jumping move available, then I won't need to run a search at all.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I will therefore only use quiescence search if I initially don't have to make a jump on my first move. I will only active quiescence search in my alpha beta pruning becomes active. (The alpha beta will only be active if my first algorithm which first checks if there are jumps available returns a 0, which means there  are no jumps available.)&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Is my thinking of implementing quiescence search correct? &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;My options are slim when it comes to optimizations due to serious memory constraints, hence I won't be using PVS or other algorithm like that as they require additional memory.&lt;/em&gt;&lt;/p&gt;&#xA;" OwnerUserId="16906" LastEditorUserId="1671" LastEditDate="2018-07-23T19:15:20.600" LastActivityDate="2018-07-23T19:15:20.600" Title="Quiescence search" Tags="&lt;game-ai&gt;&lt;optimization&gt;&lt;minimax&gt;&lt;checkers&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="7260" PostTypeId="2" ParentId="7254" CreationDate="2018-07-23T13:19:44.157" Score="3" Body="&lt;p&gt;I understand your question to be:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;If some moves are compulsory, and my agent has no choice about which move to make next, do I need to perform a search, or can I just return the compulsory move?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;The answer depends on what your goal is.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If your goal is to make an interactive agent that will play the game against you, then you are correct: there's no need to perform a search. Just return the compulsory move, and then run the search next time your agent has a choice about what to do.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If your goal is to determine the optimal way to play a game, or the expected payoff from a certain game position (another common use of search techniques), then you should run the search as normal, since the forced move won't necessarily lead to a particular end state.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Tangentially, if you're interested in ways to speed up search for checkers, check out the Chinook papers. There's a popularized account &lt;a href=&quot;https://www.aaai.org/ojs/index.php/aimagazine/article/viewFile/1208/1109&quot; rel=&quot;nofollow noreferrer&quot;&gt;here&lt;/a&gt;, and more technical ones &lt;a href=&quot;https://mycourses.aalto.fi/pluginfile.php/273655/course/section/60890/ICS-E4000_checkers_is_solved.solved.science.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://www.ijcai.org/Proceedings/05/Papers/0515.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;here&lt;/a&gt; by Schaeffer et al.&lt;/p&gt;&#xA;" OwnerUserId="16909" LastActivityDate="2018-07-23T13:19:44.157" CommentCount="0" />
	<row Id="7518" PostTypeId="1" AcceptedAnswerId="7708" CreationDate="2018-08-11T06:41:18.710" Score="4" ViewCount="85" Body="&lt;p&gt;I am trying to make balanced weapon pairs. So there are five stats per weapon, and I am simulating a number of combats (1000) with different stats randomized, and counting the win, lose, and draw of the &quot;weapon fight&quot; for the database. I want an algorithm for making weapon1win-weapon2win as small as possible for balance through changing the weapon stats.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What happens:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Random Stats --&gt; Combat 1000 Times --&gt; Count Win &amp;amp; Lose --&gt; Data For Training The AI&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Data Sample:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;{[(1,2,3,4,5) --&gt; Weapon1Stats,(5,4,3,2,1) --&gt;Weapon2Stats,1 --&gt; WinWeapon1-WinWeapon2],[....]} (The text isn't part of the data sample, they are just there to help you know which variable is which. Also, the {[( s are all supposed to be [ s but changed for clarity)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like an function, preferably in C++ or Python, but just with text that is well explained is fine, for handling the data. The result would be a method to determine how to minimize WinWeapon1-WInWeapon2.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(edit)&#xA;I would say that the one I was looking for is one with something like a score for the weapon as in strength (1*stat1 + 2*stat2 etc...) but I do want something new that works better, I am also having problems creating leeway for the functions coefficients.(edit end)&lt;/p&gt;&#xA;" OwnerUserId="17423" LastEditorUserId="1671" LastEditDate="2018-08-13T20:54:59.367" LastActivityDate="2018-08-25T00:37:53.073" Title="Algorithm For Making Balanced Weapons In A Game?" Tags="&lt;algorithm&gt;&lt;game-ai&gt;&lt;python&gt;&lt;datasets&gt;&lt;c++&gt;" AnswerCount="1" CommentCount="7" />
	<row Id="7708" PostTypeId="2" ParentId="7518" CreationDate="2018-08-25T00:37:53.073" Score="2" Body="&lt;p&gt;I'm going to start by trying to restate your problem as I understand it.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;You have a game which contains weapons.&lt;/li&gt;&#xA;&lt;li&gt;Weapons are characterized by 5 different numbers, which can range over different values (1-5 in your examples?).&lt;/li&gt;&#xA;&lt;li&gt;You have a way to simulate combat involving the two weapons. &lt;/li&gt;&#xA;&lt;li&gt;The combat is random, but can be repeated many times. An average win rate can be determined.&lt;/li&gt;&#xA;&lt;li&gt;You are looking for an AI algorithm that would take in a lot of pairs of statistics, along with the average win rates for one over the other, and give you insight into how to make the average win rate as close to 50% as possible.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;If this sounds right, then fundamentally your problem is a form of &lt;a href=&quot;https://en.wikipedia.org/wiki/Linear_regression&quot; rel=&quot;nofollow noreferrer&quot;&gt;regression&lt;/a&gt;, which something you &lt;em&gt;could&lt;/em&gt; use AI for, but probably don't need to. However, your problem is probably not linear, so you need the interactions between the features. Here's what I suggest:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For each pair of weapons, store a comma separated list consisting of the stats for each weapon (one by one), followed by wins1 - wins2. At the top, list out the names of each attribute, separated by commas, (e.g. weapon1Str, weapon1Range, ... ,weapon1-weapon2 Then use a &lt;a href=&quot;https://www.r-project.org/about.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;language like R&lt;/a&gt; that has simple support for complex forms of regression.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In R, this is then as simple as:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;data &amp;lt;- read.csv(file=&quot;Myfile.csv&quot;)&#xA;lm(formula = dist ~ .*., data = data)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;This should produce a list of &quot;coefficients&quot;, one for each of the attributes, and one for the interaction between each pair of attributes, which form a lengthy quadratic equation in 10 variables.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any zero of that equation should be a pair of weapons that minimizes this difference.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That's probably the place to start. If it doesn't work out, maybe come post a different question and we can help more.&lt;/p&gt;&#xA;" OwnerUserId="16909" LastActivityDate="2018-08-25T00:37:53.073" CommentCount="0" />
	<row Id="7589" PostTypeId="1" AcceptedAnswerId="7590" CreationDate="2018-08-16T02:13:15.483" Score="6" ViewCount="87" Body="&lt;p&gt;To the best of my understanding, Monte Carlo Search is an alternative method to Minimax for searching a tree of nodes. It works by choosing a move (generally the one with the highest chance of being the best), and then performing a random playout on the move to see what the result is. This process keeps continuing for however much time is allotted.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This doesn't sound like Machine Learning, but rather a way to traverse a tree. However, I've heard that AlphaZero uses Monte Carlo search, so I'm confused. Is using Monte Carlo search why AlphaZero learns? Or did AlphaZero do some kind of machine learning before it played any matches, and then use the intuition it gained from Machine learning to know which moves to spend more time playing out with Monte Carlo search?&lt;/p&gt;&#xA;" OwnerUserId="16917" LastActivityDate="2018-08-16T08:53:16.167" Title="Does Monte Carlo Search (specifically used by AlphaZero) Qualify as Machine Learning?" Tags="&lt;machine-learning&gt;&lt;reinforcement-learning&gt;&lt;game-ai&gt;&lt;monte-carlo-tree-search&gt;&lt;alphazero&gt;" AnswerCount="2" CommentCount="0" />
	<row Id="7590" PostTypeId="2" ParentId="7589" CreationDate="2018-08-16T02:25:00.650" Score="5" Body="&lt;p&gt;Monte Carlo Tree Search is not usually thought of as a machine learning technique, but as a search technique. There are parallels (MCTS does try to learn general patterns from data, in a sense, but the patterns are not very general), but really MCTS is not a suitable algorithm for most learning problems.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;AlphaZero was a combination of several algorithms. One was MCTS, but MCTS needs a function to tell it how good different states of the game might be (or else, it needs to simulate entire games). One way to handle this function in a game like chess or Go is to approximate it by training a neural network, which is what the Deep Mind researchers did. This is the learning component of AlphaZero. &lt;/p&gt;&#xA;" OwnerUserId="16909" LastEditorUserId="1641" LastEditDate="2018-08-16T08:25:51.067" LastActivityDate="2018-08-16T08:25:51.067" CommentCount="0" />
	<row Id="7596" PostTypeId="2" ParentId="7589" CreationDate="2018-08-16T08:39:12.793" Score="3" Body="&lt;p&gt;John's answer is correct in that MCTS is traditionally not viewed as a Machine Learning approach, but as a tree search algorithm, and that AlphaZero combines this with Machine Learning techniques (Deep Neural Networks and Reinforcement Learning).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, there are some interesting similarities between MCTS itself and Machine Learning. In some sense, MCTS attempts to &quot;learn&quot; the value of nodes from experience generated through those nodes. This is very similar to how Reinforcement Learning (RL) works (which itself is typically described as a subset of Machine Learning). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some researchers have also experimented with replacements for the traditional &lt;em&gt;Backpropagation phase&lt;/em&gt; of MCTS (which, from an RL point-of-view, can be described as implementing a Monte-Carlo backups) based on other RL methods (e.g., Temporal-Difference backups). A comprehensive paper describing these sorts of similarities between MCTS and RL is: &lt;a href=&quot;https://jair.org/index.php/jair/article/view/11099/26289&quot; rel=&quot;nofollow noreferrer&quot;&gt;On Monte Carlo Tree Search and Reinforcement Learning&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also note that the &lt;em&gt;Selection phase&lt;/em&gt; of MCTS is typically treated as a sequence of small Multi-Armed Bandit problems, and those problems also have strong connections with RL.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;: MCTS is not normally viewed as a Machine Learning technique, but if you inspect it closely, you can find lots of similarities with ML (in particular, Reinforcement Learning).&lt;/p&gt;&#xA;" OwnerUserId="1641" LastEditorUserId="1641" LastEditDate="2018-08-16T08:53:16.167" LastActivityDate="2018-08-16T08:53:16.167" CommentCount="0" />
	<row Id="7611" PostTypeId="1" AcceptedAnswerId="7613" CreationDate="2018-08-16T23:33:09.813" Score="4" ViewCount="91" Body="&lt;p&gt;I'm making a Connect Four game where my engine uses Minimax with Alpha-Beta pruning to search. Since Alpha-Beta pruning is much more effective when it looks at the best moves first (since then it can prune branches of poor moves), I'm trying to come up with a set of heuristics that can rank moves from best to worst. These heuristics obviously aren't guaranteed to always work, but my goal is that they'll &lt;em&gt;often&lt;/em&gt; allow my engine to look at the best moves first. An example of such heuristics would be as follows:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Closeness of a move to the centre column of the board - weight 3.&lt;/li&gt;&#xA;&lt;li&gt;How many pieces surround a move - weight 2.&lt;/li&gt;&#xA;&lt;li&gt;How low, horizontally, a move is to the bottom of the board - weight 1.&lt;/li&gt;&#xA;&lt;li&gt;etc&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;However, I have no idea what the best set of weight values are for each attribute of a move. The weights I listed above are just my estimates, and can obviously be improved. I can think of two ways of improving them:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1) Evolution. I can let my engine think while my heuristics try to guess which move will be chosen as best by the engine, and I'll see the success score of my heuristics (something like x% guessed correctly). Then, I'll make a pseudo-random change/mutation to the heuristics (by randomly adjusting one of the weight values by a certain amount), and see how the heuristics do then. If it guesses better, then that will be my new set of heuristics. Note that when my engine thinks, it considers thousands of different positions in its calculations, so there will be enough data to average out how good my heuristics are at prediction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2) Generate thousands of different heuristics with different weight values from the start. Then, let them all try to guess which move my engine will favor when it thinks. The set of heuristics that scores best should be kept.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm not sure which strategy is better here. Strategy #1 (evolution) seems like it could take a long time to run, since every time I let my engine think it takes about 1 second. This means testing each new pseudo-random mutation will take a second. Meanwhile, Strategy #2 seems faster, but I could be missing out on a great set of heuristics if I myself didn't include them.&lt;/p&gt;&#xA;" OwnerUserId="16917" LastEditorUserId="1641" LastEditDate="2018-08-17T12:08:28.820" LastActivityDate="2018-08-17T12:08:28.820" Title="More effective way to improve the heuristics of an AI... evolution or testing between thousands of pre-determined sets of heuristics?" Tags="&lt;game-ai&gt;&lt;evolutionary-algorithms&gt;&lt;search&gt;&lt;heuristics&gt;&lt;alpha-beta-pruning&gt;" AnswerCount="2" CommentCount="0" />
	<row Id="7613" PostTypeId="2" ParentId="7611" CreationDate="2018-08-17T09:07:14.453" Score="1" Body="&lt;p&gt;Hmmm, I see some issues that are actually present in both of the approaches you propose.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is important to note that the depth level that your Minimax search process manages to reach, and therefore also the speed with which it can traverse the tree, is extremely important for the algorithm's performance. Therefore, when evaluating how good or bad a particular heuristic function for move ordering is, &lt;strong&gt;it is not only important to look at how well it ordered moves; it is also important to take into account the runtime overhead of the heuristic function call&lt;/strong&gt;. If your heuristic functions manages to sort well, but is so computationally expensive that you can't search as deep in the tree, it's often not really worth it. Neither of the solutions you propose are able to take this into account.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another issue is that it's not trivial to measure what ordering is the &quot;best&quot;. A heuristic that has the highest accuracy for the position of the best move only is not necessarily the best heuristic. For example, a heuristic that always places the best move in the second position ($0\%$ accuracy because it's in the wrong position, should be first position) might be better than a heuristic that places the best move in the first position $50\%$ of the time ($50\%$ accuracy), and places the best move last in the other $50\%$ of cases.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;I would be more inclined to evaluate the performance of different heuristic functions by setting up tournaments where different versions of your AI (same search algorithm, &lt;strong&gt;same processing time constraints per turn&lt;/strong&gt;, different heuristic function) play against each other, and &lt;strong&gt;measuring the win percentage&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This set up can also be done with two variants analogous to what you proposed; you can exhaustively put all the heuristic functions you can come up with against each other in tournaments, or you can let let an evolutionary algorithm sequentially generate populations of hypothesis-heuristic-functions, and run a tournament with each population. Generally, &lt;strong&gt;I would lean towards the evolutionary approach&lt;/strong&gt;, since we expect it to search the same search space of hypotheses (heuristic functions), but we expect it to do so in a more clever / efficient manner than an exhaustive search. Of course, if you happen to have a ridiculous amount of hardware available (e.g., if you're Google), you might be able to perform the complete exhaustive search at once in parallel.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Note that there are also ways to do fairly decent move ordering without heuristic functions like the ones you suggested.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, you likely should be using &lt;strong&gt;iterative deepening&lt;/strong&gt;; this is a variant of your search algorithm where you first only perform a search with a depth limit $d = 1$, then repeat the complete search process with a depth limit $d = 2$, then again with a limit $d = 3$, etc., until processing time runs out.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Once you have completed such a search process for a depth limit $d$, and move on to the subsequent search process with a limit of $d + 1$, you can order order the moves &lt;strong&gt;in the root node&lt;/strong&gt; according to your evaluations from the previous search process (with depth limit $d$). Yes, here you would only have move ordering in the root node, and nowhere else, but this is by far the most influential / important place in the tree to do move ordering. Move ordering becomes less and less important as you move further away from the root.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you're using a &lt;strong&gt;transposition table&lt;/strong&gt; (TT), it is also common to store the &quot;best move&quot; found for every state in your TT. If, later on, you run into a state that already exists in your TT (which will be very often if you're using iterative deepening), and if you cannot directly take the stored value but have to actually do a search (for instance, because your depth limit increased due to iterative deepening), you can search the &quot;best move&quot; stored in the TT first. This is very light move ordering in that you only put one move at the front and don't order the rest, but it can still be effective.&lt;/p&gt;&#xA;" OwnerUserId="1641" LastActivityDate="2018-08-17T09:07:14.453" CommentCount="5" />
  	<row Id="7614" PostTypeId="2" ParentId="7611" CreationDate="2018-08-17T10:19:46.747" Score="0" Body="&lt;p&gt;With regards to random vs evolutionary algorithm, an evolutionary algorithm will almost always be superior.  Imagine the space of all possible heuristics.  An evolutionary algorithm moves through it 'intelligently' i.e. it somewhat follows the gradient of the space and should converge to a local optimum.  A random algorithm will not be able to achieve this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With regards to the time taken, surely it would be the same for each one to evaluate X heuristics?&lt;/p&gt;&#xA;" OwnerUserId="16724" LastActivityDate="2018-08-17T10:19:46.747" CommentCount="0" />
	<row Id="7618" PostTypeId="1" AcceptedAnswerId="7626" CreationDate="2018-08-17T20:47:17.640" Score="3" ViewCount="70" Body="&lt;p&gt;I recently &lt;a href=&quot;https://ai.stackexchange.com/a/7582/1671&quot;&gt;came across this function&lt;/a&gt;:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;$$\sum_{t = 0}^{\infty} \gamma^t R_t.$$&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's elegant and looks to be useful in the type of deterministic, perfect-information, finite models I'm working with.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, it occurs to me that using $\gamma^t$ in this manner might be seen as somewhat arbitrary.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Specifically, the objective is to discount per the added uncertainty/variance of &quot;temporal distance&quot; between the present gamestate and any potential gamestate being evaluated, but that variance would seem to be a function of the branching factors present in a given state, and the sum of the branching factors leading up to the evaluated state.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Are there any defined discount-factors based on the number of branching factors for a given, evaluated node, or the number of branches in the nodes leading to it?  &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;If not, I'd welcome thoughts on how this might be applied. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;(An initial thought is that I might divide 1 by the number of branches and add that value to the goodness of a given state, which is a technique I'm using for heuristic tie-breaking with no look-ahead, but that's a &quot;value-add&quot; as opposed to a discount.)&lt;/em&gt;  &lt;/p&gt;&#xA;&#xA;&lt;h2&gt;--------------------&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;For context, this is for a form of &lt;a href=&quot;https://www.reddit.com/r/abstractgames/comments/8khl96/formal_definition_of_mnpgames/&quot; rel=&quot;nofollow noreferrer&quot;&gt;partisan Sudoku&lt;/a&gt;, where an expressed position $p_x$ (value, coordinates) typically removes some number of potential positions $p$ from the gameboard.  &lt;em&gt;(Without the addition of an element displacement mechanic, the number of branches can never increase.)&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On a $(3^2)^2$ Sudoku, the first $p_x$ removes $30$ out of $729$ potential positions $p$, including itself.   &lt;/p&gt;&#xA;&#xA;&lt;p&gt;With each $p_x$, the number of branches diminishes until the game collapses into a tractable state, allowing for perfect play in endgames.  [Even there, a discounting function may have some utility because outcomes sets of ratios. Where the macro metric is territorial (controlled regions at the end of play), the most meaningful metric may ultimately be &quot;efficiency&quot; &lt;em&gt;(loosely, &quot;points_expended to regions_controlled&quot;)&lt;/em&gt;, which acknowledges a benefit to expending the least amount of points $p_x$, even in a tractable endgame where the ratio of controlled regions cannot be altered. Additionally, zugzwangs are possible in the endgame, and in that case reversing the discount to maximize branches may have utility.]&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sub&gt; $(3^2)^2 = 3x3(3x3) = &quot;9x9&quot;$ but the exponent is preferred so as not to restrict the number of dimensions. &lt;/sub&gt;&lt;/p&gt;&#xA;" OwnerUserId="1671" LastEditorUserId="1671" LastEditDate="2018-08-22T19:45:02.567" LastActivityDate="2018-09-07T20:43:57.300" Title="Are there any discount-factors based on branching factors?" Tags="&lt;ai-design&gt;&lt;algorithm&gt;&lt;game-ai&gt;&lt;math&gt;&lt;discount-factor&gt;" AnswerCount="2" CommentCount="0" />
	<row Id="7644" PostTypeId="1" AcceptedAnswerId="7663" CreationDate="2018-08-20T14:09:31.723" Score="5" ViewCount="66" Body="&lt;p&gt;I've developed a neural network that can play a card game.  I now want to use it to create decks for the game.  My first thought would be to run a lot of games with random decks and use some approximation (maybe just a linear approximation with a feature for each card in your hand) to learn the value function for each state.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, this will probably take a while, so in the mean time is there any way I could get this information directly from the neural network? &lt;/p&gt;&#xA;" OwnerUserId="16724" LastActivityDate="2018-08-21T15:52:24.657" Title="Can you analyse a neural network to determine good states?" Tags="&lt;neural-networks&gt;&lt;game-ai&gt;" AnswerCount="1" CommentCount="4" FavoriteCount="2" />
	<row Id="7663" PostTypeId="2" ParentId="7644" CreationDate="2018-08-21T15:52:24.657" Score="4" Body="&lt;p&gt;I don't think your network, trained using PPO to play a card game, already contains sufficient information to also use for drafting. I'm not saying this with 100% certainty, maybe there's something I'm overlooking, but I can't think of anything right now.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A small adaptation to the network might be sufficient (though it would also involve re-training again). Recently, OpenAI has been writing about their attempts to train agents to play the game DOTA 2. Now, this isn't a card game, it doesn't require deckbuilding, but there is an aspect to the game that is somewhat similar to deckbuilding: &lt;em&gt;drafting&lt;/em&gt;. In DOTA 2, there are two teams of 5 players each. Before a game start, each team selects 5 &lt;em&gt;heroes&lt;/em&gt; (one per player) to play in that game. This is very similar to deckbuilding, except that it's likely a much smaller problem; there's only a &quot;deck&quot; (team composition) of 5 &quot;cards&quot; (heroes).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Anyway, they also trained agents to play the game (controlling one hero per agent) using PPO. In a &lt;a href=&quot;https://blog.openai.com/openai-five-benchmark-results/&quot; rel=&quot;nofollow noreferrer&quot;&gt;blog post&lt;/a&gt;, they write the following about how they managed to add drafting capabilities relatively easily:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;In late June we added a win probability output to our neural network to introspect what OpenAI Five is predicting. When later considering drafting, we realized we could use this to evaluate the win probability of any draft: just look at the prediction on the first frame of a game with that lineup. In one week of implementation, we crafted a fake frame for each of the 11 million possible team matchups and wrote a tree search to find OpenAI Five’s optimal draft.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;So, if you want to try a similar technique, you'd have to adapt your network such that it also learns to generate a prediction of the win probability as output. I imagine that it'd be much less effective for deckbuilding, because win probabilities may all be very close to 50% in card games where luck (when drawing cards for example) can be a significant factor, but it might be worth a try.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Alternatively, instead of generating lots of random decks and playing with them all, you could view the problem of deckbuilding as an additional separate &quot;game&quot; or Markov Decision Process; adding a specific card to the deck can be an action, and this MDP terminates once you have a complete deck. Then you can try to do that better than random using search algorithms (like Monte-Carlo Tree Search) or, again, a Reinforcement Learning approach like PPO. Again, I imagine it will be a very difficult problem though, likely requiring lots of time before it will be capable of doing better than random.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;I also know of some research related to deckbuilding in the collectible card game &lt;em&gt;Hearthstone&lt;/em&gt;, which may be relevant for you. Unfortunately I did not yet get to read through any of this in detail, so I don't know for sure if you'll find a solution here, but it may be worth a try:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://dockhorn.antares.uberspace.de/wordpress/additional-material/&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://dockhorn.antares.uberspace.de/wordpress/additional-material/&lt;/a&gt;: At the recent IEEE CIG 2018 conference, there were two competitions involving Hearthstone: one for game-playing AI with pre-built decks, and for generating new decks (and then playing with them). The page I linked to here contains references to related work from earlier years.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1806.09771&quot; rel=&quot;nofollow noreferrer&quot;&gt;Q-DeckRec: A Fast Deck Recommendation System for Collectible Card Games&lt;/a&gt;: This is a new paper that was published in the proceedings of this recent IEEE CIG 2018 conference.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1641" LastActivityDate="2018-08-21T15:52:24.657" CommentCount="0" />
	<row Id="7696" PostTypeId="1" CreationDate="2018-08-24T08:16:56.343" Score="3" ViewCount="58" Body="&lt;p&gt;So I wrote simple feed forward neural network that plays tic-tac-toe:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;9 neurons in input layers: 1 - my sign, -1 - opponent's sign, 0 - empty;&lt;/li&gt;&#xA;&lt;li&gt;9 neurons in hidden layer: value calculated using Relu;&lt;/li&gt;&#xA;&lt;li&gt;9 neurons in output layer: value calculated using softmax;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I am using evolutionary approach: 100 individuals play against each other (all-play-all). Top 10 best are selected to mutate and reproduce into the next generation. The fitness score calculated: +1 for correct move (it's possible to place your sing on already occupied tile), +9 for victory, -9 for a defeat.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I notice is that the network's fitness keeps climbing up and falling down again. It seems that my current approach only evolves certain patterns on placing signs on the board and once random mutation interrupts current pattern new one emerges. My network goes in circles without ever evolving actual strategy. I suspect solution for this would be to pit network against tic-tac-toe AI, but is there any way to evolve actual strategy just by making it to playing against itself?&lt;/p&gt;&#xA;" OwnerUserId="17693" LastEditorUserId="1671" LastEditDate="2018-08-24T19:55:37.763" LastActivityDate="2018-08-24T19:55:37.763" Title="Evolving network in game" Tags="&lt;neural-networks&gt;&lt;training&gt;&lt;game-ai&gt;&lt;evolutionary-algorithms&gt;&lt;feedforward&gt;" AnswerCount="0" CommentCount="9" />
	<row Id="7762" PostTypeId="1" AcceptedAnswerId="7943" CreationDate="2018-08-30T20:05:59.967" Score="4" ViewCount="131" Body="&lt;p&gt;Artificial Intelligence can be realized as a full autonomous or as a semi-autonomous system. A full autonomous system takes the human operator out of the loop, his hands are away from keyboard and he is doing nothing. Such systems have a high probability of failure because most software isn't able to model the system overall. In contrast, a semi-autonomous system supports the human player in a co-working space. The human stays in control but the AI is providing heat-up displays, suggestions and automation of minor tasks. Such a semi-autonomous system is called &lt;a href=&quot;https://ai.stackexchange.com/questions/5656/it-is-advisable-to-use-c-to-start-in-the-world-of-ai&quot;&gt;Aimbot&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note: This question can also be asked from an anti-cheat point of view. I am just asking this question out of curiosity.  CS:GO refers to &lt;a href=&quot;https://en.wikipedia.org/wiki/Counter-Strike:_Global_Offensive&quot; rel=&quot;nofollow noreferrer&quot;&gt;Counter-Strike Global Offensive&lt;/a&gt;.&lt;/strong&gt;&lt;/em&gt; &lt;br&gt;&lt;br&gt;&#xA;Considering the fact that we can move forward with this problem with &lt;em&gt;two apparent solutions&lt;/em&gt; in mind.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;First one can be an image recognition model. It will recognize the&lt;br&gt;&#xA;head of the enemy and move the cursor to the position of the enemy's &#xA;head and fire.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Second one can be a model which will be trained using the viewing&#xA;angles    of your model in real time.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Things to consider:&lt;/strong&gt; &lt;br&gt;&#xA;It would be much more preferable to train the second model in real time than using demos. Most of the available demos you might have may be 32 tick, but while playing the game, it works at 64 tick.&lt;br&gt;&lt;br&gt;&#xA;These were my thoughts on it. It is a very fresh idea in my mind, so I didn't actually think a lot about it. Ignoring facts like detection by VAC for a few moments.&#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;strong&gt;Can someone suggest ways I could get started with something like this?&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Later on this idea can be expanded to a completely  self working BOT which can play the game by itself, but that's a bit too much initially.&lt;/p&gt;&#xA;" OwnerUserId="17849" LastEditorUserId="11571" LastEditDate="2018-08-31T06:56:52.853" LastActivityDate="2018-09-13T06:45:20.927" Title="How to go forward with creating an artifically intelligent aimbot for a game like CS:GO" Tags="&lt;neural-networks&gt;&lt;game-ai&gt;&lt;getting-started&gt;&lt;generative-adversarial-networks&gt;" AnswerCount="2" CommentCount="14" />
	<row Id="7869" PostTypeId="2" ParentId="7762" CreationDate="2018-09-07T07:00:51.687" Score="0" Body="&lt;p&gt;Thare are many ways to approache this. One approach to start would be to try to describe the problem using a formalism closer to reinforcement learning. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Output:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Aiming in any shooter type game, as I recall, involves moving the mouse. So the output of your aimbot has two dimentions. Depending on the required accuracy, you can consider these two dimentions continous, with a limited range, or if you consider each pixel as a integer, you might be able to discretize your action space. (I assume mouse XY coordinates should be input to the game, not increments)&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Input:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;You  definetly need screen information. You can take the whole screen as input to a CNN, similarly to DeepQLearning for Atari.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Reward function&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;This might be tricky since your rewards need to be as dense as possible, however, the only feedback you get from the game is that someone was shot. &#xA;It might be ebough but this will definetly increase your training time. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Training data / Environemnt:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Your environment for training is the game itseld. Using a &lt;a href=&quot;https://ronan.collobert.com/pub/matos/2009_curriculum_icml.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;curriculum learning&lt;/a&gt; approach would probably make the training process more efficient. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can also try an &lt;a href=&quot;https://arxiv.org/abs/1801.06503&quot; rel=&quot;nofollow noreferrer&quot;&gt;imitation learning&lt;/a&gt; approach, since I assume you are happy to provide expert training examples (in this case probably headshots in the game environment). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can read more about how to apply reinforcement learning for games &lt;a href=&quot;https://github.com/Unity-Technologies/ml-agents&quot; rel=&quot;nofollow noreferrer&quot;&gt;here&lt;/a&gt;. The Unity ML-Agents Library also includes sample tracking problems and their solutions. &lt;/p&gt;&#xA;" OwnerUserId="2585" LastActivityDate="2018-09-07T07:00:51.687" CommentCount="0" />
	<row Id="7943" PostTypeId="2" ParentId="7762" CreationDate="2018-09-13T04:48:51.533" Score="0" Body="&lt;p&gt;&lt;strong&gt;Automation of Game-play&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Aimbots are indeed designed to provide assistance to the human game player when the complexity of game play escapes full cybernetic autonomy at the current state of technology.  There are five basic components in any game player, DNA based or digital.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Acquisition of the current state of the game&lt;/li&gt;&#xA;&lt;li&gt;Control over execution of move options&lt;/li&gt;&#xA;&lt;li&gt;Intercommunication with other players&lt;/li&gt;&#xA;&lt;li&gt;Models related to the game&lt;/li&gt;&#xA;&lt;li&gt;Execution engine for applying these&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The models are as follows for a CS:GO aimbot.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Model of game players&lt;/li&gt;&#xA;&lt;li&gt;Model of the opposing team&lt;/li&gt;&#xA;&lt;li&gt;Model of the game player being assisted&lt;/li&gt;&#xA;&lt;li&gt;Model of that player's team&lt;/li&gt;&#xA;&lt;li&gt;Model of the opposing team&lt;/li&gt;&#xA;&lt;li&gt;Model of the game state&lt;/li&gt;&#xA;&lt;li&gt;Model of legal game moves that transition state&lt;/li&gt;&#xA;&lt;li&gt;Model of objectives (winning or maintaining a top score)&lt;/li&gt;&#xA;&lt;li&gt;Models of game-play strategy involving the first three items in the previous list &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Learning all of these is not in the scope of current deep learning strategies but not outside the scope of AI if the following problem analysis and system approaches are taken.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Assumptions are made similar to those of Morgenstern and von Neumann in the later chapters of their &lt;em&gt;Game Theory&lt;/em&gt; to mathematically treat the decisioning of game players in a minimalistic way.&lt;/li&gt;&#xA;&lt;li&gt;DSP, GPU, network realization hardware, cluster computing, or some other artificial network hardware acceleration is available&lt;/li&gt;&#xA;&lt;li&gt;Models programmed in Prolog, DRools, or some other production system and then leveraged by the execution engine in conjunction with other components such as deep learning networks, convolution processing, Markov trees, fuzzy logic, and the application of oversight functions or heuristics as needed&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The two services, (a) the provision of suggestions and (b) the automation of minor tasks, may indeed represent the low hanging fruit from a software engineering perspective, but the problem analysis and system approach above may provide more.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Objectives in CS:GO&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The CS:GO (Counter-Strike Global Offensive) game seems to have been written from a Westphalian geopolitical point of view.  This is the typical western perspective, somewhat oblivious to the mindset of the true nature of asymmetric warfare&lt;sup&gt;1&lt;/sup&gt;.  This answer will focus on the creation of an aimbot for the existing models of game-play rather than a realistic simulation of geopolitical balance in this decade.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We have the objective types listed in online resources that provide a game overview, again, narrowed in authenticity by the prevailing western view of asymmetric war&lt;sup&gt;1&lt;/sup&gt;.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Terminating players of the opposing team&lt;/li&gt;&#xA;&lt;li&gt;Planting a bomb toward that end (terrorists only)&lt;/li&gt;&#xA;&lt;li&gt;Defend hostages (terrorists only)&lt;/li&gt;&#xA;&lt;li&gt;Prevention of bomb casualties (counter-terrorists only)&lt;/li&gt;&#xA;&lt;li&gt;Rescue of hostages (counter-terrorists only)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ballistic Control&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The targetting of the body or head of an opponent is within the scope of what image recognition can do in conjunction with a movement model.  In military applications, aeronautic devices must be propelled against air friction and the propulsion requires a largely exothermic reaction like combustion.  Thus all targets have a heat signature, which can be recognized in an infrared video stream in such a way as to plot an intercept course for the ballistic weapon.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The targetting formulation for CS:GO is not as complex and aiming and firing may be fully automated with much less software machinery.  A LSTM with sufficient speed can be trained to recognize a head in subsequent frames and terminate opponents even if moving.  A simple web search for LSTM will provide a plethora of resources to the novice intending to learn about image recognition.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;One Ambiguity&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Whether the second objective can be met is dependent on what is meant by the term, &quot;Viewing angles,&quot; in the context of image recognition.  Can the player see from perspectives other than the location of their eyes?  If so, this answer can be adjusted if given a clear picture of what is meant.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Training and Re-entrant Learning&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Training of an artificial neural net to target a head is unnecessary unless the 3D rendering of the game objects and players is distorted by a wide angle virtual lens and trajectories and movements are curved.  As mentioned LSTM can be used to locate a head in multiple frames and extrapolate an opposing players trajectory.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where deep learning may be most effective is in the training of how to interact with the player to best assist.  Also, if there are other non-targeting techniques that are more discrete, those who play CS:GO well could record their interactions and those recordings can be processed in preparation for use as training data.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Certainly a re-entrant learning strategy such as reinforcement is useful for game-play especially if the make up of teams changes and players exhibit different behaviors, executing differing strategies over different networks with different latencies and through-puts, and communicating with the game clients through different peripheral devices.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;[DeepMind Lab Test Bed for Reinforcement Technology](&lt;a href=&quot;https://github.com/deepmind/lab&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://github.com/deepmind/lab&lt;/a&gt;}&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;More than Suggestions&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With proper architecture, more than suggestive strategies can be provided to the player.  Statistical dashboards, identification of a bomb before or after planting, and identification of hostages should be among the aimbot services provided, which might suggest a new name, such as obot for objective bot or asbot for assistive bot.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is not certain that the aimbot interface need be integrated with dashboards or bomb or hostage identifiers.  Sometimes independent bots provide a more flexible arrangement for a user.  Individual bots can always use the same underlying image recognition components and models.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Entry Points into Developing Such a System&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Read some of the work on the above concepts and download what code you can find that demonstrates it in Python or Java, install what is necessary, and develop some proficiency with the components discussed above as well as the associated theory.  Don't shy away from the math, since success will require some proficiency with feedback signalling and concepts like gradient descent and back-propagation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://scholar.google.com/scholar?hl=en&amp;amp;as_sdt=0%2C10&amp;amp;q=reinforcement+games&amp;amp;btnG=&quot; rel=&quot;nofollow noreferrer&quot;&gt;Reinforcement in Games&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://scholar.google.com/scholar?hl=en&amp;amp;as_sdt=0%2C10&amp;amp;q=lstm+locating+head&amp;amp;btnG=&quot; rel=&quot;nofollow noreferrer&quot;&gt;LSTM Head Locating&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1312.5602.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;Playing Atari with Deep Reinforcement Learning, Mnih et al., 2013&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Phased Approach&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The following phased research and development approach is suggested.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Learn the theory&lt;/li&gt;&#xA;&lt;li&gt;Practice the theory in code&lt;/li&gt;&#xA;&lt;li&gt;Develop the image recognition front end&lt;/li&gt;&#xA;&lt;li&gt;Develop the library to control a virtual player&lt;/li&gt;&#xA;&lt;li&gt;Develop at least one of the above models&lt;/li&gt;&#xA;&lt;li&gt;Create the simplest bot to use it&lt;/li&gt;&#xA;&lt;li&gt;Expand automation from there&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Footnotes&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;[1] In asymmetric power struggles, there are always at least two factions within each side because didactic legitimacy seeks division.  Unity is not practically possible.  Each real team usually has a more religious and more secular faction, each of which has economic, philosophic, and historical justifications for their position and agenda.  Also, terrorists don't seek the public detonation of bombs or retention of hostages as objective but rather as means, with the total elimination of all not fully adhered to their view of legitimacy as the sole endgame objective.  Suicide or high risk bombing is considered by most of those that employ it as the poor man's nukes, so without nuclear strike capability for the counter-terrorists and their allies, the terrorism lacks the important dimension of last resort.  The last resort aspect of nuclear strike is missing from the counter-terrorist side too.  CS:GO may sell better by glossing over these particular characteristics of asymmetric warfare and such was left out deliberately.  There may be some benefit to adding these features in from an educational and anti-propaganda point of view.&lt;/p&gt;&#xA;" OwnerUserId="9203" LastEditorUserId="9203" LastEditDate="2018-09-13T06:45:20.927" LastActivityDate="2018-09-13T06:45:20.927" CommentCount="0" />
	<row Id="7877" PostTypeId="1" AcceptedAnswerId="7878" CreationDate="2018-09-07T14:42:12.617" Score="3" ViewCount="102" Body="&lt;p&gt;I'm confused regarding a specific detail of MCTS.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To illustrate my question, lets take the simple example of tic-tac-toe.&#xA;After the selection phase, when a leaf node is reached, the tree is expanded in the so called Expansion Phase. Lets say a particular leaf node has 6 children. Would the expansion phase expand all the children and run simulation on them? Or would the expansion phase only pick a single child at random and run simulation, and only expand the other children if the selection policy arrives at them at some later point?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alternatively, if both of these are accepted variants, what are the pros/cons of each one?&lt;/p&gt;&#xA;" OwnerUserId="12201" LastActivityDate="2018-09-07T15:56:10.540" Title="Monte Carlo Tree Search Expansion Phase" Tags="&lt;algorithm&gt;&lt;game-ai&gt;&lt;monte-carlo-tree-search&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="7878" PostTypeId="2" ParentId="7877" CreationDate="2018-09-07T15:56:10.540" Score="1" Body="&lt;p&gt;By far the &lt;strong&gt;most common&lt;/strong&gt; (and likely also the most simple / straightforward) implementation is to &lt;strong&gt;expand exactly one node in the Expansion Phase&lt;/strong&gt;; specifically, &lt;strong&gt;the node corresponding to the very first state selected (semi-)randomly by the Play-Out Phase&lt;/strong&gt;. This is also pretty much the bare minimum you have to do if you want any form of tree growing at all (which you do).&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Other variants are possible too, but are much less common. The variant you suggest in the question is to &lt;strong&gt;expand all the children of the final node encountered during the Selection Phase, and run a Play-Out for all of them&lt;/strong&gt;. I am not familiar with any literature on such a strategy really, never tried that myself. Intuitively, I would expect it to perform very similarly, perhaps &lt;em&gt;slightly&lt;/em&gt; worse. Essentially what this would do is that it moves the &quot;behaviour&quot; of the search algorithm slightly more towards Breadth-First Search behaviour, rather than Best-First search behaviour. You spend a bit less of your computation time in the Selection Phase, because every Selection Phase is followed up by for example 6 (or whatever branching factor you have) Play-Outs instead of just a single one. On average I'd expect this to be slightly worse, because the Selection Phase is the primary source of the &quot;Best-First Search&quot; behaviour of the algorithm. I certainly don't expect a change like this to cause a large difference in performance though, if any. It will also likely be domain-dependent; worse in some cases, better in other cases.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;A different variant that I did once use myself is to &lt;strong&gt;expand every node in the complete line of play followed by the Play-Out phase&lt;/strong&gt;. You can visualize this as a very &quot;thin&quot;, but &quot;deep&quot; expansion, whereas your suggestion discussed above would be visualized as a &quot;shallow&quot; but &quot;wide&quot; expansion (and the conventional expansion strategy of a single node would be &quot;thin&quot; and &quot;shallow&quot;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For this strategy, it is much easier to clearly define the advantages and disadvantages that it has in comparison to the standard strategy. The main &lt;strong&gt;advantage&lt;/strong&gt; is that you &lt;strong&gt;retain more information from your Play-Outs&lt;/strong&gt;, you throw less information away. This is because the Backpropagation phase, after the Play-Out terminates, can only store information in nodes that exist. If you immediately expand the complete line of play followed in the Play-Out Phase, you can store the result (the evaluation in the terminal state) in all of those nodes. If you don't expand the complete Play-Out (e.g. only expand the very first node), you'll have to &quot;skip&quot; all of those nodes which you didn't expand yet (they don't exist), and you can't store results in there yet.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The main &lt;strong&gt;disadvantage&lt;/strong&gt; of this approach is that it requires &lt;strong&gt;more memory&lt;/strong&gt;, the tree grows a lot more quickly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would personally recommend this approach if you have &lt;strong&gt;very strict limitations on computation time&lt;/strong&gt;, if you expect to be able to only run very few iterations of the MCTS algorithm. For example, I personally used this in my &lt;a href=&quot;https://github.com/DennisSoemers/MaastCTS2&quot; rel=&quot;nofollow noreferrer&quot;&gt;General Video Game AI agent&lt;/a&gt;; this is a real-time game where you have to make decisions every &lt;strong&gt;~40 milliseconds&lt;/strong&gt;. In such a low amount of time, you cannot run many MCTS simulations. This means that:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;You do not expect to run out of memory, even if you grow your tree very quickly, so the increased memory requirements become a non-issue.&lt;/li&gt;&#xA;&lt;li&gt;Due to the low expected number of iterations, it is extremely important to retain as much information as possible, not throw any information away. If we can't run many simulations, we want to make sure to squeeze every little bit of information we can out of each of them.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;For contrast, if you're developing an agent to play a board game, and it has in the order of &lt;strong&gt;multiple minutes of thinking time&lt;/strong&gt; per turn, the standard approach of only expanding a single node per Expansion Phase becomes a lot more appealing. If you're capable of running tens of thousands of iterations or more, it really doesn't hurt if you &quot;forget&quot; about a little bit of information deep down in the tree. The risk of running out of memory also becomes a lot more serious if you're running many iterations, so you don't want to grow the tree too quickly.&lt;/p&gt;&#xA;" OwnerUserId="1641" LastActivityDate="2018-09-07T15:56:10.540" CommentCount="2" />
	<row Id="7881" PostTypeId="1" CreationDate="2018-09-07T23:43:14.730" Score="4" ViewCount="79" Body="&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Connect6&quot; rel=&quot;nofollow noreferrer&quot;&gt;Connect6&lt;/a&gt; is an example of a game with a very high branching factor. It is about 45 thousand, dwarfing even the impressive Go.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What algorithms can you use on games with such high branching factors? I tried MCTS (soft rollouts, counting a ply as placing one stone), but it does not even block the opponent, due to the high branching factor.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the case of Connect6, there are stronger AIs out there, but they aren't described in any research papers that I know of.&lt;/p&gt;&#xA;" OwnerUserId="18006" LastActivityDate="2018-09-08T10:52:44.217" Title="Algorithms for games with very high branching factors (Connect6)" Tags="&lt;algorithm&gt;&lt;game-ai&gt;&lt;monte-carlo-tree-search&gt;&lt;combinatorial-games&gt;&lt;branching-factors&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="7887" PostTypeId="2" ParentId="7881" CreationDate="2018-09-08T10:52:44.217" Score="5" Body="&lt;p&gt;Typically, Monte-Carlo Tree Search (MCTS) actually is the go-to &quot;solution&quot; for such problems with large branching factors. I can understand that &quot;vanilla&quot; MCTS may still have unsatisfactory performance, but there is a plethora of extensions/enhancements available.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I don't have experience with the specific game you mentioned (Connect6), but from a quick look at how the game works, I imagine there will be a huge number of transpositions in the search tree (positions that are the same but can be reached through multiple different paths in the search tree). This will especially be very common if you treat placing one stone as a single ply; every &quot;combined move&quot; (of placing two stones in two positions subsequently) can be reached in two different ways, simply by switching the order in which the player places them. There has been research in using Transposition Tables with MCTS, so that may be a promising direction to look into.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I also suspect there will be great value in using Deep (Reinforcement) Learning approaches. If there is a large board on which to place stones, there will likely be many moves that are &quot;absurd&quot; and can easily be dismissed altogether by Deep Learning approaches (e.g., placing stones far away in a corner of the board where none of the &quot;action&quot; is going on). Vanilla MCTS, without Deep Learning extensions, will not be able to recognize and dismiss such absurd moves, and play them way too often (in Play-Out but also Selection phase due to the high branching factor). The most obvious source of inspiration here would be AlphaGo Zero.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally, there's definitely some published research on Connect6 AI (and even MCTS in Connect6). For example: &lt;a href=&quot;http://web.csie.ndhu.edu.tw/sjyen/Journal/0022011IEEE.pdf&quot; rel=&quot;noreferrer&quot;&gt;Two-Stage Monte Carlo Tree Search for Connect6&lt;/a&gt;. You can likely also find more relevant research by checking that paper's list of References, and &lt;a href=&quot;https://scholar.google.nl/scholar?cites=2123165069157963257&amp;amp;as_sdt=2005&amp;amp;sciodt=0,5&quot; rel=&quot;noreferrer&quot;&gt;checking later papers on google scholar that cite this one&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="1641" LastActivityDate="2018-09-08T10:52:44.217" CommentCount="0" />
	<row Id="7925" PostTypeId="1" CreationDate="2018-09-11T20:19:55.103" Score="1" ViewCount="39" Body="&lt;p&gt;I was recently perusing the paper &lt;a href=&quot;https://researcher.watson.ibm.com/researcher/files/us-beygel/samuel-checkers.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;em&gt;Some Studies in Machine Learning Using the Game of Checkers II--Recent Progress&lt;/em&gt; (A.L. Samuel, 1967)&lt;/a&gt;, which is interesting historically.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was looking at this figure, which involved Alpha-Beta pruning.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/qT5oL.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/qT5oL.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It occurred to me that the types of non-trivial, non-chance, perfect information, zero-sum, sequential, partisan games utilized (Chess, Checkers, Go) involve game states that cannot be precisely quantified. For instance, there is no way to ascribe an objective value to a piece in Chess, or any given board state.  In some sense, the assignment of values is arbitrary, consisting of estimates.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The combinatorial games I'm working on are forms of &lt;a href=&quot;http://mbranegame.com/tutorial/&quot; rel=&quot;nofollow noreferrer&quot;&gt;partisan Sudoku&lt;/a&gt;, which are bidding/scoring (economic) games involving territory control.  In these models, any given board state produces an array of ratios allowing precise quantification of player status. Token values and positions can be precisely quantified.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This project involves a consumer product, and the approach we're taking currently is to utilize a series of agents of increasing sophistication to provide different levels challenge for human players.  These agents also reflect what is known as a &quot;&lt;a href=&quot;http://julian.togelius.com/Lantz2017Depth.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;strategy ladder&lt;/a&gt;&quot;.   &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Reflex Agents &lt;em&gt;(beginner)&lt;/em&gt; &lt;br&gt;&#xA;Model-based Reflex Agents &lt;em&gt;(intermediate)&lt;/em&gt; &lt;br&gt;&#xA;Model-based Utility Agents &lt;em&gt;(advanced)&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Goals may also be incorporated to these agents such as desired margin of victory (regional outcome ratios) which will likely have an effect on performance in that narrower margins of victory appear to entail less risk.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The &quot;respectably weak&quot; vs. human performance of the first generation of reflex agents suggests that strong GOFAI might be possible. (The branching factors are extreme in the early and mid-game due to the factorial nature of the models, but initial calculations suggest that even a naive minimax lookahead will be able to look farther more effectively than humans.) Alpha-Beta pruning in partisan Sudoku, even sans a learning algorithm, should provide greater utility than in previous combinatorial game models where the values are estimates. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Is the historical weakness of GOFAI in relation to non-trivial combinatorial games partly a function of the structure of the games studied, where game states and token values cannot be precisely quantified?&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Looking for any papers that might comment on this subject, research into combinatorial games where precise quantification is possible, and thoughts in general.&lt;/strong&gt;  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm trying to determine if it might be worth attempting to develop a strong GOFAI for these models prior to moving up the ladder to learning algorithms, and, if such a result would have research value.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;There would definitely be commercial value in that strong GOFAI with no long-term memory would allow minimal local file size for the apps, which must run on lowest-common-denominator smartphones with no assumption of connectivity.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;PS- My previous work on this has involved defining the core heuristics that emerge from the structure of the models, and I'm slowly dipping my toes into the look ahead pool.  Please don't hesitate to let me know if I've made any incorrect assumptions.&lt;/em&gt;&lt;/p&gt;&#xA;" OwnerUserId="1671" LastActivityDate="2018-09-12T12:03:23.320" Title="Historical weakness of GOFAI in relation to partisan combinatorial games?" Tags="&lt;game-ai&gt;&lt;combinatorial-games&gt;&lt;soft-question&gt;&lt;gofai&gt;&lt;alpha-beta-pruning&gt;" AnswerCount="1" CommentCount="5" />
	<row Id="7934" PostTypeId="2" ParentId="7925" CreationDate="2018-09-12T12:03:23.320" Score="2" Body="&lt;p&gt;Nice question!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think there are a couple of issues at work here.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Is the historical weakness of GOFAI in relation to non-trivial&#xA;  combinatorial games partly a function of the structure of the games&#xA;  studied, where game states and token values cannot be precisely&#xA;  quantified?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;I think the short answer is &lt;em&gt;yes&lt;/em&gt;. The real issue is in the last part:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;token values cannot be precisely quantified&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;The most successful GOFAI approaches to these games were all some variation on A* search, combining combinatorial search with some form of &lt;em&gt;heuristic function&lt;/em&gt; that estimated the value of the pieces and their positions in any given state. Piece counting is probably a better heuristic than not counting anything at all, but it's still clearly incorrect, because a player with less material may still have an overwhelming positional advantage. Some heuristics can try to estimate this positional advantage as well however.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The real problem that GOFAI encounters in these games is that positional advantage can be &lt;em&gt;emergent&lt;/em&gt; in ways that require incredible heuristic power to detect. Checkers is a good example. In the 1990's, the &lt;a href=&quot;https://webdocs.cs.ualberta.ca/~chinook/project/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Chinook project&lt;/a&gt; at the University of Alberta set out to solve it completely. Checkers is notable because it had the same world champion for more than 15 consecutive years, &lt;a href=&quot;https://en.wikipedia.org/wiki/Marion_Tinsley&quot; rel=&quot;nofollow noreferrer&quot;&gt;Marion Tinsley&lt;/a&gt;. Tinsley lost a total of 7 competitive matches over 40 years of play. This makes him an especially interesting person to examine when we look at combinatorial games. Figuring out how Tinsley plays can help us understand how human intelligence works in games like this. In the course of solving checkers, the researchers noted that Tinsley was making moves that required up to &lt;em&gt;42 move lookaheads&lt;/em&gt; to reveal an advantage (See &lt;a href=&quot;https://doi.org/10.1609/aimag.v17i1.1208&quot; rel=&quot;nofollow noreferrer&quot;&gt;Schaeffer et al.&lt;/a&gt;, AI Magazine, Vol. 17, Issue 1).  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;This strongly suggests that Tinsley was &lt;em&gt;not&lt;/em&gt; methodically considering each possible move. Instead, by his own admission, his thinking was guided by a combination of &lt;em&gt;memory&lt;/em&gt; over his 40 year career (in one match against Chinook in 1992, he indicated he was trying to recall a sequence from a match 30 years prior when making a move (&lt;a href=&quot;https://www.aaai.org/ojs/index.php/aimagazine/article/download/1040/958&quot; rel=&quot;nofollow noreferrer&quot;&gt;AI Magazine Volume 14, Number 2&lt;/a&gt;); and of attentional heuristics (i.e. not thinking about every move sequence, and being able to reliably rule out parts of the search space without looking at them).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The key is that for GOFAI to solve checkers without heuristics (i.e. to solve it exactly), required enormous amounts of computational power, because some moves yield positional advantages that require 40+ moves of followthrough. Even an incredibly simple game (branching factor of 2) would be hard under that constraint.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In contrast though, self-play techniques like those pioneered in Backgammon with &lt;a href=&quot;http://enzodesiage.com/wp-content/uploads/2017/08/tesauro-tdgammon-1995.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;TD-Gammon&lt;/a&gt; (Tesauro, Comm. of the ACM 1995) mimic the process through which Tinsley became so good: they play lots and lots of games, learn a good heuristic estimate of position and material value, and more importantly, can learn to &lt;em&gt;remember&lt;/em&gt; odd circumstances that require careful play. TD-Gammon achieved worldclass play despite only explicitly looking 2 moves ahead. GOFAI search techniques weren't even close despite searching much more deeply.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Modern research on &lt;a href=&quot;https://www.nature.com/articles/d41586-018-03067-x&quot; rel=&quot;nofollow noreferrer&quot;&gt;attention&lt;/a&gt; could salvage the GOFAI approach however. If you can learn to tell what's important, you might be able to get a lot more value out of deeper lookaheads. This seems even closer to how Tinsley played: great ability to estimate value was used to guide an explicit analysis of a specific chain of moves.&lt;/p&gt;&#xA;" OwnerUserId="16909" LastActivityDate="2018-09-12T12:03:23.320" CommentCount="1" />
	<row Id="7962" PostTypeId="1" AcceptedAnswerId="7973" CreationDate="2018-09-14T02:32:33.923" Score="1" ViewCount="63" Body="&lt;p&gt;Is it possible for a genetic algorithm + Neural Network that is used to learn to play one game such as a platform game able to be applied to another different game of the same genre.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So for example, could an AI that learns to play Mario also learn to play another similar platform game.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also, if anyone could point me in the direction of material i should familiarise myself with in order to complete my project.&lt;/p&gt;&#xA;" OwnerUserId="18209" LastEditorUserId="1641" LastEditDate="2018-09-14T10:58:39.703" LastActivityDate="2018-09-14T11:46:40.210" Title="Can genetic algorithms be used to learn to play multiple games of the same type?" Tags="&lt;neural-networks&gt;&lt;game-ai&gt;&lt;python&gt;&lt;genetic-algorithms&gt;" AnswerCount="3" CommentCount="6" />
	<row Id="7971" PostTypeId="2" ParentId="7962" CreationDate="2018-09-14T10:28:06.640" Score="0" Body="&lt;p&gt;Definitely depends on the design of your algorithm. According to my knowledge, almost all ML algorithms are targeting at specific issues, thus it’s difficult for general usage. And you have to train again for any new issues. It’s also difficult to understand the internal working mechanism of those AI algorithms due to general statistics methods (and yes, they call AI). I will recommend a regional/encapsulated method applied on general methods, therefore algorithms are not specific and micro-structured for general purposes. If games are similar, definitely we can apply on both with appropriate designed methods. Hinton has started his Capsule network which I think is a good direction. Just beware, training shouldn’t be specific object related. Instead, it should be micro-structure related or feature (it’s hard to differ current AI feature from human insight feature). For example, human can easily differ differences even though never see those before. And human do not have to re-train nerve units except for better understanding or accuracy. Genetic algorithms should have the same ability to survive in different but similar environments. Unfortunately, we are at the beginning of AI era but also luckily we have a lot to do. In fact, almost all current techs imitate the nature. If the nature can, definitely we can at one day.&lt;/p&gt;&#xA;" OwnerUserId="18221" LastActivityDate="2018-09-14T10:28:06.640" CommentCount="0" />
  	<row Id="7972" PostTypeId="2" ParentId="7962" CreationDate="2018-09-14T10:49:50.703" Score="0" Body="&lt;p&gt;Genetic algorithms can learn multiple games, yes, in fact genetic algorithms is a bad term to describe this family, there is only one generic genetic algorithm with many variations depending on the problem at hand. I recommend this pdf for a introduction on how they work and how to build them:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.boente.eti.br/fuzzy/ebook-fuzzy-mitchell.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;http://www.boente.eti.br/fuzzy/ebook-fuzzy-mitchell.pdf&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="18123" LastActivityDate="2018-09-14T10:49:50.703" CommentCount="1" />
  	<row Id="7973" PostTypeId="2" ParentId="7962" CreationDate="2018-09-14T11:46:40.210" Score="3" Body="&lt;p&gt;Genetic algorithms and Neural Networks both are &quot;general&quot; methods, in the sense that they are not &quot;domain-specific&quot;, they do not rely specifically on any domain knowledge of the game of Mario. So yes, if they can be used to successfully learn how to play Mario, it is likely that they can also be applied with similar success to other Platformers (or even completely different games). Of course, some games may be more complex than others. Learning Tic Tac Toe will likely be easier than Mario, and learning Mario will likely be easier than StarCraft. But in principle the techniques should be similarly applicable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you only want to learn in one environment (e.g., Mario), and then immediately play a different game without separately training again, that's much more complicated. For research in that area you'll want to look for Transfer Learning and/or Multi-Task learning. There has definitely been research there, with the latest developments that I'm aware of having been published &lt;a href=&quot;https://deepmind.com/blog/preserving-outputs-precisely-while-adaptively-rescaling-targets/&quot; rel=&quot;nofollow noreferrer&quot;&gt;yesterday&lt;/a&gt; (this is Deep Reinforcement Learning though, no GAs I think).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The most &quot;famous&quot; recent work on training Neural Networks to play games using Genetic Algorithms that I'm aware of is &lt;a href=&quot;https://eng.uber.com/deep-neuroevolution/&quot; rel=&quot;nofollow noreferrer&quot;&gt;this work by Uber&lt;/a&gt; (blog post links to multiple papers). I'm not 100% sure if that really is the state of the art anymore, if it's the best work, etc... I didn't follow all the work on GAs in sufficient detail to tell for sure. It'll be relevant at least though.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know there's also been quite a lot of work on AI in general for Mario / other platformers (for instance in venues such as the IEEE Conference on Computational Intelligence and Games, and the TCIAIG journal).&lt;/p&gt;&#xA;" OwnerUserId="1641" LastActivityDate="2018-09-14T11:46:40.210" CommentCount="0" />
	<row Id="8057" PostTypeId="1" CreationDate="2018-09-20T06:06:06.213" Score="1" ViewCount="34" Body="&lt;p&gt;I have created a game based on &lt;a href=&quot;https://sites.google.com/site/boardandpieces/list-of-games/fox--geese-checkerboard&quot; rel=&quot;nofollow noreferrer&quot;&gt;this game here&lt;/a&gt;. I am attempting to use Deep Q Learning to do this, and this is my first foray into Neural networks (please be gentle!!)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am trying to create a NN that can play this game. Here are some relevant facts about the game:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Player 1 (the fox) has 1 piece that he can move diagonally 1 step in any direction &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Player 2(The geese) has 4 pieces that they can move only forward diagonally (either diagonal left or diagonal right) 1 step.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The Fox wins if he reaches the other end of the board, the geese win if they trap the fox so it cannot move.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;I am trying to work on the agent first for the geese as it seems to be the harder agent with more pieces and restrictions. Here is the important sections of code I have so far:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;This is where I setup the game board, and set the total actions for the geese&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;def __init__(self):&#xA;    self.state_size = (LENGTH,LENGTH) ##LENGTH is 8 so (8,8)&#xA;    #...&#xA;    #other DQN variables that aren't important to question&#xA;    #...&#xA;    self.action_size = 8 ##4 geese, each can potentially make 2 moves&#xA;    self.model = self.build_model()&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;And here is where I create my model&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;def build_model(self):&#xA;    #builds the NN for Deep-Q Model&#xA;    model = Sequential() #establishes a feed forward NN&#xA;    model.add(Dense(64,input_shape = (LENGTH,), activation='relu'))&#xA;    model.add(Dense(64, activation='relu'))&#xA;    model.add(Dense(self.action_size, activation = 'linear'))&#xA;    model.compile(loss='mse', optimizer='Adam')&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;This is where I perform an action&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;def act(self, state,env):&#xA;    #get the list of allowed actions for the geese&#xA;    actions_allowed = env.allowed_actions_geese_agent()&#xA;&#xA;    if np.random.rand(0,1) &amp;lt;= self.epsilon: ##do a random move&#xA;        return actions_allowed[random.randint(0, len(actions_allowed)-1)]&#xA;    act_values = self.model.predict(state)&#xA;    print(act_values)&#xA;    return np.argmax(act_values)&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;My question: Since there are 4 geese and each can make 2 possible moves, am I correct in thinking that my action_size should be &lt;strong&gt;8&lt;/strong&gt; (2 for each goose) or should it be maybe 2 (for diagonal left or right) or something else entirely? &lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;The reason why I am at a loss is because on any given turn, some of the geese may have an invalid move, does that matter?&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;My next Question: Even if I have the right output layer for the geese agent, when I call &lt;code&gt;model.predict(state)&lt;/code&gt; where I pick my action...how do I interpret the output? And how would I map that action it selects to a valid action that can be made?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Here is a picture of the result of using &lt;code&gt;model.predict(state)&lt;/code&gt;, as you can see it returns a ton of data and then when I call &lt;code&gt;return np.argmax(act_values)&lt;/code&gt; I get 59 back...not sure how to utilize that (or if it's even correct based on my output layer)... and finally I included a drawing of the board. F is the fox and 1,2,3,4 are the different geese.&#xA;&lt;a href=&quot;https://i.stack.imgur.com/fhPCI.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/fhPCI.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I apologize for the massive post, but I am just trying to provide as much information that is helpful. &lt;/p&gt;&#xA;" OwnerUserId="18244" LastActivityDate="2018-09-20T06:06:06.213" Title="Mapping Actions to the Output Layer in Keras Model for a Board Game" Tags="&lt;machine-learning&gt;&lt;game-ai&gt;&lt;python&gt;&lt;keras&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="8060" PostTypeId="1" AcceptedAnswerId="8075" CreationDate="2018-09-20T08:14:08.480" Score="1" ViewCount="190" Body="&lt;p&gt;The Wumpus World proposed in book of Stuart Russel and Peter Norvig, is a game which happens on a 4x4 board and the objective is to grab the gold and avoiding the threats that can kill you. The rules of game are:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;You move just one box for round&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Start in position (1,1), bottom left&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;You have a vector of sensors for perceiving the world around you.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;When you are next to another position (including the gold), the vector is 'activated'.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;There is one wumpus (a monster), 2-3 pits (feel free to put more or less) and just one gold pot&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;You only have one arrow that flies in a straight line and can kill the wumpus&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Entering the room with a pit, the wumpus or the gold finishes the game&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/QHzFT.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/QHzFT.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Scoring is as follows: +1000 for grabbing the gold, -1000 for dying to the wumpus, -1 for each step, -10 for shooting an arrow. Fore more details about the rules, chapter 7 of &lt;a href=&quot;https://rads.stackoverflow.com/amzn/click/0136042597&quot; rel=&quot;nofollow noreferrer&quot;&gt;the book&lt;/a&gt; explains them.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Well now that game has been explained, the question is: in the book, the solution is demonstrated by logic and searching, does there exist another form to solve that problem with neural networks? If yes, how to do that? What topology to use? What paradigm of learning and algorithms to use?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1*: My English is horrible, if you can send grammar corrections, I'm grateful.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2*: I think this is a bit confusing and a bit complex. if you can help me to clarify better, please do commentary or edit!&lt;/p&gt;&#xA;" OwnerUserId="18391" LastEditorUserId="4709" LastEditDate="2018-09-20T12:41:44.133" LastActivityDate="2018-09-21T13:28:38.530" Title="Does a solution for Wumpus World with neural networks exist?" Tags="&lt;neural-networks&gt;&lt;deep-learning&gt;&lt;reinforcement-learning&gt;&lt;game-ai&gt;&lt;learning-algorithms&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="8075" PostTypeId="2" ParentId="8060" CreationDate="2018-09-21T13:28:38.530" Score="2" Body="&lt;p&gt;Yes! If you read ahead to the chapters in reinforcement learning in the same book, you'll see that the wompus world appears again there. Techniques like Q-learning can be used to solve it, and since Q-learning involves learning the shape of a function, a neural network can be employed as a function approximator.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The basic idea is to treat this problem as an input/output mapping (states -&gt; actions), and to learn which actions produce the greatest rewards. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note however, that these approaches rely on trial and error. The logic based approach reasons about the rules of the game, and can play reasonably well right away. The learning approach will need to try and fail many times before playing well.&lt;/p&gt;&#xA;" OwnerUserId="16909" LastActivityDate="2018-09-21T13:28:38.530" CommentCount="0" />
	<row Id="8097" PostTypeId="1" AcceptedAnswerId="8098" CreationDate="2018-09-23T10:29:05.220" Score="0" ViewCount="33" Body="&lt;p&gt;I'm trying to implement an algorithm that would choose the optimal next move for the game of Connect 4. As I just want to make sure that the basic &lt;strong&gt;minimax&lt;/strong&gt; works correctly, I am actually testing it like a Connect 3 on a 4x4 field. This way I don't need the alpha-beta pruning, and it's more obvious when the algorithm makes a stupid move. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The problem is that the algorithm &lt;strong&gt;always&lt;/strong&gt; starts the game with the leftmost move, and also during the game it's just very stupid. It doesn't see the best moves.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have thoroughly tested methods &lt;code&gt;makeMove()&lt;/code&gt;, &lt;code&gt;undoMove()&lt;/code&gt;,  &lt;code&gt;getAvailableColumns()&lt;/code&gt;, &lt;code&gt;isWinningMove()&lt;/code&gt; and &lt;code&gt;isLastSpot()&lt;/code&gt; so I am absolutely &lt;strong&gt;sure&lt;/strong&gt; that the problem is not there.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here is my algorithm.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;NextMove.java&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;private static class NextMove {&#xA;    final int evaluation;&#xA;    final int moveIndex;&#xA;&#xA;    public NextMove(int eval, int moveIndex) {&#xA;        this.evaluation = eval;&#xA;        this.moveIndex = moveIndex;&#xA;    }&#xA;&#xA;    int getEvaluation() {&#xA;        return evaluation;&#xA;    }&#xA;&#xA;    public int getMoveIndex() {&#xA;        return moveIndex;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;The Algorithm&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;private static NextMove max(C4Field field, int movePlayed) {&#xA;    // moveIndex previously validated&#xA;&#xA;    // 1) check if moveIndex is a final move to make on a given field&#xA;    field.undoMove(movePlayed);&#xA;&#xA;    // check&#xA;    if (field.isWinningMove(movePlayed, C4Symbol.BLUE)) {&#xA;        field.playMove(movePlayed, C4Symbol.RED);&#xA;        return new NextMove(BLUE_WIN, movePlayed);&#xA;    }&#xA;    if (field.isWinningMove(movePlayed, C4Symbol.RED)) {&#xA;        field.playMove(movePlayed, C4Symbol.RED);&#xA;        return new NextMove(RED_WIN, movePlayed);&#xA;    }&#xA;    if (field.isLastSpot()) {&#xA;        field.playMove(movePlayed, C4Symbol.RED);&#xA;        return new NextMove(DRAW, movePlayed);&#xA;    }&#xA;&#xA;    field.playMove(movePlayed, C4Symbol.RED);&#xA;&#xA;    // 2) moveIndex is not a final move&#xA;    // --&amp;gt; try all possible next moves&#xA;    final List&amp;lt;Integer&amp;gt; possibleMoves = field.getAvailableColumns();&#xA;    int bestEval = Integer.MIN_VALUE;&#xA;    int bestMove = 0;&#xA;    for (int moveIndex : possibleMoves) {           &#xA;        field.playMove(moveIndex, C4Symbol.BLUE);&#xA;&#xA;        final int currentEval = min(field, moveIndex).getEvaluation();&#xA;        if (currentEval &amp;gt; bestEval) {&#xA;            bestEval = currentEval;&#xA;            bestMove = moveIndex;&#xA;        }&#xA;&#xA;        field.undoMove(moveIndex);&#xA;    }&#xA;&#xA;    return new NextMove(bestEval, bestMove);&#xA;}&#xA;&#xA;private static NextMove min(C4Field field, int movePlayed) {&#xA;    // moveIndex previously validated&#xA;&#xA;    // 1) check if moveIndex is a final move to make on a given field&#xA;    field.undoMove(movePlayed);&#xA;&#xA;    // check&#xA;    if (field.isWinningMove(movePlayed, C4Symbol.BLUE)) {&#xA;        field.playMove(movePlayed, C4Symbol.BLUE);&#xA;        return new NextMove(BLUE_WIN, movePlayed);&#xA;    }&#xA;    if (field.isWinningMove(movePlayed, C4Symbol.RED)) {&#xA;        field.playMove(movePlayed, C4Symbol.BLUE);&#xA;        return new NextMove(RED_WIN, movePlayed);&#xA;    }&#xA;    if (field.isLastSpot()) {&#xA;        field.playMove(movePlayed, C4Symbol.BLUE);&#xA;        return new NextMove(DRAW, movePlayed);&#xA;    }&#xA;&#xA;    field.playMove(movePlayed, C4Symbol.BLUE);&#xA;&#xA;    // 2) moveIndex is not a final move&#xA;    // --&amp;gt; try all other moves&#xA;    final List&amp;lt;Integer&amp;gt; possibleMoves = field.getAvailableColumns();&#xA;    int bestEval = Integer.MAX_VALUE;&#xA;    int bestMove = 0;&#xA;    for (int moveIndex : possibleMoves) {&#xA;        field.playMove(moveIndex, C4Symbol.RED);&#xA;&#xA;        final int currentEval = max(field, moveIndex).getEvaluation();&#xA;        if (currentEval &amp;lt; bestEval) {&#xA;            bestEval = currentEval;&#xA;            bestMove = moveIndex;&#xA;        }&#xA;&#xA;        field.undoMove(moveIndex);&#xA;    }&#xA;&#xA;    return new NextMove(bestEval, bestMove);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;The idea is that the algorithm takes in the arguments of a &lt;code&gt;currentField&lt;/code&gt; and the &lt;code&gt;lastPlayedMove&lt;/code&gt;. Then it checks if the last move somehow finished the game. If it did, I just return that move, and otherwise I go in-depth with the subsequent moves.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Blue player is MAX, red player is MIN.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In each step I first undo the last move, because it's easier to check if the &quot;next&quot; move will finish the game, than check if the current field is finished (this would require to analyze for all possible winning options in the field). After I check, I just redo the move.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From some reason this doesn't work. I am stuck with that for days! I have no idea what's wrong... Any help greatly appreciated!&lt;/p&gt;&#xA;&#xA;&lt;h2&gt;EDIT&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;I'm adding the code how I'm invoking the algorithm.&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;@Override&#xA;public int nextMove(C4Game game) {&#xA;    C4Field field = game.getCurrentField();&#xA;    C4Field tmp = C4Field.copyField(field);&#xA;&#xA;    int moveIndex = tmp.getAvailableColumns().get(0);&#xA;    final C4Symbol symbol = game.getPlayerToMove().getSymbol().equals(C4Symbol.BLUE) ? C4Symbol.RED : C4Symbol.BLUE;&#xA;    tmp.dropToColumn(moveIndex, symbol);&#xA;&#xA;    NextMove mv = symbol&#xA;            .equals(C4Symbol.BLUE) ? &#xA;                    max(tmp, moveIndex) : &#xA;                        min(tmp, moveIndex);&#xA;&#xA;                    int move = mv.getMoveIndex();&#xA;                    return move;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="18470" LastEditorUserId="18470" LastEditDate="2018-09-23T12:26:05.070" LastActivityDate="2018-09-23T12:55:11.693" Title="Connect 4 minimax does not make the best move" Tags="&lt;game-ai&gt;&lt;minimax&gt;&lt;java&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="8098" PostTypeId="2" ParentId="8097" CreationDate="2018-09-23T10:37:35.337" Score="1" Body="&lt;p&gt;I suspect that you'll have to remove this code:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;    if (field.isWinningMove(movePlayed, C4Symbol.BLUE)) {&#xA;        field.playMove(movePlayed, C4Symbol.RED);&#xA;        return new NextMove(BLUE_WIN, movePlayed);&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;from the &lt;code&gt;max()&lt;/code&gt; method, and remove this code:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;    if (field.isWinningMove(movePlayed, C4Symbol.RED)) {&#xA;        field.playMove(movePlayed, C4Symbol.BLUE);&#xA;        return new NextMove(RED_WIN, movePlayed);&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;from the &lt;code&gt;min()&lt;/code&gt; method.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;In the first case, you're checking whether the move that RED just made was a winning move. You don't want to check there if it was a winning move from BLUE, because it wasn't BLUE who just made that move; it was red. The same counts the other way around in the second case.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Additionally, the initial call into the algorithm seems overly complicated. I am not sure what the intended use of the &lt;code&gt;tmp&lt;/code&gt; variable there is, or that &lt;code&gt;dropToColumn()&lt;/code&gt; call. I would rewrite it to be more like:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;@Override&#xA;public int nextMove(C4Game game) {&#xA;    C4Field field = game.getCurrentField();&#xA;&#xA;    NextMove mv = null;&#xA;&#xA;    if(game.getPlayerToMove().getSymbol().equals(C4Symbol.BLUE)){&#xA;        mv = max(field, -1);&#xA;    }&#xA;    else{&#xA;        mv = min(field, -1);&#xA;    }&#xA;&#xA;    return mv.getMoveIndex();&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;This will require an adaptation of the &lt;code&gt;max()&lt;/code&gt; and &lt;code&gt;min()&lt;/code&gt; methods such that they skip the whole checking-for-wins thing if the previous &lt;code&gt;movePlayed&lt;/code&gt; equals &lt;code&gt;-1&lt;/code&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With the code you currently have there, you do not perform a minimax search for the optimal move in the current game state; instead you first arbitrarily modify the current game state using that &lt;code&gt;tmp.dropToColumn()&lt;/code&gt; call, and perform the minimax search in that arbitrarily modified game state. The optimal move to play in such an arbitrarily-modified game state will tend not to be the optimal move in the game state that you really are in.&lt;/p&gt;&#xA;" OwnerUserId="1641" LastEditorUserId="1641" LastEditDate="2018-09-23T12:55:11.693" LastActivityDate="2018-09-23T12:55:11.693" CommentCount="8" />
	<row Id="8178" PostTypeId="1" CreationDate="2018-09-30T03:22:19.437" Score="0" ViewCount="25" Body="&lt;p&gt;I’ve seen some papers using neural network as evaluation function to evaluate game state. I wonder if they can value the state to train the neural network, isn’t the function that is used to value the state a evaluation function and aren’t the neural network and the function the same?&lt;/p&gt;&#xA;" OwnerUserId="18631" LastActivityDate="2018-09-30T03:22:19.437" Title="How does using neural network to improve evaluation function work?" Tags="&lt;neural-networks&gt;&lt;machine-learning&gt;&lt;game-ai&gt;&lt;chess&gt;" AnswerCount="0" CommentCount="2" />
	<row Id="8283" PostTypeId="1" AcceptedAnswerId="8286" CreationDate="2018-10-06T15:40:41.847" Score="0" ViewCount="35" Body="&lt;p&gt;Example: texas holdem poker vs texas holdem poker with the same rounds, just with no public cards dealt.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Would algorithms like CFR approximate Nash-equilibrium more easily?&lt;br&gt;&#xA;Could AI that does not look at public cards achieve similar performance in normal texas holdem as AI that looks at public state tree?&lt;/p&gt;&#xA;" OwnerUserId="18808" LastEditorUserId="18808" LastEditDate="2018-10-08T14:56:26.247" LastActivityDate="2018-10-08T14:56:26.247" Title="What's the difference between poker with public cards and without them?" Tags="&lt;ai-design&gt;&lt;game-ai&gt;&lt;ai-community&gt;&lt;poker&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="8286" PostTypeId="2" ParentId="8283" CreationDate="2018-10-06T19:35:10.143" Score="1" Body="&lt;p&gt;It depends a little on what you mean by &quot;the same rounds, just with no public cards dealt.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you mean that each player will just be dealt 2 cards, and no public cards exist, then really we're playing a sort of &quot;high card&quot; game. The best hand is just a pair of aces, CFR will solve this quickly, because the number of possible game states is extremely small compared to a full poker game (especially if we exploit the symmetry of suits, since flushes aren't possible).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you mean that each player will be dealt 5 cards, with several rounds of betting as before, CFR will probably do &lt;em&gt;less&lt;/em&gt; well. The state space will be larger, since there are more cards in play (10 instead of 9). Betting may become more complex, and more complex betting &lt;a href=&quot;https://arxiv.org/pdf/1302.7008.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;expands the state space enormously&lt;/a&gt;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you mean that the cards are dealt as before, but the program simply will not look at the cards, then you've kept the state space of the game the same size, but radically reduced the number of information sets. Playing against an opponent who &lt;em&gt;can&lt;/em&gt; look at the cards on the table, your program would be at an enormous disadvantage. For instance, imagine the cards on the table are &quot;3 3 8 8 5&quot;, and that you have a pair of 2's in your hand. You would want to play very differently from if the cards on the table were &quot;2 2 10 4 7&quot;, but an AI without access to the table cards would have to act the same in both situations. &lt;/p&gt;&#xA;" OwnerUserId="16909" LastActivityDate="2018-10-06T19:35:10.143" CommentCount="5" />
	<row Id="8297" PostTypeId="1" CreationDate="2018-10-07T17:37:00.000" Score="1" ViewCount="28" Body="&lt;p&gt;I'm programming on Connect6 with MCTS.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Monte Carlo Tree Search is based on random moves. It counts up the number of wins in certain moves. (Whether it wins in 3 turns or 30 turns)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is the move with less turns more powerful than the move with more turns?(as mcts just sees if it's win or not -- not considering the number of turns it took to win) And if so, is it meaningful to give bigger weight to the one with less turn win?&lt;/p&gt;&#xA;" OwnerUserId="18844" LastEditorUserId="1641" LastEditDate="2018-10-08T19:35:36.270" LastActivityDate="2018-11-07T20:00:03.040" Title="Is it meaningful to give more weight to the result of monte carlo search with less turn win?" Tags="&lt;game-ai&gt;&lt;monte-carlo-tree-search&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="8300" PostTypeId="2" ParentId="8297" CreationDate="2018-10-07T19:46:39.377" Score="1" Body="&lt;p&gt;Traditionally (when not considering your idea), the evaluation function for terminal game states would be implemented to return &lt;span class=&quot;math-container&quot;&gt;$1$&lt;/span&gt;, &lt;span class=&quot;math-container&quot;&gt;$0$&lt;/span&gt;, or &lt;span class=&quot;math-container&quot;&gt;$-1$&lt;/span&gt; for wins, draws, or losses, respectively.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Changing that in a naive/straightforward way to make short-term wins more rewarding, long-term wins less rewarding, short-term losses more negative, and long-term losses less negative can be dangerous, it may change the objective that your agent is ultimately optimizing for (i.e. may lose the guarantee of converging towards optimal play given an infinite amount of time) if not done very carefully.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is definitely value in considering the idea though, especially because in the Play-Out phase of MCTS, trajectories of (semi-)random moves introduce uncertainty in the evaluations at the end of those simulations, and this uncertainty increases as the length of the trajectories increases (due to increased number of uninformed decisions being made along the trajectory). Note that it is especially important to take into consideration here the number of moves played in the Play-Out phase, not necessarily including the number of moves made in the Selection phase (which are selected according to a much more informed strategy).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One paper I know of that investigates ideas along these lines is &lt;a href=&quot;https://dke.maastrichtuniversity.nl/m.winands/documents/QB_ECAI2014.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;&quot;Quality-based Rewards for Monte-Carlo Tree Search Simulations&quot;&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="1641" LastActivityDate="2018-10-07T19:46:39.377" CommentCount="0" />
	<row Id="8403" PostTypeId="1" AcceptedAnswerId="8404" CreationDate="2018-10-14T09:05:08.993" Score="3" ViewCount="35" Body="&lt;p&gt;I'm making a Connect Four game using the typical minimax + alpha-beta pruning algorithms. I just implemented a Transposition Table, but my tests tell me the TT only helps 17% of the time. By this I mean that 17% of the positions my engine comes across in its calculations can be automatically given a value (due to the position being calculated previously via a different move order).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For most games, is this figure expected? To me it seems very low, and I was optimistically hoping for the TT to speed up my engine by around 50%. It should be noted though that on each turn in the game, I reset my TT (since the evaluation previously assigned to each position is inaccurate due to lower depth back then).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know that the effectiveness of TT's are largely dependent on the game they're being used for, but any ballparks of how much they speed up common games (chess, go, etc) would be helpful.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;EDIT - After running some more tests and adjusting my code, I found that the TT sped up my engine to about 133% (so it took 75% as much time to calculate). This means those 17% nodes were probably fairly high up in the tree, since not having to calculate the evaluation of these 17% sped up things by 33%. This is definitely better, but my question still remains on whether this is roughly expected performance of a typical TT.&lt;/p&gt;&#xA;" OwnerUserId="16917" LastEditorUserId="16917" LastEditDate="2018-10-14T13:25:32.393" LastActivityDate="2018-10-14T13:29:50.357" Title="Transposition table is only used for roughly 17% of the nodes - is this expected?" Tags="&lt;game-ai&gt;&lt;search&gt;&lt;gaming&gt;&lt;minimax&gt;&lt;efficiency&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="8404" PostTypeId="2" ParentId="8403" CreationDate="2018-10-14T13:24:13.643" Score="2" Body="&lt;p&gt;I don't think that's necessarily a strange number. It's impossible for anyone to really tell you whether that 17% is &quot;correct&quot; or not without reproducing it, which would require much more info (basically would have to know every single tiny detail of your implementation to be able to reproduce).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some things to consider:&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;The &lt;strong&gt;size of your transposition table / the number of bits you use for indexing into the TT&lt;/strong&gt;. If you have a relatively small TT, meaning you use relatively few bits for indexing, you'll have bigger probabilities of collisions. That means you will have to replace existing entries more often, which means they might no longer be in the table anymore by the time you encounter transpositions during the search.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Where in the search tree are the nodes located that are recognized as transpositions already in the table?&lt;/strong&gt; If you detect transpositions very high up in the search tree, you save a lot more search time than if you detect a transposition somewhere deep down in the search tree; once you detect a transposition that has already been searched sufficiently deep for the value stored in the table to be valid, you can cut off the complete subtree below that node from the search. This becomes more valuable as it happens closer to the root. So, just the number &quot;17% of nodes&quot; doesn't really tell us much.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Are you using iterative deepening?&lt;/strong&gt; Since you mentioned only minimax + alpha-beta pruning in the question, I suspect you're not using iterative deepening. TTs become significantly more valuable once you do use iterative deepening, because then almost every state encountered becomes a &quot;transposition&quot;. You'll already have seen all those states in a previous iteration with a lower search depth limit. Now, it is important to note with this combo of ID + TTs, that you can no longer completely cut off searches for all recognized transpositions. If an entry in the table holds a value that was computed with a search depth of &lt;span class=&quot;math-container&quot;&gt;$d$&lt;/span&gt;, that value will no longer be valid when performing a subsequent iteration of ID with a max search depth of &lt;span class=&quot;math-container&quot;&gt;$d + 1$&lt;/span&gt; for example. However, that &quot;outdated&quot; value stored in the TT &lt;strong&gt;can still be used for move ordering&lt;/strong&gt;, which can lead to significantly more prunings from alpha-beta pruning.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;How efficient is the remainder of your engine?&lt;/strong&gt; A TT is not 100% free, it takes a bit of additional time too (for example to compute the hash values for your game states). If the rest of your engine is relatively slow (i.e. inefficient implementation for playing moves, copying game states, etc.), the computational overhead of the TT won't matter much and even a low number of recognized transpositions will still be valuable. If the rest of your engine is very fast, it'll be more important to have a high number of transpositions for the TT to be really valuable.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;As an &quot;educated guess&quot;, I'd say the number of 17% you describe is not necessarily strange. Especially given your edit to the question, where you indeed mention that it is likely that transpositions are found high up in the tree (close to the root). When this happens, you immediately remove the probability of recognizing all those states deeper down in the tree of getting recognized as transpositions yourself. So, the pool of states that could &quot;potentially&quot; be found in the TT is much less than 100% of the states stored in the TT.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's really just that though, just an educated guess. It's going to be very difficult for anyone to give a conclusive &quot;yes&quot; or &quot;no&quot;.&lt;/p&gt;&#xA;" OwnerUserId="1641" LastEditorUserId="1641" LastEditDate="2018-10-14T13:29:50.357" LastActivityDate="2018-10-14T13:29:50.357" CommentCount="0" />
	<row Id="8430" PostTypeId="1" CreationDate="2018-10-15T15:28:58.157" Score="1" ViewCount="20" Body="&lt;p&gt;I have coded an AI checkers game but would like to see how good it is. Some people have informed me to use the Chinook AI opensource code. But I am having trouble trying to integrate that software into my AI code. How do I integrate another game engine in checkers with the AI I have coded?&lt;/p&gt;&#xA;" OwnerUserId="16906" LastActivityDate="2018-10-15T15:28:58.157" Title="Checkers AI game engines" Tags="&lt;game-ai&gt;&lt;checkers&gt;" AnswerCount="0" CommentCount="11" />
	<row Id="8465" PostTypeId="1" CreationDate="2018-10-16T15:43:07.630" Score="0" ViewCount="31" Body="&lt;p&gt;I already know the basics of the basic of Machine Learning. E.g.: Backpropagation, Convolution, etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;First of let me explain Reinforcement learning to make sure I grasped the concept correctly.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In Reinforcement learning a random-initialized network will first &quot;play&quot;/&quot;do&quot; a sequence of moves in an environment. (In this case a Game). After that, it will receive a reward &lt;span class=&quot;math-container&quot;&gt;$r$&lt;/span&gt;. Furthermore a q-Value gets defined by the engineer/hooby coder. This reward times the q-Value &lt;span class=&quot;math-container&quot;&gt;$q$&lt;/span&gt; to the power of the  position &lt;span class=&quot;math-container&quot;&gt;$n$&lt;/span&gt; of the action will be feeded back using BP. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;So how do I know how slight chances in &lt;span class=&quot;math-container&quot;&gt;$\vec{w}$&lt;/span&gt; are changing &lt;span class=&quot;math-container&quot;&gt;$rq^n$&lt;/span&gt;?&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="19062" LastEditorUserId="1581" LastEditDate="2018-10-16T19:10:37.147" LastActivityDate="2018-10-16T19:10:37.147" Title="How do I know how changes in the weights are changing the reward in Reinforcement Learning" Tags="&lt;reinforcement-learning&gt;&lt;game-ai&gt;&lt;backpropagation&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="8466" PostTypeId="2" ParentId="8465" CreationDate="2018-10-16T17:03:08.297" Score="2" Body="&lt;p&gt;You have the concept slightly wrong.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This part is mostly correct:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;In Reinforcement learning a random-initialized network will first &quot;play&quot;/&quot;do&quot; a sequence of moves in an environment. (In this case a Game). After that, it will receive a reward r. &lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Technically neural networks are not required in RL, and it is really worth studying some simple systems that don't need them. It will make everything much clearer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A reward &lt;span class=&quot;math-container&quot;&gt;$r$&lt;/span&gt; can be received on every time step. However, some environments will only have a single reward at the end for success or failure for a whole episode - e.g. an instance of a game like chess where a player wins or loses.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This part is where things go a bit off track:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Furthermore a q-Value gets defined by the [developer]. This reward times the q-Value q to the power of the position n of the action will be [fed] back using BP.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Q values are one type of data that can be calculated for an agent acting in a &lt;a href=&quot;https://en.wikipedia.org/wiki/Markov_decision_process&quot; rel=&quot;nofollow noreferrer&quot;&gt;Markov Decision Process&lt;/a&gt;. They are also called &quot;action values&quot; and they are not usually defined by a developer. The q value, &lt;em&gt;if correct&lt;/em&gt; should return the expected future sum of rewards from following a current policy. One way of writing this is:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;span class=&quot;math-container&quot;&gt;$$q(s,a) = \mathbb{E}_{\pi}[\sum_{k=0}^{\infty}\gamma^k R_{t+k+1}| S_t=s, A_t=a]$$&lt;/span&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In natural language, the q value for state s and action a is the expected value (when following the given policy) of the discounted sum of rewards, starting from the given state and action. The discount factor, &lt;span class=&quot;math-container&quot;&gt;$\gamma$&lt;/span&gt; can take any value from &lt;span class=&quot;math-container&quot;&gt;$0$&lt;/span&gt; up to &lt;span class=&quot;math-container&quot;&gt;$1$&lt;/span&gt;, but only strictly episodic problems (which always terminate) should use the value &lt;span class=&quot;math-container&quot;&gt;$1$&lt;/span&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A developer does not get to define that (except they might get to choose reward system and value of &lt;span class=&quot;math-container&quot;&gt;$\gamma$&lt;/span&gt;). Instead, they need to implement &lt;em&gt;something&lt;/em&gt; that estimates the value of &lt;span class=&quot;math-container&quot;&gt;$q(s,a)$&lt;/span&gt; based on what the agent has experienced. There are a few different algorithms that can do this. A popular one is called Q learning.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Regarding &quot;[fed] back using BP&quot;, this is correct if you are using a neural network. Typically in DQN (Q learning with neural networks), this just consists of creating a small sample of training data from recent experience and training the neural network almost identically to supervised learning.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;So how do I know how slight chances in &lt;span class=&quot;math-container&quot;&gt;$\vec{w}$&lt;/span&gt; are changing &lt;span class=&quot;math-container&quot;&gt;$rq^n$&lt;/span&gt;?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Definitely don't use &lt;span class=&quot;math-container&quot;&gt;$rq^n$&lt;/span&gt; - there is no purpose to that quantity in RL. Instead for value-based RL, you are mostly interested in your estimate for Q value. This might be written &lt;span class=&quot;math-container&quot;&gt;$\hat{q}(s,a,\vec{w}) \approx q(s,a)$&lt;/span&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, in general your question stands. If you have implemented a neural network to learn q values, how do you know if it is working?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are actually two parts to this problem:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;How do you know whether the agent is getting better at it's task?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;How do you know whether the q values are getting more accurate?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;What you need to do is measure, and maybe plot some relevant quantities. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For the first question, you would typically plot the total reward that the agent gets each episode. This will be noisy, so it is a good idea to smooth it out by taking some kind of moving average (e.g. average total reward over last 100 episodes).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For the second question, it is normal to plot some loss function of the network, just like supervised learning. Typically this is Mean Squared Error loss, as the network is learning a regression to predict q values given &lt;span class=&quot;math-container&quot;&gt;$s$&lt;/span&gt; and &lt;span class=&quot;math-container&quot;&gt;$a$&lt;/span&gt;.  You can compare observed sums of discounted reward (aka &quot;return&quot; or &quot;utility&quot;) with the earlier predicted ones, and take the error function. You need to get some measure of a &quot;true&quot; value of q - usually a noisy sample taken during training or testing, and measure loss. For MSE that might be &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;span class=&quot;math-container&quot;&gt;$$J(\vec{w}) = \frac{1}{2|D|}\sum_{(s,a) \in D}(\hat{q}(s,a, \vec{w}) - q(s,a))^2$$&lt;/span&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where &lt;span class=&quot;math-container&quot;&gt;$D$&lt;/span&gt; is some dataset you have put together of &lt;span class=&quot;math-container&quot;&gt;$s,a$&lt;/span&gt; and &lt;span class=&quot;math-container&quot;&gt;$q(s,a)$&lt;/span&gt; measurements to test with. If this looks familiar to you from supervised learning MSE loss, then that's correct - it is essentially the same thing, just different how you go about collecting the data.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You may expect the loss function for &lt;span class=&quot;math-container&quot;&gt;$\hat{q}$&lt;/span&gt; in Q learning to be somewhat unstable as the agent learns. That's because in Q learning, the policy is updating at the same time as the estimates are improving. Which makes the estimates out-of-date. However, it should still be possible to see a reduction in error as learning progresses. If it becomes stable at a relatively low value compared to initially, then the agent has probably learned all that it can - although sometimes new discoveries by the agent can open up more improvements, even late in training, and throw the error function out again. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note that a low value of the error function does not mean you have an optimal agent. It means that the value function estimate is good for how the agent is currently behaving. In turn that means the agent cannot make further improvements without new and different experience.&lt;/p&gt;&#xA;" OwnerUserId="1847" LastEditorUserId="1847" LastEditDate="2018-10-16T17:24:57.423" LastActivityDate="2018-10-16T17:24:57.423" CommentCount="1" />
	<row Id="8751" PostTypeId="1" CreationDate="2018-11-02T19:52:14.770" Score="1" ViewCount="18" Body="&lt;p&gt;Until now, I always thought that Genetic Algorithm can be used for problems of which the solution space can be encoded (modeled) as a chromosome of a specific length. However, some people claim that they used GA for &lt;a href=&quot;https://www.codingame.com/multiplayer/optimization/code-vs-zombies&quot; rel=&quot;nofollow noreferrer&quot;&gt;this game&lt;/a&gt; and &lt;a href=&quot;https://www.codingame.com/multiplayer/bot-programming/coders-strike-back&quot; rel=&quot;nofollow noreferrer&quot;&gt;this game&lt;/a&gt;. They are basically games in which we control an agent on a 2-dimensional area. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Obviously, the length of the genome sequence depends on how fast the game is finished. So, how is GA used for such games?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you think GA is not the most suitable method for this kind of problems can you explain why and give better alternatives?&lt;/p&gt;&#xA;" OwnerUserId="19539" LastActivityDate="2018-11-02T19:52:14.770" Title="How to use Genetic Algorithm for varying lengths of solutions" Tags="&lt;game-ai&gt;&lt;genetic-algorithms&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="9044" PostTypeId="1" CreationDate="2018-11-18T18:21:59.040" Score="0" ViewCount="9" Body="&lt;p&gt;I made a Connect Four engine that uses the standard minimax/alpha-beta algorithms as its underlying structure, with iterative deepening added on. Because the engine uses iterative deepening, its thinking process follows this pseudo-code:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;depth limit = 1;&#xA;&#xA;while (time spent thinking up to this point &amp;lt; specified time limit)&#xA;{&#xA;     employ alpha-beta search algorithm at depth limit.&#xA;&#xA;     increment depth limit by 1.&#xA;&#xA;     // Note that the Engine actually spends slightly more time thinking &#xA;     // than the specified time limit, due to the last iteration of the &#xA;     // loop. This doesn't affect my question though, since both Engines &#xA;     // follow the same algorithm.&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;In my testing program that allows two engines to play against each other, the two engines take turns playing both sides of a randomly selected position (and I ensure the position is reasonable to play). So in each trial, possible scores are 2-0, 1.5-5, 1-1, 0.5-1.5, 0-2.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When I get my iterative deepening engine to play against an exact copy of itself in this testing program, the overall match score for x number of trials tends to be roughly level. However, there are some trials where one Engine does better than the other Engine (like 2-0 or 1.5-0.5). This seems odd, since the engines have the same code.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What I suspect is happening is that since the Engine thinks for a certain period of time, how much it calculates isn't deterministic. I've made sure to do nothing else on my computer while the testing program runs, but there's obviously background processes in my computer that I can't control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: Is it normal for two identical iterative deepening engines, when giving an equal amount of time to think, to not always be exactly the same in strength?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Bonus question&lt;/strong&gt;: Is there even a way for me to test that two such Engines are exactly equal?&lt;/p&gt;&#xA;" OwnerUserId="16917" LastActivityDate="2018-11-18T18:21:59.040" Title="My iterative deepening engine doesn't have an exactly equal score when playing against itself" Tags="&lt;ai-design&gt;&lt;game-ai&gt;&lt;minimax&gt;&lt;time&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="9106" PostTypeId="1" AcceptedAnswerId="9140" CreationDate="2018-11-22T06:11:55.800" Score="0" ViewCount="53" Body="&lt;p&gt;In evolutionary computation and in particular in the context of genetic algorithms, there is a stochastic operation called &lt;a href=&quot;https://en.wikipedia.org/wiki/Fitness_function&quot; rel=&quot;nofollow noreferrer&quot;&gt;&quot;fitness function&quot;&lt;/a&gt;. The better a state, the greater the value of the fitness function for that state. &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What would be a good fitness function for the &lt;a href=&quot;https://en.wikipedia.org/wiki/Eight_queens_puzzle&quot; rel=&quot;nofollow noreferrer&quot;&gt;8-queens problem&lt;/a&gt;?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="19652" LastEditorUserId="1671" LastEditDate="2018-11-26T02:14:58.200" LastActivityDate="2018-11-26T02:14:58.200" Title="How to calculate fitness function of 8-queens problem?" Tags="&lt;game-ai&gt;&lt;genetic-algorithms&gt;&lt;fitness-functions&gt;" AnswerCount="1" CommentCount="3" />
	<row Id="9140" PostTypeId="2" ParentId="9106" CreationDate="2018-11-24T13:24:35.257" Score="0" Body="&lt;p&gt;&lt;a href=&quot;https://kushalvyas.github.io/gen_8Q.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;here&lt;/a&gt; you can find an example of how to apply genetic algorithms to solve the 8-queens problem.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The proposed fitness function is based on the chessboard arrangement, and in particular, it is inversely proportional to the number of clashes amongst attacking positions of queens; thus, a high fitness value implies a low number of clashes.&lt;/p&gt;&#xA;" OwnerUserId="20166" LastActivityDate="2018-11-24T13:24:35.257" CommentCount="0" />
	<row Id="9165" PostTypeId="1" CreationDate="2018-11-26T00:42:57.097" Score="6" ViewCount="562" Body="&lt;p&gt;From DeepMind's &lt;a href=&quot;https://arxiv.org/pdf/1712.01815.pdf&quot; rel=&quot;noreferrer&quot;&gt;research paper&lt;/a&gt; on arxiv.org:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;In this paper, we apply a similar but fully generic algorithm, which&#xA;  we call &lt;em&gt;AlphaZero&lt;/em&gt;, to the games of chess and shogi as well as Go,&#xA;  without any additional domain knowledge except the rules of the game,&#xA;  demonstrating that a general-purpose reinforcement learning algorithm&#xA;  can achieve, tabula rasa, superhuman performance across many&#xA;  challenging domains.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Does this mean AlphaZero is an example of AGI (Artificial General Intelligence)?&lt;/p&gt;&#xA;" OwnerUserId="17601" LastEditorUserId="1581" LastEditDate="2018-11-28T21:24:10.427" LastActivityDate="2018-11-29T21:30:54.587" Title="Is AlphaZero an example of an AGI?" Tags="&lt;game-ai&gt;&lt;definitions&gt;&lt;agi&gt;&lt;alphago&gt;" AnswerCount="2" CommentCount="0" FavoriteCount="1" />
	<row Id="9170" PostTypeId="2" ParentId="9165" CreationDate="2018-11-26T02:36:15.403" Score="7" Body="&lt;p&gt;Good question!&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;AlphaZero, though a major milestone, is most definitely &lt;em&gt;not&lt;/em&gt; an AGI :)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;AlphaGo, though strong at the game of Go, is &lt;em&gt;narrowly strong&lt;/em&gt; (&quot;strong-narrow AI&quot;), defined as strength in a single problem or type of problem (such as Go and other non-chance, perfect information games.) &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;AGI, at minimum, must be about as strong as humans in &lt;em&gt;all&lt;/em&gt; problems worked on or solved by humans.  &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;AGI is often associated with &lt;a href=&quot;https://en.wikipedia.org/wiki/Superintelligence&quot; rel=&quot;nofollow noreferrer&quot;&gt;superintelligence&lt;/a&gt;, defined as intelligence that surpasses human levels.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;AGI does not necessarily imply super-intelligence, in the sense that we'd consider an android that can perform all human activities with the same capability as humans as an &lt;a href=&quot;https://en.wikipedia.org/wiki/Artificial_general_intelligence&quot; rel=&quot;nofollow noreferrer&quot;&gt;Artificial General Intelligence&lt;/a&gt;.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;But technically, AlphaGo is a narrow superintelligence in that it exceeds all human performance in a single problem.&lt;/p&gt;&#xA;" OwnerUserId="1671" LastEditorUserId="1671" LastEditDate="2018-11-29T21:30:54.587" LastActivityDate="2018-11-29T21:30:54.587" CommentCount="0" />
	<row Id="9202" PostTypeId="2" ParentId="9165" CreationDate="2018-11-27T07:37:05.203" Score="1" Body="&lt;p&gt;&lt;strong&gt;Assumptions That May Be Incorrect&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are two assumptions identifiable in the tone of the paper.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;All mental challenges can be reduced to a game with fixed rules.&lt;/li&gt;&#xA;&lt;li&gt;Machines better than humans are what humans really want or need.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;There is another two identifiable in the question.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;General intelligence exists in humans&lt;sup&gt;1&lt;/sup&gt;&lt;/li&gt;&#xA;&lt;li&gt;If it exists in humans, it is therefore feasible in computers.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;All four may be true, but none of the four are certain.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Productivity of AlphaZero&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If our chess board is on the game shelf in our closet, our grass is long, and our lawnmower is broken, AlphaZero, if connected to a humanoid robot, would have no game rules encoded for the task sequence.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Listening to its owner's request,&lt;/li&gt;&#xA;&lt;li&gt;Learning how to puppet-master the robot,&lt;/li&gt;&#xA;&lt;li&gt;Locating and identifying all our tools and spare parts,&lt;/li&gt;&#xA;&lt;li&gt;Fixing the lawnmower, and&lt;/li&gt;&#xA;&lt;li&gt;Letting us know the lawnmower is ready to use.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Therefore it is of no particular consumer value to us in that scenario.  Not very general.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even if it could mow the lawn with an already working lawnmower, it would be of value, which doesn't require the ability to win anything but rather the ability to obey and exhibit the subhuman intelligence required to not run over the flower bed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That the smart people of DeepMind chose to use the Latin &lt;em&gt;tabula rasa&lt;/em&gt; rather than &lt;em&gt;blank slate&lt;/em&gt; is notable, but not nearly as impressive as constructing a learning program that can learn to plays three games well with only the rules encoded and actual game play as input.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To consider these game programs truly useful in a product space, one cannot rely on a sustained interest in buying software that beats the buyer every time.  For AI products to be viable, the learning features must be capable of what is colloquially called common sense, which requires a much wider and flexible domain knowledge than the fixed rules of a game.  We can guess that most researchers that have accomplished milestones in winning game play learning are pushing in that direction.  They too know their research output must eventually be productized or lead to a purchasable SaaS offering.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What would be impressive to those outside the field is if these advancements can be redirected, in the data center space, to generate remedial gene therapies to cure cancer or herpes or reverse diabetes or Alzheimer's.  Then we could forgive researchers for not providing us with a download that could puppet-master a robot to clean our bathroom.  It is not clear from the paper that AlphaZero has adequately demonstrated that it exhibits, &quot;Superhuman performance across many challenging domains.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What they have done is still impressive and along the lines down which others have made progress too.  Few of us would dare try to invent a game that these generic game learning programs wouldn't learn fast and defeat us within a few game instances.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Advances Viewed in Perspective&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Certainly in performing arithmetic, sorting mail, and now game play, the inventions of humanity extend the abilities of the naked human, absent of his tools.  That progress places computer systems firmly within the realm of a tool.  A back hoe is superhuman in a way too.  Try to lay a kilometer of pipe without one.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Conversely, humanity plays the role of health care provider for computers.  If they get sick or fail, we are compelled to expel their viruses and worms or replace their failed parts.  Otherwise our homes and businesses fall into disarray.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Technology, as in all things, should be viewed in perspective.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It would be prudent for humans to be less enthralled with games and beating one another and more focused on collaborative social behavior directed toward solving social and economic problems with its newly invented tools and doing so in a way that doesn't create new problems or invite new atrocities.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Footnotes&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That what has been described as general intelligence exists in humans is disputable on the basis of evidence to the contrary.  Many would cite these strategies and trends as evidence of limits to human intelligent.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Nuclear deterrence as a peace strategy&lt;/li&gt;&#xA;&lt;li&gt;A complete lack of moderation in the consumption of finite, critical natural energy resources&lt;/li&gt;&#xA;&lt;li&gt;Continuously increasing density of addiction patterns globally&lt;/li&gt;&#xA;&lt;li&gt;Causing the sixth mass extinction on earth&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="4302" LastEditorUserId="4302" LastEditDate="2018-11-27T10:52:20.730" LastActivityDate="2018-11-27T10:52:20.730" CommentCount="1" />
	<row Id="9264" PostTypeId="1" CreationDate="2018-11-30T00:55:46.390" Score="-1" ViewCount="26" Body="&lt;p&gt;I am currently looking into sc2ai.&#xA;So i started with Tackling the minigames - turns out there is a leaderboard for this as well: &lt;a href=&quot;http://starcraftgym.com/&quot; rel=&quot;nofollow noreferrer&quot;&gt;http://starcraftgym.com/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Now how can I submit my bots to compete on the leaderboard?&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="18713" LastEditorUserId="1671" LastEditDate="2018-11-30T18:37:23.123" LastActivityDate="2018-11-30T18:37:23.123" Title="How do i submit my sc2ai bot to the minigames leaderboard?" Tags="&lt;game-ai&gt;&lt;ai-community&gt;&lt;starcraft&gt;" AnswerCount="0" CommentCount="1" />
	<row Id="9276" PostTypeId="1" CreationDate="2018-11-30T07:38:52.187" Score="3" ViewCount="43" Body="&lt;p&gt;I have to build a KI for a made-up game similiar to chess. As I did research for a proper solution I came upon the MinMax-Algorithm but I'm not sure it will work with the given game dynamics.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Problem is, in opposition to chess, we have far more possible moves:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;-Six pieces on the board, with different ranges. In average there are 8 possible moves for a piece per turn.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;-The player can choose as many pieces to move as he likes. For example none, all of them, or some number inbetween. (Whereas in chess you can only move one)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So even for the first move the number of branches would be enormous!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Actual questions: Is it after all feasible to implement MinMax for the described game? Can alpha-beta-pruning and a refined evaluation function help (despite of the insane number of possible moves) ?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If no, is there a proper alternative?&lt;/p&gt;&#xA;" OwnerUserId="20303" LastActivityDate="2018-11-30T11:12:53.700" Title="MinMax and enormous branches" Tags="&lt;game-ai&gt;&lt;logic&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="1" />
	<row Id="9277" PostTypeId="2" ParentId="9276" CreationDate="2018-11-30T08:41:34.293" Score="0" Body="&lt;p&gt;A huge “branch depth” is a common problem in game AI. The best-practice method to overcome it are heuristics. Formalizing heuristics in game playing can be done with Domain specific languages. The assumption is, that a board game solver has certain commands like “pickup figure”, “setsearch depth 17” or “search freefield”. The board game solver is treated as a textadventure which provides a userinterface and allows to formalize all the heuristics in a convincingly way. From a performance perspective such a solver works similar to the minimax algorithm. He has to search in the game tree until he finds a solution. The difference is, that the search is fine granular like in a PDDL solver. Instead of occupying all the cpu cores with 100% the search in the game tree is declared as an art which follows rules. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the cited paper, the manhattan distance was used as an evaluation function. Partial Evaluation is another promising approach. The idea is to divide the goal into subgoals and solve them separate.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Romein, John W., Henri E. Bal, and Dick Grune. &quot;An Application Domain Specific Language for Describing Board Games.&quot; Parallel and Distributed Processing Techniques and Applications. Vol. 1. 1997.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="11571" LastEditorUserId="11571" LastEditDate="2018-11-30T09:18:55.210" LastActivityDate="2018-11-30T09:18:55.210" CommentCount="2" />
	<row Id="9279" PostTypeId="2" ParentId="9276" CreationDate="2018-11-30T11:12:53.700" Score="0" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;-The player can choose as many pieces to move as he likes. For example none, all of them, or some number inbetween. (Whereas in chess you can only move one)&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;That quote specifically is the part that really causes the size of your legal action set to blow up. You have a combinatorial action space here. If each of your pieces has 8 legal moves, then that is:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;8 legal moves for the first piece (or 9 if that count didn't already include the &quot;do nothing&quot; option)&lt;/li&gt;&#xA;&lt;li&gt;for each of those, there are again 8 or 9 different choices for the second piece (leading to e.g. &lt;span class=&quot;math-container&quot;&gt;$8 \times 8 = 64$&lt;/span&gt; possible combinations for just the first two pieces)&lt;/li&gt;&#xA;&lt;li&gt;for each of those, again 8 choices for the third piece (leading to &lt;span class=&quot;math-container&quot;&gt;$64 \times 8 = 512$&lt;/span&gt; possible combinations for just the first three pieces).&lt;/li&gt;&#xA;&lt;li&gt;etc.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;This blows up way too quickly, and there's really no hope of ever getting a decent player for this using any MiniMax-based algorithm (including things like alpha-beta pruning, principal variation search etc.).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the kinds of games that you describe, you'll want to use algorithms that can exploit the &quot;structure&quot; of your action space. A raw enumeration of all possible combinations blows up quickly, but many algorithms can do reasonably well by re-phrasing the problem in such a way that you have more &quot;depth&quot; rather than &quot;breadth&quot;. For example, instead of viewing a full combination of choices for all pieces as a single &quot;action&quot;, you can treat the choices per piece as a separate &quot;action&quot;. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Rather than making a single choice out of &lt;span class=&quot;math-container&quot;&gt;$8 \times 8 \times 8 \times \dots$&lt;/span&gt; possibilities every turn, you want to have a search tree where your player makes one choice out of &lt;span class=&quot;math-container&quot;&gt;$8$&lt;/span&gt; (for the first piece), followed immediately by another choice out of &lt;span class=&quot;math-container&quot;&gt;$8$&lt;/span&gt; (for the second piece), etc. The opposing player only gets to make a choice after the current player has made choices for all pieces. With such a strategy, the breadth of your search tree will no longer be a problem, but the depth will become a problem. To address this, you'll additionally want to make sure that your methods can generalize across different depth levels.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A good place to look would be combinatorial versions of Monte-Carlo Tree Search, such as those described in:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://project.dke.maastrichtuniversity.nl/games/files/msc/Roelofs_thesis.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://project.dke.maastrichtuniversity.nl/games/files/msc/Roelofs_thesis.pdf&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://www.jair.org/index.php/jair/article/view/11053&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://www.jair.org/index.php/jair/article/view/11053&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;(probably a few other publications by the author of that second link)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;These algorithms are quite a bit more complicated than MiniMax though, MiniMax is a very basic algorithm in comparison.&lt;/p&gt;&#xA;" OwnerUserId="1641" LastActivityDate="2018-11-30T11:12:53.700" CommentCount="3" />
	<row Id="111" PostTypeId="1" AcceptedAnswerId="134" CreationDate="2016-08-02T18:57:57.550" Score="48" ViewCount="3206" Body="&lt;p&gt;Obviously driverless cars aren't perfect, so imagine that the Google car (as an example) got into difficult situation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here are a few examples of unfortunate situations caused by set of events:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;the car is heading toward a crowd of 10 people crossing the road, so it cannot stop in time, but it can avoid killing 10 people by hitting the wall (killing the passengers),&lt;/li&gt;&#xA;&lt;li&gt;avoiding killing the rider of the motorcycle considering that the probability of survival is greater for the passenger of the car,&lt;/li&gt;&#xA;&lt;li&gt;killing animal on the street in favour of human being,&lt;/li&gt;&#xA;&lt;li&gt;changing lanes to crash into another car to avoid killing a dog,&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;And here are few dilemmas:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Does the algorithm recognize the difference between a human being and an animal?&lt;/li&gt;&#xA;&lt;li&gt;Does the size of the human being or animal matter?&lt;/li&gt;&#xA;&lt;li&gt;Does it count how many passengers it has vs. people in the front?&lt;/li&gt;&#xA;&lt;li&gt;Does it &quot;know&quot; when babies/children are on board?&lt;/li&gt;&#xA;&lt;li&gt;Does it take into the account the age (e.g. killing the older first)?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;How would an algorithm decide what should it do from the technical perspective? Is it being aware of above (counting the probability of kills), or not (killing people just to avoid its own destruction)?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Related articles:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://www.technologyreview.com/s/542626/why-self-driving-cars-must-be-programmed-to-kill/&quot;&gt;Why Self-Driving Cars Must Be Programmed to Kill&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://www.technologyreview.com/s/539731/how-to-help-self-driving-cars-make-ethical-decisions/&quot;&gt;How to Help Self-Driving Cars Make Ethical Decisions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="8" LastEditorUserId="75" LastEditDate="2016-08-12T15:22:36.363" LastActivityDate="2017-03-07T15:55:25.200" Title="How could self-driving cars make ethical decisions about who to kill?" Tags="&lt;algorithm&gt;&lt;self-driving&gt;&lt;decision-theory&gt;&lt;ethics&gt;" AnswerCount="12" CommentCount="6" FavoriteCount="11" />
	<row Id="112" PostTypeId="1" CreationDate="2016-08-02T18:59:44.230" Score="3" ViewCount="489" Body="&lt;p&gt;Which deep neural network is used in &lt;a href=&quot;https://en.wikipedia.org/wiki/Google_self-driving_car&quot; rel=&quot;nofollow&quot;&gt;Google's driverless cars&lt;/a&gt; to analyse the surroundings? Is this information is open?&lt;/p&gt;&#xA;" OwnerUserId="8" LastActivityDate="2016-11-05T10:34:25.450" Title="Which machine learning algorithm is used in self-driving cars?" Tags="&lt;deep-network&gt;&lt;algorithm&gt;&lt;self-driving&gt;" AnswerCount="2" CommentCount="0" />
	<row Id="2269" PostTypeId="2" ParentId="112" CreationDate="2016-11-04T16:07:30.833" Score="1" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;The most common machine learning algorithms found in self driving cars involve &lt;strong&gt;object tracking&lt;/strong&gt; based technologies used in order to pinpoint and distinguish between different objects in order to better analyse a digital landscape.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Algorithms are designed to become more efficient at this by modifying internal parameters and testing these changes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I hope that provides a general overview of the subject.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Since Google's cars are in development and are proprietary, they will probably not share their specific algorithm, however you can take a look at similar technologies to learn more.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;To find out more, take a look at an &lt;a href=&quot;http://ori.ox.ac.uk/how-robotcar-works/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Oxford-based initiative in self driving cars and how they work&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="3427" LastEditorUserId="8" LastEditDate="2018-04-13T18:55:08.723" LastActivityDate="2018-04-13T18:55:08.723" CommentCount="0" />
	<row Id="2273" PostTypeId="2" ParentId="112" CreationDate="2016-11-05T10:34:25.450" Score="2" Body="&lt;p&gt;It will not be single DNN architecture, rather it will be a collection of different DNN architectures that are used together to make the final decision. Convolutions are using the images/videos from the camera. Other architectures use other sensory sources. These DNNs will be trained to compute the high-level features from their sensory sources and then those high-level features will probably be fed into an LSTM (or some other form of RNN) that is trained with some form of Reinforcement learning algorithm to compute the action (like slowing down, applying breaks etc).&lt;/p&gt;&#xA;" OwnerUserId="1462" LastEditorUserId="14723" LastEditDate="2018-04-14T02:42:26.697" LastActivityDate="2018-04-14T02:42:26.697" CommentCount="0" />
	<row Id="1318" PostTypeId="1" AcceptedAnswerId="1820" CreationDate="2016-08-04T15:10:41.230" Score="1" ViewCount="294" Body="&lt;p&gt;&lt;strong&gt;The Situation:&lt;/strong&gt;&#xA;A self-driving car is traveling at it's maximum speed, 25 mph (40 km/h), in the middle of an empty street with the ability to change lanes on both sides. There are two passengers, one in the front and another in the back.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Someone jumps from the side of the road directly into the path of the car. A collision would occur in 50 meters. &lt;a href=&quot;http://www.brake.org.uk/rsw/15-facts-a-resources/facts/1255-speed&quot; rel=&quot;nofollow&quot;&gt;Breaking distance&lt;/a&gt; at this speed is about 24m.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;The Question:&lt;/strong&gt; Is it known how the current implementation of the Google Car AI would react, or is it currently a matter of speculation? A step-by-step explanation of the AI's decisioning process would be preferred.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Possible Answers:&lt;/strong&gt; The car could activate its brakes immediately, coming to a halt as quickly as possible. This would be sooner than a human could stop, as people require time to recognize the possibility of a collision, and then physically slam on the brake. (&lt;em&gt;thinking distance&lt;/em&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alternatively, the car could continue traveling forward, processing the situation. (Similar to a humans &lt;em&gt;thinking distance&lt;/em&gt;). The person may continue to move, either out of the way, or still into danger of being hit. In this case, the car may decide to change lanes in an attempt to pass around the person.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Lastly and most unlikely, the car will not alter its course and proceed to drive forward.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;Do not attempt to do it to check;)&lt;/sup&gt;&lt;/p&gt;&#xA;" OwnerUserId="8" LastEditorUserId="1812" LastEditDate="2016-08-31T23:17:29.040" LastActivityDate="2016-09-01T01:52:21.400" Title="What would happen if someone jumped in the front of a Google car?" Tags="&lt;self-driving&gt;&lt;decision-theory&gt;" AnswerCount="1" CommentCount="5" />
	<row Id="1820" PostTypeId="2" ParentId="1318" CreationDate="2016-09-01T01:52:21.400" Score="2" Body="&lt;p&gt;Given this &lt;a href=&quot;https://www.youtube.com/watch?v=YXylqtEQ0tk&quot; rel=&quot;nofollow&quot;&gt;YouTube video&lt;/a&gt; which is being given by Sebastian Thrun who had a TED talk which had nowhere near the same level of detail but had similar conclusions, it looks like the lidar system used by google's automated car system has decent resolution out to at least 30m picking out mobile bodies in the static background and then identifying it. So it should have plenty of time to brake and stop long before there was any risk to the pedestrian attempting to cross the street.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Skip to about 6:40 in the video to see a visual representation of the detection system.&lt;/p&gt;&#xA;" OwnerUserId="1991" LastActivityDate="2016-09-01T01:52:21.400" CommentCount="0" />
	<row Id="1488" PostTypeId="1" AcceptedAnswerId="1522" CreationDate="2016-08-09T10:10:25.253" Score="5" ViewCount="319" Body="&lt;p&gt;Do we know why Tesla's Autopilot mistaken empty sky with a high-sided lorry which resulted in fatal crash involving a car in self-drive mode? Was it AI fault or something else? Is there any technical explanation behind this why this happened?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;References: &lt;a href=&quot;http://news.sky.com/story/tesla-driver-in-first-self-drive-fatal-crash-10330121&quot; rel=&quot;nofollow&quot;&gt;Sky News article&lt;/a&gt;, &lt;a href=&quot;http://www.theverge.com/2016/6/30/12072408/tesla-autopilot-car-crash-death-autonomous-model-s&quot; rel=&quot;nofollow&quot;&gt;The Verge&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="8" LastEditorUserId="8" LastEditDate="2016-08-09T22:17:20.030" LastActivityDate="2016-08-14T23:54:03.540" Title="Why did a Tesla car mistake a truck with a bright sky?" Tags="&lt;self-driving&gt;&lt;cars&gt;" AnswerCount="3" CommentCount="3" />
	<row Id="1579" PostTypeId="2" ParentId="1488" CreationDate="2016-08-12T03:22:24.100" Score="1" Body="&lt;p&gt;Tesla model S has &lt;a href=&quot;https://www.tesla.com/models&quot; rel=&quot;nofollow noreferrer&quot;&gt;Autopilot&lt;/a&gt; which allows to steer within a lane, change lanes with the simple tap of a turn signal, and can manage speed by using traffic-aware cruise control. Multiple digital controls helps to avoid collisions. Based on that, this isn't fully self-driving car.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However it is using a computer vision detection system, but it is not intended to be used hands-free.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So basically what is known is that the accident involved the side of a truck trailer (of a large white 18-wheel truck) and most likely the camera had a washed out of picture possibly due to glare or blooming from overexposure which made that the side of the trailer white and thin which failed to distinguish with the sky which was bright as well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This may have happened in part, because the crash-avoidance system only engage when both radar and vision system detect an obstacle which could not happen.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Further more it was suggested by &lt;em&gt;The Associated Press&lt;/em&gt; that the driver most likely was watching a &lt;em&gt;Harry Potter&lt;/em&gt; at the time of the crash and assuming system would alert Brown, we don't know if he was able to retake controls quickly enough to avoid impact. As mentioned again, the system wasn't intended for hands-free driving and parts of the system was unfinished. Not to mention that the car was driving with full speed under the trailer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Tesla officially said about this crash in a statement on its website:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;&lt;strong&gt;The high ride height of the trailer combined with its positioning across the road and the extremely rare circumstances&lt;/strong&gt; of the impact caused the Model S to pass under the trailer, with the bottom of the trailer impacting the windshield of the Model S.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Neither Autopilot nor the driver noticed the white side of the tractor-trailer against a brightly lit sky, so the brake was not applied.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;They also said, according to techno-optimists, that they will tweaks their code, so this particular case won't happen again.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To summarize, this was a 'technical failure' of braking system and most likely Autopilot was not at as Tesla told Senate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/obdLM.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/obdLM.png&quot; alt=&quot;The New York Times |Source: Florida traffic crash report&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;The New York Times |Source: Florida traffic crash report&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sources:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.freep.com/story/money/cars/2016/07/01/tesla-autopilot-death-highlights-autonomous-risks/86591130/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Tesla Autopilot death highlights autonomous risks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://robotfuturesbook.wordpress.com/2016/07/01/layers-of-autonomy&quot; rel=&quot;nofollow noreferrer&quot;&gt;Layers of Autonomy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.nytimes.com/interactive/2016/07/01/business/inside-tesla-accident.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;Inside the Self-Driving Tesla Fatal Accident&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://www.theguardian.com/technology/2016/jun/30/tesla-autopilot-death-self-driving-car-elon-musk&quot; rel=&quot;nofollow noreferrer&quot;&gt;Tesla driver dies in first fatal crash while using autopilot mode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="8" LastEditorUserId="8" LastEditDate="2016-08-12T03:38:43.983" LastActivityDate="2016-08-12T03:38:43.983" CommentCount="0" />
	<row Id="1560" PostTypeId="1" AcceptedAnswerId="1577" CreationDate="2016-08-11T18:06:34.053" Score="1" ViewCount="215" Body="&lt;p&gt;Based on this &lt;a href=&quot;http://www.dailymail.co.uk/sciencetech/article-3677950/Google-s-self-driving-cars-spot-cyclists-Sensors-read-hand-signals-predict-riders-behavior.html&quot; rel=&quot;nofollow&quot;&gt;article&lt;/a&gt;, Google's self-driving cars can spot cyclists, cars, road signs, markings, traffic lights, and pedestrians.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How exactly does it identify pedestrians? Is it based on face recognition, shape, size, distance, infrared signature?&lt;/p&gt;&#xA;" OwnerUserId="8" LastEditorUserId="1504" LastEditDate="2016-08-13T16:39:19.730" LastActivityDate="2017-08-24T18:35:03.653" Title="How does Google's self-driving car identify pedestrians?" Tags="&lt;self-driving&gt;&lt;cars&gt;&lt;object-recognition&gt;" AnswerCount="1" CommentCount="10" FavoriteCount="1" />
	<row Id="1577" PostTypeId="2" ParentId="1560" CreationDate="2016-08-12T02:30:20.793" Score="3" Body="&lt;p&gt;The AI of the car uses sensor data to process all the data and classifies objects &lt;strong&gt;based on the size, shape and movement patterns&lt;/strong&gt;. It can recognize surroundings from a 360 degree perspective by making predictions about vehicles, people and objects around it will move.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It can detect pedestrians, but as moving, &lt;strong&gt;column-shaped blurs of pixels&lt;/strong&gt;, so it really cannot tell whether it's a rock or a crumpled piece of paper.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;https://media.giphy.com/media/3oEduYqb4Ty6dSReKc/giphy-downsized-large.gif&quot; alt=&quot;Google&amp;#39;s self-driving car sees traffic&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However it is programmed to determine certain patterns when a police officer has halted traffic or the car is being signaled to move forward.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;https://media.giphy.com/media/l41lGfjhDlrSE9ILS/giphy-downsized-large.gif&quot; alt=&quot;Google&amp;#39;s self-driving car determines when a police officer has halted traffic or when the car is being signaled to move forward&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It also recognizes cyclists as objects outlined in red and can slow down to let the cyclist enter into a lane.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&quot;https://media.giphy.com/media/3oEduTuU46cDCGGuC4/giphy-downsized-large.gif&quot; alt=&quot;Google&amp;#39;s self-driving car sees when a cyclist is trying to merge into a lane, the vehicle also knows to slow down and let the cyclist enter&quot;&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;Above images are provided by Chris Urmson who heads up Google's driverless car program.&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sources:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.techinsider.io/how-googles-self-driving-cars-see-the-world-2015-10/#then-it-uses-its-sensor-data-to-understand-what-it-sees-in-the-moment-the-software-processes-all-of-the-data-and-classifies-objects-based-on-size-shape-and-movement-patterns-2&quot; rel=&quot;nofollow&quot;&gt;How Google's self-driving cars see the world&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://www.technologyreview.com/s/530276/hidden-obstacles-for-googles-self-driving-cars/&quot; rel=&quot;nofollow&quot;&gt;Hidden Obstacles for Google’s Self-Driving Cars&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;(video) &lt;a href=&quot;https://www.youtube.com/watch?v=tiwVMrTLUWg&quot; rel=&quot;nofollow&quot;&gt;Chris Urmson: How a driverless car sees the road&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="8" LastEditorUserId="8" LastEditDate="2016-08-13T02:51:10.783" LastActivityDate="2016-08-13T02:51:10.783" CommentCount="4" />
	<row Id="1561" PostTypeId="1" AcceptedAnswerId="1578" CreationDate="2016-08-11T18:18:27.973" Score="12" ViewCount="337" Body="&lt;p&gt;In &lt;a href=&quot;https://www.technologyreview.com/s/530276/hidden-obstacles-for-googles-self-driving-cars/&quot;&gt;Hidden Obstacles for Google’s Self-Driving Cars&lt;/a&gt; article we can read that:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Google’s cars can detect and respond to stop signs that aren’t on its map, a feature that was introduced to deal with temporary signs used at construction sites.&lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;Google says that its cars can identify almost all unmapped stop signs, and would remain safe if they miss a sign because the vehicles are always looking out for traffic, pedestrians and other obstacles.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;What would happen if a car spotted somebody in front of it (but not on the collision path) wearing a T-shirt that has a stop sign printed on it. Would it react and stop the car?&lt;/p&gt;&#xA;" OwnerUserId="8" LastEditorUserId="145" LastEditDate="2016-08-11T19:50:36.397" LastActivityDate="2016-08-29T17:29:29.030" Title="Would Google's self-driving-car stop when it sees somebody with a T-shirt with a stop sign printed on it?" Tags="&lt;self-driving&gt;&lt;decision-theory&gt;&lt;cars&gt;&lt;object-recognition&gt;" AnswerCount="1" CommentCount="9" />
	<row Id="1578" PostTypeId="2" ParentId="1561" CreationDate="2016-08-12T02:48:59.620" Score="6" Body="&lt;p&gt;Google’s self-driving car most likely uses &lt;a href=&quot;https://viejournal.springeropen.com/articles/10.1186/s40327-015-0027-1&quot; rel=&quot;nofollow noreferrer&quot;&gt;mapping of traffic signs using google street view images for roadway inventory management&lt;/a&gt;. If traffic signs are not in its database, it can still “see” and detect moving objects which can be distinguished from the presence of certain stationary objects, like traffic lights. So its software can classify objects based on the size, shape and movement patterns. Therefore it is highly unlikely that a person would be mistaken for a traffic sign. See: &lt;a href=&quot;https://ai.stackexchange.com/q/1560/8&quot;&gt;How does Google&amp;#39;s self-driving car identify pedestrians?&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://www.technologyreview.com/s/530276/hidden-obstacles-for-googles-self-driving-cars/&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/setJb.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;Image: Technology Review&lt;/sup&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To support such a claim, &lt;a href=&quot;http://www.cs.cmu.edu/~illah/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Illah Nourbakhsh&lt;/a&gt;, a professor of robotics at Carnegie Mellon University, gave an interview to the New York Times magazine cover story on autonomous driving cars, and includes this hypothetical scenario, saying:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;If they’re outside walking, and the sun is at just the right glare level, and there’s a mirrored truck stopped next to you, and the sun bounces off that truck and hits the guy so that you can’t see his face anymore — well, now your car just sees a stop sign. &lt;strong&gt;The chances of all that happening are diminishingly small — it’s very, very unlikely&lt;/strong&gt; — but the problem is we will have millions of these cars. The very unlikely will happen all the time.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Even so, the risk would be minimal, since the car is always looking out for traffic, pedestrians and other obstacles.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Sources:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.techinsider.io/how-googles-self-driving-cars-see-the-world-2015-10/#googles-self-driving-vehicles-first-establish-their-location-by-using-mapping-and-sensor-data-1&quot; rel=&quot;nofollow noreferrer&quot;&gt;How Google's self-driving cars see the world&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;http://www.nytimes.com/2015/11/15/magazine/the-dream-life-of-driverless-cars.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;The Dream Life of Driverless Cars&lt;/a&gt; at The New York Times&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="8" LastEditorUserId="-1" LastEditDate="2017-04-13T12:53:10.013" LastActivityDate="2016-08-29T17:29:29.030" CommentCount="0" />
	<row Id="1567" PostTypeId="1" CreationDate="2016-08-11T19:56:31.223" Score="2" ViewCount="68" Body="&lt;p&gt;&lt;sub&gt; This is a scope experiment. &lt;/sub&gt;&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;After Google/Tesla/whoever else is making self-driving cars finishes perfecting them, will they replace the cars with human drivers, so that there are only self-driving cars?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If they do, it would probably make the roads safer.&lt;/p&gt;&#xA;" OwnerUserId="145" LastEditorUserId="145" LastEditDate="2016-08-11T20:06:42.147" LastActivityDate="2016-08-12T01:42:05.757" Title="Once self-driving cars are perfected, will they replace old-fashioned cars?" Tags="&lt;self-driving&gt;&lt;cars&gt;" AnswerCount="1" CommentCount="6" ClosedDate="2016-08-12T06:39:38.000" />
	<row Id="1576" PostTypeId="2" ParentId="1567" CreationDate="2016-08-12T01:42:05.757" Score="3" Body="&lt;p&gt;It likely to be happen, because it's more convenient that way. In general people, organizations and government are always keen to make things more efficient by standarizing things (computers, technology, law, science, etc.) in order to make it manageable and predictable to reduce the time and minimalize the risk of the same mistakes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The whole world now moves into technological advancement where automation of everything is where we are going, so we can manage complexities in more reliable way, so we can focus on much bigger picture. This includes technology such as mobiles, computers, UAV (delivery drones), robots and now self-driving cars.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The pros of that change would be:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;To have safer streets by introducing autonomous cars on the road.&lt;/li&gt;&#xA;&lt;li&gt;To have fewer drunk, tired, drugged or crazy drivers.&lt;/li&gt;&#xA;&lt;li&gt;To avoid poor weather conditions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;To reduce &lt;a href=&quot;https://en.wikipedia.org/wiki/Braking_distance&quot; rel=&quot;nofollow noreferrer&quot;&gt;braking distances&lt;/a&gt; by dropping driver's reaction time and predicting dangerous situations much earlier.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.cyberphysics.co.uk/topics/forces/stopping_distance.htm&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/cz9yP.png&quot; alt=&quot;Typical stopping distance&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;Source: &lt;a href=&quot;http://www.cyberphysics.co.uk/topics/forces/stopping_distance.htm&quot; rel=&quot;nofollow noreferrer&quot;&gt;Cyber Physics&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Reducing car deaths and costs of GNP.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;An estimated 1.3 million people die on the world's roads every year with around 50 million injured or disabled by accidents, with accidents costing countries up to four per cent of their Gross National Product (GNP) yearly. - &lt;a href=&quot;http://www.un.org/apps/news/story.asp?NewsID=36823&quot; rel=&quot;nofollow noreferrer&quot;&gt;UN News Centre&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;To have central point of safety improvements, you cannot change people, but you can fix the known safety issue on global scale.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;To introduce global standards from the central point (e.g. new law to which manufactures needs to apply).&lt;/li&gt;&#xA;&lt;li&gt;To increase &lt;a href=&quot;http://www.slideshare.net/sbishop2/p22-car-design-safety&quot; rel=&quot;nofollow noreferrer&quot;&gt;car safety&lt;/a&gt; in general on larger scale.&lt;/li&gt;&#xA;&lt;li&gt;And so on.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;h3&gt;Why we need the 'only self-driving cars'?&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;The &lt;a href=&quot;http://www.un.org/apps/news/story.asp?NewsID=36823&quot; rel=&quot;nofollow noreferrer&quot;&gt;Secretary-General said the UN&lt;/a&gt; would work hard to prevent further deaths on the roads:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Many tragedies can be avoided through a set of proven, simple measures that benefit not only individuals and families but society at large.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Here are my points:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;To achieve 'a set of proven measures' - do not allow people to drive - simple.&lt;/li&gt;&#xA;&lt;li&gt;People tend to break the rules, always, so do not allow them to drive without permission.&lt;/li&gt;&#xA;&lt;li&gt;Reduce stealing cars and other crime.&lt;/li&gt;&#xA;&lt;li&gt;Law enforcement dream is to able to stop any car on demand.&lt;/li&gt;&#xA;&lt;li&gt;Do not allow drunk people to drive a car.&lt;/li&gt;&#xA;&lt;li&gt;Disallow terrorist attacks, like in &lt;a href=&quot;https://en.wikipedia.org/wiki/2016_Nice_attack&quot; rel=&quot;nofollow noreferrer&quot;&gt;Nice where truck killed over 80 people&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Avoid bank robberies and similar which are possible by escaping fast cars.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Is it possible? I believe it depends on specific countries and unions and how quickly we're able to advance and be ready for such change.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To support above points and summarize the 'only self-driving cars' point, please see below references which shows that this is already happening:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;2014: &lt;a href=&quot;http://www.theverge.com/2014/5/28/5758734/uber-will-eventually-replace-all-its-drivers-with-self-driving-cars&quot; rel=&quot;nofollow noreferrer&quot;&gt;Uber will eventually replace all its drivers with self-driving cars&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;2016: &lt;a href=&quot;http://www.dezeen.com/2016/02/12/google-self-driving-car-artficial-intelligence-system-recognised-as-driver-usa/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Google's self-driving car system has been officially recognised as a driver in the US.&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The move is seen as a first step towards changing the law for cars that have &quot;no need for a human driver&quot;.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;2016: &lt;a href=&quot;http://www.dezeen.com/2016/04/19/beverly-hills-replace-public-transport-driverless-cars-los-angeles/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Beverly Hills to replace public transport with self-driving cars&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;2016: &lt;a href=&quot;http://www.sfexaminer.com/sf-pitches-149-million-plan-replace-cars-self-driving-vehicles/&quot; rel=&quot;nofollow noreferrer&quot;&gt;San Francisco pitches $149 million plan to replace cars with self-driving vehicles&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;San Francisco’s future is autonomous and shared vehicles – and that future may be only a decade away.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;2016: &lt;a href=&quot;http://spectrum.ieee.org/cars-that-think/transportation/self-driving/otto-selfdriving-truck-company-wants-to-replace-teamsters&quot; rel=&quot;nofollow noreferrer&quot;&gt;Otto Self-Driving Truck Company Wants to Replace Teamsters&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="8" LastActivityDate="2016-08-12T01:42:05.757" CommentCount="4" />
	<row Id="1592" PostTypeId="1" CreationDate="2016-08-12T20:27:15.577" Score="6" ViewCount="73" Body="&lt;p&gt;Google, Tesla, Apple etc have all built or are building their own self-driving cars. As an expert in a related area, I am interested in knowing at a high level, the systems and techniques that go into self-driving cars. How easy is it for me to make a tabletop prototype (large enough to accomodate the needed computing power needs)?&lt;/p&gt;&#xA;" OwnerUserId="130" LastActivityDate="2016-08-13T15:48:26.767" Title="What technologies are needed for a self-driving car?" Tags="&lt;self-driving&gt;&lt;ai-design&gt;" AnswerCount="1" CommentCount="1" FavoriteCount="1" />
	<row Id="1610" PostTypeId="2" ParentId="1592" CreationDate="2016-08-13T15:48:26.767" Score="4" Body="&lt;p&gt;You're going to need some way to 'see' the area around the car, and to track the speed of nearby objects. Google uses a combination of &lt;a href=&quot;https://en.wikipedia.org/wiki/Lidar&quot; rel=&quot;nofollow&quot;&gt;LIDAR&lt;/a&gt;, radar, conventional cameras, and occasionally sonar (see &lt;a href=&quot;http://www.makeuseof.com/tag/how-self-driving-cars-work-the-nuts-and-bolts-behind-googles-autonomous-car-program&quot; rel=&quot;nofollow&quot;&gt; here&lt;/a&gt; for a high-level overview). This technology is quite expensive, and can easily cost thousands of US dollars.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, a bigger obstacle than the expense of the hardware (which would be smaller for a table-top prototype) is the software complexity. Like many major projects, the software for self-driving cars is the result of years of work from AI research teams, and thus extremely difficult to duplicate on your own.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That said, you're not trying to make a state-of-the-art self-driving car.  Assuming you're an expert in image processing and robotics, you can probably create a basic prototype, (like something that drive in a limited table-top environment). However, it's still going to take a lot of time and money. &lt;/p&gt;&#xA;" OwnerUserId="127" LastActivityDate="2016-08-13T15:48:26.767" CommentCount="2" />
	<row Id="1946" PostTypeId="1" CreationDate="2016-09-11T14:54:44.943" Score="6" ViewCount="145" Body="&lt;p&gt;Can self-driving cars deal with snow, heavy rain, or other weather conditions like these? Can they deal with unusual events, such as &lt;a href=&quot;http://beijingcream.com/wp-content/uploads/2012/06/Ducks-galore-2.jpeg&quot; rel=&quot;nofollow noreferrer&quot;&gt;ducks on the road&lt;/a&gt;?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/a0PVLm.jpg&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/a0PVLm.jpg&quot; alt=&quot;ducks on the road&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="1670" LastEditorUserId="8" LastEditDate="2016-09-12T19:26:42.193" LastActivityDate="2017-01-11T16:21:04.840" Title="What kind of road/weather conditions can AI-driven cars can deal with, as of 2016?" Tags="&lt;self-driving&gt;&lt;cars&gt;" AnswerCount="3" CommentCount="2" FavoriteCount="1" />
	<row Id="1952" PostTypeId="2" ParentId="1946" CreationDate="2016-09-12T00:40:55.673" Score="0" Body="&lt;p&gt;The state of the art AI driving systems utilize stereoscopic/depth cameras for visual perception. Scenarios such as your &lt;em&gt;ducks on the road&lt;/em&gt; example would make the system perceive them as obstacles on the road (it doesn't really matter if they are ducks/goats/humans). The base algorithm should be able to circumvent this situation and bring the vehicle to a safe halt avoiding chances of possible disaster. Hence I doubt scenarios such as this would pose much of a problem to today's AI drivers. &lt;/p&gt;&#xA;" OwnerUserId="1774" LastActivityDate="2016-09-12T00:40:55.673" CommentCount="0" />
	<row Id="2461" PostTypeId="2" ParentId="1946" CreationDate="2016-12-11T22:28:08.830" Score="0" Body="&lt;p&gt;Many cars now instead of just cameras, use radars. Snow, heavy rain, and other weather conditions should not affect them at all. Objects like ducks will be detected. The only problem right now is dealing with things like red lights or road signs, as you have to use a camera to see and interpret them.&lt;/p&gt;&#xA;" OwnerUserId="4198" LastActivityDate="2016-12-11T22:28:08.830" CommentCount="0" />
	<row Id="2468" PostTypeId="2" ParentId="1946" CreationDate="2016-12-12T16:15:19.177" Score="2" Body="&lt;p&gt;No, smart cars do not know what to do when surrounded with ducks or flood waters, and it's possible they never will.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;As with all machine learning, a computer knows only what it's taught.  If an event arises that's unusual, the AI will have less relevant training on how to respond, so its reaction behavior &lt;em&gt;necessarily&lt;/em&gt; will be inferior to its routine &quot;standard operating procedure&quot;, for which is has been heavily trained.  (Of course this is true of humans too.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Due to liability concerns, when encountering an outlier condition, smart cars will almost certainly be designed by their makers to &lt;em&gt;immediately&lt;/em&gt; pull off the road and wait to be explicitly told what to do -- by the human in the car or by communicating with a central command office that exists to disambiguate such confusion and resolve cognitive impasses.  When confused, just like a child, a smart car will be designed to seek external assistance -- and is likely to do so indefinitely, I suspect.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That's why, despite Google's recent cars that lack steering wheels, smart cars most certtainly &lt;em&gt;will&lt;/em&gt; retain some means of manual control -- be it a wheel and pedals, or at least verbal commands.  Given the many forms of weirdness that are possible on the road, it's possible smart cars will &lt;em&gt;never&lt;/em&gt; be fully autonomous.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As for bad weather conditions, how well do smart cars currently perform?  Nobody outside of a car manufacturer can say for certain.  Lidar and radar are superior to the human eye in seeing through fog and snow.  But (competent) humans are likely to remain better than a smart car at dynamically learning the limit of adhesion and compensating (since this is a learned skill few smart cars will already know or can learn quickly -- given this car, these tires, this road surface, this angle of road, etc).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Initially smart cars will turn to the human when the going gets rough, ceding control back to them.  Once smart cars have driven a few million miles in snow, slush, high wind, floods, and ice, and encountered many ducks, angry mooses, and irate pedestrians, they will have been taught to do more for themselves.  Until then, and perhaps for decades yet, I suspect they will turn to mommy and ask for help.&lt;/p&gt;&#xA;" OwnerUserId="1657" LastActivityDate="2016-12-12T16:15:19.177" CommentCount="0" />
	<row Id="2126" PostTypeId="1" CreationDate="2016-10-12T06:56:47.753" Score="6" ViewCount="271" Body="&lt;p&gt;How are autonomous cars related to artificial intelligence? I would presume that artificial intelligence is when we are able to copy the human state of mind and perform tasks in the same way. But isn't autonomous car just rule-based machines that operates due to its environment? They are not self-aware, and they cannot choose a good way to act in a never before experienced situation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know that many people often mention autonomous cars when speaking about AI, but I am not really convinced that these are related. Either I have a too strict understanding of what AI is or &lt;/p&gt;&#xA;" OwnerUserId="2963" LastEditorUserId="42" LastEditDate="2016-10-12T16:48:22.203" LastActivityDate="2017-03-23T09:23:57.097" Title="Why are autonomous cars categorized as AI?" Tags="&lt;self-driving&gt;&lt;strong-ai&gt;&lt;cars&gt;&lt;weak-ai&gt;" AnswerCount="4" CommentCount="0" FavoriteCount="2" />
	<row Id="2129" PostTypeId="2" ParentId="2126" CreationDate="2016-10-12T08:35:47.800" Score="5" Body="&lt;p&gt;There is a neat definition of artificial intelligence, which circumvents the problem of defining &quot;intelligence&quot; and which I would ascribe to &lt;a href=&quot;https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)&quot; rel=&quot;noreferrer&quot;&gt;McCarthy&lt;/a&gt;, the founder of the field, although I can only find it now in &lt;a href=&quot;https://books.google.de/books?id=IY19CAAAQBAJ&amp;amp;pg=PA53&amp;amp;lpg=PA53&amp;amp;dq=that%20we%20would%20call%20intelligent%20if%20it%20were%20done%20by%20a%20human&amp;amp;source=bl&amp;amp;ots=I8O-U1Jx8q&amp;amp;sig=3VfZuVaLYtLGCtUo4uSbOjzrboE&amp;amp;hl=en&amp;amp;sa=X&amp;amp;ved=0ahUKEwjG18Se6tTPAhUE1hoKHUppA88Q6AEIHjAA#v=onepage&amp;amp;q=that%20we%20would%20call%20intelligent%20if%20it%20were%20done%20by%20a%20human&amp;amp;f=false&quot; rel=&quot;noreferrer&quot;&gt;this book&lt;/a&gt; by H. Simon:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&quot;… having to do with finding ways to do intelligent tasks, to do tasks which, if they were done by human beings, would call for our human intelligence.&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So, at its core we call the automation of every task AI, that can only be done by the human mind. At the time people thought that a computer able to play chess would also be intelligent in other ways. When this turned out to be false, the term AI was split into &quot;narrow or weak AI&quot;, i.e. a program able to do one task of the human mind, and &quot;general or strong AI&quot;, a program that can do all the tasks of the human mind. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Self-driving cars are narrow AI. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note, that all these definitions don't specify whether these programs copy the way the human mind works or whether they come to the same result via completely different algorithms. &lt;/p&gt;&#xA;" OwnerUserId="2227" LastActivityDate="2016-10-12T08:35:47.800" CommentCount="2" />
	<row Id="2134" PostTypeId="2" ParentId="2126" CreationDate="2016-10-12T18:42:15.673" Score="0" Body="&lt;p&gt;Self driving cars exhibit a level of agency and multi-domain resilience. By certain definitions they &lt;em&gt;are&lt;/em&gt; self aware and they are definitely designed to fail safely in a large number of potentially unknown circumstances, which is similar to biological agents.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;AI really has to do with the study of non-biological agents and their methods of agency. Everything else is just computer science, algorithmic efficiency, biology, art, etc. Eventually the study of biological and non-biological agency will converge, though, and we'll just call it the study of &quot;intelligence.&quot;&lt;/p&gt;&#xA;" OwnerUserId="1712" LastActivityDate="2016-10-12T18:42:15.673" CommentCount="0" />
	<row Id="3035" PostTypeId="2" ParentId="2126" CreationDate="2017-03-23T04:12:33.810" Score="0" Body="&lt;p&gt;Others have given very detailed answers, this is my layman view of the problem statement. The self driving car is a 'goal seeking' machine. It has a set of goals with different priorities. Example. Safety of Occupants, Safety of others, Go from Point A to Point B etc. Some are negotiable, other not so.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To satisfy the goals, the system should use the inputs available (radar, GPS, Camera etc) to determine what is the best possible course of action. At times when it doesn't have all the info (a truck which is hiding a speed sign), it still has to take a decision (historic memory or through awareness of its surroundings) to satisfy its design goals. Hence the AI.&lt;/p&gt;&#xA;" OwnerUserId="6173" LastActivityDate="2017-03-23T04:12:33.810" CommentCount="0" />
  	<row Id="3036" PostTypeId="2" ParentId="2126" CreationDate="2017-03-23T09:23:57.097" Score="2" Body="&lt;p&gt;Other answers tell about sets of instructions for the car in certain situations, or a goal seeking machine, while in fact, self-driving cars don't have a specific set of instructions. Most self-driving cars use deep learning to figure out what to do at certain events. We don't tell them what to do. They learn what to do by example.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The neural networks used to automate cars need massive amounts of data to train. Using the data, the car can figure out what the best action is for certain events. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;According to &lt;a href=&quot;https://youtu.be/U1toUkZw6VI?t=2431&quot; rel=&quot;nofollow noreferrer&quot;&gt;this video&lt;/a&gt; Tesla's Autopilot had only &lt;strong&gt;one&lt;/strong&gt; casualty in 300.000.000 miles. For human drivers, the number of casualties in 2014 was 32.675. That is per 300.000.000.000 miles. That means 1 in 90 million human drivers cause a fatal accident, compared to 1 in 300 million for automated cars. Deep Learning surpassed our own 'safety-rate', not by instruction, but by learning what to do itself. If that isn't AI, I don't know what is. &lt;/p&gt;&#xA;" OwnerUserId="6200" LastActivityDate="2017-03-23T09:23:57.097" CommentCount="0" />
  	<row Id="8319" PostTypeId="2" ParentId="2126" CreationDate="2018-10-09T01:52:15.453" Score="0" Body="&lt;p&gt;Autonomous vehicles are dependent upon AI technology in that, to be autonomous in their driving or piloting, they cannot be controlled by people.  Therefore they must make complex decisions required of drivers and pilots at least as safely and reliably as human drivers or pilots.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They must recognize objects to the degree that both the value and the typical behavior can be assigned to those objects (i.e. people, pets, property, barriers, curbs, grass, trees, bridges)&lt;/li&gt;&#xA;&lt;li&gt;They must map trajectories of a wide array of object types based on their object type, what is known about that type of object, detectable variations such as age or condition, and what the object appears to be involved in doing at the time.&lt;/li&gt;&#xA;&lt;li&gt;They must be able to acquire publicly available representations of drive-able roads (route segments, connection points, and other data), match the representation with the current state of the roads, and track their progress along an intended route to the destination.&lt;/li&gt;&#xA;&lt;li&gt;They must plan their course in lieu of these real time and difficult to predict actions, traffic law, traffic conventions, traffic signs and signals, given destination, known possible routes, discontinuities, and anomalies.&lt;/li&gt;&#xA;&lt;li&gt;They must be able to alter the plan to reach the destination if at all possible regardless of changes and challenges encountered.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Driving or piloting a vehicle is an intelligence intensive task.  The only reason AVs will likely surpass human driven vehicles on the road in the near future in terms of the distributions of rates of fatalities and injuries per million meter of travel in the near future is because humans have two key handicaps that offset their intelligence potential as drivers.  &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Carelessness, as defined as multitasking either mentally or physically at a time when hazards might appear&lt;/li&gt;&#xA;&lt;li&gt;Selfishness, as defined as risking the life, health, or property of others to gain a transportation related or psychologically related advantage&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Although the above two appear to be subjective, they can be easily proven empirically by taking a sample of traffic patterns at any point in time in any highly trafficked road in the world.  This is less true of pilots.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We should not presume that artificial intelligence in AVs is achieved when the behavior of the human mind is copied.  That is the criteria for Alan Turing's Imitation Game, a test that was intended to define intelligence in the context of natural language dialog.  But words don't normally kill people directly.  Vehicles often do.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It would be a very limited vision the potential AV design space to consider human minds as the model of driving excellence.  The tasks should not be performed in the same way by the AI system.  The AI design objectives of AVs should be more consistent with these concerns and interests.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Road or sky safety laws&lt;/li&gt;&#xA;&lt;li&gt;Ethics regarding right of way in normal and emergency situations&lt;/li&gt;&#xA;&lt;li&gt;Civil rights concerns in terms of equal access to public resources&lt;/li&gt;&#xA;&lt;li&gt;Balancing of spacial flow details to maximize transportation throughput&lt;/li&gt;&#xA;&lt;li&gt;Collision aversion when difficult to predict risks emerge&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;These requirements on the cognitive and adaptive capabilities of the driving or piloting AI are not solely rule-based and mechanical.  The vehicle itself is mostly mechanical in its operation, but it too presents surprises like blowouts or other difficult to predict failures.  Vehicle control is not at all like chess or a game with a fixed rules of play and fixed game-play environment.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Although the intelligence requirements do NOT include self-awareness of itself as an intelligent system, there are forms of self-awareness required.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The relative position of the exterior surface of the vehicle and its projected path relative to that of other objects&lt;/li&gt;&#xA;&lt;li&gt;The condition of the operational parts of the vehicle&lt;/li&gt;&#xA;&lt;li&gt;The mass and location of passengers and any other transported objects in the vehicle&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The question ended with an interesting and challenging requirement.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Choose a good way to act in a never before experienced situation&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;That is perhaps the most challenging aspect of AV driving or piloting system design.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Returning to the question of, &quot;Why are autonomous cars categorized as AI?&quot;, the meaning of AI is indeed a critical aspect of answering well.  Taken literally, the term artificial intelligence specifies two things.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It is artificial, in that it does not naturally occur in nature&lt;/li&gt;&#xA;&lt;li&gt;It is intelligent, in that it adapts in ways that, if those ways are mechanical, they are mechanical at a level of detail that is beyond obviousness without considerable study&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;As year dependent and culturally dependent as that definition of intelligence is, no other definition is quite as sustainable over decades from both scientific and linguistic perspectives.  By narrower definitions, AVs may not require AI, but there is no compelling scientific reason to narrow the definition of AI to a subset of this previous definition.&lt;/p&gt;&#xA;" OwnerUserId="4302" LastActivityDate="2018-10-09T01:52:15.453" CommentCount="0" />
	<row Id="2127" PostTypeId="1" CreationDate="2016-10-12T07:40:44.907" Score="8" ViewCount="568" Body="&lt;p&gt;What are the advantages of having self-driving cars?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We will be able to have more cars in the traffic at the same time, but won't it also make more people choose to use the cars, so both the traffic and the public health will actually become worse?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are we really interested in this?&lt;/p&gt;&#xA;" OwnerUserId="2963" LastActivityDate="2016-12-12T09:51:11.747" Title="Advantages of having self-driving cars" Tags="&lt;research&gt;&lt;self-driving&gt;&lt;cars&gt;" AnswerCount="8" CommentCount="0" FavoriteCount="2" />
	<row Id="2128" PostTypeId="2" ParentId="2127" CreationDate="2016-10-12T08:16:04.947" Score="11" Body="&lt;p&gt;One of the main arguments for self-driving cars is that presumably they'll get better and better at driving as the technology progresses, they have no temporal attention deficits or aggressive urges or drug habits and sense their environment 360°, all the while communicating with the other cars, which all together basically amounts to LESS DEAD PEOPLE. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;We are really interested in this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is also unclear whether most people will actually own cars in 30 years. Maybe there'll be a net of mini busses with flexible routes which take you from door to door on demand. That would reduce traffic quite a bit and there would also be less incentive to drive 200 m to get cigarettes or something. Self-driving cars would allow us to use the car as a resource a lot more efficiently, because suddenly we can relocate empty cars without paying a driver.  &lt;/p&gt;&#xA;" OwnerUserId="2227" LastActivityDate="2016-10-12T08:16:04.947" CommentCount="0" />
	<row Id="2146" PostTypeId="2" ParentId="2127" CreationDate="2016-10-13T21:35:12.593" Score="1" Body="&lt;p&gt;Safety is often put in focus by journalists. Although there is potential to make the roads safer, I don't think that is the driving force behind the push for self-driving cars. The main advantage of self-driving cars is that this will reduce costs for businesses, while increasing efficiency (both fuel and time). From the perspective of the public, the self-driving cars are attractive, because they will turn the task of driving, into commute. Activity that requires attention will be replaced with somewhat free time.&lt;/p&gt;&#xA;" OwnerUserId="2997" LastActivityDate="2016-10-13T21:35:12.593" CommentCount="0" />
	<row Id="2167" PostTypeId="2" ParentId="2127" CreationDate="2016-10-16T11:45:03.207" Score="3" Body="&lt;p&gt;If they are able to network, then they can notify the car behind that it is about to break. In this way they can drive closer together at high speeds. As soon as one puts on the breaks, all the cars behind would apply the breaks. They would not require the 2 seconds that it takes for a human to respond.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Children could be dropped at school or the train station automatically.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;People would not need to park a car; it could drop them at work and drive away.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Taxis would probably become more viable than private car ownership.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Car theft might be more difficult.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where I live, public transport is hardly viable because the government struggles to provide enough parking spaces at train stations and bus stops. The closest empty parking spot by 8:30am is 30minuets walk to the platform. Driverless cars would solve this problem, and Traveling by train would actually become viable for me.&lt;/p&gt;&#xA;" OwnerUserId="2983" LastActivityDate="2016-10-16T11:45:03.207" CommentCount="0" />
	<row Id="2178" PostTypeId="2" ParentId="2127" CreationDate="2016-10-18T18:22:41.927" Score="4" Body="&lt;p&gt;Why are self-driving cars awesome?&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Safety: better awareness (due to more sensors), better reaction time, fewer distracted/injured/drunk/texting drivers on the road, etc&lt;/li&gt;&#xA;&lt;li&gt;Convenience: pick up my kids from school, park itself at the grocery store, take itself to be serviced, etc&lt;/li&gt;&#xA;&lt;li&gt;Faster transit: with increased safety, you can increase speed limits, with proper routing algorithms you don't need traffic lights and stop signs any more (when you have dedicated self-driving lanes &amp;amp; intersections)&lt;/li&gt;&#xA;&lt;li&gt;Comfort: recline, read, game, or snooze while traveling (yay!)&lt;/li&gt;&#xA;&lt;li&gt;Cost: subsidize the cost of the vehicle using ads (e.g. projected onto the windshield)&lt;/li&gt;&#xA;&lt;li&gt;etc&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="3107" LastActivityDate="2016-10-18T18:22:41.927" CommentCount="0" />
	<row Id="2230" PostTypeId="2" ParentId="2127" CreationDate="2016-10-28T11:29:45.403" Score="4" Body="&lt;p&gt;I'd like to add, self-driving cars would also be excellent for disabled people who would otherwise not be able to drive. Adds a lot more autonomy to vulnerable people&lt;/p&gt;&#xA;" OwnerDisplayName="user3313" LastActivityDate="2016-10-28T11:29:45.403" CommentCount="0" />
	<row Id="2254" PostTypeId="2" ParentId="2127" CreationDate="2016-11-03T11:22:49.013" Score="8" Body="&lt;p&gt;There are multiple motivations for self driving cars.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;ol&gt;&#xA;  &lt;li&gt;Self driving cars have the potential to be much safer.&lt;/li&gt;&#xA;  &lt;/ol&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Self driving cars are far more reliable than humans and can learn and have their software improved and upgraded, resulting in safer roads and far fewer accidents.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;More on self-driving car safety: &lt;a href=&quot;http://bigthink.com/ideafeed/googles-self-driving-car-is-ridiculously-safe&quot; rel=&quot;nofollow noreferrer&quot;&gt;http://bigthink.com/ideafeed/googles-self-driving-car-is-ridiculously-safe&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;ol start=&quot;2&quot;&gt;&#xA;  &lt;li&gt;Self driving cars can lead to greater road efficiency.&lt;/li&gt;&#xA;  &lt;/ol&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Traffic jams and obstructions occur due to inefficiencies in human driving, see this MIT simulation of a &lt;strong&gt;&quot;phantom traffic jam&quot;&lt;/strong&gt;: &lt;a href=&quot;https://www.youtube.com/watch?v=Q78Kb4uLAdA&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://www.youtube.com/watch?v=Q78Kb4uLAdA&lt;/a&gt; and self driving cars can be programmed to avoid this.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/H3S0G.jpg&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/H3S0G.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;ol start=&quot;3&quot;&gt;&#xA;  &lt;li&gt;Greater economic and environmental benefit&lt;/li&gt;&#xA;  &lt;/ol&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Self driving cars can keep driving costs down by conserving fuel and hence lead to a better environmental impact.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;More on fuel efficiency: &lt;a href=&quot;http://movimentogroup.com/blog/how-self-driving-cars-increase-fuel-efficiency-decrease-waste/&quot; rel=&quot;nofollow noreferrer&quot;&gt;http://movimentogroup.com/blog/how-self-driving-cars-increase-fuel-efficiency-decrease-waste/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;ol start=&quot;4&quot;&gt;&#xA;  &lt;li&gt;Ease of transport&lt;/li&gt;&#xA;  &lt;/ol&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Self driving cars make transport easier and mean that drivers may be unnecessary in the future, resulting in a more pleasurable and easier drive.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/eb7ZC.jpg&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/eb7ZC.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In addition, this would make it easier for people with disabilities to travel as well as simplify the travel experience. Children could potentially be driven to school by a car without the supervision of a parent, for instance.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;ol start=&quot;5&quot;&gt;&#xA;  &lt;li&gt;Parking&lt;/li&gt;&#xA;  &lt;/ol&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Self driving cars can be called to pick you up, meaning the need for parking in nearby locations and/or long walks to find your car may become a thing of the past as your car would drive up to you to pick you up.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;ol start=&quot;6&quot;&gt;&#xA;  &lt;li&gt;Things we haven't even thought of yet :) &lt;/li&gt;&#xA;  &lt;/ol&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="3427" LastEditorUserId="3427" LastEditDate="2016-12-05T18:16:16.683" LastActivityDate="2016-12-05T18:16:16.683" CommentCount="0" />
	<row Id="2460" PostTypeId="2" ParentId="2127" CreationDate="2016-12-11T21:01:57.633" Score="0" Body="&lt;p&gt;I think that one very big advantage would be that if the cars could communicate with each other, they could drive synchronously.&lt;br&gt;&#xA;For example, if there was a traffic light, and, let's say, 10 cars are waiting for it to change to green (let's just assume that there would still be something similar to traffic lights). Then when it changes to green all cars could accelerate at the same speed (depending on the acceleration of the front car) at the same time.&lt;/p&gt;&#xA;" OwnerUserId="4196" LastEditorUserId="145" LastEditDate="2016-12-12T09:51:11.747" LastActivityDate="2016-12-12T09:51:11.747" CommentCount="1" />
	<row Id="2232" PostTypeId="2" ParentId="2127" CreationDate="2016-10-29T08:26:08.497" Score="1" Body="&lt;p&gt;Self driving cars are good for the following reasons:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;In the case of an emergancy, urgancy, or just someone being unable to drive unexpactedly, the car can go by itself to a designated location - this is useful in so many use cases - kids who need to get somewhere while parents are busy, Parents who drank a little too much and prefer to take 'the cab' home, or while running, you got injured and need a pick-up.&lt;/li&gt;&#xA;&lt;li&gt;The examples above are for the more obvious things, which we currently have a struggle with. but other than those, Self-driving cars will open a door for a much wider scale of things: safe police chases (just a car without a police officer), taxies, help in the battle field, and much more...&lt;/li&gt;&#xA;&lt;li&gt;The third and most important benefit, is the safety and economical properties of self driving cars: with a lot of those cars on the road, they can 'understand' each other and nothing will go unpredicted. they have much faster response time then humans, and maybe in the future they will even be able to predict traffic-light changes, and by that save gas and money (even more than what they can save right now by driving economicly)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="3328" LastActivityDate="2016-10-29T08:26:08.497" CommentCount="0" />
	<row Id="3457" PostTypeId="1" AcceptedAnswerId="3466" CreationDate="2017-06-07T18:20:37.757" Score="1" ViewCount="100" Body="&lt;p&gt;What are the ethical and legal issues of self driving cars being released in the UK?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This question came up on our exam today and I was left in a daze.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I initially thought it would be issues like the legal driving age for self driving cars since they are AI do you need a minimum age limit?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another one I thought was whether or not you need driving licenses for AI cars?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Could someone please list all the possible ethical &lt;strong&gt;and&lt;/strong&gt; legal issues that surround AI controlled cars?&lt;/p&gt;&#xA;" OwnerUserId="7756" LastEditorUserId="8" LastEditDate="2017-06-13T19:54:39.130" LastActivityDate="2017-06-13T19:54:39.130" Title="What are the ethical and legal issues of self driving cars being released in the UK?" Tags="&lt;self-driving&gt;&lt;ethics&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
	<row Id="4257" PostTypeId="1" AcceptedAnswerId="4262" CreationDate="2017-10-12T21:46:05.993" Score="1" ViewCount="139" Body="&lt;p&gt;For example...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;1) If a dog is crossing the road, I'd expect the car to try to avoid it. But what if this leads to .00001% more risk for the driver? What is the 'risk cut-off'?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;2) What if a cockroach is crossing the road? Will the car have a list of animals okay to run over?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;3) What if a kid is crossing the street and avoiding it would kill the driver?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;These questions seem to not really have an answer, yet self driving cars are almost ready. What are they doing about all of this?&lt;/p&gt;&#xA;" OwnerUserId="9648" LastActivityDate="2017-10-20T21:26:57.540" Title="How will morality questions be settled in the domain on self-driving cars?" Tags="&lt;ai-design&gt;&lt;self-driving&gt;" AnswerCount="4" CommentCount="7" FavoriteCount="1" />
	<row Id="4262" PostTypeId="2" ParentId="4257" CreationDate="2017-10-13T10:41:26.043" Score="2" Body="&lt;p&gt;As far as i know, there is still a huge debate about this topic. I would say, that the main rule for every self-driving car is to avoid a crash if possible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The question one should always ask is, in what situation would a crash realy happen and would a human react differently?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;My answer is no. The point is, a human might try to avoid the child (3) but it would be out of instinct rather than &quot;consideration&quot;. The driver might even harm others in this situation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since a self-driving car will normally follow the rules a critical situation will most of the time arise due to the other person, not the car. So i believe it is best to protect the driver at all cost.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The dog vs child problem could be solved via advanced animal recognition (human vs no human)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Regarding no (2): Too small = no human ==&gt; car will ignore it.    &lt;/p&gt;&#xA;" OwnerUserId="10171" LastEditorUserId="9647" LastEditDate="2017-10-17T23:46:45.617" LastActivityDate="2017-10-17T23:46:45.617" CommentCount="0" />
	<row Id="4265" PostTypeId="2" ParentId="4257" CreationDate="2017-10-13T19:07:09.020" Score="1" Body="&lt;p&gt;I don't think these questions will need to be answered.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A self driving car will almost certainly avoid a situation like the ones described well before a human would have and hence would not have to choose. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example it would slow down as soon as it sees a child close to the road. It will identify and react to the fact that the child starts moving towards the road and act before the situation requires the &quot;drastic&quot; scenarios that we invent. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;If for some reason the car has to choose, it can also make the impact/avoidance have the highest chance of not killing the occupant of the vehicle considering how well designed cars are these days and that the speeds involved shouldn't be anything wild like 200mph.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Not to mention a network of cars along with street cameras and sensors would act/work together to resolve as a swarm intelligence so the car ahead or the traffic camera can warn/tell other cars that something they cannot see is a potential hazard. I can go on and on...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In my opinion, the bottom line is a self driving car will &lt;em&gt;not&lt;/em&gt; road rage, drive at dangerous speeds in a residential area, get tired and fall asleep, text and drive or drink and drive, etc... I cannot wait.&lt;/p&gt;&#xA;" OwnerUserId="9998" LastEditorUserId="75" LastEditDate="2017-10-13T22:53:44.617" LastActivityDate="2017-10-13T22:53:44.617" CommentCount="0" />
	<row Id="4275" PostTypeId="2" ParentId="4257" CreationDate="2017-10-15T07:35:47.547" Score="0" Body="&lt;p&gt;As others have said, your question is, and will continue to be a hot topic.&#xA;I also agree that eventually self-driving cars will be able to handle your&#xA;hypothetical situations better than many human drivers. I am not prepared to say &#xA;when that &quot;eventually&quot; will eventuate.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, I can also imagine some human drivers deliberately trying to cause &#xA;self-driven cars to make poor decisions. For example, a &quot;team&quot; of three or more&#xA;cars could easily confound a self-driven car's programming by co-ordinating &#xA;their actions, especially once the actual program code used by the car is known.&#xA;I'm thinking of situations where the self-driven car is boxed in by human-driven &#xA;cars which indicate they are about to make a move and then do not, while others&#xA;change speed and direction at the same time, or at slightly different times.&#xA;Humans can be incredibly sneaky and unethical, and some are very good at &#xA;finding exploits and weaknesses.&lt;/p&gt;&#xA;" OwnerUserId="10198" LastActivityDate="2017-10-15T07:35:47.547" CommentCount="5" />
	<row Id="4315" PostTypeId="2" ParentId="4257" CreationDate="2017-10-20T21:26:57.540" Score="2" Body="&lt;p&gt;The core issue with this question rests in probability.  Specifically:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;What if a kid is crossing the street and avoiding it would kill the driver?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;How does the AI know for certain that avoiding it would &lt;em&gt;kill&lt;/em&gt; the driver?  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;and certainty rears its head re:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;1) If a dog is crossing the road, I'd expect the car to try to avoid it. But what if this leads to .00001% more risk for the driver? What is the 'risk cut-off'?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;There would likely be no &quot;hard cutoff&quot;.  Earlier fuzzy logic systems have been implemented in automotive gear shifting and anti-lock breaking, but it is precisely the &quot;fuzziness&quot; that made them effective.  Contemporary AI is far more sophisticated, and part of that sophistication rests in what might be though of as dynamic thresholds for decision-making.  Because certainty only exists in special, limited cases (such as &lt;a href=&quot;https://en.wikipedia.org/wiki/Solved_game&quot; rel=&quot;nofollow noreferrer&quot;&gt;solved games&lt;/a&gt;), estimation must be used. &lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Regarding the cockroach, it would likely be too small to warrant a response, although a swarm of cicadas might affect the car's sensing ability and prompt poor-visibility navigational protocols.  In general I'm sure pet-sized animals and bigger would be avoided, in the case of actual pets for humanitarian reasons, and for animals like deer, for reasons of driver risk (impaled by the horns at the worst, and at the least potentially costly damage to the vehicle.)  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;But I suspect the protocols for this would be breaking or swerving if there is a clear margin on either side of the animal (i.e. not a barrier, wall or cliff) and the direction change is controllable (i.e. hitting the animal is likely to result in less harm than an actual crash, and certainly less risk to the human, except in the case of the deer's horns.) &lt;/p&gt;&#xA;" OwnerUserId="1671" LastActivityDate="2017-10-20T21:26:57.540" CommentCount="0" />
	<row Id="4343" PostTypeId="1" CreationDate="2017-10-24T06:17:26.953" Score="1" ViewCount="51" Body="&lt;p&gt;I have a liberal arts background so I need help understanding &lt;a href=&quot;https://arxiv.org/pdf/1708.09839.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;this paper&lt;/a&gt;, particularly pages 26 to 30. The authors test a four-camera system for localization, mapping, and obstacle detection for self-driving cars. The paper seems to say the multi-camera system can map the environment to within an average of 7 cm (2.8 inches) of accuracy (with the largest error being 16 cm or 6.3) and detect obstacles to within 10 cm (3.9 inches) of accuracy. Am I getting this right?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given that automotive lidar can detect objects to within 1.5 cm (0.6 inches) of accuracy, and given that for driving purposes the difference between 1.5 cm and 7 cm, 10 cm, or 16 cm seems quite small, can a multi-camera system be used instead of lidar in a self-driving car application? How do driving speeds affect things? What crucial elements of the problem space might I be overlooking or misunderstanding?   &lt;/p&gt;&#xA;" OwnerUserId="10350" LastActivityDate="2017-12-25T07:19:49.200" Title="‪Can a multi-camera system be used for localization, mapping, and obstacle detection in self-driving cars to within 10 cm of accuracy? Whither lidar?‬" Tags="&lt;self-driving&gt;" AnswerCount="2" CommentCount="0" />
	<row Id="4764" PostTypeId="1" CreationDate="2017-12-16T16:16:22.330" Score="0" ViewCount="94" Body="&lt;p&gt;As self-driving technology is improving, there are so many companies developing  self-driving cars like Google, Uber, etc. Is it possible that we won't need any private/paid self-driving cars and the &quot;self-driving taxi&quot; becomes ubiquitous in the city? If we assume that there are such taxis everywhere, would transportation become extremely low cost or free? (The self-driving car company could benefit from broadcasting advertisements for advertising agencies.)&lt;/p&gt;&#xA;" OwnerUserId="11621" LastEditorUserId="1671" LastEditDate="2018-01-02T22:42:35.153" LastActivityDate="2018-01-02T22:42:35.153" Title="Could the deployment of self-driving cars make rides free?" Tags="&lt;self-driving&gt;&lt;social&gt;" AnswerCount="2" CommentCount="2" FavoriteCount="2" />
	<row Id="4343" PostTypeId="1" CreationDate="2017-10-24T06:17:26.953" Score="1" ViewCount="93" Body="&lt;p&gt;I have a liberal arts background so I need help understanding &lt;a href=&quot;https://arxiv.org/pdf/1708.09839.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;this paper&lt;/a&gt;, particularly pages 26 to 30. The authors test a four-camera system for localization, mapping, and obstacle detection for self-driving cars. The paper seems to say the multi-camera system can map the environment to within an average of 7 cm (2.8 inches) of accuracy (with the largest error being 16 cm or 6.3) and detect obstacles to within 10 cm (3.9 inches) of accuracy. Am I getting this right?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given that automotive lidar can detect objects to within 1.5 cm (0.6 inches) of accuracy, and given that for driving purposes the difference between 1.5 cm and 7 cm, 10 cm, or 16 cm seems quite small, can a multi-camera system be used instead of lidar in a self-driving car application? How do driving speeds affect things? What crucial elements of the problem space might I be overlooking or misunderstanding?   &lt;/p&gt;&#xA;" OwnerUserId="10350" LastActivityDate="2017-12-25T07:19:49.200" Title="‪Can a multi-camera system be used for localization, mapping, and obstacle detection in self-driving cars to within 10 cm of accuracy? Whither lidar?‬" Tags="&lt;self-driving&gt;" AnswerCount="2" CommentCount="0" />
	<row Id="4349" PostTypeId="2" ParentId="4343" CreationDate="2017-10-24T15:15:40.080" Score="1" Body="&lt;p&gt;Given that a self-driving car is trying to replicate the performance of a two-camera system (or one in a pinch), there is nothing in principal that mandates lidar for a self-driving car.  Lidar is a shortcut, substituting sensor sophistication for image-processing sophistication.  AFAIK &lt;a href=&quot;https://www.youtube.com/watch?v=-96BEoXJMs0&quot; rel=&quot;nofollow noreferrer&quot;&gt;Nvidia's own self-driving vehicle&lt;/a&gt;  doesn't have Lidar.  My personal opinion is that Level 5 self-driving vehicles won't be practical until they have the kind of image-processing sophistication that makes Lidar an unnecessary crutch. &lt;/p&gt;&#xA;" OwnerUserId="2329" LastActivityDate="2017-10-24T15:15:40.080" CommentCount="0" />
	<row Id="4842" PostTypeId="2" ParentId="4343" CreationDate="2017-12-25T07:19:49.200" Score="2" Body="&lt;p&gt;It seems that LIDAR presents a problem for resolving the car's environment at higher speed. While I'm not too familiar with the dynamics of LIDAR I do know that &lt;a href=&quot;https://www.edn.com/design/analog/4442319/Autonomous-automotive-sensors--How-processor-algorithms-get-their-inputs&quot; rel=&quot;nofollow noreferrer&quot;&gt;it's a physical system that relies on sending and receiving laser pulses to various points around the car by way of rotating mirrors&lt;/a&gt;. As speeds increase, it seems &lt;a href=&quot;https://en.wikipedia.org/wiki/Lidar#Autonomous%20vehicles&quot; rel=&quot;nofollow noreferrer&quot;&gt;different arrangements of mirrors and light collectors might have to be used&lt;/a&gt; to maintain a high-resolution image. There's some evidence that &lt;a href=&quot;ftp://ftp.rap.ucar.edu/pub/rgf/velerr.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;Doppler LIDAR (developed in the 1990s) became less accurate with higher velocities.&lt;/a&gt; However, LIDAR is partly preferred over radar because of its higher accuracy even when tracking objects at high speeds - &lt;a href=&quot;https://www.officer.com/on-the-street/article/10250592/lidar-the-speed-enforcement-weapon-of-choice&quot; rel=&quot;nofollow noreferrer&quot;&gt;this is why LIDAR guns are increasingly being used by police instead of radar guns to track speeding vehicles&lt;/a&gt;. It seems natural that a set of high-resolution cameras paired with a well-trained neural network would not be subject to the same physical limitations as LIDAR.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think that an important intuition to consider is that while LIDAR is used to generate clouds of data points whose shapes and patterns can be analyzed by autonomous car software, cameras can pick up non-topograhical features such as road lines, the content of roadsigns, and additional location context such as storefronts and intersection layouts. Considering that these cameras can use pattern recognition and stereoscopy to also generate a 3D topographic map of the environment, it seems plausible that Level 5 self driving cars would not require LIDAR.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://seekingalpha.com/article/4106093-tesla-betting-cameras-full-self-driving&quot; rel=&quot;nofollow noreferrer&quot;&gt;Here's an interesting look at the problem.&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="11787" LastActivityDate="2017-12-25T07:19:49.200" CommentCount="0" />
	<row Id="4764" PostTypeId="1" CreationDate="2017-12-16T16:16:22.330" Score="2" ViewCount="113" Body="&lt;p&gt;As self-driving technology is improving, there are so many companies developing  self-driving cars like Google, Uber, etc. Is it possible that we won't need any private/paid self-driving cars and the &quot;self-driving taxi&quot; becomes ubiquitous in the city? If we assume that there are such taxis everywhere, would transportation become extremely low cost or free? (The self-driving car company could benefit from broadcasting advertisements for advertising agencies.)&lt;/p&gt;&#xA;" OwnerUserId="11621" LastEditorUserId="1671" LastEditDate="2018-01-02T22:42:35.153" LastActivityDate="2018-10-19T02:45:03.577" Title="Could the deployment of self-driving cars make rides free?" Tags="&lt;self-driving&gt;&lt;social&gt;" AnswerCount="3" CommentCount="0" FavoriteCount="2" />
	<row Id="4772" PostTypeId="2" ParentId="4764" CreationDate="2017-12-17T16:22:16.920" Score="3" Body="&lt;p&gt;You ask an interesting question.  There have been many discussions by industry on this topic.  A company called &lt;a href=&quot;https://govugo.com/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Vugo&lt;/a&gt; has their business model based on advertising to passengers.  An article about Vugo, &lt;a href=&quot;http://tcbmag.com/news/articles/2017/november/the-quest-to-make-ridesharing-free&quot; rel=&quot;nofollow noreferrer&quot;&gt;&quot;The Quest to Make Ridesharing Free&quot;&lt;/a&gt;, states:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Flessner is co-founder and CEO of Minneapolis-based rideshare advertising platform Vugo, which uses its patented TripIntent technology to display targeted advertisements to Uber and Lyft passengers on a tablet attached to the back of the vehicle’s headrests.&lt;/li&gt;&#xA;&lt;li&gt;The company’s founders predict that within the next few years, all ridesharing vehicles in the U.S. will be driverless, and in-vehicle advertising tailored to passengers’ destinations and interests will lead to free transportation. “The idea is to put brands in front of passengers who are en route to make purchases,” says Flessner. For example, retailers will sponsor transportation to their stores so they can preview products to customers who are headed their way.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;This article &lt;a href=&quot;http://money.cnn.com/2017/09/01/technology/future/free-transportation-self-driving-cars/index.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;&quot;How free self-driving car rides could change everything&quot;&lt;/a&gt; makes these comments:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Car data is so lucrative that Ben Volkow -- CEO of otonomo, an Israeli startup that sells vehicle data -- expects automakers to make more money selling data than vehicles by 2020.&lt;/li&gt;&#xA;&lt;li&gt;If the money made off self-driving vehicle data outweighs the costs of offering rides, then it becomes reasonable for a business to offer free rides broadly.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;A paper entitled &lt;a href=&quot;http://scet.berkeley.edu/wp-content/uploads/Report-Leveraging-Adverts-in-the-Coming-Autocar-Ecosystem.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;&quot;Leveraging Adverts in the Coming&#xA;Autonomous Car Eco-system&quot;&lt;/a&gt; published by Berkeley, University of California, proposes &quot;a world where rideshares are free, or in some cases, heavily subsidized through the use of advertisements&quot;.&lt;/p&gt;&#xA;" OwnerUserId="5763" LastEditorUserId="5763" LastEditDate="2017-12-17T16:29:44.873" LastActivityDate="2017-12-17T16:29:44.873" CommentCount="1" />
  	<row Id="4773" PostTypeId="2" ParentId="4764" CreationDate="2017-12-17T21:23:13.500" Score="2" Body="&lt;p&gt;Oil prices are not cheap, but online advertisement per impression is relatively cheap. Especially given that there isn't much engagement in a taxi, its hard to imagine that ads alone can fully support a taxi service.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From &lt;a href=&quot;http://www.pennapowers.com/how-much-do-ads-on-youtube-cost/&quot; rel=&quot;nofollow noreferrer&quot;&gt;this source&lt;/a&gt;, we find CPM for a youtube video about 0.1$:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But keep in mind this value could be lower since user engagement in a taxi is much lower compared to someone on the internet. With smartphones everywhere, how can you entice someone to watch an ad on a moving taxi?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From &lt;a href=&quot;https://www.investopedia.com/articles/personal-finance/021015/uber-versus-yellow-cabs-new-york-city.asp.&quot; rel=&quot;nofollow noreferrer&quot;&gt;this source&lt;/a&gt;, we see:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;For a 5-mile, 10-minute trip going 25 miles per hour the entire way, uberX would cost the $2.55 base fare plus $3.50 for the 10 minutes plus $10.75 for the mileage, for a total of $16.80. It is not customary to tip the Uber driver.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;No matter how you cut it, the margins seems to be quite thin. So free taxis seems unlikely for now unless someone comes up with a different business plan. &lt;/p&gt;&#xA;" OwnerUserId="6779" LastActivityDate="2017-12-17T21:23:13.500" CommentCount="1" />
	<row Id="4769" PostTypeId="1" AcceptedAnswerId="4771" CreationDate="2017-12-17T04:44:32.630" Score="3" ViewCount="108" Body="&lt;p&gt;Providing that&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;more and more decisions about human life are (to be) decided by machine (like access to loans, housing, scholarship, jobs, healthcare, insurance, etc.)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;at the same time, in many countries there are laws and codes of conduct against (negative/positive) discrimination&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Does there any industrial-accepted way to examine the AI system its legal compliance? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I believed that ACM/IEEE software engineer professional code of conduct can be applied here, but also like to learn more about auditing process from examiner side as well, if there's any.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thank you. &lt;/p&gt;&#xA;" OwnerUserId="11535" LastEditorUserId="11535" LastEditDate="2017-12-17T05:17:45.823" LastActivityDate="2018-03-15T21:21:07.203" Title="Legal compliance and AI auditing framework" Tags="&lt;ai-design&gt;&lt;algorithm&gt;&lt;self-driving&gt;&lt;ethics&gt;&lt;ai-safety&gt;" AnswerCount="3" CommentCount="1" FavoriteCount="1" />
	<row Id="5337" PostTypeId="2" ParentId="4769" CreationDate="2018-02-16T11:46:33.847" Score="3" Body="&lt;p&gt;Understanding how an algorithm works can be realized with two possibilities. At first, with Opensource software. That is a well known method and prevents proprietary non-documented code. Opensource software alone doesn't solve the problem, as seen by @k.c. sayz 'k.c sayz' correctly. For example, if we are implementing a neural network as opensource, it remains a blackbox which is not predictable, especially for non-experts.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The shared language between legal laws and engineering capabilities is the natural language, especially English. So the engineers have to create their system in a way, that it communicates with the world in normal English. That means not, that the car speaks like K.I.T.T., it means only that the interface for controlling the car has commands like “start”, “stop” and “drive slower”. If the car detects with his neural network a pedestrian, than it should print out on the console a simple “pedestrian detected”. That seems natural, but most programs today printing out “memoryadress $3400 = -65” or “sigmoid activation function is set to sin(4-x)”.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In a potential law case it makes sense to cite status-messages of the onboard computer. Because if they are written in normal English, lawyers will understand it. How the natural language output was produced is in the scope of the engineers and is only a detail question.&lt;/p&gt;&#xA;" OwnerUserId="11571" LastActivityDate="2018-02-16T11:46:33.847" CommentCount="1" />
	<row Id="5041" PostTypeId="1" CreationDate="2018-01-17T11:53:21.057" Score="4" ViewCount="149" Body="&lt;p&gt;Many of the architectures that do semantic segmentation like SegNet, DilatedNet (Yu and Koltun), DeepLab, etc. do not work on high resolution images. For such benchmarks like &lt;a href=&quot;https://www.cityscapes-dataset.com/benchmarks/#pixel-level-results&quot; rel=&quot;nofollow noreferrer&quot;&gt;Cityscapes&lt;/a&gt;, what is a standard/practical approach for such methods to perform on the benchmark?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've tried to look into the paper, but I couldn't find such details. There's an &lt;a href=&quot;http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review&quot; rel=&quot;nofollow noreferrer&quot;&gt;article&lt;/a&gt; mentioning that they output at 1/8 of input images than do interpolation (usually 2, 4 or 8 times) from their results, but the article does not specify which upsampling techniques are the most reasonable one.&lt;/p&gt;&#xA;" OwnerUserId="3098" LastEditorUserId="3098" LastEditDate="2018-01-17T12:03:30.943" LastActivityDate="2018-05-28T03:56:36.300" Title="Semantic Segmentation how to upsampling" Tags="&lt;deep-learning&gt;&lt;self-driving&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="6218" PostTypeId="1" AcceptedAnswerId="6220" CreationDate="2018-05-01T05:13:30.430" Score="0" ViewCount="39" Body="&lt;p&gt;I can't find much information on modern PDDL usage. Are there more popular alternatives, maybe something more suited to modern neural network/deep learning techniques?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I'm particularly interested in PDDL or alternative's current usage in autonomous driving software.&lt;/p&gt;&#xA;" OwnerUserId="15343" LastActivityDate="2018-05-01T08:27:42.477" Title="How is PDDL used in production AI systems?" Tags="&lt;self-driving&gt;&lt;path-planning&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="6220" PostTypeId="2" ParentId="6218" CreationDate="2018-05-01T08:27:42.477" Score="0" Body="&lt;p&gt;I have seen it used in automated story-telling (or game AI to control NPCs), and in NLG systems, where the generation of text is reinterpreted as a planning task.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What these systems have in common is that they're either off-line or in a simple environment (NPC control). I'm not sure they would be suitable for real-time applications, unless you can be sure that a feasible plan exists which can be found within certain time bounds. I wouldn't want to sit in a car going at high speed on the motorway and waiting for the driving unit to work out a plan how to avoid an obstacle that suddenly appears on the road.&lt;/p&gt;&#xA;" OwnerUserId="2193" LastActivityDate="2018-05-01T08:27:42.477" CommentCount="0" />
	<row Id="6460" PostTypeId="1" CreationDate="2018-05-18T23:20:52.177" Score="4" ViewCount="63" Body="&lt;p&gt;I remember the first time hearing about google trying to make driverless cars.  That was YEARS ago!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;These days, I'm beginning to learn about Neural Nets and other types of ML and I was wondering:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does anybody know how many hours (or days, months, etch) is needed in training time to get the results that are now used in today's self-driving vehicles?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(I am ASSUMING they use Neural networks for this...)&lt;/p&gt;&#xA;" OwnerUserId="15733" LastActivityDate="2018-08-17T20:55:53.717" Title="How long has it taken for autonomous driving cars to be being sold and used on the roads today?" Tags="&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;training&gt;&lt;self-driving&gt;" AnswerCount="2" CommentCount="0" FavoriteCount="2" />
	<row Id="7619" PostTypeId="2" ParentId="6460" CreationDate="2018-08-17T20:55:53.717" Score="0" Body="&lt;p&gt;Building self-driving cars is surprisingly easy. The question is not if in 10 years or in 50 years the technology is high enough developed. Because waiting alone will not solve any technical problems. Instead the question is more how many “man years” have to be invested until the car reaches Level 2, Level 3 or whatever goal is needed.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In a short notice from the Darpa Urban challenge a concrete amount was given:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;“With [...] less than two man-years of software development time,&#xA;  [...] the team still managed to place roughly in the middle of the&#xA;  pack pitted against the competitive field.”&#xA;  &lt;a href=&quot;https://www.perronerobotics.com/darpa-urban-challenge/&quot; rel=&quot;nofollow noreferrer&quot;&gt;(1)&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;From another team in the DARPA self-driving car challenge it is known, that their software contains of 1 million lines of code. If the average programmer is able to create 10 lines per day, the total amount is 274 “man years” to complete the project. That means, if mankind is only able to let one programmer work on driverless cars, the first prototype will be ready in around 300 years from now.&lt;/p&gt;&#xA;" OwnerUserId="11571" LastActivityDate="2018-08-17T20:55:53.717" CommentCount="0" />
	<row Id="6644" PostTypeId="1" AcceptedAnswerId="6647" CreationDate="2018-06-04T12:21:33.773" Score="5" ViewCount="167" Body="&lt;p&gt;We are doing a research design project on autonomous vehicles and have some questions on AV Levels 4/5; specifically on the roles, impacts and consequences of AV on society, government, users and other stakeholders.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We're currently stuck on this main question:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Q: What functionally, does control look like in AV levels 4 and 5?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, is the whole purpose of a level 4/5 that a user has no input into the control?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Could a driver in AV (level 5) stop in an emergency, or say they want to &quot;take corners harder, speed up, slow down&quot;?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Could I choose to change the equi-distance between my AV and the others around me because I like space?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We're wondering about what functionally, does AV level 4/5 offer a user; and what it looks like?&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Context:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Our remit is within the world of design (design thinking), not specifically technology, or expert system functionality. We're looking at the issue from a design perspective; who does it impact, who are the stakeholders, what are the consequences and impacts. What role does a driver have an in level 5? Could an auto-manufacturer want to give drivers control in level 5? How do emergency services act in these situations? What are the touchpoints to society and whom does it impact and what does it say about the design of AV for the future of society.&lt;/p&gt;&#xA;" OwnerUserId="16051" LastEditorUserId="4302" LastEditDate="2018-09-20T05:51:43.987" LastActivityDate="2018-09-20T05:51:43.987" Title="What functionality, does control look like in autonomous vehicles levels 4 and 5?" Tags="&lt;ai-design&gt;&lt;self-driving&gt;&lt;social&gt;&lt;automation&gt;&lt;autonomous-vehicles&gt;" AnswerCount="2" CommentCount="0" FavoriteCount="1" />
	<row Id="7201" PostTypeId="1" AcceptedAnswerId="7213" CreationDate="2018-07-19T09:53:50.233" Score="3" ViewCount="96" Body="&lt;p&gt;To reach full autonomy in any fully automated device it must finish its task in such a way that human control is unnecessary.  We know when the automation is excellent when there are no manual controls and we call it repair and bring in a specialist if something goes wrong.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Four examples of full automation in existence are.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Appliances&lt;/li&gt;&#xA;&lt;li&gt;Home and mobile computer connectivity&lt;/li&gt;&#xA;&lt;li&gt;Mail sorters&lt;/li&gt;&#xA;&lt;li&gt;Hundred million dollar military drones&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;These four are specifically intelligent in varying degrees.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Process control under household conditions&lt;/li&gt;&#xA;&lt;li&gt;Adapting to new hardware and networking&lt;/li&gt;&#xA;&lt;li&gt;Reading addresses written with poor penmanship and odd fonts&lt;/li&gt;&#xA;&lt;li&gt;Adaptively avoiding detection to reach a reconnaissance vantage point&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;These four are good enough for their markets.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Examples of not being good enough, as indicated by their lack of any substantial market penetration, are these four.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Autonomous vacuum cleaners&lt;/li&gt;&#xA;&lt;li&gt;Autonomous cars (without a driver's seat)&lt;/li&gt;&#xA;&lt;li&gt;Unpiloted private or passenger aircraft&lt;/li&gt;&#xA;&lt;li&gt;Narrowly targeted medical nanites&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The question, &quot;How good is good enough?&quot; is this one:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What is the challenge for researchers and engineers to provide ENOUGH intelligence into these kinds of autonomous vehicles to make them better than current methods in the minds of policy makers and consumers?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Stepping back to look with a scientific eye at what is acceptable, consider how unsatisfactory the existing equivalents of the above four are.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Manual vacuuming misses anywhere from 10% to 90% of the dust depending on the surface, blows microbes into the user's lungs, and produces additional health risk when disposal is required.&lt;/li&gt;&#xA;&lt;li&gt;Human beings drive cars regularly, but they are driving what is technically a piece of heavy equipment in pedestrian situations when tired, drunk, high, while text messaging, or while simply loosing focus.&lt;/li&gt;&#xA;&lt;li&gt;The human resources required to deploy, guide, and land vehicles that have no other obstacles than topographical features and other aircraft is significant and leave open not only human failure but hijacking.&lt;/li&gt;&#xA;&lt;li&gt;Chemotherapy, antibiotics, and other pharmacological interventions often only delay the progress of disease and sometimes produce other negative outcomes of varying scope from symptoms worse than what is being treated to death.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Many things that are manual are like that.  They need to be automated.  Artificial intelligence, especially miniaturized and low cost artificial intelligence, is critical to achieving anything like excellence.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;What makes something intelligent enough.  What specific research and engineering efforts can bring the items that aren't good enough into the realm of consumer demand and supported by policy?&lt;/strong&gt;&lt;/p&gt;&#xA;" OwnerUserId="4302" LastActivityDate="2018-08-18T21:01:03.397" Title="How good is good enough for fully autonomous vehicles?" Tags="&lt;deep-learning&gt;&lt;self-driving&gt;&lt;automation&gt;&lt;marketability&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="3" />
	<row Id="7213" PostTypeId="2" ParentId="7201" CreationDate="2018-07-19T20:32:29.170" Score="3" Body="&lt;p&gt;The ideal answer should be: &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When the algorithm is shown statistically to outperform humans in a given task. &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;However, there does seem to be an emotional component when related to life-or-death scenarios.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have no doubt that robot-vaccums are vastly inferior to good-old-fashioned cleaning, but as a celebrated writer once noted &quot;you can either have clean floors or you can use a mop.&quot;  &lt;em&gt;(i.e. if you want floors that are actually clean, you need to use elbow grease and scrub them;)&lt;/em&gt;  But people rarely die from shoddily cleaned floors and the majority seems to value convenience over all other factors. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;By contrast, the internet goes crazy when there's a single autonomous vehicle fatality, even as a significant subset of humans are driving more erratically due to mobile phones and on-board computer distractions. &lt;em&gt;(I liken it to fear of flying--&lt;a href=&quot;http://fortune.com/2017/07/20/are-airplanes-safer-than-cars/&quot; rel=&quot;nofollow noreferrer&quot;&gt;statistically safer than driving&lt;/a&gt; but humans aren't always strictly rational.)&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Beyond the safety issue, humans are often irrationally selfish--commute in any major city during rush hour and you will notice pervasive &lt;a href=&quot;https://en.wikipedia.org/wiki/Gridlock&quot; rel=&quot;nofollow noreferrer&quot;&gt;grid-locking&lt;/a&gt;.  While gridlock is mostly just an inconvenience, humans often make the same irrationally selfish decisions accelerating into yellow lights, increasing risk of an accident.  Similarly, you often encounter rogue drivers speeding in highway traffic, making unsafe lane changes, regardless of whether it actually saves them any time.  &lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;My sense with self-driving cars is that they will have to exceed humans by a large margin due to our emotional nature, regardless of what the statistics indicate.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;AND, there will be an entrenched, obstinate population of aging drivers who resist the change, even as their own driving becomes more erratic and dangerous.  File under: &lt;em&gt;&quot;You'll get my driver's license when you pry it from my cold, dead hands&quot;.&lt;/em&gt; &lt;/p&gt;&#xA;" OwnerUserId="1671" LastEditorUserId="1671" LastEditDate="2018-07-19T20:53:21.353" LastActivityDate="2018-07-19T20:53:21.353" CommentCount="1" />
	<row Id="7541" PostTypeId="1" AcceptedAnswerId="7812" CreationDate="2018-08-13T07:24:54.763" Score="12" ViewCount="439" Body="&lt;p&gt;I recently heard someone make a statement that when you're designing a self-driving car, you're not building a car but really a computerized driver, so you're trying to model a human mind -- at least the part of the human mind that can drive.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since humans are unpredictable, or rather since their actions depend on so many factors some of which are going to remain unexplained for a long time, how would a self-driving car reflect that, if they do?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A dose of unpredictability could have its uses. If, say, two self-driving cars are in a stuck in a right of way deadlock, it could be good to inject some randomness instead of maybe seeing the same action applied at the same time if the cars run the same system. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;But on the other hand, we know that non-deterministic isn't friends with software development, especially in testing. How would engineers be able to control it and reason about it?&lt;/p&gt;&#xA;" OwnerUserId="17446" LastEditorUserId="17446" LastEditDate="2018-08-13T08:49:03.483" LastActivityDate="2018-09-04T06:20:07.363" Title="Do self-driving cars resort to randomness to make decisions?" Tags="&lt;ai-design&gt;&lt;self-driving&gt;&lt;cars&gt;" AnswerCount="2" CommentCount="7" FavoriteCount="1" />
	<row Id="7542" PostTypeId="2" ParentId="7541" CreationDate="2018-08-13T11:54:58.807" Score="2" Body="&lt;p&gt;Self driving cars apply Reinforcement Learning and Semi-Supervised learning, this allows them to be more suited for situations that developers did not anticipate themselves.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some cars now apply &lt;a href=&quot;https://en.m.wikipedia.org/wiki/Swarm_intelligence&quot; rel=&quot;nofollow noreferrer&quot;&gt;Swarm Intelligence&lt;/a&gt;, where they effectively learn from interactions among themselves, which can also aid in cases of transfer learning.&lt;/p&gt;&#xA;" OwnerUserId="15465" LastEditorUserId="1671" LastEditDate="2018-08-13T20:56:50.950" LastActivityDate="2018-08-13T20:56:50.950" CommentCount="0" />
	<row Id="7812" PostTypeId="2" ParentId="7541" CreationDate="2018-09-04T06:20:07.363" Score="3" Body="&lt;p&gt;&lt;strong&gt;Driving Priorities&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When considering the kind of modeling needed to create reliable and safe autonomous vehicles, the following driving safety and efficacy criteria should be considered, listed in priority with the most important first.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The safety of those inside the vehicle and outside the vehicle&lt;/li&gt;&#xA;&lt;li&gt;Reduction of wear on passengers&lt;/li&gt;&#xA;&lt;li&gt;The safety of property&lt;/li&gt;&#xA;&lt;li&gt;The arrival at the given destination&lt;/li&gt;&#xA;&lt;li&gt;Reduction of wear on the vehicle&lt;/li&gt;&#xA;&lt;li&gt;Thrift in fuel resources&lt;/li&gt;&#xA;&lt;li&gt;Fairness to other vehicles&lt;/li&gt;&#xA;&lt;li&gt;The thrift in time&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;These are ordered in a way that makes civic and global sense, but they are not the priorities exhibited by human drivers.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Copy Humans or Reevaluate and Design from Scratch?&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Whoever said that the goal of autonomous car design is to model the portions of a human mind that can drive should not be designing autonomous cars for actual manufacture.  It is well known that most humans, although they may have heard of the following safety tips, cannot bring them into consciousness with sufficient speed to benefit from them in actual driving arrangements.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When the tires slip sideways, steer into the skid.&lt;/li&gt;&#xA;&lt;li&gt;When a forward skid starts, pump the breaks.&lt;/li&gt;&#xA;&lt;li&gt;If someone is headed tangentially into your car's rear, immediately accelerate and then break.&lt;/li&gt;&#xA;&lt;li&gt;On an on ramp, accelerate to match the speed of the cars in the lane into which you merge, unless there is no space to merge.&lt;/li&gt;&#xA;&lt;li&gt;If you see a patch of ice, steer straight and neither accelerate nor decelerate once you reach it.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Many collisions between locomotives and cars are because a red light causes a line in multiple lanes across the tracks.  Frequently, a person will move onto the railroad tracks to gain one car's length on the other cars.  When others move to make undoing that choice problematic, a serious risk emerges.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As absurd as this behavior is to anyone watching, many deaths occur as a fast traveling 2,000 ton locomotive hits what feels like a dust speck to the train passengers.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Predictability and Adaptability&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Humans are unpredictable, as the question indicates, but although adaptability may be unpredictable, unpredictability may not be adaptive.  It is adaptability that is needed, and it is needed in five main ways.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Adaptive in the moment to surprises&lt;/li&gt;&#xA;&lt;li&gt;Adaptive through general driving experience&lt;/li&gt;&#xA;&lt;li&gt;Adaptive to the specific car&lt;/li&gt;&#xA;&lt;li&gt;Adaptive to passenger expression&lt;/li&gt;&#xA;&lt;li&gt;Adaptive to particular map regions&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;In addition, driving a car is&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Highly mechanical,&lt;/li&gt;&#xA;&lt;li&gt;Visual,&lt;/li&gt;&#xA;&lt;li&gt;Auditory,&lt;/li&gt;&#xA;&lt;li&gt;Plan oriented&lt;/li&gt;&#xA;&lt;li&gt;Geographical, and&lt;/li&gt;&#xA;&lt;li&gt;Preemptive in surprise situations.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Modelling Driving Complexities&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This requires a model or models comprise of several kinds of objects.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Maps&lt;/li&gt;&#xA;&lt;li&gt;The vehicle&lt;/li&gt;&#xA;&lt;li&gt;The passenger intentions&lt;/li&gt;&#xA;&lt;li&gt;Other vehicle&lt;/li&gt;&#xA;&lt;li&gt;Other obstructions&lt;/li&gt;&#xA;&lt;li&gt;Pedestrians&lt;/li&gt;&#xA;&lt;li&gt;Animals&lt;/li&gt;&#xA;&lt;li&gt;Crossings&lt;/li&gt;&#xA;&lt;li&gt;Traffic signals&lt;/li&gt;&#xA;&lt;li&gt;Road signs&lt;/li&gt;&#xA;&lt;li&gt;Road side&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Neither Mystery nor Indeterminance&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Although these models are cognitively approximated in the human brain, how well they are modeled and how effective those models are at reaching something close to a reasonable balance of the above priorities varies from driver to driver, and varies from trip to trip for the same driver.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, as complex as driving is, it is not mysterious.  Each of the above models are easy to consider at a high level in terms of how they interact and what mechanical and probabilistic properties they have.  Detailing these is an enormous task, and making the system work reliably is a significant engineering challenge, in addition to the training question.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Inevitability of Achievement&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Regardless of the complexity, because of the economics involved and the fact that it is largely a problem of mechanics, probability, and pattern recognition, it will be done, and it will eventually be done well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When it is, as unlikely as this sounds to the person who accepts our current culture as permanent, human driving may become illegal in this century in some jurisdictions.  Any traffic analyst can mount heaps of evidence that most humans are ill equipped to drive a machine that weighs a ton at common speeds.  The licensing of unprofessional drivers has only become widely accepted because of public insistence on transportation convenience and comfort and because the workforce economy requires it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Autonomous cars may reflect the best of human capabilities, but they will likely far surpass them because, although the objects in the model are complex, they are largely predictable, with the notable exception of children playing.  AV technology will use the standard solution for this.  The entire scenario can be brought into slow motion to adapt for children playing simply by slowing way down.  AI components that specifically detect children and dogs are likely to emerge soon, if they do not already exist.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Randomness&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Randomness is important in training.  For instance, a race car driver will deliberately create skids of various types to get used to how to control them. In machine learning we see some pseudo random perturbations introduced during training to ensure that the gradient descent process does not get caught in a local minimum but rather is more likely to find a global minimum (optimum).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Deadlock&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The question is correct in stating that, &quot;A dose of unpredictability could have its uses.&quot;  The deadlock scenario is an interesting one, but is unlikely to occur as standards develop.  When four drivers come to a stop sign at the same time, they really don't.  It only seems like they did.  The likelihood that none of them arrived more than a millisecond before the others is astronomically small.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;People will not detect (or even be honest enough) to distinguish these small time differences, so it usually comes to who is most gracious to wave the others on, and there can be some deadlock there too, which can become comical, especially since all of them really wish to get moving.  Autonomous vehicles will extremely rarely encounter a deadlock that is not covered by the rule book the government licensing entity publishes, which can be programmed as driving rules into the system.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On those rare occasions, the vehicles could digitally draw lots, as suggested, which is one place where unpredictability is adaptive.  Doing skid experimentation like a race car driver on Main Street at midnight may be what some drunk teen might do, but that is a form of unpredictability that is not adaptive toward a sensible ordering of the priorities of driving.  Neither would be texting or trying to eat and drive.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Determinism&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Regarding determinism, in the context of the uses discussed, pseudo-random number generation of particular distributions will suffice.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Deadlock release or&lt;/li&gt;&#xA;&lt;li&gt;Training speed-ups and improved reliability when there are local minima that are not the global minimum during optimization,&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Functional tests and unit testing technologies are not only able to handle the testing of components with pseudo-randomness, but they sometimes employ pseudo-randomness to provide better testing coverage.  The key to doing this well is understanding of probability and statistics, and some engineers and AI designers understand it well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Element of Surprise&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Where randomness is most important in AV technology is not in the decision making but in the surprises.  That is the bleeding edge of that engineering work today.  How can one drive safely when a completely new scenario appears in the audio or visual channels?  This is perhaps the place where the diversity of human thought may be best adept, but at highway speeds, it is usually too slow to react in the way we see in movie chase scenes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Correlation Between Risk and Speed&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;This brings up an interesting interaction of risk factors.  It is assumed that higher speeds are more dangerous, the actual mechanics and probability are not that clear cut.  Low speeds produce temporally longer trips and higher traffic densities.  Some forms of accidents are less likely at higher speeds, specifically ones that are related mostly to either traffic density or happenstance.  Other forms are more likely at higher speeds, specifically ones that are related to reaction time and tire friction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;With autonomous vehicles, tire slippage may be more accurately modeled and reaction time may be orders of magnitude faster, so minimum speed limits may be more imposed and upper limits may increase once we get humans out of the driver's seats.&lt;/p&gt;&#xA;" OwnerUserId="9203" LastActivityDate="2018-09-04T06:20:07.363" CommentCount="3" />
	<row Id="7879" PostTypeId="1" CreationDate="2018-09-07T17:14:48.587" Score="3" ViewCount="51" Body="&lt;p&gt;Objects tracking is finding the trajectory of each object in consecutive frames. Human tracking is a subset of object tracking which just considers humans.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I've seen many papers that divide tracking methods into two parts: &#xA;1- Online tracking: Tracker just uses current and previous frames.&#xA;2- Offline tracking: Tracker uses all frames.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;All of them mention that online tracking is suitable for autonomous driving and robotics, but I don't understand this part. What are the applications of object/human tracking in autonomous driving? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do you know some related papers?&lt;/p&gt;&#xA;" OwnerUserId="10051" LastEditorUserId="10051" LastEditDate="2018-09-07T18:46:05.940" LastActivityDate="2018-11-10T12:13:53.190" Title="what are applications of object/human tracking in autonomous cars?" Tags="&lt;computer-vision&gt;&lt;self-driving&gt;&lt;autonomous-vehicles&gt;" AnswerCount="1" CommentCount="7" />
	<row Id="8048" PostTypeId="1" AcceptedAnswerId="8062" CreationDate="2018-09-19T19:01:45.640" Score="3" ViewCount="29" Body="&lt;p&gt;I want to implement Sparse Extended information slam. There is four step to implement it. The algorithm is available in &lt;a href=&quot;https://docs.ufpr.br/~danielsantos/ProbabilisticRobotics.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;Probabilistic Robotics Book&lt;/a&gt; at page 310, Table 12.3.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/1OA52.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/1OA52.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In this algorithm line no:13 is not very clear to me. I have 15 landmarks. So $\mu_t$ will be a vector of (48*1) dimension where (3*1) for pose. Now $H_t^i$ is a matrix whose columns are dynamic as per the algorithm it is (3j-3) and 3j. J is the values of landmarks 1 to 15. Now how could I multiply a dynamic quantity with a  static one. There must be a error that matrix dimension mismatch when implement in matlab.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Please help me to understand the algorithm better. &lt;/p&gt;&#xA;" OwnerUserId="18384" LastActivityDate="2018-09-20T12:19:25.623" Title="SEIF motion update algorithm doubt" Tags="&lt;research&gt;&lt;intelligent-agent&gt;&lt;self-driving&gt;&lt;probabilistic&gt;&lt;robotics&gt;" AnswerCount="1" CommentCount="2" />
	<row Id="8220" PostTypeId="1" AcceptedAnswerId="8266" CreationDate="2018-10-02T11:54:03.637" Score="2" ViewCount="116" Body="&lt;p&gt;I will be undertaking a project over the next year to create a self learning AI to play a racing game, currently the game will be Mario Kart 64.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have a few questions which will hopefully help me get started: &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;What aspects of AI would be most applicable to creating a self learning game AI for a racing game (Q-Learning, NEAT etc)&lt;/li&gt;&#xA;&lt;li&gt;Could a ANN or NEAT that has learned to play Mario Kart 64 be used to learn to play another racing game? &lt;/li&gt;&#xA;&lt;li&gt;What books/material should i read up on to undertake this project? &lt;/li&gt;&#xA;&lt;li&gt;What other considerations should i take throughout this project? &lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Thank you for your help! &lt;/p&gt;&#xA;" OwnerUserId="18209" LastActivityDate="2018-10-05T08:54:33.797" Title="Creating a self learning Mario Kart game AI?" Tags="&lt;neural-networks&gt;&lt;game-ai&gt;&lt;python&gt;&lt;self-driving&gt;&lt;neat&gt;" AnswerCount="2" CommentCount="3" />
	<row Id="8296" PostTypeId="1" CreationDate="2018-10-07T14:48:28.470" Score="4" ViewCount="46" Body="&lt;p&gt;Naturally everyone knows most common advantages of autonomous (not autopilot-controlled) cars, e.g. safety, efficiency, parking, etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But are there any advantages for the law? Normally you only hear about problems like having to change a lot of the legal aspects.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would have thought that there was no hit and run, drunk driving and generally no deliberately caused car accidents.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would be very interested if someone would come up with further advantages.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I hope this is the right page for a question like that. &lt;/p&gt;&#xA;" OwnerUserId="18839" LastActivityDate="2018-11-08T01:02:15.463" Title="Legal advantages of autonomous vehicles" Tags="&lt;self-driving&gt;&lt;legal&gt;&lt;autonomous-vehicles&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="8301" PostTypeId="2" ParentId="8296" CreationDate="2018-10-07T21:30:04.453" Score="0" Body="&lt;p&gt;It is only a matter of time before autonomous vehicles surpass human driven vehicles in terms of passenger and pedestrian safety.  We can expect that some cities and regions in the world will be dominated by AVs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When this occurs to a sufficient degree, it is more than merely probable that the remaining human drivers will be seen as a nuisance, since they cause the greatest proportion of road risk.  People will react two ways to this idea.&lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Fear&lt;/strong&gt;, because the notion speaks of a future drastically different from the last hundred years, the culture of which has been influenced by powerful advertising connecting a person's virility, femininity, or autonomy with their automobiles&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Humor, because it is so obvious to anyone who drives that so many of the other drivers are a nuisance &amp;mdash; Those that are brutally self-honest would see that, at certain times, they themselves are nuisances.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;It is very probable that laws against human driving will eventually start in one or two jurisdictions where critical proportions of well designed AVs on the roads have been reached.  From there it will spread.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It would not be surprising if, in fifty years, when the world population is at least double, vehicular fatalities will have radically decreased because of AVs.  If nothing interferes to stop such a trend, the jurisdictions that continue to permit unregulated driving would be then considered uncivilized and dangerous.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We can imagine travel brochures saying, &quot;Vacation in Ireland, now sidewalk-safe,&quot; because Ireland had passed a law ten years prior to gradually reduce the number of registered vehicles with steering wheels to zero.  Sidewalk safe might not be the term, but some marketing term for AV only roadways will be coined to sell tourists and families.&lt;/p&gt;&#xA;" OwnerUserId="4302" LastEditorUserId="4302" LastEditDate="2018-10-09T00:56:19.247" LastActivityDate="2018-10-09T00:56:19.247" CommentCount="1" />
	<row Id="9189" PostTypeId="1" CreationDate="2018-11-26T19:00:01.253" Score="3" ViewCount="23" Body="&lt;p&gt;I'm doing an EPQ (Extended-Project Qualification) on Artificial Intelligence Bias, and would like to gather some primary data for analysis. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do driver-less cars lead into controversies that are to do with ethics? For example: if the AI had to choose to minimize damage and could not avoid casualties.&lt;/p&gt;&#xA;" OwnerUserId="20057" LastEditorUserId="1847" LastEditDate="2018-11-26T19:46:27.360" LastActivityDate="2018-11-27T00:19:09.213" Title="Does research into driver-less cars cause ethical problems?" Tags="&lt;machine-learning&gt;&lt;self-driving&gt;&lt;ethics&gt;" AnswerCount="1" CommentCount="4" />
	<row Id="9189" PostTypeId="1" CreationDate="2018-11-26T19:00:01.253" Score="3" ViewCount="23" Body="&lt;p&gt;I'm doing an EPQ (Extended-Project Qualification) on Artificial Intelligence Bias, and would like to gather some primary data for analysis. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Do driver-less cars lead into controversies that are to do with ethics? For example: if the AI had to choose to minimize damage and could not avoid casualties.&lt;/p&gt;&#xA;" OwnerUserId="20057" LastEditorUserId="1847" LastEditDate="2018-11-26T19:46:27.360" LastActivityDate="2018-11-27T00:19:09.213" Title="Does research into driver-less cars cause ethical problems?" Tags="&lt;machine-learning&gt;&lt;self-driving&gt;&lt;ethics&gt;" AnswerCount="1" CommentCount="4" />
	<row Id="9193" PostTypeId="2" ParentId="9189" CreationDate="2018-11-27T00:19:09.213" Score="1" Body="&lt;p&gt;&lt;strong&gt;Ethics of Research Into AVs&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Research that does not, in the course of lab operations, harm people in any stage of development or mammals used in lieu of people, rarely present prohibitive ethical conflicts.  Whether a perception of possible ethical conflict limits funding and presents marketing and public relations challenges to those who sell the products of engineering using the research output is a different question.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Productization Challenges&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Initial safety metrics and the media play of accidents that must inevitably occur and how these indicators compare with human driving metrics will have much to do with early perceptions.  The automotive industry and new entries into it are aware of this.  That automotive products are such a ubiquitous part of modern life both raises the stakes in terms of profitability and will increase the visibility of the transition.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Driving Ethics Defined by Law&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Statutes and case law have already clarified the ethical expectations of the public regarding safety priorities.  Early public discussions about public safety and the introduction of automated vehicle AI shows no significant conflict between the straightforward application of existing law and public expectations of full driving automation safety.  Saving lives comes before saving people from non-fatal injury, which comes before saving pets and property.  The trailing priorities are saving time, saving fuel, and saving wear on the vehicle itself.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A search on this AI site using the tags associated with AVs, self-driving, and ethics will reveal much more on this topic that is unnecessary to duplicate here. Also a basic search for the word VEHICLE reveals a number of good postings.  As an example, this question could use a few answers, but the question in some ways addresses this question: &lt;a href=&quot;https://ai.stackexchange.com/questions/8631/recognition-and-response-generalizations-for-autonomous-vehicles-or-not&quot;&gt;Recognition and Response Generalizations for Autonomous Vehicles or Not?&lt;/a&gt;.  This question has some of the best discussion on priority in situational ethics in AVs: &lt;a href=&quot;https://ai.stackexchange.com/questions/4148/how-would-ai-prioritize-situational-ethics/8816#8816&quot;&gt;How would AI prioritize situational ethics?&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The key to analyzing the ethics of the driving process itself is statistical comparison.  AVs will not likely be accepted well by the public or by government unless the accident rates reflect AV safety advantages.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One metric that should be primary is the percentage of fatalities among all reported accidents as a function of what percentage of the drivers were computers.  Whether legislators and regulators will pick up on the importance of this specific metric remains to be seen.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If statistically proven safer in terms of fatality and injury metrics, then it would be unethical to let people continue to drive cars.  Who would dare oppose measures that save human lives, including pedestrians, children walking to school, and the elderly and disabled?  This nearly inescapable reality is the foreshadow of a likely future legal paradigm shift.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Normal Resistance to Change&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The word I hear most often about fully automated vehicles is the word, &quot;Creepy.&quot; Sometimes I must explain to those not up on the AV technology that a fully automated vehicle is like a quiet limo driver, responding appropriately to the specification of a destination and commands to stop and go, possibly asking for clarification on occasion.  That they then respond with, &quot;That's creepy,&quot; is not surprising.  The modern world is increasingly emotionally and economically entrenched in daily driving.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It is important, when considering market acceptance, to notice that the word, &quot;Creepy,&quot; is also used for people who are considered potential serial killers, rapists, abductors, vampires, and other fictitious or real types that stalk and either kill or otherwise destroy the psyche of people.  Interestingly, being spooked by the suggestion of cars without human drivers is the same response, adjusting for changes in common linguistic expression, as upon the initial introductions of a long list of other technological advancements.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;From scribes to printing presses&lt;/li&gt;&#xA;&lt;li&gt;From staying clear of the deep ocean to circumnavigation&lt;/li&gt;&#xA;&lt;li&gt;From kerosene to electric lighting&lt;/li&gt;&#xA;&lt;li&gt;From bird watching to human flight&lt;/li&gt;&#xA;&lt;li&gt;From sail power to steam power&lt;/li&gt;&#xA;&lt;li&gt;From horses to cars&lt;/li&gt;&#xA;&lt;li&gt;From tellers to ATMs&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Automated home product store cashiers and automated check depositing at banks are still in the midst of a slow and reserved acceptance curve.  Yet there are more articles being written and uploaded each day about online social network addiction than there are about heroin addiction.  People graduate with degrees in English Lit and find ways to get onto software engineering teams so they can afford a house, and intercontinental sex involving three of the five senses is on the rise.  In general, postmodern people in most economic and education levels worldwide are almost risk-oblivious toward most technology changes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Looking Back from a Possible Future&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another ethical question may appear in hindsight in another century.  Those future people may read about the driving conditions of today and wonder how nineteenth century people decided to ignore the ethical considerations of allowing unqualified and often highly distracted people to drive heavy equipment.  (That is a culture-bias-free description of what much current car and truck driving is.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When the transition from horses to cars began, cars were relatively slow.  Still, people saw that cars could run over children and the elderly whereas a healthy horse would not.  The genes of the horse that would trample a child had been eliminated by putting down horses that trampled children over a period of thousands of years.  So in historical context, it may later become an ethical problem to continue to let humans drive cars.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ethics in All Technology Introductions&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The introduction in technology generally creates jobs and eliminates others. What the net effect is depends on the technology.  Brewing beer created many jobs and displaced a very few wine makers, producing a net improvement in employment opportunity.  Farm automation displaced many small farmers and created very few equipment operation and repair jobs in comparison.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The displacement of professional drivers may be an ethical problem.  Whether some private car owner lets their car drive them to the store or yoga class is not challenging any ethical standards, except for the ethical perspectives of Ludites, Amish, technophobes, and other fringe groups.  However, buses and trucks lack some of the frequency of challenging choices that cars, trucks, recreational vehicles, and minivans have.  The probability distributions for lane transitions, cruising speed, acceleration, stopping deceleration, stopping conditions, turns, route deviations, and signalling are narrower.  They are much more likely to be fully automated first, and those drivers have no lateral moves within those transportation companies.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Since both licenses and registrations would be held by the same entity, the AV itself, motor vehicle department workers will be displaced.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Although not entirely displaced, some businesses and careers would likely be negatively impacted.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Personal injury lawyers and legal teams&lt;/li&gt;&#xA;&lt;li&gt;Insurance carriers, agents, and administrative organizations that handle a large number of automotive policies and claims&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Ethical Considerations Other Than Employment&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A number of systems that are based on universal social standards related to cars will likely resist change to computer driving and may launch campaigns opposing the public relations campaigns launched by those introducing AV products.  Such opposition would likely use mechanisms to build apprehension about possible collapses of social infrastructure.  There are several groups that benefit from human driving.  Most of them are the personnel and systems that use driver's licenses as a primary tool to support law enforcement and investigative work.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Acceptance and Public Relations&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Convincing people may be about clever marketing.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;If you saw all the crazy driving in my city, you wouldn't be quibbling over removing steering wheels.&lt;/li&gt;&#xA;&lt;li&gt;Keep teens safe.&lt;/li&gt;&#xA;&lt;li&gt;What's the real objective?  Driving or getting there?&lt;/li&gt;&#xA;&lt;li&gt;AVs save fuel.&lt;/li&gt;&#xA;&lt;li&gt;Even fewer accidents with the Honda Driver-free Autobot&lt;/li&gt;&#xA;&lt;li&gt;Like having a limousine service in your garage&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;One of the greatest feats of marketing and public relations is the construction of the idea of personal transportation.  Betting that automotive manufacturers can overcome the initial sense of creepiness and sell the new AI infused products is not exactly a bet for fools.  Consider their current achievements.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A large percentage of families in nearly every income bracket with one personal vehicle per adult family member&lt;/li&gt;&#xA;&lt;li&gt;People spending 20% of their annual income solely to own the latest trending body aesthetics and dashboard features&lt;/li&gt;&#xA;&lt;li&gt;Commuting through hordes of traffic to get to a cubicle containing a computer no more powerful than their home computer and sitting on the same Internet&lt;/li&gt;&#xA;&lt;li&gt;People selecting their life long partners on the basis of the car or truck that person owns&lt;/li&gt;&#xA;&lt;li&gt;The assembly of a sustainable and unconscious social force to buy a new car every two or three years when fully restoring the current one would require less than a quarter the expense&lt;/li&gt;&#xA;&lt;li&gt;People, based on an association between mechanical power and social dominance, maximally accelerating to just over the speed limit merely to stop at the next light in an only slightly different order, modifying their arrival time by only two or three seconds in exchange for unnecessary mechanical wear and burned fuel&lt;/li&gt;&#xA;&lt;li&gt;The creation of a global economy as dependent upon cars as the availability of air or water&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;The automotive industry even surpasses the fashion industry in their public relations and marketing prowess.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Footnotes&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Other Aspects to This Answer's Approach&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;No formal definitions of the terms used in the question were given.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Extended-Project Qualification&lt;/li&gt;&#xA;&lt;li&gt;Artificial Intelligence Bias&lt;/li&gt;&#xA;&lt;li&gt;Primary data for analysis&lt;/li&gt;&#xA;&lt;li&gt;Controversies that are to do with ethics&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;It was assumed that gauging whether computer driven vehicles will be a technology that achieves ready market acceptance or stalls due to apprehension is the objective of the question author.  Until more specifics are given about what would make data primary and to what decisions the qualifications mentioned would apply, hunting for data sets would be premature.&lt;/p&gt;&#xA;" OwnerUserId="4302" LastActivityDate="2018-11-27T00:19:09.213" CommentCount="0" />
	<row Id="111" PostTypeId="1" AcceptedAnswerId="134" CreationDate="2016-08-02T18:57:57.550" Score="62" ViewCount="3883" Body="&lt;p&gt;Obviously, driverless cars aren't perfect, so imagine that the Google car (as an example) got into a difficult situation.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here are a few examples of unfortunate situations caused by a set of events:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The car is heading toward a crowd of 10 people crossing the road, so it cannot stop in time, but it can avoid killing 10 people by hitting the wall (killing the passengers),&lt;/li&gt;&#xA;&lt;li&gt;Avoiding killing the rider of the motorcycle considering that the probability of survival is greater for the passenger of the car,&lt;/li&gt;&#xA;&lt;li&gt;Killing an animal on the street in favour of a human being,&lt;/li&gt;&#xA;&lt;li&gt;Changing lanes to crash into another car to avoid killing a dog,&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;And here are few dilemmas:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Does the algorithm recognize the difference between a human being and an animal?&lt;/li&gt;&#xA;&lt;li&gt;Does the size of the human being or animal matter?&lt;/li&gt;&#xA;&lt;li&gt;Does it count how many passengers it has vs. people in the front?&lt;/li&gt;&#xA;&lt;li&gt;Does it &quot;know&quot; when babies/children are on board?&lt;/li&gt;&#xA;&lt;li&gt;Does it take into the account the age (e.g. killing the older first)?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;How would an algorithm decide what should it do from the technical perspective? Is it being aware of above (counting the probability of kills), or not (killing people just to avoid its own destruction)?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Related articles:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://www.technologyreview.com/s/542626/why-self-driving-cars-must-be-programmed-to-kill/&quot; rel=&quot;noreferrer&quot;&gt;Why Self-Driving Cars Must Be Programmed to Kill&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&quot;https://www.technologyreview.com/s/539731/how-to-help-self-driving-cars-make-ethical-decisions/&quot; rel=&quot;noreferrer&quot;&gt;How to Help Self-Driving Cars Make Ethical Decisions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="8" LastEditorUserId="14723" LastEditDate="2018-04-13T18:44:57.490" LastActivityDate="2018-04-14T01:49:58.217" Title="How could self-driving cars make ethical decisions about who to kill?" Tags="&lt;algorithm&gt;&lt;self-driving&gt;&lt;decision-theory&gt;&lt;ethics&gt;" AnswerCount="13" CommentCount="6" FavoriteCount="14" />
	<row Id="134" PostTypeId="2" ParentId="111" CreationDate="2016-08-02T20:10:47.850" Score="41" Body="&lt;p&gt;The answer to a lot of those questions depends on how the device is programmed. A computer capable of driving around and recognizing where the road goes is likely to have the ability to visually distinguish a human from an animal, whether that be based on outline, image, or size. With sufficiently sharp image recognition, it might be able to count the number and kind of people in another vehicle. It could even use existing data on the likelihood of injury to people in different kinds of vehicles.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Ultimately, people disagree on the ethical choices involved. Perhaps there could be &quot;ethics settings&quot; for the user/owner to configure, like &quot;consider life count only&quot; vs. &quot;younger lives are more valuable.&quot; I personally would think it's not terribly controversial that a machine should damage itself before harming a human, but people disagree on how important pet lives are. If explicit kill-this-first settings make people uneasy, the answers could be determined from a questionnaire given to the user.&lt;/p&gt;&#xA;" OwnerUserId="75" LastEditorUserId="2989" LastEditDate="2016-10-14T09:49:20.523" LastActivityDate="2016-10-14T09:49:20.523" CommentCount="10" />
	<row Id="161" PostTypeId="2" ParentId="111" CreationDate="2016-08-02T23:31:57.630" Score="11" Body="&lt;p&gt;This is the well known &lt;a href=&quot;https://en.wikipedia.org/wiki/Trolley_problem&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;em&gt;Trolley Problem&lt;/em&gt;&lt;/a&gt;. As &lt;a href=&quot;https://ai.stackexchange.com/a/134/8&quot;&gt;Ben N&lt;/a&gt; said, people disagree on the right course of action for trolley problem scenarios, but it should be noted that with self-driving cars, reliability is so high that these scenarios are really unlikely. So, not much effort will be put into the problems you are describing, at least in the short term.&lt;/p&gt;&#xA;" OwnerUserId="130" LastEditorUserId="-1" LastEditDate="2017-04-13T12:53:10.013" LastActivityDate="2016-08-04T00:19:36.570" CommentCount="2" />
  	<row Id="162" PostTypeId="2" ParentId="111" CreationDate="2016-08-02T23:44:57.983" Score="5" Body="&lt;p&gt;For a driverless car that is designed by a single entity, the best way for it to make decisions about whom to kill is by estimating and minimizing the probable liability.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It doesn't need to absolutely correctly identify all the potential victims in the area to have a defense for its decision, only to identify them as well as a human could be expected to.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It doesn't even need to know the age and physical condition of everyone in the car, as it can ask for that information and if refused, has the defense that the passengers chose not to provide it, and therefore took responsibility for depriving it of the ability to make a better decision.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It only has to have a viable model for minimizing exposure of the entity to lawsuits, which can then be improved over time to make it more profitable.&lt;/p&gt;&#xA;" OwnerUserId="46" LastActivityDate="2016-08-02T23:44:57.983" CommentCount="0" />
  	<row Id="200" PostTypeId="2" ParentId="111" CreationDate="2016-08-03T09:17:14.977" Score="24" Body="&lt;p&gt;Personally, I think this might be an overhyped issue. Trolley problems only occur when the situation is optimized to prevent &quot;3rd options&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A car has brakes, does it not? &quot;But what if the brakes don't work?&quot; Well, then &lt;strong&gt;the car is not allowed to drive at all.&lt;/strong&gt; Even in regular traffic, human operators are taught that your speed should be limited as such that you can stop within the area you can see. Solutions like these will reduce the possibility of a trolley problem.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As for animals... if there is no explicit effort to deal with humans on the road I think animals will be treated the same. This sounds implausible - roadkill happens often and human &quot;roadkill&quot; is unwanted, but animals are a lot smaller and harder to see than humans, so I think detecting humans will be easier, preventing a lot of the accidents.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In other cases (bugs, faults while driving, multiple failures stacked onto each other), perhaps accidents will occur, they'll be analysed, and vehicles will be updated to avoid causing similar situations. &lt;/p&gt;&#xA;" OwnerUserId="74" LastEditorUserId="74" LastEditDate="2016-08-03T09:31:21.937" LastActivityDate="2016-08-03T09:31:21.937" CommentCount="1" />
  	<row Id="1790" PostTypeId="2" ParentId="111" CreationDate="2016-08-30T16:59:57.733" Score="38" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;How could self-driving cars make ethical decisions about who to kill?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;It shouldn't. Self-driving cars are not moral agents. Cars fail in predictable ways. Horses fail in predictable ways. &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;the car is heading toward a crowd of 10 people crossing the road, so&#xA;  it cannot stop in time, but it can avoid killing 10 people by hitting&#xA;  the wall (killing the passengers),&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;In this case, the car should slam on the brakes. If the 10 people die, that's just unfortunate. We simply cannot &lt;em&gt;trust&lt;/em&gt; all of our beliefs about what is taking place outside the car. What if those 10 people are really robots made to &lt;em&gt;look&lt;/em&gt; like people? What if they're &lt;em&gt;trying&lt;/em&gt; to kill you?&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;avoiding killing the rider of the motorcycle considering that the&#xA;  probability of survival is greater for the passenger of the car,&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Again, hard-coding these kinds of sentiments into a vehicle opens the rider of the vehicle up to all kinds of attacks, including &lt;em&gt;&quot;fake&quot;&lt;/em&gt; motorcyclists. Humans are &lt;em&gt;barely&lt;/em&gt; equipped to make these decisions on their own, if at all. When it doubt, just slam on the brakes.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;killing animal on the street in favour of human being,&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Again, just hit the brakes. What if it was a baby? What if it was a bomb?&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;changing lanes to crash into another car to avoid killing a dog,&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Nope. The dog was in the wrong place at the wrong time. The other car wasn't. Just slam on the brakes, as safely as possible.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Does the algorithm recognize the difference between a human being and an animal?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Does a human? Not always. What if the human has a gun? What if the animal has large teeth? Is there no context?&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;ul&gt;&#xA;  &lt;li&gt;Does the size of the human being or animal matter?&lt;/li&gt;&#xA;  &lt;li&gt;Does it count how many passengers it has vs. people in the front?&lt;/li&gt;&#xA;  &lt;li&gt;Does it &quot;know&quot; when babies/children are on board?&lt;/li&gt;&#xA;  &lt;li&gt;Does it take into the account the age (e.g. killing the older first)?&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Humans can't agree on these things. If you ask a cop what to do in any of these situations, the answer won't be, &quot;You should have swerved left, weighed all the relevant parties in your head, assessed the relevant ages between all parties, then veered slightly right, and you would have saved 8% more lives.&quot; No, the cop will just say, &quot;You should have brought the vehicle to a stop, as quickly and safely as possible.&quot; Why? Because cops know people normally aren't equipped to deal with high-speed crash scenarios.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Our target for &quot;self-driving car&quot; should not be 'a moral agent on par with a human.' It should be an agent with the reactive complexity of cockroach, which fails predictably.&lt;/p&gt;&#xA;" OwnerUserId="1712" LastEditorUserId="1712" LastEditDate="2016-08-30T17:20:42.577" LastActivityDate="2016-08-30T17:20:42.577" CommentCount="1" />
  	<row Id="1813" PostTypeId="2" ParentId="111" CreationDate="2016-08-31T03:30:54.023" Score="2" Body="&lt;p&gt;Frankly I think this issue (the Trolley Problem) is inherently overcomplicated, since the real world solution is likely to be pretty straightforward.  Like a human driver, an AI driver will be programmed to act at all times in a generically ethical way, always choosing the course of action that does no harm, or the least harm possible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If an AI driver encounters danger such as imminent damage to property, obviously the AI will brake hard and aim the car away from breakable objects to avoid or minimize impact.  If the danger is hitting a pedestrian or car or building, it will choose to collide with the least precious or expensive object it can, to do the least harm -- placing a higher value on a human than a building or a dog.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally, if the choice of your car's AI driver is to run over a child or hit a wall... it will steer the car, &lt;em&gt;and you&lt;/em&gt;, into the wall.  That's what any good human would do.  Why would a good AI act any differently?&lt;/p&gt;&#xA;" OwnerUserId="1657" LastActivityDate="2016-08-31T03:30:54.023" CommentCount="2" />
  	<row Id="2296" PostTypeId="2" ParentId="111" CreationDate="2016-11-08T04:02:24.983" Score="4" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;“This moral question of whom to save: 99 percent of our engineering work is to prevent these situations from happening at all.”&#xA;  —Christoph von Hugo, Mercedes-Benz &lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;This quote is from an article titled &lt;a href=&quot;http://blog.caranddriver.com/self-driving-mercedes-will-prioritize-occupant-safety-over-pedestrians/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Self-Driving Mercedes-Benzes Will Prioritize Occupant Safety over Pedestrians published OCTOBER 7, 2016 BY MICHAEL TAYLOR&lt;/a&gt;, retrieved 08 Nov 2016. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Here's an excerpt that outlines what the technological, practical solution to the problem.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;The world’s oldest carmaker no longer sees the problem, similar to the question from 1967 known as the Trolley Problem, as unanswerable. Rather than tying itself into moral and ethical knots in a crisis, Mercedes-Benz simply intends to program its self-driving cars to save the people inside the car. Every time. &lt;/p&gt;&#xA;  &#xA;  &lt;p&gt;All of Mercedes-Benz’s future Level 4 and Level 5 autonomous cars will prioritize saving the people they carry, according to Christoph von Hugo, the automaker’s manager of driver assistance systems and active safety.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;There article also contains the following fascinating paragraph.  &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;A study released at midyear &lt;a href=&quot;http://science.sciencemag.org/content/352/6293/1514&quot; rel=&quot;nofollow noreferrer&quot;&gt;by Science&lt;/a&gt; magazine didn’t clear the air, either. The majority of the 1928 people surveyed thought it would be ethically better for autonomous cars to sacrifice their occupants rather than crash into pedestrians. Yet the majority also said they wouldn’t buy autonomous cars if the car prioritized pedestrian safety over their own.  &lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="3526" LastActivityDate="2016-11-08T04:02:24.983" CommentCount="0" />
  	<row Id="2345" PostTypeId="2" ParentId="111" CreationDate="2016-11-17T04:05:06.240" Score="2" Body="&lt;p&gt;I think that in most cases the car would default to reducing speed as a main option, rather than steering toward or away from a specific choice. As others have mentioned, having settings related to ethics is just a bad idea. What happens if two cars that are programmed with opposite ethical settings and are about to collide? The cars could potentially have a system to override the user settings and pick the most mutually beneficial solution. It's indeed an interesting concept, and one that definitely has to discussed and standardized before widespread implementation. Putting ethical decisions in a machines hands makes the resulting liability sometimes hard to picture.&lt;/p&gt;&#xA;" OwnerUserId="3684" LastEditorUserId="3684" LastEditDate="2016-11-18T05:22:24.577" LastActivityDate="2016-11-18T05:22:24.577" CommentCount="2" />
  	<row Id="2763" PostTypeId="2" ParentId="111" CreationDate="2017-01-31T22:16:32.373" Score="2" Body="&lt;p&gt;How could self-driving cars make ethical decisions about who to kill?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;By managing legal liability and consumer safety.&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;A car that offers the consumer safety is going to be a car that is bought by said consumers. Companies do not want to be liable for killing their customers nor do they want to sell a product that gets the user in legal predicaments. Legal liability and consumer safety are the same issue when looked at from the perspective of &quot;cost to consumer&quot;.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;And here are few dilemmas:&lt;/p&gt;&#xA;  &#xA;  &lt;ul&gt;&#xA;  &lt;li&gt;Does the algorithm recognize the difference between a human being and&#xA;  an animal?&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;If an animal/human cannot be legally avoided (and the car is in legal right - if it is not then something else is wrong with the AI's decision making), it likely won't. If the car can safely avoid the obstacle, the AI could reasonably be seen to make this decision, ie. swerve to another lane on an open highway. Notice there is an emphasis on liability and driver safety.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;ul&gt;&#xA;  &lt;li&gt;Does the size of the human being or animal matter?&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Only the risk factor from hitting the obstacle. Hitting a hippo might be less desirable than hitting the ditch. Hitting a dog is likely more desirable than wrecking the customer's automobile.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;ul&gt;&#xA;  &lt;li&gt;Does it count how many passengers it has vs. people in the front?&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;It counts the people as passengers to see if the car-pooling lane can be taken. It counts the people in front as a risk factor in case of a collision.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;ul&gt;&#xA;  &lt;li&gt;Does it &quot;know&quot; when babies/children are on board?&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;No.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;ul&gt;&#xA;  &lt;li&gt;Does it take into the account the age (e.g. killing the older first)?&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;No. This is simply the wrong abstraction to make a decision, how could this be weighted into choosing the right course of action to reduce risk factor? If Option 1 is hit young guy with 20% chance of significant occupant damage and no legal liability and Option 2 is hit an old guy with 21% chance of significant occupant damage and no legal liability, then what philosopher can convince even just 1 person of the just and equitable weights to make a decision?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thankfully, the best decision a lot of the time is to hit the breaks to reduce speed (especially when you consider that it is often valuable to act predictably so that pedestrians and motorists can react accordingly). In the meantime, better value improvements can be made in terms of predicting when drivers will make bad decisions and when other actions (such as hitting the reverse) are more beneficial than hitting the breaks. At this point, it is not worth it to even begin collecting the information to make the ethical decisions proposed by philosophers. Thus, this issue is over-hyped by sensational journalists and philosophers.&lt;/p&gt;&#xA;" OwnerUserId="5157" LastEditorUserId="14723" LastEditDate="2018-04-14T01:44:34.400" LastActivityDate="2018-04-14T01:44:34.400" CommentCount="0" />
  	<row Id="2813" PostTypeId="2" ParentId="111" CreationDate="2017-02-12T10:48:09.903" Score="1" Body="&lt;p&gt;The only sensible choice is to use predictable behaviour. So in the people in front of the car scenario: First the car hits the brakes, at the same time honks the horn, and stays on course.  The people then have a chance to jump out of the way leading to zero people being killed. Also with full brakes (going from 50km per hour to zero is less than 3 car lengths), an impact situation is almost not imaginable. Even if full stop cannot be reached, severe damage to the pedestrians is unlikely.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The other scenario is just crazy. So the distance has to be less than 3 car lengths, at least 1 car length in needed for the steering, then a car crashing is an uncontrollable situation, might lead to spinning and kill all 11 persons.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Apart from saying that I don't believe there is an example in reality where there is a dilemma;  the solution in these unlikely cases if to conform with the expectations of the opposing party to allow the other party to mitigate the situation as well.&lt;/p&gt;&#xA;" OwnerUserId="5423" LastEditorUserId="14723" LastEditDate="2018-04-14T01:49:58.217" LastActivityDate="2018-04-14T01:49:58.217" CommentCount="4" />
  	<row Id="2814" PostTypeId="2" ParentId="111" CreationDate="2017-02-13T04:50:51.100" Score="1" Body="&lt;p&gt;I think there would not be a way to edit such ethics settings in a car. But hey, if cell phones can be rooted, why not cars? I imagine there'll be Linux builds in the future for specific models that will let you do whatever you want.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As for who'll make such decisions, it'll be much like privacy issues of today. There'll be a tug-of war on the blanket by the OS providers (who'll try to set it to a minimum amount of people injured, each with its own methods), insurance companies (who'll try to make you pay more for OS's that will be statistically shown to damage your car easier), and car manufacturers (who'll want you to trash your car as soon as you can, so you'll buy a new one; or make cars that require a ridiculous amount of $$$ service). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Then some whistleblower will come out and expose a piece of code that chooses to kill young children over adults - because it will have a harder time distinguishing them from animals, and will take chances to save who it'll more surely recognize as humans. The OS manufacturer will get a head-slap from the public and a new consensus will be found. Whistleblowers will come out from insurance companies and car manufacturers too. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Humanity will grab a hot frying pan and burn itself and then learn to put on gloves beforehand. My advice would just make sure you won't be that hand - stay away from them for a couple of years until all the early mistakes are made.&lt;/p&gt;&#xA;" OwnerUserId="5434" LastEditorUserId="14723" LastEditDate="2018-04-14T01:49:27.290" LastActivityDate="2018-04-14T01:49:27.290" CommentCount="0" />
  	<row Id="6044" PostTypeId="2" ParentId="111" CreationDate="2018-04-13T20:41:24.237" Score="2" Body="&lt;p&gt;They shouldn't. People should.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;People cannot put the responsibilities of ethical decisions into the hands of computers. It is our responsibility as computer scientists/AI experts to program decisions for computers to make. Will human casualties still exist from this? Of course, they will--- people are not perfect and neither are programs.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There is an excellent in-depth debate on this topic &lt;a href=&quot;https://www.youtube.com/watch?v=93Xv8vJ2acI&amp;amp;index=46&amp;amp;list=WL&amp;amp;t=6s&quot; rel=&quot;nofollow noreferrer&quot;&gt;here&lt;/a&gt;. I particularly like Yann LeCun's argument regarding the parallel ethical dilemma of testing potentially lethal drugs on patients. Similar to self-driving cars, both can be lethal while having good intentions of saving &lt;em&gt;more&lt;/em&gt; people in the long run.&lt;/p&gt;&#xA;" OwnerUserId="6252" LastEditorUserId="6252" LastEditDate="2018-04-14T00:53:25.007" LastActivityDate="2018-04-14T00:53:25.007" CommentCount="0" />
	<row Id="112" PostTypeId="1" CreationDate="2016-08-02T18:59:44.230" Score="4" ViewCount="715" Body="&lt;p&gt;Which deep neural network is used in &lt;a href=&quot;https://en.wikipedia.org/wiki/Google_self-driving_car&quot; rel=&quot;nofollow noreferrer&quot;&gt;Google's driverless cars&lt;/a&gt; to analyze the surroundings? Is this information open to the public?&lt;/p&gt;&#xA;" OwnerUserId="8" LastEditorUserId="14723" LastEditDate="2018-04-13T18:53:56.720" LastActivityDate="2018-04-14T02:42:26.697" Title="Which machine learning algorithm is used in self-driving cars?" Tags="&lt;deep-network&gt;&lt;algorithm&gt;&lt;self-driving&gt;" AnswerCount="2" CommentCount="1" />
	<row Id="2269" PostTypeId="2" ParentId="112" CreationDate="2016-11-04T16:07:30.833" Score="1" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;The most common machine learning algorithms found in self driving cars involve &lt;strong&gt;object tracking&lt;/strong&gt; based technologies used in order to pinpoint and distinguish between different objects in order to better analyse a digital landscape.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Algorithms are designed to become more efficient at this by modifying internal parameters and testing these changes.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I hope that provides a general overview of the subject.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Since Google's cars are in development and are proprietary, they will probably not share their specific algorithm, however you can take a look at similar technologies to learn more.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;To find out more, take a look at an &lt;a href=&quot;http://ori.ox.ac.uk/how-robotcar-works/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Oxford-based initiative in self driving cars and how they work&lt;/a&gt;.&lt;/p&gt;&#xA;" OwnerUserId="3427" LastEditorUserId="8" LastEditDate="2018-04-13T18:55:08.723" LastActivityDate="2018-04-13T18:55:08.723" CommentCount="0" />
	<row Id="2273" PostTypeId="2" ParentId="112" CreationDate="2016-11-05T10:34:25.450" Score="2" Body="&lt;p&gt;It will not be single DNN architecture, rather it will be a collection of different DNN architectures that are used together to make the final decision. Convolutions are using the images/videos from the camera. Other architectures use other sensory sources. These DNNs will be trained to compute the high-level features from their sensory sources and then those high-level features will probably be fed into an LSTM (or some other form of RNN) that is trained with some form of Reinforcement learning algorithm to compute the action (like slowing down, applying breaks etc).&lt;/p&gt;&#xA;" OwnerUserId="1462" LastEditorUserId="14723" LastEditDate="2018-04-14T02:42:26.697" LastActivityDate="2018-04-14T02:42:26.697" CommentCount="0" />
	<row Id="1318" PostTypeId="1" AcceptedAnswerId="1820" CreationDate="2016-08-04T15:10:41.230" Score="2" ViewCount="326" Body="&lt;p&gt;&lt;strong&gt;The Situation:&lt;/strong&gt;&#xA;A self-driving car is traveling at it's maximum speed, 25 mph (40 km/h), in the middle of an empty street with the ability to change lanes on both sides. There are two passengers, one in the front and another in the back.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Someone jumps from the side of the road directly into the path of the car. A collision would occur in 50 meters. &lt;a href=&quot;http://www.brake.org.uk/rsw/15-facts-a-resources/facts/1255-speed&quot; rel=&quot;nofollow&quot;&gt;Breaking distance&lt;/a&gt; at this speed is about 24m.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;The Question:&lt;/strong&gt; Is it known how the current implementation of the Google Car AI would react, or is it currently a matter of speculation? A step-by-step explanation of the AI's decisioning process would be preferred.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Possible Answers:&lt;/strong&gt; The car could activate its brakes immediately, coming to a halt as quickly as possible. This would be sooner than a human could stop, as people require time to recognize the possibility of a collision, and then physically slam on the brake. (&lt;em&gt;thinking distance&lt;/em&gt;).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Alternatively, the car could continue traveling forward, processing the situation. (Similar to a humans &lt;em&gt;thinking distance&lt;/em&gt;). The person may continue to move, either out of the way, or still into danger of being hit. In this case, the car may decide to change lanes in an attempt to pass around the person.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Lastly and most unlikely, the car will not alter its course and proceed to drive forward.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;sup&gt;Do not attempt to do it to check;)&lt;/sup&gt;&lt;/p&gt;&#xA;" OwnerUserId="8" LastEditorUserId="1812" LastEditDate="2016-08-31T23:17:29.040" LastActivityDate="2016-09-01T01:52:21.400" Title="What would happen if someone jumped in the front of a Google car?" Tags="&lt;self-driving&gt;&lt;decision-theory&gt;" AnswerCount="1" CommentCount="5" />
	<row Id="1820" PostTypeId="2" ParentId="1318" CreationDate="2016-09-01T01:52:21.400" Score="2" Body="&lt;p&gt;Given this &lt;a href=&quot;https://www.youtube.com/watch?v=YXylqtEQ0tk&quot; rel=&quot;nofollow&quot;&gt;YouTube video&lt;/a&gt; which is being given by Sebastian Thrun who had a TED talk which had nowhere near the same level of detail but had similar conclusions, it looks like the lidar system used by google's automated car system has decent resolution out to at least 30m picking out mobile bodies in the static background and then identifying it. So it should have plenty of time to brake and stop long before there was any risk to the pedestrian attempting to cross the street.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Skip to about 6:40 in the video to see a visual representation of the detection system.&lt;/p&gt;&#xA;" OwnerUserId="1991" LastActivityDate="2016-09-01T01:52:21.400" CommentCount="0" />
	<row Id="1393" PostTypeId="1" CreationDate="2016-08-06T00:37:24.067" Score="2" ViewCount="241" Body="&lt;p&gt;This &lt;a href=&quot;http://repository.supsi.ch/5145/1/IDSIA-04-12.pdf&quot; rel=&quot;nofollow&quot;&gt;study&lt;/a&gt; (pages 7-8) shows an attempt at recognizing the traffic signs with lower error rates by using multi-column deep neural networks &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Are Google cars using similar techniques of predicting signs using DNN, or are they using some other method?&lt;/p&gt;&#xA;" OwnerUserId="8" LastEditorUserId="145" LastEditDate="2016-08-18T20:10:33.393" LastActivityDate="2016-10-09T11:49:20.453" Title="How do Google cars recognize the traffic signs?" Tags="&lt;deep-network&gt;&lt;image-recognition&gt;&lt;self-driving&gt;&lt;classification&gt;&lt;cars&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="1911" PostTypeId="2" ParentId="1393" CreationDate="2016-09-09T11:09:38.703" Score="2" Body="&lt;p&gt;I'm not sure what google is using to perform that task but most companies use region based convolutional neural nets to locate traffic signs and other objects.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;But other companies use a Deep neural net + Bag of words approach to find objects.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;See: &lt;a href=&quot;https://www.researchgate.net/publication/284505205_Bag-of-Words_Based_Deep_Neural_Network_for_Image_Retrieval&quot; rel=&quot;nofollow&quot;&gt;Bag-of-Words Based Deep Neural Network for Image Retrieval&lt;/a&gt; which shows a general approach, to get the exact location you can use &lt;em&gt;Feature Matching&lt;/em&gt; or &lt;em&gt;Random Boxes&lt;/em&gt;.&lt;/p&gt;&#xA;" OwnerUserId="2320" LastEditorUserId="8" LastEditDate="2016-09-09T11:36:05.420" LastActivityDate="2016-09-09T11:36:05.420" CommentCount="1" />
	<row Id="1491" PostTypeId="1" CreationDate="2016-08-09T10:40:35.500" Score="1" ViewCount="47" Body="&lt;p&gt;Some time ago playing chess was challenging for algorithms, then Go game which is vastly more complex than compared to chess.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;How about playing RTS game which have enormous branching factors limited by its time and space (like deciding what to do next)? What are the successful approaches to such problems?&lt;/p&gt;&#xA;" OwnerUserId="8" LastActivityDate="2016-10-19T07:44:43.773" Title="How to deal with huge branching factors in real-time?" Tags="&lt;gaming&gt;&lt;branching-factors&gt;&lt;real-time&gt;" AnswerCount="1" CommentCount="0" />
	<row Id="4489" PostTypeId="1" CreationDate="2017-11-11T17:39:21.537" Score="2" ViewCount="982" Body="&lt;p&gt;I want to build a personal assistant that listens to me continuously.. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;The flow looks like this: &lt;/p&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;continuously record voice &lt;/li&gt;&#xA;&lt;li&gt;stream it to google speech api.&lt;/li&gt;&#xA;&lt;li&gt;get back the text in real time -&gt; parse for intent etc..&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;Problem is, google speech api gets expensive if you record for hours. A better way to do it is to only submit the parts where I'm actually speaking to it.. Then the cost of running this full time (17 hours a day, every day) becomes very accessible.&#xA;Now my question is:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;How can i detect that a voice is present in the microphone stream?&lt;/strong&gt; &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have a lot of noise in the background, dumb &lt;code&gt;increase in volume detection&lt;/code&gt; is not a very good solution. I need something more intelligent. It doesn't need to be very accurate - just good enough to not break my cloud computing budget. I'm thinking that human voice sounds distinct enough that is not such a big problem to detect when is there.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What do you recommend me to do, given this is a real time stream - not an audio file.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The audio will be generated in chromium browser (electron) - with &lt;code&gt;getUserMedia&lt;/code&gt; API, and using &lt;code&gt;node.js&lt;/code&gt; i plan to handle the streaming logic. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note: there is a built in &lt;code&gt;speechRecognition api&lt;/code&gt; in &lt;code&gt;electron&lt;/code&gt; - but from my experience currently it doesn't work (not even after i give it my API key), and even if would have worked, i think it has the same cost problem. So this is why i'm trying to provide my own implementation. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I don't know what i'm doing, any insight is welcomed:) Thank you.&lt;/p&gt;&#xA;" OwnerUserId="10650" LastEditorUserId="1671" LastEditDate="2017-11-12T22:13:25.073" LastActivityDate="2017-11-13T19:05:55.950" Title="How to detect when human voice / speech appears in an microphone stream?" Tags="&lt;intelligent-agent&gt;&lt;voice-recognition&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="8223" PostTypeId="1" AcceptedAnswerId="8234" CreationDate="2018-10-02T14:18:40.637" Score="4" ViewCount="41" Body="&lt;p&gt;I've been told this is how I should be preprocessing audio samples, but what information does this method actually give me? What are the alternatives and why shouldn't I use them.&lt;/p&gt;&#xA;" OwnerUserId="18709" LastActivityDate="2018-10-03T05:39:22.023" Title="Why is Short-Time Fourier Transform used for preprocessing audio samples?" Tags="&lt;voice-recognition&gt;" AnswerCount="1" CommentCount="3" />
	<row Id="77" PostTypeId="1" AcceptedAnswerId="131" CreationDate="2016-08-02T16:45:01.487" Score="14" ViewCount="483" Body="&lt;p&gt;I know that language of &lt;strong&gt;&lt;code&gt;Lisp&lt;/code&gt;&lt;/strong&gt; was used early on when working on artificial intelligence problems.  Is it still being used today for significant work?  If not, is there a new language that has taken its place as the most common one being used for work in AI today?&lt;/p&gt;&#xA;" OwnerUserId="55" LastEditorUserId="102" LastEditDate="2016-08-02T17:44:07.997" LastActivityDate="2016-08-04T00:21:27.440" Title="Is Lisp still being used to tackle AI problems?" Tags="&lt;history&gt;&lt;programming-languages&gt;&lt;lisp&gt;" AnswerCount="4" CommentCount="0" FavoriteCount="5" />
	<row Id="115" PostTypeId="2" ParentId="77" CreationDate="2016-08-02T19:14:12.347" Score="1" Body="&lt;p&gt;In my opinion python and java have taken over from LISP. Many people use them, there is a large amount of libraries available. And more importantly, they are easy to integrate in web technologies. &lt;/p&gt;&#xA;" OwnerUserId="52" LastActivityDate="2016-08-02T19:14:12.347" CommentCount="0" />
	<row Id="131" PostTypeId="2" ParentId="77" CreationDate="2016-08-02T20:01:05.593" Score="7" Body="&lt;p&gt;The following thread has many answers regarding why LISP used to be thought of as the AI language: &lt;a href=&quot;https://stackoverflow.com/questions/130475/why-is-lisp-used-for-ai&quot;&gt;Why is Lisp used for AI&lt;/a&gt; and the following is an answer by Peter Norvig, who wrote a popular textbook on the subject and is currently Director of Research at Google: &lt;a href=&quot;https://www.quora.com/Is-it-true-that-Lisp-is-highly-used-programming-language-in-AI&quot; rel=&quot;nofollow noreferrer&quot;&gt;Is it true that Lisp is highly used programming language in AI?&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am not overly familiar with the history, but I think LISP was oversold to industry as &quot;the AI language&quot;. It is a good language for humans to think in and pioneered many important ideas which have since been incorporated into many modern languages (see &lt;a href=&quot;https://en.wikipedia.org/wiki/Lisp_(programming_language)&quot; rel=&quot;nofollow noreferrer&quot;&gt;the Wikipedia page&lt;/a&gt;), but it is no way the &quot;best&quot;. It was likely also popular because it is very expressive: you can write short programs to represent complex ideas, a property it shares with other functional languages in use such as Scala. This also means that it is easy to write a program that is very hard to debug in LISP. Modern functional languages have been trying to do better in this regard through typing etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The paradigm for AI that currently receives most attention is Machine Learning, i.e. learning hypothesis from data, as opposed to previous approaches like Expert Systems where experts wrote rules for the AI to follow. Python is currently the most widely used language for prototyping machine learning algorithms and has many libraries and an active community. Another important detail about modern AI is the volume of data it uses. Big Data analysis is done using cluster computing systems like Hadoop (with code written in Java) and Spark (with code written in Python or Scala). Often, the core time-intensive subroutines are written in C, but this is often done in the form of third-party libraries.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally it must be said that the AI Winter of the 80s was not because we did not have the right language, but because we did not have the right algorithms and did not have enough computational power. This has changed as GPUs have gotten better. If you're trying to learn AI, spend your time studying algorithms and not languages.&lt;/p&gt;&#xA;" OwnerUserId="130" LastEditorUserId="-1" LastEditDate="2017-05-23T12:39:33.010" LastActivityDate="2016-08-04T00:21:27.440" CommentCount="0" />
	<row Id="164" PostTypeId="2" ParentId="77" CreationDate="2016-08-03T00:16:14.550" Score="3" Body="&lt;p&gt;LISP is still used significantly, but less and less. There is still momentum due to so many people using it in the past, who are still active in the industry or research (anecdote: the last VCR was produced by a Japanese maker in July 2016, yes). The language is however used (to my knowledge) for the kind of AI that does not leverage Machine Learning, typically as the reference books from Russell and Norvig. These applications are still very useful, but Machine Learning gets all the steam these days.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Another reason for the decline is that LISP practitioners have partially moved to Clojure and other recent languages.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are learning about AI technologies, LISP (or Scheme or Prolog) is good choice to understand what is going on with &quot;AI&quot; at large. But if you wish or have to be very pragmatic, Python or R are the community choices&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Note: The above lacks concrete example and reference. I am aware of some work in universities, and some companies inspired by or directly using LISP.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;To add on @Harsh's answer, LISP (and Scheme, and Prolog) has qualities that made it look like it was better suited for creating intelligent mechanisms---making AI as perceived in the 60s.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One of the qualities was that the language design leads the developer to think in a quite elegant way, to decompose a big problem into small problems, etc. Quite &quot;clever&quot;, or &quot;intelligent&quot; if you will. Compared to some other languages, there is almost no choice but to develop that way. LISP is a list processing language, and &quot;purely functional&quot;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One problem, though, can be seen in work related to LISP. A notable one in the AI domain is the work on the &lt;a href=&quot;https://en.wikipedia.org/wiki/Situation_calculus&quot; rel=&quot;nofollow&quot;&gt;Situation Calculus&lt;/a&gt;, where (in short) one describes objects and rules in a &quot;world&quot;, and can let it evolve to compute &lt;em&gt;situations&lt;/em&gt;---states of the world. So it is a model for reasoning on situations. The main problem is called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Frame_problem&quot; rel=&quot;nofollow&quot;&gt;frame problem&lt;/a&gt;, meaning this calculus cannot tell what does &lt;em&gt;not&lt;/em&gt; change---just what changes. Anything that is not defined in the world cannot be processed (note the difference here with ML). First implementations used LISPs, because that was the AI language then. And there were bound by the frame problem. But, as @Harsh mentioned, it is not LISP's fault: Any language would face the same framing issue (a conceptual problem of the Situation Calculus).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So the language really does not matter from the AI / AGI / ASI perspective. The concepts (algorithms, etc.) are really what matters.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even in Machine Learning, the language is just a practical choice. Python and R are popular today, primarily due to their library ecosystem and the focus of key companies. But try to use Python or R to run a model for a RaspberryPI-based application, and you will face some severe limitations (but still possible, I am doing it :-)). So the language choice burns down to pragmatism.&lt;/p&gt;&#xA;" OwnerUserId="169" LastActivityDate="2016-08-03T00:16:14.550" CommentCount="0" />
	<row Id="166" PostTypeId="2" ParentId="77" CreationDate="2016-08-03T01:08:53.837" Score="5" Body="&lt;p&gt;I definitely continue to often use Lisp when working on AI models.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You asked if it is being used for &lt;em&gt;substantial&lt;/em&gt; work.  That's too subjective for me to answer regarding my own work, but I queried one my AI models whether or not it considered itself substantial, and it replied with an affirmative response.  Of course, it's response is naturally biased as well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Overall, a significant amount of AI research and development is conducted in Lisp.  Furthermore, even for non-AI problems, Lisp is sometimes used.  To demonstrate the power of Lisp, I engineered the first neural network simulation system written entirely in Lisp over a quarter century ago.&lt;/p&gt;&#xA;" OwnerUserId="156" LastActivityDate="2016-08-03T01:08:53.837" CommentCount="1" />
	<row Id="1303" PostTypeId="1" AcceptedAnswerId="1305" CreationDate="2016-08-04T12:28:07.427" Score="1" ViewCount="919" Body="&lt;p&gt;I read some information&lt;sup&gt;1&lt;/sup&gt; about attempts to build neural networks in the PHP programming language. Personally I think PHP is not the right language to do so at all probably because it's a high-level language, I assume low level language are way more suitable for AI in terms of performance and scalability. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there a good/logical reason why you should or shouldn't use PHP as a language to write AI in?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/em&gt; &lt;a href=&quot;http://www.developer.com/lang/php/creating-neural-networks-in-php.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;http://www.developer.com/lang/php/creating-neural-networks-in-php.html&lt;/a&gt; and &lt;a href=&quot;https://stackoverflow.com/questions/2303357/are-there-any-artificial-intelligence-projects-in-php-out-there&quot;&gt;https://stackoverflow.com/questions/2303357/are-there-any-artificial-intelligence-projects-in-php-out-there&lt;/a&gt; &lt;/p&gt;&#xA;" OwnerUserId="217" LastEditorUserId="-1" LastEditDate="2017-05-23T12:39:33.010" LastActivityDate="2016-10-31T09:06:48.290" Title="Can PHP be considered as a serious programming language for AI?" Tags="&lt;neural-networks&gt;&lt;programming-languages&gt;" AnswerCount="2" CommentCount="3" ClosedDate="2016-08-04T14:55:53.457" />
	<row Id="1305" PostTypeId="2" ParentId="1303" CreationDate="2016-08-04T12:35:10.167" Score="6" Body="&lt;p&gt;&lt;em&gt;Question on-topicness questionable, but...&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;The most logical reason why PHP is unsuited for neural networks is that PHP is, well, intended to be used for server side webpages. It can connect to various external resources, such as databases, via native language features. It is very much a glue language, and not a processing language. PHP is also mostly stateless, only allowing you to store state in either clients, file storage or databases.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As such, it's &lt;strong&gt;not&lt;/strong&gt; suitable for this sort of thing - not because PHP is a high level language, but rather because it's so request based and focused towards creating pages to serve to clients.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That won't stop people from trying, though - there are various esoteric programming languages out there in which regular programming would be an insane task or not possible at all - but from a ease of development perspective, making a neural network in PHP makes no sense.&lt;/p&gt;&#xA;" OwnerUserId="74" LastEditorUserId="74" LastEditDate="2016-10-31T09:06:48.290" LastActivityDate="2016-10-31T09:06:48.290" CommentCount="1" />
	<row Id="1307" PostTypeId="2" ParentId="1303" CreationDate="2016-08-04T12:50:23.533" Score="3" Body="&lt;p&gt;Actually, yes. Remember, that due to the history of PHP development, some very good things has formed what we have now:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;From a simple/laggy/limited interpreter in PHP 3, we have now three mainstream lines coming one-by-one like v5/v6/v7 with &lt;em&gt;full bytecode&lt;/em&gt; supported.   &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;In PHP v7 you don't even need a bytecode cache due to HHVM, old Zend VM is a hell-good-debugged and using a cacher like XCache you can achieve a true native execution speed &lt;strong&gt;and&lt;/strong&gt; payload&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;The PHP language interface allows &lt;strong&gt;any&lt;/strong&gt; external C/C++ library &lt;em&gt;just to be added&lt;/em&gt; as a module via very simple wrapper that can be written by the person that just red Kerrigan&amp;amp;Richie and Straustrup base books on C and C++. This is amazing feature, exclusive to PHP as far as I know&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;In PHP v7 you're welcome to use &lt;em&gt;native&lt;/em&gt; multi-threading and even CUDA-based things, if you wish to do it. I did it, so I can confirm that it works&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="1263" LastActivityDate="2016-08-04T12:50:23.533" CommentCount="2" />
	<row Id="3110" PostTypeId="1" CreationDate="2017-04-05T22:09:08.163" Score="1" ViewCount="107" Body="&lt;p&gt;I assume, there must be &quot;signal-driven&quot; and maybe also real-time programming language, which based on connectivy-data more than variables (int, string, etc).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I would like to have a language without equaton (x=4) but more like &quot;x related to 4&quot; or &quot;cat related to animal&quot; etc...&lt;/p&gt;&#xA;" OwnerUserId="6482" LastActivityDate="2017-04-06T18:45:09.317" Title="Is there a &quot;better&quot; (signal-based) language for artificial intelligence" Tags="&lt;neural-networks&gt;&lt;ai-design&gt;&lt;programming-languages&gt;&lt;signal-processing&gt;" AnswerCount="2" CommentCount="1" FavoriteCount="1" />
	<row Id="3112" PostTypeId="2" ParentId="3110" CreationDate="2017-04-06T07:10:39.567" Score="4" Body="&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;What You need are other ways of &lt;a href=&quot;https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning&quot; rel=&quot;nofollow noreferrer&quot;&gt;knowledge representation&lt;/a&gt;, such as semantic networks or conceptual graphs. there you can define any possible relation between your entities. the knowledge of &quot;x related to 4&quot; exactly fits into &quot;frames&quot; and &quot;semantic networks&quot;. &lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Edwin_Thompson_Jaynes&quot; rel=&quot;nofollow noreferrer&quot;&gt;Jaynes&lt;/a&gt; in his book,discusses thoroughly what &quot;plausibility&quot; means and why we need to take into account weak syllogisms and start using probability theory as a platform for developing a (general) AI. this might also help with your &quot;reasoning&quot; phase (after you've developed your knowledge base)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="6258" LastActivityDate="2017-04-06T07:10:39.567" CommentCount="3" />
	<row Id="3116" PostTypeId="2" ParentId="3110" CreationDate="2017-04-06T18:45:09.317" Score="2" Body="&lt;p&gt;I don't know if this is what you want, but Artificial Intelligence Markup Language or simply AIML is something that you should consider.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The only problem I see with this language is that it is not popular thus there aren't many compilers for it.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Here is an example of AIML.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Code from tutorials point :&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;&amp;lt;aiml version = &quot;1.0.1&quot; encoding = &quot;UTF-8&quot;?&amp;gt;&#xA;   &amp;lt;category&amp;gt;&#xA;      &amp;lt;pattern&amp;gt; HELLO ALICE &amp;lt;/pattern&amp;gt;&#xA;&#xA;      &amp;lt;template&amp;gt;&#xA;         Hello User!&#xA;      &amp;lt;/template&amp;gt;&#xA;&#xA;   &amp;lt;/category&amp;gt;&#xA;&amp;lt;/aiml&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Result : &lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;User: Hello Alice&#xA;Bot: Hello User&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;" OwnerUserId="6495" LastActivityDate="2017-04-06T18:45:09.317" CommentCount="1" />
	<row Id="3351" PostTypeId="1" CreationDate="2017-05-22T09:02:25.810" Score="0" ViewCount="197" Body="&lt;p&gt;Hello i new to artificial intelligence, i am web developer i know html, javascript, node js and php. Are these language is ok to create simple AI app.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I have simple AI app in my mind to which will take input as a voice command to shut down my computer.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To create above simple above technologies ok or i have to learn new technology for above app.After creating this simple app i will update and try to control my windows with voice.&lt;/p&gt;&#xA;" OwnerUserId="7360" LastEditorUserId="33" LastEditDate="2017-05-25T22:20:36.467" LastActivityDate="2017-05-28T07:15:46.477" Title="Which language(s) should one know in order to start with Artificial Intelligence?" Tags="&lt;self-learning&gt;&lt;programming-languages&gt;" AnswerCount="5" CommentCount="1" FavoriteCount="1" />
	<row Id="3374" PostTypeId="1" AcceptedAnswerId="3382" CreationDate="2017-05-24T19:07:38.987" Score="3" ViewCount="3305" Body="&lt;p&gt;I am a software engineering student and I am complete beginner to AI. I have read a lot of articles on how to start but each article suggests a different way.  I was wondering if some of you experts can help me get started in the right way.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;First, which language should I focus? as of right now, my main language is Java, but a lot of articles suggests that I should learn python, C++ or lisp for AI. Can I use Java instead of any of the other languages mentioned?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Second, what kind of maths background should I have? During the first year, I did discrete maths which included the following topics :- Sets, Matrices, vectors, functions, logic and graph theory (They taught these topics briefly). are the are there any more topics that I should learn now (calculus maybe?)?&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;If possible I would appreciate any resources or books I could use in order to get started or maybe you guys can give me a detailed procedure I can follow in order to catch up with to your level.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Note: For now I would like to focus on neural networks and machine learning. After I that I would like to explore robotics and natural language processing.&lt;/p&gt;&#xA;" OwnerUserId="4427" LastEditorUserId="1671" LastEditDate="2018-03-09T20:23:35.520" LastActivityDate="2018-03-09T22:33:01.543" Title="How does one start learning artificial intelligence?" Tags="&lt;ai-design&gt;&lt;ai-basics&gt;&lt;getting-started&gt;&lt;programming-languages&gt;&lt;math&gt;" AnswerCount="6" CommentCount="10" FavoriteCount="6" />
	<row Id="3375" PostTypeId="2" ParentId="3374" CreationDate="2017-05-25T03:31:19.040" Score="3" Body="&lt;p&gt;You'll find that both Calculus and Linear Algebra have some application in AI/ML techniques.  In many senses, you can argue that most of ML reduces to Linear Algebra, and Calculus is used in, eg. the backpropagation algorithm for training neural networks.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;You'd be well served to take a class or two in probability and statistics as well.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Programming language choice is less important, IMO.  You can do AI/ML in pretty much any mainstream language, and plenty of non-mainstream languages.  The biggest difference involve performance, and availability of libraries / tools.  C++, for example, is usually going to outperform Java or Python and it lets you get &quot;close to the metal&quot; to really maximize the capabilities of your hardware.  Python, however, has a really good FFI, and is often used in conjunction with C or C++.   Python, C++, Java, R, Octave/Matlab and a few other languages tend to have lots of high quality libraries available, which may be important to you depending on what you want to do. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;That said, you probably don't want to try and do ML / AI in, say, COBOL or PL/I or RPG/400 or something.  Stick to something at least reasonably popular.  Poke around mloss.org and look at what libraries / toolkits are available in different languages and that should help guide your choice.&lt;/p&gt;&#xA;" OwnerUserId="33" LastActivityDate="2017-05-25T03:31:19.040" CommentCount="0" />
	<row Id="3382" PostTypeId="2" ParentId="3374" CreationDate="2017-05-25T17:34:07.587" Score="11" Body="&lt;p&gt;Artificial Intelligence is a very broad field and it covers many and very deep areas of computer science, mathematics, hardware design and even biology and psychology. As for the math: I think calculus, statistics and optimization are the most important topics, but learning as much math as you can won't hurt.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There are many good free introductory resources about AI for beginners.&#xA;I highly recommend to start with this one:&#xA;&lt;a href=&quot;http://aiplaybook.a16z.com/&quot; rel=&quot;noreferrer&quot;&gt;http://aiplaybook.a16z.com/&lt;/a&gt;&#xA;They also published two videos about the general concepts of AI, you can find them on Vimeo:&#xA;&quot;AI, Deep Learning, and Machine Learning: A Primer&quot;&#xA;and&#xA;&quot;The Promise of AI&quot;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Once you have a clear understanding of the basic AI terms and approaches, you have to figure out what your goals are. What kind of AI software do you want to develop? What industries are you interested in? What are your chances to get involved in projects of big companies? It's easier to pick up the right tools when you know exactly what you want to achieve.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For most newcomers to AI the most interesting area is Deep Learning.&#xA;Just to make it clear, there are many areas of AI outside of Machine Learning and there are many areas of Machine Learning outside of Deep Learning.&#xA;(Artificial Intelligence &gt; Machine Learning &gt; Deep Learning)&#xA;Most of recent developments and hyped news are about DL.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you got interested in Deep Learning too, you have to start with learning about the concepts of artificial neural networks. Fortunately it's not too difficult to understand the basics and there are lots of tutorials, code examples and free learning resources on the web and there are many open-source frameworks to start experimenting with.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The most popular such Deep Learning framework is TensorFlow. It's backed by Google. Love it or hate it, it's a Python based framework. There are many other Python based frameworks, as well. Scikit-learn, Theano, Keras are frequently mentioned in tutorials too. (A tip: if you use Windows you can download WinPython that includes all of these frameworks.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;As for about Java frameworks, unfortunately there are not so many options. The most prominent Java framework for DL is Deeplearning4j. It's developed by a small company and its user base is much smaller then the crowd around TensorFlow. There are fewer projects and tutorials for this framework. However, industry specialists say Java based frameworks eventually integrate better with Java based Big Data solutions and they may provide a higher level of portability and easier product deployment. Just a sidenote: NASA's Jet Propulsion Laboratory used Deeplearning4j for many projects.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you decide to go with the flow and want to start learning more about TensorFlow, I recommend you to check out the YouTube channels of &quot;DeepLearning.TV&quot;, &quot;sentdex&quot; and &quot;Siraj Raval&quot;. They have nice tutorials and some cool demos. And if you decide to take a deeper dive, you can sign up for an online course at udacity or coursera.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It also may be interesting to you to know that there are other Deep Learning frameworks for the Java Virtual Machine with alternative languages, for example Clojure. ( Clojure is a dialect of LISP and it was invented by John McCarthy, the same computer scientist who coined the term &quot;artificial intelligence&quot;. In other words there are more modern and popular programming languages and tools, but it's still possible /and kinda cool/ to use the language for AI that was originally designed for AI. ThinkTopic in Boulder and Freiheit in Hamburg are two companies that use Clojure for AI projects. And if you want to see something awesome to get inspiration to use Clojure in AI and robotics, I recommend you to check out the YouTube video &quot;OSCON 2013: Carin Meier, The Joy of Flying Robots with Clojure&quot;. (Mentioning Clojure in this answer was just an example to show you there is life outside of the bubble of Python-based AI frameworks.)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(+++ Anybody feel free to correct me if I said anything wrong. +++)&lt;/p&gt;&#xA;" OwnerUserId="6933" LastEditorUserId="6933" LastEditDate="2017-05-27T10:10:40.553" LastActivityDate="2017-05-27T10:10:40.553" CommentCount="2" />
	<row Id="3383" PostTypeId="2" ParentId="3374" CreationDate="2017-05-25T19:15:57.830" Score="2" Body="&lt;p&gt;To start AI first of all understand what is AI. Why MNIST's accuracy increase rapidly after 2012. Why machine learning  need AI to increase its accuracy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;To start and build Application on Machine learning with AI you didn't need maths or some kind of rocket science. &#xA;You are late my bro people build shortcuts for all machine learning problems like a wrapper. You just need to pass data to a method and method will do all shit.&#xA;Start with MNIST's problem its exciting. Read about MNIST's history use basic algorithm on it.&#xA;Try Linear Regression, Logistic Regression,Kmean clusting, KNN .&#xA;Tools for Machine learning &#xA;Skite learn (python lib) or Tensorflow ( python lib)tflearn(higher level api of Tensorflow like a wrapper)&#xA;Both are open source. Examples are available on GitHub .&#xA;Start searching on GitHub. You found a great example. For both lib. Use kaggel to solve problem participate in comptition.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;When you complete all above algorithm try to focus on your your error. Now AI came in roll . Try to figure out how neural network help you to decrease error and increase accuracy.&#xA;Then try some basic neural network like sigmoid , relu and cnn. Don't forget to use dropout in your neural network.&#xA;You can use Tensorflow or keras or Tensorflow with keras&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Side by side check 3 Blue 1 Brown's Linear algebra video's to improve your maths. once a day but everyday one video.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And now focus on maths behind the logic(any algorithm)&#xA;You can try andrew ng machine learning course. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Use Tensorflow for building Android app,IOS app, RaspPi&#xA;Check Tensorflow dev summit 2016/2017. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Or if you need crash course then check this &lt;a href=&quot;https://youtu.be/u4alGiomYP4&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://youtu.be/u4alGiomYP4&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="7446" LastActivityDate="2017-05-25T19:15:57.830" CommentCount="2" />
	<row Id="3396" PostTypeId="2" ParentId="3374" CreationDate="2017-05-27T13:39:27.993" Score="2" Body="&lt;p&gt;When I got interested in AI, I started with the most basic things. My very first book was Russell&amp;amp;Norvig's &lt;a href=&quot;http://aima.cs.berkeley.edu/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Artificial Intelligence- A modern Approach&lt;/a&gt;. I think that's a good place to start, even if you're mostly interested in Deep Nets. It treats not just the basic AI concepts and algorithms (expert systems, depth-first and breadth-first search,knowledge representation,etc.) but also the fundamental mathematics (Bayesian reasoning, First Order Logic, NL n-grams, etc.) and some commonly known problems (as Traveling salesman problem for example). &lt;/p&gt;&#xA;&#xA;&lt;p&gt;It may also be a good idea to learn statistics, since you are particularly interested in ML. After the mentioned book, you should also have a good idea about what to learn next.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Don't care too much about the programming language. &lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;It's much more important to understand programming itself and the related techniques. Learn something about data structures, algorithms, and the different programming paradigms (like OOP, Functional Programming, etc.). Try to understand the logic behind programming and not just a particular language. After all, learning a new language isn't that hard once you understand how to program (then learning a new language is just more or less syntactic sugar).&lt;/p&gt;&#xA;" OwnerUserId="1781" LastEditorUserId="1671" LastEditDate="2018-03-09T19:02:02.363" LastActivityDate="2018-03-09T19:02:02.363" CommentCount="1" />
	<row Id="5583" PostTypeId="2" ParentId="3374" CreationDate="2018-03-08T22:27:45.270" Score="1" Body="&lt;p&gt;I am a newbie in the AI field as well. I am like you, trying to look for good resources to learn about AI and Machine Learning. Here are some resources I have found useful to get to know the basics of AI-&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=UzxYlbK2c7E&amp;amp;list=PLA89DCFA6ADACE599&quot; rel=&quot;nofollow noreferrer&quot;&gt;Andrew Ng's lecture series on AI&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=21EiKfQYZXc&quot; rel=&quot;nofollow noreferrer&quot;&gt;Andrew Ng's lecture at the Stanford Business School&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=NKpuX_yzdYs&quot; rel=&quot;nofollow noreferrer&quot;&gt;Andrew Ng - The State of Artificial Intelligence&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Andrew Ng is a visiting professor at Stanford, founder of Coursera and currently the head of research at Alibaba. The above videos should give you all the basics you need about AI.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;-Raj&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://hubs.ly/H09V9LC0&quot; rel=&quot;nofollow noreferrer&quot;&gt;Testim.io&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="13204" LastEditorUserId="13204" LastEditDate="2018-03-13T21:11:40.860" LastActivityDate="2018-03-13T21:11:40.860" CommentCount="0" />
	<row Id="5605" PostTypeId="2" ParentId="3374" CreationDate="2018-03-09T19:38:09.620" Score="2" Body="&lt;p&gt;Before getting into Artificial Intelligence, one should be done with the prerequisites. There is not a solid list, but a good knowledge of various algorithms is compulsory. Apart from that you should be comfortable with at least one programming language, like C++ or Java. I won’t suggest you to dive into Artificial Intelligence if you are completely new to Computer Science. Some experience with programming prior to diving into Artificial Intelligence will be a plus point for you.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Start reading (blogs, papers, scholar articles, etc.) about Artificial Intelligence. Like what it is, its applications, current status and other stuff that you can find. Start making AI codes for small games like Tic Tac Toe, Sudoku, Reversi (Othello), etc. for the start. You can create your own simulator and build a code that solves Rubik cube. Similarly, make codes for Pattern Recognition and Machine Learning. Nothing is better than learning by doing. Languages like LISP and python will be very helpful. Here are two answers that will help you, &lt;a href=&quot;https://ai.stackexchange.com/questions/2236/why-is-lisp-such-a-good-language-for-ai/2238#2238&quot;&gt;ans1&lt;/a&gt; and &lt;a href=&quot;https://ai.stackexchange.com/questions/3494/why-is-python-the-most-popular-language-in-the-ai-field/3503#3503&quot;&gt;ans2&lt;/a&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you are a person likes like to read and learn from books (like me), then you can buy Artificial Intelligence: A Modern Approach (Peter Norvig and Stuart Russell). The book is very good and works well for the intermediate and advanced level. Try to solve the exercise problems given in the book. The solution pdf of the books is available &lt;a href=&quot;http://qr.ae/TU8juA&quot; rel=&quot;nofollow noreferrer&quot;&gt;online&lt;/a&gt;. For Machine Learning two books that I recommend is Pattern Recognition and Machine Learning (Christopher M. Bishop) and Programming Collective Intelligence (O’Reilly).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For the start, there is a very good &lt;a href=&quot;https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;article&lt;/a&gt; on Artificial Intelligence and Technological Singularity.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The article is long and divided into two parts. I strongly recommend you to read this article if you are serious about Artificial Intelligence. It will give you some good insights.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Knowledge of Computational Theory will greatly help you. Especially when you are working in the field of Natural Language Processing. Other sub-fields of AI that might interest you will be Machine Learning, Evolutionary Computing, Genetic Algorithms, Reinforcement Learning, Deep Learning etc. The list goes on.&#xA;Better your knowledge of Statistics, better it will be for Artificial Intelligence. Stay tuned to recent goings in the field via forums, websites, etc. Open AI &lt;a href=&quot;https://openai.com/&quot; rel=&quot;nofollow noreferrer&quot;&gt;website&lt;/a&gt; is also a very good source.&lt;/p&gt;&#xA;" OwnerUserId="3005" LastEditorUserId="3005" LastEditDate="2018-03-09T22:33:01.543" LastActivityDate="2018-03-09T22:33:01.543" CommentCount="0" />
	<row Id="3494" PostTypeId="1" CreationDate="2017-06-15T09:13:48.660" Score="20" ViewCount="3703" Body="&lt;p&gt;First of all, I'm a beginner studying AI and this is not an opinion oriented question or one to compare programming languages. I'm not saying that is the best language (actually I know almost nothing about Python). But the fact is that most of the famous AI frameworks have primary support for Python. They can even be multilanguage supported, for example, TensorFlow that support Python, C++ or CNTK from Microsoft that support C# and C++, but the most used is Python (I mean more documentation, examples, bigger community, support etc). Even if you choose C# (developed by Microsoft and my primary programming language) you must have the Python environment set up.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I read in other forums that Python is preferred for AI because the code is simplified and cleaner, good for fast prototyping.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I was watching a movie with AI thematics (Ex_Machina). In some scene, the main character hacks the interface of the house automation. Guess which language was on the scene? Python.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;So what is the big deal, the relationship between Python and AI?&lt;/p&gt;&#xA;" OwnerUserId="7268" LastEditorUserId="33" LastEditDate="2017-06-20T17:48:44.027" LastActivityDate="2017-06-20T17:48:44.027" Title="Why is Python the most popular language in the AI field?" Tags="&lt;machine-learning&gt;&lt;programming-languages&gt;&lt;tensorflow&gt;" AnswerCount="4" CommentCount="0" FavoriteCount="9" />
	<row Id="3495" PostTypeId="2" ParentId="3494" CreationDate="2017-06-15T12:04:53.177" Score="4" Body="&lt;p&gt;Python has a standard library in development, and a few for AI. It has an intuitive syntax, basic control flow, and data structures. It also supports interpretive run-time, without standard compiler languages. This makes Python especially useful for prototyping algorithms for AI.&lt;/p&gt;&#xA;" OwnerUserId="7897" LastActivityDate="2017-06-15T12:04:53.177" CommentCount="1" />
  	<row Id="3496" PostTypeId="2" ParentId="3494" CreationDate="2017-06-15T13:27:43.930" Score="14" Body="&lt;p&gt;Practically all of the most popular and widely used deep-learning frameworks are implemented in Python on the surface and C/C++ under the hood.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I think the main reason is that Python is widely used in scientific and research communities, because it's easy to experiment with new ideas and code prototypes quickly in a language with minimal syntax like Python.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Moreover there may be another reason. As I can see, most of the over-hyped online courses on AI are pushing Python because it is easy for newbie programmers. AI is the new marketing hot word to sell programming courses.&#xA;( Mentioning AI can sell programming courses to kids who want to build HAL 3000, but can not even write a Hello World or drop a trend-line onto an Excel graph. :)&lt;/p&gt;&#xA;" OwnerUserId="6933" LastEditorUserId="6933" LastEditDate="2017-06-15T15:49:47.377" LastActivityDate="2017-06-15T15:49:47.377" CommentCount="0" />
  	<row Id="3503" PostTypeId="2" ParentId="3494" CreationDate="2017-06-16T05:56:16.907" Score="17" Body="&lt;p&gt;Python comes with a huge amount of inbuilt libraries. Many of the libraries are for Artificial Intelligence and Machine Learning. Some of the libraries are Tensorflow (which is high-level neural network library), scikit-learn (for data mining, data analysis and machine learning), pylearn2 (more flexible than scikit-learn), etc. The list keeps going and never ends.&lt;br&gt;&lt;br&gt;&#xA;You can find some libraries &lt;a href=&quot;https://wiki.python.org/moin/PythonForArtificialIntelligence&quot; rel=&quot;noreferrer&quot;&gt;here&lt;/a&gt;.&lt;br&gt;&lt;br&gt;&#xA;Python has an easy implementation for OpenCV. What makes Python favourite for everyone is its powerful and easy implementation.&lt;br&gt;&#xA;For other languages, students and researchers need to get to know the language before getting into ML or AI with that language. &lt;strong&gt;This is not the case with python&lt;/strong&gt;. Even a programmer with vert basic knowledge can easily handle python. Apart from that, the time someone spends on writing and debugging code in python is way less when compared to C, C++ or Java. This is exactly the students of AI and ML wants. &lt;strong&gt;They don't want to spend time on debugging the code for syntax errors, they want to spend more time on their algorithms and heuristics related to AI and ML&lt;/strong&gt;.&lt;br&gt;&#xA;&lt;strong&gt;Not just the libraries but their tutorials, handling of interfaces are easily available online&lt;/strong&gt;. People build their own libraries and upload them on GitHub or elsewhere to be used by others.&lt;br&gt;&lt;br&gt;&#xA;All these features make Python suitable for them.&lt;/p&gt;&#xA;" OwnerUserId="3005" LastActivityDate="2017-06-16T05:56:16.907" CommentCount="0" />
  	<row Id="6496" PostTypeId="2" ParentId="3494" CreationDate="2018-05-23T09:25:07.680" Score="1" Body="&lt;p&gt;What attracts me to Python for my analysis work is the &quot;full-stack&quot; of tools that are available by virtue of being designed as a general purpose language vs. R as a domain specific language. The actual data analysis is only part of the story, and Python has rich tools and a clean full-featured language to get from the beginning to the end in a single language (use of C/Fortran wrappers notwithstanding).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the front end, my work commonly starts with getting data from a variety of sources, including databases, files in various formats, or web scraping. Python support for this is good and most database or common data formats have a solid, well-maintained library available for the interface. R seems to share a general richness for data I/O, though for FITS the R package appears not to be under active development (no release of FITSio in 2.5 years?). A lot of the next stage of work typically occurs in the stage of organizing the data and doing pipeline-based processing with a lot of system-level interactions.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;On the back end, you need to be able present large data sets in a tangible way, and for me, this commonly means generating web pages. For two projects I wrote significant Django web apps for inspecting the results of large Chandra survey projects. This included a lot of scraping (multiwavelength catalogs) and so forth. These were just used internally for navigating the data set and helping in source catalog generation, but they were invaluable in the overall project.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Moving to the astronomy-specific functionality for analysis, it seems clear that the community is solidly behind Python. This is seen in the depth of available packages and level of development activity, both at an individual and institutional level (&lt;a href=&quot;http://www.astropython.org/resources&quot; rel=&quot;nofollow noreferrer&quot;&gt;http://www.astropython.org/resources&lt;/a&gt;). Given this level of infrastructure that is available and in work, I think it makes sense to direct effort to port the most useful R statistical tools for astronomy to Python. This would complement the current capability to call R functions from Python via rpy2.If you are interested, I strongly recommend that you read this article, here it is a question of comparing programming languages &lt;a href=&quot;https://diceus.com/what-technology-is-b&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://diceus.com/what-technology-is-b&lt;/a&gt; ... nd-java-r/ I hope it helps.Good Luck&lt;/p&gt;&#xA;" OwnerUserId="15811" LastActivityDate="2018-05-23T09:25:07.680" CommentCount="0" />
  	<row Id="6508" PostTypeId="2" ParentId="3494" CreationDate="2018-05-24T19:39:16.993" Score="0" Body="&lt;p&gt;That’s because python is a modern scripting object-oriented programming language that has stylish syntax. Contrary to structural programming languages like java and C++, its scripting nature enables the programmer to test his/her hypothesis very fast. Furthermore, there are lots of open source machine learning libraries (including scikit-learn and Keras) that broaden the use of python in AI field.&lt;/p&gt;&#xA;" OwnerUserId="15861" LastActivityDate="2018-05-24T19:39:16.993" CommentCount="0" />
	<row Id="5593" PostTypeId="1" AcceptedAnswerId="5603" CreationDate="2018-03-09T07:29:44.073" Score="7" ViewCount="261" Body="&lt;p&gt;What are the advantages/ strengths and disadvantages/weakness of programming languages like Common Lisp, Python and Prolog? or Why these languages are used in the domain of artificial intelligence? What type of problems related to AI are solved using these languages? Please give link of papers/ books regarding the mentioned topic.&lt;/p&gt;&#xA;" OwnerUserId="12803" LastEditorUserId="12803" LastEditDate="2018-03-09T11:21:50.513" LastActivityDate="2018-03-10T11:27:19.920" Title="Artificial Inteligence and programming languages" Tags="&lt;programming-languages&gt;&lt;problem-solving&gt;" AnswerCount="2" CommentCount="3" FavoriteCount="6" />
	<row Id="5596" PostTypeId="2" ParentId="5593" CreationDate="2018-03-09T08:53:50.123" Score="-2" Body="&lt;p&gt;Only Forth is the correct programming language for implementing an AI. Because Forth is a lowlevel and a high-level language at the same time. It supports the object-oriented paradigm, functional programming and is superior to the Z specification language. Programming a small agent in Forth is easy, here is the sourcecode for an aimbot which is levelling through a maze:&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;class Agent {&#xA;public:&#xA;  void reset() {&#xA;  }&#xA;  void followline() {&#xA;  }&#xA;  void stopwalking() {&#xA;  }&#xA;  void show() {&#xA;  }&#xA;};&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Apart from Forth no other language is recommended, for example C++ or Lisp. In theory, it is possible to create with them also working AI systems, but Forth is the more elegant way of doing so. An example, how to implement the Prolog virtual machine (PVM) in Forth is given in &lt;a href=&quot;https://www.researchgate.net/profile/Lou_Odette/publication/234780918_Compiling_Prolog_to_Forth/links/02e7e52fd0f1345936000000/Compiling-Prolog-to-Forth.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;Compiling prolog to forth&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="11571" LastActivityDate="2018-03-09T08:53:50.123" CommentCount="5" />
	<row Id="5603" PostTypeId="2" ParentId="5593" CreationDate="2018-03-09T18:58:18.777" Score="4" Body="&lt;p&gt;If we talk about applied AI, the choice of a programming language for an AI application has the same points to be taken into account that in any other software area: speed of generated code, expressive, reusable, etc.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;By example, as training of a neural net is very expensive in CPU, languages as C/C++, that produces very optimized code, are very convenient. Moreover, there are GPUs librarians in C/C++ that allows use of strong parallelism.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;A system with some complexity will combine more than one language&lt;/strong&gt;, in order to use the best of the language in the points where it is need. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;But returning to the list of languages that appears in the question. As all them are Turing complete compare them means talk about its paradigm, features, syntax and available compilers/interpreters. Obviously, something that exceeds the possibilities of a simple answer. Just to show some key points about the ones mentioned in the question:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Prolog&lt;/strong&gt; is a programming paradigm by itself. Its main advantage was that Prolog sentences are independent from remainder ones and near to the mathematical definitions of the concepts. Moreover, it is itself a database. Its drawback are also well known: very slow, lack of librarians for i/o, ... . Very interesting (even mandatory) to known a few examples of algorithms in Prolog, but I doubt nobody is using it nowadays, except in obsolete university courses (when you reach the &quot;!&quot;, cut its study).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Lisp&lt;/strong&gt; is also a zombie. Its functional paradigm has been now included in lots of very more modern languages, combining it with object oriented paradigm: scala, haskell, ocaml/F#, ... . Being functional allows a syntax that made easier to express logic concepts as recursive definition of logic or types, ... . Something very interesting in AI.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In the category of object oriented paradigm and valid for all applications, we have &lt;strong&gt;Python&lt;/strong&gt; ( easy to learn, fast prototyping, slow, ... ) C/C++ (very optimized code), Java, ... . More or less, all them are adopting also functional features in latest standards. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In AI there are a lot of very interesting language features to be also considered: rule based systems, ... . Librarians for them can be found in all main languages.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Finally, some words about AGI (strong AI): you do not need a computer. In best moments, we are at the stage of pencil and paper, remainder ones looking at ceiling.&lt;/p&gt;&#xA;" OwnerUserId="12630" LastEditorUserId="12630" LastEditDate="2018-03-10T09:25:38.747" LastActivityDate="2018-03-10T09:25:38.747" CommentCount="0" />
	<row Id="5656" PostTypeId="1" AcceptedAnswerId="5657" CreationDate="2018-03-13T03:57:18.043" Score="0" ViewCount="66" Body="&lt;p&gt;I am currently learning c #&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Any advice with this language about courses or should use another programming language,Preferred languages ​​Spanish or English&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="12179" LastActivityDate="2018-03-13T06:43:31.920" Title="It is advisable to use c # to start in the world of AI" Tags="&lt;programming-languages&gt;&lt;spanish-language&gt;" AnswerCount="1" CommentCount="3" FavoriteCount="0" />
	<row Id="5657" PostTypeId="2" ParentId="5656" CreationDate="2018-03-13T06:43:31.920" Score="1" Body="&lt;p&gt;C# is the perfect choice for programming the first Aimbot. &lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Quote: “Libraries for the large programming languages like Java and C#&#xA;  have methods for extracting the color value of a certain pixel,&#xA;  rendering this information extraction a very easy task.” &lt;a href=&quot;https://brage.bibsys.no/xmlui/bitstream/handle/11250/262729/570786_FULLTEXT01.pdf?sequence=2&quot; rel=&quot;nofollow noreferrer&quot;&gt;Cheating in&#xA;  online games: a case study of bots and bot-detection in browser-based&#xA;  multiplayer&#xA;  games&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;C# can also be used for parsing events from RTS-games.&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;Quote: “We implemented this tool in C# using Visual Studio 2008. It&#xA;  parses combat logs produced by World of Warcraft”. &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.227.2306&amp;amp;rep=rep1&amp;amp;type=pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;Sequence-Based Bot&#xA;  Detection in Massive Multiplayer Online&#xA;  Games&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;For all, who are not familiar with the concept itself: An &lt;a href=&quot;https://en.wikipedia.org/wiki/Cheating_in_online_games#Aimbots_and_triggerbots&quot; rel=&quot;nofollow noreferrer&quot;&gt;Aimbot&lt;/a&gt; is a software program to play existing computergames semi-automatically. It is similar to the “Mario AI-” and “Starcraft AI” challange, but is created outside of the university sector by beginners in Artificial Intelligence.&lt;/p&gt;&#xA;" OwnerUserId="11571" LastActivityDate="2018-03-13T06:43:31.920" CommentCount="0" />
	<row Id="6322" PostTypeId="1" CreationDate="2018-05-09T13:58:33.037" Score="4" ViewCount="716" Body="&lt;p&gt;I am a University student taking an Artificial Intelligence class this semester. Our Professor's programming language of choice is Java, but it seems that perhaps with some nudging, he can change it to Python.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I wanted to know if there is any merit in doing so. I know a programming language is just a programming language - however, given the industry's wide use of Python when implementing AI algorithms (especially with ML), I think it makes much more sense for us to use Python. It will be easier to transition from a University environment to an Industrial one having done several assignments in Python and having a clear understanding of all the tools it provides than if we continue using Java, correct?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;What are your thoughts?&lt;/p&gt;&#xA;" OwnerUserId="15529" LastEditorUserId="1671" LastEditDate="2018-05-09T19:31:20.113" LastActivityDate="2018-05-10T09:41:05.900" Title="Learning Artificial Intelligence with Python vs. Java" Tags="&lt;ai-design&gt;&lt;python&gt;&lt;programming-languages&gt;&lt;java&gt;" AnswerCount="4" CommentCount="1" />
	<row Id="6324" PostTypeId="2" ParentId="6322" CreationDate="2018-05-09T14:45:59.173" Score="2" Body="&lt;p&gt;I don't think there is much merit in using one language over the other.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It's true that you will get a better feeling for what libraries etc. are available in Python when using it, but I think it's more important to focus on the mathematics and application of the algorithms and techniques you will learn, as these will be relevant regardless of the language / library you end up using.&lt;/p&gt;&#xA;" OwnerUserId="15533" LastActivityDate="2018-05-09T14:45:59.173" CommentCount="0" />
	<row Id="6328" PostTypeId="2" ParentId="6322" CreationDate="2018-05-09T22:28:01.127" Score="3" Body="&lt;p&gt;While dyedgreen is right in some respects, I don't agree entirely with that sentiment. Sure, you can theoretically use any language as long as you know the maths and understand the concepts inside and out whilst having some applicable knowledge. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;However, I don't believe if you are starting from scratch, you should learn to develop models in Java. While the underlying material is the same, all you are doing is wasting time IMO learning a language that is rarely used in the field and lacks sufficient support by most modern ML frameworks. Also, while this is rather subjective, python feels better when used as a data science language. Working with data especially is where that difference is clear to me. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;That being said, this could all change, and Java could become the ML language of choice(extremely unlikely).&lt;/p&gt;&#xA;" OwnerUserId="9608" LastEditorUserId="9608" LastEditDate="2018-05-10T00:40:09.663" LastActivityDate="2018-05-10T00:40:09.663" CommentCount="0" />
	<row Id="6331" PostTypeId="2" ParentId="6322" CreationDate="2018-05-10T02:24:31.313" Score="2" Body="&lt;p&gt;I'm going to go ahead and disagree with the others.  From an academic perspective for AI or any CS related assignment Java (or C or C++) will always have much more benefit as you will get to write the actual code instead of using libraries others have already written.  That way later on when you transition to Python or whatever language you choose you'll know whats under the hood and use it and optimise it more effectively than someone who only knows which libraries to use for what application.&lt;/p&gt;&#xA;" OwnerUserId="9413" LastActivityDate="2018-05-10T02:24:31.313" CommentCount="5" />
	<row Id="6341" PostTypeId="2" ParentId="6322" CreationDate="2018-05-10T09:41:05.900" Score="0" Body="&lt;p&gt;To add a few cents, I do not think it will make any difference. The reason is that the content of the course will be, by design (if you can teach it using java), very general, general enough so it will not matter what language you use (this has to be so otherwise you would not be able to use Java). Once you need to do advanced stuff and want to automatize the basic algorithms, you can switch to python, where you can use super advanced API's like Keras, which is on top of tensorflow which is on top of python. To give you a particular example,  with full time dedication you should be able to  switch from matlab to python and implement your first keras model, by self learning, in not more than a couple of months.  &lt;/p&gt;&#xA;" OwnerUserId="5911" LastActivityDate="2018-05-10T09:41:05.900" CommentCount="0" />
	<row Id="6909" PostTypeId="1" CreationDate="2018-06-27T09:25:31.037" Score="2" ViewCount="88" Body="&lt;p&gt;I am currently studying information systems engineering (BA) and I'm thinking of getting a master degree in Artificial Intelligence.So, What are the main important skills do I need to succeed at this field, and what kind of math does it require?&lt;/p&gt;&#xA;" OwnerUserId="16547" LastEditorUserId="1671" LastEditDate="2018-06-27T18:27:12.983" LastActivityDate="2018-06-27T18:27:12.983" Title="What skills are needed to succeed at artificial intelligence field?" Tags="&lt;deep-learning&gt;&lt;ai-basics&gt;&lt;programming-languages&gt;&lt;soft-question&gt;" AnswerCount="2" CommentCount="3" />
	<row Id="6910" PostTypeId="2" ParentId="6909" CreationDate="2018-06-27T10:27:44.683" Score="3" Body="&lt;p&gt;Hey the main important skill you need is self discipline :).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For math:- &#xA;i believe you need to know alot of statistics and probability(Most machine learning algorithms are build on statistics),Vectors and Matrices, calculus.&#xA;Programming:-&#xA;Python for data science but not limited to python there are a couple of libraries in other programming languages that can help, you can use R for a mathematical(statistical approach to ai).. &#xA;............&#xA;If you want to go to the theoretical(algorithmic) side work mostly on R and research and mathematics(from both pure and applied math branches)..&#xA;If you want the applied side of ai.... work on programming languages preferably python and get farmiliar with data science libraries and working with big data(things like knowledge in hadoop can also help) &lt;/p&gt;&#xA;" OwnerUserId="8680" LastActivityDate="2018-06-27T10:27:44.683" CommentCount="1" />
  	<row Id="6911" PostTypeId="2" ParentId="6909" CreationDate="2018-06-27T12:51:40.050" Score="1" Body="&lt;p&gt;&quot;artificial intelligence&quot; is now a mature field and there are many subfields in it. there are entire theories erected around each subfield of artificial intelligence. a simple analogy would like &quot;what are the skills needed for succeeding in mathematics/physics?&quot;. the answer really depends on what branch you want to delve into. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;if you are planning to go into more application specific side of artificial intelligence (machine learning/ deep learning) then you must be thorough with linear algebra . since most of machine learning algorithms can be boiled down to simple tricks in linear algebra. learning about optimization will help a lot because you will encounter many algorithms involving convex/nonconvex optimization methods. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also statistics and probability are must for any field in artificial algorithms.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;That said, at core artificial intelligence deals with machines that think.&#xA;So it would be better if you are through with formal logic , automata and complexity theory . &lt;/p&gt;&#xA;" OwnerUserId="15935" LastActivityDate="2018-06-27T12:51:40.050" CommentCount="0" />
	<row Id="7108" PostTypeId="1" CreationDate="2018-07-10T21:17:29.053" Score="2" ViewCount="52" Body="&lt;p&gt;I am learning about Restricted Boltzmann Machines and I'm so excited by the ability it gives us for unsupervised learning. The problem is that I do not know how to implement it using one of the programming languages I know without using libraries. I want to implement it manually, which means that I want to use native functionalities of a language as much as possible.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The programming languages I know are Java, C, PHP (my preferred language), JavaScript, R and Python. I am not familiar with TensorFlow or Scikit-Learn or similar stuff. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks in advance&lt;/p&gt;&#xA;" OwnerUserId="11589" LastActivityDate="2018-07-11T07:34:38.460" Title="How to implement a Restricted Boltzmann Machine manually?" Tags="&lt;programming-languages&gt;&lt;implementation&gt;&lt;boltzmann-machine&gt;" AnswerCount="2" CommentCount="1" />
	<row Id="7113" PostTypeId="2" ParentId="7108" CreationDate="2018-07-11T04:00:38.433" Score="1" Body="&lt;p&gt;If you already know Java, you may wish to investigage Java-ML, Mahout, MLib, and DL4J for AI experimentation and research.  Once you have visualizations to publish from your investigation, you can couch them in PHP for web publication. Also, use of RBMs has been giving way to convolution layering and other types of auto-encoding and feature extraction designs.&lt;/p&gt;&#xA;" OwnerUserId="9203" LastActivityDate="2018-07-11T04:00:38.433" CommentCount="2" />
	<row Id="7116" PostTypeId="2" ParentId="7108" CreationDate="2018-07-11T07:34:38.460" Score="1" Body="&lt;p&gt;If your interest is to follow the hype and become an &quot;expert&quot; in machine learning so that we can automate the world the rest of the way and our grandchildren can just play golf and video games, then the fast path is to learn TensorFlow, Scikit-Learn, or Keras while making money writing PHP apps for fortune 500 companies.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can begin by finding some RBM example code that looks like it executes and has some example data or a link to some.  Then download whatever of those common frameworks they use, and then study by following the path of least resistance as if you were a machine learning.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;No joke.  Many will make money from big corporations that way and probably already are.  Also if the reason you want to do the RBMs manually is you want to see how they work, this is the way to go.  Take apart what others wrote like you would an old lawnmower to learn about internal combustion engines.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If your interest is to learn about the nature of intelligence and consciousness because you like to discover new things, then take the trendy frameworks less seriously and learn what RBMs are and why they are being superseded by other architectures.  In that case, learning about probability, calculus, and searching algorighms in 2D, 3D, and higher dimensions (and reading books that most of the trendy people would think were dated) is the best direction.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you want to see if, in your lifetime, you can create a digital brain that you can teach to fix the lawnmower and then go mow your lawn (also no joke) then learn to code in C and C++ and learn sockets, other systems level programming, and how to access the DSP in a video card because your going to need some blinding speed and parallelism.&lt;/p&gt;&#xA;" OwnerUserId="4302" LastActivityDate="2018-07-11T07:34:38.460" CommentCount="1" />
	<row Id="7205" PostTypeId="1" AcceptedAnswerId="7227" CreationDate="2018-07-19T12:23:23.540" Score="8" ViewCount="438" Body="&lt;p&gt;I like the enforced indentation of Python that many don't like because I hate parenthetic typing and redundant semicolons.  I like the shell interface, but why do some think Python is &lt;em&gt;de facto&lt;/em&gt; for machine learning?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Even with straight rectified linear activation, because of sheer dimensionality, simulating circuits comprised of artificial neurons places large demands upon computing resources.  Processing video in a typical adversarial artificial network algorithm requires seven nested loops.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Adversarial pair iteration&lt;/li&gt;&#xA;&lt;li&gt;Neural net layer depth&lt;/li&gt;&#xA;&lt;li&gt;Sample index&lt;/li&gt;&#xA;&lt;li&gt;Frame index&lt;/li&gt;&#xA;&lt;li&gt;Pixel depth&lt;/li&gt;&#xA;&lt;li&gt;Vertical&lt;/li&gt;&#xA;&lt;li&gt;Horizontal&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;We call the filter for convolution a &quot;kernel&quot; and pawn it off to DSPs in GPUs to squeeze out performance then use a scripting language to code in.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why wouldn't we write deep learning code like Linus Torvalds writes kernel code, with &lt;code&gt;gcc -S&lt;/code&gt; so we can make sure the assembly language is efficient and there are almost no cache misses?  From a performance point of view, one could fly to the moon and back with C before Python even broke the tree line.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In terms of ease of experimentation, C++ is plenty object oriented so that clean abstractions can be written as .hpp files to configure and govern the kernel-efficient C that does the mechanics of parameter optimization.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;We type on keyboards to code and bloc, we program microwave ovens, and some of us play musical keyboards that nicely simulate pianos.  We then forget it is C/C++ underneath these highly intuitive user interfaces.  I frankly, don't buy the Python argument yet.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Most of us understand that Python wrappers have been created around the efficient matrix algorithms written in FORTRAN and ported to C, and that the Python constructs for ML are relatively elegant, but is that a good reason to dismiss the fact that many C++ libraries for ML that are also elegant have been developed?&lt;/p&gt;&#xA;" OwnerUserId="4302" LastEditorUserId="4302" LastEditDate="2018-10-15T23:34:53.140" LastActivityDate="2018-10-15T23:34:53.140" Title="Why Python not C?" Tags="&lt;convolutional-neural-networks&gt;&lt;programming-languages&gt;&lt;performance&gt;&lt;efficiency&gt;&lt;tools&gt;" AnswerCount="6" CommentCount="5" FavoriteCount="5" />
	<row Id="7206" PostTypeId="2" ParentId="7205" CreationDate="2018-07-19T12:37:58.577" Score="4" Body="&lt;p&gt;The thing you are probably looking for is:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/X6lFq.jpg&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/X6lFq.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Let us see this question from 2 viewpoints:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Beginner:&lt;/strong&gt; From a viewpoint of beginner, he needs to understand how to implement a model before optimising it. He first needs to visualise the model, see the kinds of bugs that creep in, experiment with the model to gain more intuition. Certainly possible in C/C++. But is it worth it? The time the person would take to write/debug the code in C/C++ will far outweigh the time to create i in Python/MATLAB/R. So after he gains some intermediate implementation knowledge then he can move on with C/C++. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;Experts:&lt;/strong&gt; By experts I mean programming experts. They most certainly and easily use C/C++. But the main information you missed is TensorFlow which is a ML library by itself and also serves as a core for other high level ML libraries like Keras is programmed in C++ itself. &lt;a href=&quot;https://stackoverflow.com/questions/35677724/tensorflow-why-was-python-the-chosen-language&quot;&gt;Here&lt;/a&gt; is more info about it. So if I am not wrong TensorFlow creates a computational graph before taking in any data, and then runs that graph on the data generally &lt;strong&gt;completely loaded&lt;/strong&gt; in the RAM. So no intereference of Python in between. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also code readability is a massive problem (at-least I face it), Writing ML algorithm in C/C++ will take huge amounts of code which may become unreadable if you look at it after a week or so if not well documented. Whereas due to inbuilt python functions you can easily read the program.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Advice from Machine Learning expert Andrew Ng, use languages like C/C++ to implement your model once you have verified your model works in a higher level language like MATLAB.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also as  @FauChristian mentioned library support is impeccable, you can combine various other libraries in other fields to convert data into a ML form which will then be used in your ML model.&lt;/p&gt;&#xA;" OwnerUserId="9947" LastEditorUserId="9947" LastEditDate="2018-08-04T13:42:28.087" LastActivityDate="2018-08-04T13:42:28.087" CommentCount="0" />
	<row Id="7216" PostTypeId="2" ParentId="7205" CreationDate="2018-07-20T09:44:19.753" Score="4" Body="&lt;p&gt;Because there is a library for Python named &lt;strong&gt;NumPy&lt;/strong&gt;.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;It can do extremely fast computations on n-dimensional arrays of numbers, and all kinds of scientific / machine learning / image processing etc libraries are built on top of it.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You don't do actual computation in Python &lt;code&gt;for&lt;/code&gt; loops, that's really slow. You call Numpy matrix operations, and they are themselves &lt;em&gt;written in C&lt;/em&gt; (and partly in Fortran if I recall correctly, not sure if that's still the case) and mercilessly optimized for speed over the years.&lt;/p&gt;&#xA;" OwnerUserId="17003" LastActivityDate="2018-07-20T09:44:19.753" CommentCount="0" />
	<row Id="7221" PostTypeId="2" ParentId="7205" CreationDate="2018-07-20T13:57:24.910" Score="1" Body="&lt;p&gt;The primary reason for Python being preferred is overhead. C++ automatically entails greater overhead in terms of the amount of code required to do any particular thing. Artificial intelligence is difficult to understand conceptually already, which makes programming overhead a larger issue.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;With C++ modules being a way to extend the Python language, there is very little reason to not use Python. It is easier to transfer knowledge of programming in C++ to Python rather than figuring out a way to program a library in C++ extensive enough to match the current body of knowledge already incorporated into Python.&lt;/p&gt;&#xA;" OwnerUserId="16959" LastActivityDate="2018-07-20T13:57:24.910" CommentCount="1" />
	<row Id="7223" PostTypeId="2" ParentId="7205" CreationDate="2018-07-20T17:43:39.883" Score="2" Body="&lt;p&gt;In AI (and probably many other domains as well), time spent by the human programmers tends to be significantly more valuable / expensive than time spent running a program. Of course this is not always the case (just like it's not always the case that Python is used rather than C or C++), but it is often true.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Especially in the case of research, it's extremely important to be able to iterate over ideas rapidly. We need to be able to rapidly implement new ideas, test them, probably go through a few iterations of bugfixing, test again, etc. It's quite rare that the bottleneck in this iteration of ideas is the runtime of a new idea/algorithm. The human's time spent programming tends to be a bottleneck much more often. Ideas can often be tested rapidly on small toy problems which don't take a lot of runtime anyway, or run overnight / run while the programmer is busy writing other code.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Doing all that iterating, quickly implementing new ideas etc. tends to be easier / faster in Python than in C or C++. Of course this is not necessarily true for everyone, if someone already has a lot of experience in C++ and little experience in Python, they may be able to implement new ideas more quickly in C++. This does not appear to be the case for the majority of people though. Clear advantages that Python has in terms of how quickly new ideas can be implemented include:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Less verbose, don't need to type as much (e.g., &lt;code&gt;results = []&lt;/code&gt; in Python vs &lt;code&gt;std::vector&amp;lt;double&amp;gt; results;&lt;/code&gt; in C++ to create an empty list that we can start appending some results to in an experiment). &lt;/li&gt;&#xA;&lt;li&gt;No need to worry about memory management, pointers, all that stuff, which can be doable with experience but does inevitably require attention, has a greater likelihood of leading to extra bugs, etc.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;No need to go through compilation/build process&lt;/strong&gt;. This can be a very big one, which is easy to forget about.&lt;/li&gt;&#xA;&lt;li&gt;Much less of a hassle to have data structures containing stuff of different types (e.g. &lt;code&gt;config = {'algorithm': 'RandomForest', 'n_trees': 50}&lt;/code&gt; in Python vs.... no idea in C++)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Another key point is that &lt;strong&gt;the majority of code that people in AI write is not the performance-sensitive parts&lt;/strong&gt;. Again, may not be true for everyone, but is true especially in research settings. Most researchers don't spend the majority of their time writing code for forwards / backwards passes in a Neural Network. &lt;strong&gt;They spend much more time on stuff like:&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Preprocessing data (not always easy to write easily re-usable code, significant chunks will be project-specific / dataset-specific)&lt;/li&gt;&#xA;&lt;li&gt;Experiment setup (e.g. outer training loops, printing/logging results, ...)&lt;/li&gt;&#xA;&lt;li&gt;Processing results, creating all kinds of fancy plots, etc.&lt;/li&gt;&#xA;&lt;li&gt;Brand new (parts of) algorithms (e.g. a new variant in the list of SGD/RMSProp/ADAM/etc., likely just a couple of lines of simple code that can be plugged straight into an existing framework, with a lot more pen&amp;amp;paper math behind it).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Now that last point may in some cases be performance-sensitive, but still, the initial concern will not be performance. The initial concern will be; will it work at all? This can be evaluated on simpler problems or with less performant code simply by waiting a bit longer first, it's still more important to be able to implement it at all first. As mentioned in other answers, thanks to C-based frameworks like &lt;code&gt;Tensorflow&lt;/code&gt; and &lt;code&gt;numpy&lt;/code&gt;, these can quite often be performant even from Python though.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Finally, the existence of well-known, easy-to-use, established, open source libraries and frameworks that have stood the test of time is extremely important. In Python, we have:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Numpy&lt;/li&gt;&#xA;&lt;li&gt;Pandas&lt;/li&gt;&#xA;&lt;li&gt;Matplotlib, Seaborn&lt;/li&gt;&#xA;&lt;li&gt;scikit-learn&lt;/li&gt;&#xA;&lt;li&gt;Tensorflow, Pytorch&lt;/li&gt;&#xA;&lt;li&gt;XGBoost&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Again, many of those have parts implemented in C/C++ when performance matters too.&lt;/p&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;&lt;p&gt;Note that, when I'm talking about research, this doesn't just mean &quot;academia&quot;. AI in industry will also often have some flavour of research. People in industry are unlikely to be implementing Neural Networks from scratch over and over and over again. They're much more likely to be re-using implementations that are already efficient (e.g. Tensorflow), but be trying to apply them to new data (where they'll have to write some new boilerplate code around it, which is quick and easy in Python), or trying new architectures, or trying to visualize data and/or results, etc.&lt;/p&gt;&#xA;" OwnerUserId="1641" LastEditorUserId="1641" LastEditDate="2018-07-20T18:10:04.883" LastActivityDate="2018-07-20T18:10:04.883" CommentCount="2" />
	<row Id="7227" PostTypeId="2" ParentId="7205" CreationDate="2018-07-20T19:00:45.797" Score="1" Body="&lt;p&gt;Python is popular for rapid prototyping for several reasons.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It is a platform with a shell like Mathematica and MATLAB&lt;/li&gt;&#xA;&lt;li&gt;It has built in matrix and other mathematical types&lt;/li&gt;&#xA;&lt;li&gt;It is free, unlike those proprietary platforms&lt;/li&gt;&#xA;&lt;li&gt;It's libraries in the ML space is currently more mature than SciLab&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;" OwnerUserId="9203" LastEditorUserId="9203" LastEditDate="2018-07-22T09:07:05.670" LastActivityDate="2018-07-22T09:07:05.670" CommentCount="2" />
	<row Id="7320" PostTypeId="2" ParentId="7205" CreationDate="2018-07-28T21:36:13.623" Score="1" Body="&lt;p&gt;Because, while C/C++ are not &lt;a href=&quot;http://trevorjim.com/c-and-c++-are-dead-like-cobol-in-2017/&quot; rel=&quot;nofollow noreferrer&quot;&gt;dead&lt;/a&gt;, they're hard to use and hard to learn. I used to like them, but now, nobody would make me learn a thing with features like &lt;a href=&quot;https://en.wikipedia.org/wiki/Undefined_behavior&quot; rel=&quot;nofollow noreferrer&quot;&gt;undefined behavior&lt;/a&gt;. No way! Memory management? Why should I? I just don't want to waste my time on such stuff... &lt;em&gt;and I guess, that's the common attitude among students.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;There'll be always people loving &quot;the old good low level C&quot; and that's a good thing as we need kernels and drivers and such. It has its place.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;C++ is higher level, but it's become much too complicated for most of us, who prefer to spend learning time on algorithms rather than on the language itself.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Everything what can be reasonably done with less effort, should not be done with more effort. I was using C++ for years (some long time ago), and spend only a few hours with Python, but I'd always choose the latter for a few thousand lines project because of the efficiency of coding.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The efficiency of execution may be improved later, possibly even by rewriting a small part in C++. Oftentimes, more can be gained by implementing a smarter algorithm.&lt;/p&gt;&#xA;" OwnerUserId="12053" LastActivityDate="2018-07-28T21:36:13.623" CommentCount="1" />
	<row Id="7364" PostTypeId="1" CreationDate="2018-07-31T20:31:43.493" Score="3" ViewCount="103" Body="&lt;p&gt;Does an application exist that can automatically write and test a software component based on a formal functional specification?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The twentieth century saw the initial birth of electronic computers.  The early programming languages that were in primary use by 1975 were COBOL, FORTRAN, LISP, and C and UNIX were emerging for real time communications and control.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Shortly after this period two conceptual steps were proposed toward &lt;strong&gt;&lt;em&gt;executable requirements&lt;/em&gt;&lt;/strong&gt;, which, combined with natural language dialog, would permit the realization of computers that would execute high level instructions in a user's native tongue.&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Glenford J. Myers' &lt;em&gt;Advances in computer architecture&lt;/em&gt;, Wiley; 1st edition, 1978, puts forth the proposition that computers had been designed from the bottom up, creating serious obstacles in use.  He redefined the common term at the time, &lt;strong&gt;&lt;em&gt;semantic gap&lt;/em&gt;&lt;/strong&gt;, to mean the gap between the needs of those that program computers and the facilities of the computer architecture.  This thinking led to object oriented design and supporting languages such as C++, Java, EMMASCript, and Python.  (Myers worked for IBM but was recruited by a small startup company called Intel to help them design their first 32-bit architecture, the 80386.)&lt;/li&gt;&#xA;&lt;li&gt;Gene Fisher, Professor Emeritus, California Poly San Luis Obispo, proposed in 1988 what he called a, &quot;Tool for constructing executable block diagrams based,&quot; conceptually more advanced than graphical simulators like Simulink and more advanced than IDEs like Eclipse, Idea, and Jupyter interfaces..  JModelica is probably one of the closest development applications to Fisher's vision.  The term that has become popular in the literature for this concept is &lt;strong&gt;&lt;em&gt;executable diagram&lt;/em&gt;&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;Are there any applications in beta or in common use in some segment of the software industry where a formal requirement can be entered as input to a program writing application and tested source code is produced at the output?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is anyone working on an application that takes this one step further to a computer that gathers requirements through natural dialog?&lt;/p&gt;&#xA;" OwnerUserId="17209" LastEditorUserId="4302" LastEditDate="2018-10-08T11:56:05.443" LastActivityDate="2018-10-08T11:56:05.443" Title="Does an application that can write software exist?" Tags="&lt;strong-ai&gt;&lt;language-processing&gt;&lt;programming-languages&gt;" AnswerCount="3" CommentCount="3" FavoriteCount="1" />
	<row Id="7365" PostTypeId="2" ParentId="7364" CreationDate="2018-08-01T02:22:03.500" Score="4" Body="&lt;p&gt;Yes.  See &lt;a href=&quot;https://www.futurity.org/artificial-intelligence-bayou-coding-1740702/&quot; rel=&quot;nofollow noreferrer&quot;&gt;&quot;New A.I. application can write its own code&quot;&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Some excerpts:&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Computer scientists have created a deep-learning, software-coding application that can help human programmers navigate the growing multitude of often-undocumented application programming interfaces, or APIs.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Designing applications that can program computers is a long-sought grail of the branch of computer science called artificial intelligence (AI). The new application, called Bayou, came out of an initiative aimed at extracting knowledge from online source code repositories like GitHub. Users can try it out at askbayou.com.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;The researchers wrote a paper: &lt;a href=&quot;https://arxiv.org/pdf/1703.05698.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;Neural Sketch Learning for Conditional Program Generation&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="5763" LastActivityDate="2018-08-01T02:22:03.500" CommentCount="0" />
  	<row Id="7382" PostTypeId="2" ParentId="7364" CreationDate="2018-08-01T19:15:44.193" Score="1" Body="&lt;p&gt;The other answers cover modern work on this, but it's not even a new topic!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;http://www.genetic-programming.org/gpbook1toc.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;Koza's work&lt;/a&gt; in 1992 led to whole sub-fields doing this. The techniques are widely used, robust, and well understood. They're just very computationally expensive. Enough so that most of the time you're better off just hiring a programmer to do it.&lt;/p&gt;&#xA;" OwnerUserId="16909" LastActivityDate="2018-08-01T19:15:44.193" CommentCount="0" />
  	<row Id="7366" PostTypeId="2" ParentId="7364" CreationDate="2018-08-01T06:17:33.903" Score="4" Body="&lt;p&gt;Yes, we do have Neural Program Synthesis.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Using Neural Networks to generate piece of code.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Please have a look at: &lt;a href=&quot;https://www.microsoft.com/en-us/research/project/neural-program-synthesis/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Microsoft Research Project on the same&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="17192" LastActivityDate="2018-08-01T06:17:33.903" CommentCount="0" />
	<row Id="8227" PostTypeId="1" AcceptedAnswerId="8229" CreationDate="2018-10-02T17:58:58.710" Score="1" ViewCount="228" Body="&lt;p&gt;So guys, I've been seeing a lot of tutorials on the Internet about AI that are mostly done with Python. Apart from these, I've seen C# being used in AI topics but in things like for example &quot;Self-Driving cars&quot;, I've seen Python and not C# or any other languages. I wanted to ask, do you recommend that I learn Python? Because I know C# and I wanted to become more professional in it, but, now that I see that Python is being used a lot, I'm getting intrigued in it. Do you recommend Python or other languages or should I keep up with C#?&#xA;Just to mention, I'm 14 years old and I have enough time to learn more and it doesn't really matter what I love to do, because, I love coding and AI specially, so, it doesn't really matter. If it's not a waste of time, I should get started, right? If you recommend Python, please tell me which compiler I should use. I don't really know if it has a compiler, but I want to know where I should start from. Thanks.&lt;/p&gt;&#xA;" OwnerUserId="18595" LastActivityDate="2018-10-03T07:03:26.027" Title="C# or Python for AI?" Tags="&lt;getting-started&gt;&lt;programming-languages&gt;" AnswerCount="2" CommentCount="8" />
	<row Id="8229" PostTypeId="2" ParentId="8227" CreationDate="2018-10-03T02:37:35.137" Score="2" Body="&lt;p&gt;If you're doing deep learning (which I assume you are, if you say you want to learn &quot;AI&quot;), then Python is a MUST. Virtually all the big frameworks are Python wrappers over a C++ core.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;C# has no real deep learning frameworks. There are a couple such as the Microsoft Cognitive Toolkit, but they are on a completely different level from PyTorch or Tensorflow. No serious ML practitioner would do the majority of their research in a framework like that.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For more information, see: &lt;a href=&quot;https://ai.stackexchange.com/questions/3494/why-is-python-the-most-popular-language-in-the-ai-field/3503#3503&quot;&gt;Why is Python the most popular language in the AI field?&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="16035" LastActivityDate="2018-10-03T02:37:35.137" CommentCount="0" />
	<row Id="8235" PostTypeId="2" ParentId="8227" CreationDate="2018-10-03T07:03:26.027" Score="1" Body="&lt;p&gt;Corporations, government research, and academia are favoring C, Python, Java, LISP, and R currently.  The trends are not favorable to C# for AI.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;C#'s peak of use was in the 2009 to 2012 range.  By buying GitHub, Microsoft intends to regain some control over development tools and language but has never been particularly successful in either.  Even eclipse is giving way to other open tools or proprietary tools with community versions, and JavaScript and Python are the languages gaining popularity in this decade.  It is not clear whether C# will be very well known as a general purpose programming in ten years. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;C/C++, Java, and JavaScript have stood the test of time.  C/C++ is the language of choice for low level access to dedicated hardware, which is what it was designed by Bell Labs to do.  Java is almost as fast and still very popular, strongly OO, still developing, and with Scala, Groovy, Maven, and Gradle, looking strong for the future.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Python started slow but has seen continuous rapid growth trend for the last two years because of its MATLAB-ish-ness and syntactic clarity.  JavaScript, with its heavy influence from LISP and Scheme from the birth of AI, will likely enter in greater strength as AI reaches the front end and middle tiers of web applications.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;C# doesn't look hopeful for keep pace.&lt;/p&gt;&#xA;" OwnerUserId="18663" LastActivityDate="2018-10-03T07:03:26.027" CommentCount="1" />
	<row Id="8273" PostTypeId="1" CreationDate="2018-10-05T19:59:52.837" Score="1" ViewCount="20" Body="&lt;p&gt;We are currently working on developing a 3D modeling software that allows designers to set spatial constraints to models. The computer then should generate a 3D mesh conforming to these constraints.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Why should or shouldn't we use Lisp for the constraint satisfaction part? Will Prolog environment be any better? Or should we stick to C/C++ libraries?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One requirement we have is that we want to use the Unity Game Engine as it has a lot of 3D tools built in&lt;/p&gt;&#xA;" OwnerUserId="18726" LastActivityDate="2018-11-04T23:00:36.817" Title="What are the advantages and disadvantages of using LISP for constraint satisfaction in 3D space" Tags="&lt;optimization&gt;&lt;programming-languages&gt;&lt;lisp&gt;&lt;prolog&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="8276" PostTypeId="2" ParentId="8273" CreationDate="2018-10-05T22:53:33.130" Score="0" Body="&lt;p&gt;This is actually a question which will only receive opinion based answer's. A question you should ask yourself is if the constraint part is really that complex that it is worth to use a different programming language. Unity itself offers a C# API [1] and I would therefore stick with that.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;[1] &lt;a href=&quot;https://unity3d.com/programming-in-unity&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://unity3d.com/programming-in-unity&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="10228" LastActivityDate="2018-10-05T22:53:33.130" CommentCount="0" />
	<row Id="8548" PostTypeId="1" AcceptedAnswerId="8552" CreationDate="2018-10-21T08:17:40.687" Score="1" ViewCount="52" Body="&lt;p&gt;What is the best and easiest programming language to learn to implement Genetic algorithms? C++ or Python or any other?&lt;/p&gt;&#xA;" OwnerUserId="19192" LastEditorUserId="9947" LastEditDate="2018-10-21T09:34:24.130" LastActivityDate="2018-10-21T23:15:05.787" Title="Learning Genetic algorithm for beginners" Tags="&lt;genetic-algorithms&gt;&lt;programming-languages&gt;&lt;genetic-programming&gt;" AnswerCount="2" CommentCount="0" />
	<row Id="4964" PostTypeId="1" CreationDate="2018-01-10T13:21:00.913" Score="2" ViewCount="64" Body="&lt;p&gt;I am making my speech recognition project for PC (working on Windows 8) and am new in this area.  The project should have basic functionality like dictation with accuracy in email, notepad, etc., and should respond to local commands of PC.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I am using &lt;a href=&quot;https://cmusphinx.github.io/wiki/tutorialsphinx4/&quot; rel=&quot;nofollow noreferrer&quot;&gt;sphinx4&lt;/a&gt; for my speech recognition project.  I'm trying to determine if there is there is a better open source API than CMU Sphinx in terms of accuracy and large vocabulary? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Does Kaldi (deep neural network based) perform better than CMU Sphinx (HMM based)?  Are the two platforms better for different kinds of applications?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Essentially:&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;I want to increase my speech recognition system accuracy and vocabulary.  Which might be most optimal: &lt;a href=&quot;http://kaldi-asr.org/doc/about.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;Kaldi&lt;/a&gt; or &lt;a href=&quot;http://www.speech.cs.cmu.edu/sphinx/doc/Sphinx.html&quot; rel=&quot;nofollow noreferrer&quot;&gt;CMU Sphinx&lt;/a&gt;?&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;Also wondering what is the difference between a speech API and a speech Engine, and, more generally, as a developer what I will require to develop my software?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Please help me to get a clear understanding about above questions and, if possible, provide some speech recognition developer or researcher community links.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Any and all comments, suggestions and answers are welcome!&lt;/p&gt;&#xA;" OwnerUserId="12043" LastEditorUserId="1671" LastEditDate="2018-01-12T20:03:14.943" LastActivityDate="2018-02-15T13:44:07.423" Title="speech recognition software implementation by open source API" Tags="&lt;neural-networks&gt;&lt;voice-recognition&gt;&lt;getting-started&gt;&lt;software-evaluation&gt;" AnswerCount="1" CommentCount="2" FavoriteCount="1" />
	<row Id="5024" PostTypeId="2" ParentId="4964" CreationDate="2018-01-16T13:10:05.903" Score="1" Body="&lt;p&gt;The difference between a Speech API and a Speech Engine is: Speech API's enable developers to integrate speech recognition technologies into developer apps. On the other hand a speech engine is software that gives your computer the ability to play back text in a spoken voice. (Source msdn library)&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Below is a list of speech recognition tool-kits and their features.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Tensorflow - Although tensorflow doesn't arrive packaged with speech recognition libraries by default. You can use seq2seq models which have achieved high levels of accuracy in speech recognition. A few of the advantages of using tensorflow for speech recognition include: It comes with tensorboard which is useful in visualising and fine-tuning your network, it's architecture is highly modular which allows you to experiment with different voice libraries and finally it is portable meaning you can run it on GPU's, CPU's, servers or even mobile computing platforms. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Microsoft's CNTK - Microsofts Cognitive Toolkit delivers excellent results when it come to speech recognition. In recent times CNTK has outperformed humans in transcribing speech to text. Some of its perks are its efficient resource usage additionally it was originally built for speech recognition systems and consequently it is very effective at working with time series data. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;CMU Sphinx - CMU Sphinx is a speech recognition system developed at Carnegie Mellon University. The advantages of using CMU Sphinx are: it is multilingual and supports most international languages, it has excellent commercial support, it has a light mobile version called pocketsphinx, it has a wide range of tools for different purposes i.e. keyword spotting, alignment and pronunciation evaluation. It also enjoys active support from the Carnegie Mellon University.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Kaldi - Kaldi aims to provide speech recognition software that is flexible and extensible. Kaldi has powerful features such as pipelines that are highly optimized for parallel computing i.e. training models on the GPU. Additionally it supports speaker identification and detection of errors in transcripts.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;Mozilla Deep Speech - This project aims at providing speech interfaces for the web. This project achieved a word error rate on LibriSpeech's test-clean of 6.5% which is commendable.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;I found this paper comparing open source speech recognition toolkits to be relevant to your question &lt;a href=&quot;http://suendermann.com/su/pdf/oasis2014.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;http://suendermann.com/su/pdf/oasis2014.pdf&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Siraj Raval has an excellent tensorflow speech recognition tutorial. It is available here &lt;a href=&quot;https://github.com/llSourcell/tensorflow_speech_recognition_demo&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://github.com/llSourcell/tensorflow_speech_recognition_demo&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="10913" LastEditorUserId="10913" LastEditDate="2018-01-16T13:23:25.913" LastActivityDate="2018-01-16T13:23:25.913" CommentCount="0" />
	<row Id="5211" PostTypeId="1" CreationDate="2018-02-02T15:40:15.847" Score="5" ViewCount="46" Body="&lt;p&gt;If I train a speech recognition model using data collected from N different microphones, but deploy it on an unseen (test) microphone - does it impact the accuracy of the model? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;While I understand that theoretically an accuracy loss is likely, does anyone have any practical experience with this problem? &lt;/p&gt;&#xA;" OwnerUserId="12502" LastActivityDate="2018-02-10T18:48:34.000" Title="Can variations in microphones used in training set and test set impact the accuracy of speech recognition models?" Tags="&lt;deep-learning&gt;&lt;voice-recognition&gt;" AnswerCount="2" CommentCount="2" />
	<row Id="5217" PostTypeId="2" ParentId="5211" CreationDate="2018-02-02T19:29:42.600" Score="4" Body="&lt;p&gt;Yes it can. However, other differences between training and test data with audio could have greater effect:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;p&gt;Identity of the speaker (including effects from gender, age, physical build, local accent, amongst others)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Acoustics of the recording environment (including proximity to the microphone, size of space, presence of hard surfaces, background noise)&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;If any of these may vary from your training data, then it becomes harder to predict your generalised accuracy during training and early model selection.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;One possibility is to ensure your cross-validation set (which you absolutely should have) also separates data out by things that will vary from training to test. So instead of random train/cv split, you split by data that is key for generalisation. This is sometimes called a &lt;em&gt;stratified&lt;/em&gt; train/test split.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If your only concern is variation in microphone, then split your train/cv sets by microphone type. You will get a better assessment early on in the model selection process how well the training is generalising, and can focus your search on models that do well despite this expected difference.&lt;/p&gt;&#xA;" OwnerUserId="1847" LastEditorUserId="1847" LastEditDate="2018-02-02T19:39:21.110" LastActivityDate="2018-02-02T19:39:21.110" CommentCount="0" />
	<row Id="5271" PostTypeId="2" ParentId="5211" CreationDate="2018-02-10T16:08:14.443" Score="1" Body="&lt;p&gt;The most usual differences in signal records caused by different microphones will have small if not null impact in the recognition accuracy, in particular if we are talking about changes one mic by another of same model and manufactor:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Differences in bandwidth: voice is in a very common (central) bandwidth, it is not expected these differences impacts, even for low quality microphones.&lt;/li&gt;&#xA;&lt;li&gt;Microphone distortions: same as previous, they will not impact because they are smaller than, by example, a change in the speaker.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;However, if we talk about a general recognition system to be used with very different types of mics, there are some microphone issues that can cause your system completely fail:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;mic sensitivity: small sensitivity differences will have no effect because they are solved in the same way than differences in speaker volume/intonation. However, if the microphone is not enough sensible the S/N can be below the minimum need, in particular when speaker increase the distance to the mic.&lt;/li&gt;&#xA;&lt;li&gt;lack of beam-forming: if your system is prepared to use an array of microphones to filter noise and/or secondary sources, usage of a normal phone will decrease accuracy.&lt;/li&gt;&#xA;&lt;li&gt;changes in sample ratio and/or sample bits: if the microphone and its A/D has a low sampling speed or size (i.e. Bluetooth mics, phone lines, ...), the accuracy can fail.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;By example, for IOT applications, the first two of this list are the more challenging ones.&lt;/p&gt;&#xA;" OwnerUserId="12630" LastEditorUserId="12630" LastEditDate="2018-02-10T18:48:34.000" LastActivityDate="2018-02-10T18:48:34.000" CommentCount="2" />
	<row Id="5422" PostTypeId="1" AcceptedAnswerId="5424" CreationDate="2018-02-24T21:55:33.637" Score="0" ViewCount="59" Body="&lt;p&gt;If possible consider the relationship between implementation difficulty and accuracy in voice examples or simply chat conversations.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And currently, what are the directions on algorithms like Deep Learning or others to solve this.&lt;/p&gt;&#xA;" OwnerUserId="12958" LastActivityDate="2018-02-24T22:58:21.840" Title="What is easier or more efficient to summarize voice or text? [DP/RN]" Tags="&lt;neural-networks&gt;&lt;deep-learning&gt;&lt;natural-language-processing&gt;&lt;voice-recognition&gt;&lt;text-summarization&gt;" AnswerCount="2" CommentCount="0" FavoriteCount="1" />
	<row Id="5423" PostTypeId="2" ParentId="5422" CreationDate="2018-02-24T22:02:48.983" Score="0" Body="&lt;p&gt;You might want to take the Stanford Online course on YouTube &lt;a href=&quot;https://www.youtube.com/playlist?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;strong&gt;Natural Language Processing with Deep Learning&lt;/strong&gt;&lt;/a&gt;. This course will give you insight into how different kinds of neural networks can be used for different kind of NLP tasks.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;In my opinion, you can use &lt;em&gt;Gated Recurrent Units (GRUs)&lt;/em&gt; to encode and decode text. Of course, text will be easier because voice data, as it is stored in a computer, is going to be difficult to interpret in the testing phase. Another way is to get most &lt;strong&gt;&lt;em&gt;impactful&lt;/em&gt;&lt;/strong&gt; words and then use these to form sentences regarding the original text.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;You can also start by looking out for publications related to text summarizers. For example, &lt;a href=&quot;https://arxiv.org/abs/1602.06023&quot; rel=&quot;nofollow noreferrer&quot;&gt;Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond&lt;/a&gt;, will get you started. You can use this as a starting point. In case you need to understand basics regarding the underlying techniques, then you can go through references in this paper and find out useful resources to get you started.&lt;/p&gt;&#xA;" OwnerUserId="12957" LastActivityDate="2018-02-24T22:02:48.983" CommentCount="1" />
  	<row Id="5424" PostTypeId="2" ParentId="5422" CreationDate="2018-02-24T22:44:23.667" Score="2" Body="&lt;p&gt;Summarizing text is always going to be 'easier or more efficient' than voice simply because voice requires the additional step of converting to text.  That doesn't tell you anything about accuracy.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From an article published on June 1, 2017, &lt;a href=&quot;https://9to5google.com/2017/06/01/google-speech-recognition-humans/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Google’s speech recognition is now almost as accurate as humans&lt;/a&gt;:&#xA;&lt;em&gt;&quot;According to Mary Meeker’s annual Internet Trends Report, Google’s machine learning-backed voice recognition — as of May 2017 — has achieved a &lt;strong&gt;95% word accuracy rate for the English language&lt;/strong&gt;. That current rate also happens to be the threshold for human accuracy.&quot;&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;If you need this kind of accuracy check out &lt;a href=&quot;https://cloud.google.com/speech/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Google's Cloud Speech API&lt;/a&gt;.  There is even a speech to text feature on the web page.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Given a speech-to-text conversion accuracy of 95%, voice will be 5% less accurate than text if everything else is equal but it usually isn't.  People generally write better text, such as in documents or emails, than when they speak unless of course they are giving a formal lecture, or talking in a formal meeting.  If one is analyzing text messages, Tweets, or threads found in typical informal forums, you will find very poor quality in grammar, spelling, vocabulary, and punctuation.  The answer to your question will depend on the source of your text. &lt;/p&gt;&#xA;&#xA;&lt;p&gt;In another article, dated November 13, 2017, &lt;a href=&quot;https://transcribeme.com/blog/why-100-accuracy-is-not-available-with-speech-recognition-software&quot; rel=&quot;nofollow noreferrer&quot;&gt;Why 100% Accuracy Is Not Available With Speech Recognition Software Alone&lt;/a&gt;, the author gives some reasons, albeit for transcription software which has a special purpose, why there will always be some errors due to:&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Speech Patterns and Accents - Regional variations exist, for example English speakers in Boston sound different than Kentucky.  How does the software handle slurred speech or when a person blends their words?&lt;/li&gt;&#xA;&lt;li&gt;Grammar and Punctuation - speech recognition software doesn't know where a period, comma, or semi-colon belongs&lt;/li&gt;&#xA;&lt;li&gt;Homonyms and unusual words - &quot;Speech processing software can only recognize words and phrases that it has specifically been trained to recognize.&quot;&lt;/li&gt;&#xA;&lt;li&gt;Ambient Noise, Overlapping Speech, and Number of Speakers&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;To address your last question about where the technology is going...&lt;br&gt;&#xA;Four days ago a paper by Tom Young, Devamanyu Hazarika, Soujanya Poria, and Erik Cambria entitled &lt;a href=&quot;https://arxiv.org/pdf/1708.02709.pdf&quot; rel=&quot;nofollow noreferrer&quot;&gt;Recent Trends in Deep Learning Based&#xA;Natural Language Processing&lt;/a&gt; was published which gives some of the answers.  &lt;/p&gt;&#xA;&#xA;&lt;p&gt;From the 'Conclusion' section:&#xA;&lt;em&gt;With distributed representation, various deep models have&#xA;become the new state-of-the-art methods for NLP problems.&#xA;Supervised learning is the most popular practice in recent&#xA;deep learning research for NLP. In many real-world scenarios,&#xA;however, we have unlabeled data which require advanced&#xA;unsupervised or semi-supervised approaches. In cases where&#xA;there is lack of labeled data for some particular classes or the&#xA;appearance of a new class while testing the model, strategies&#xA;like zero-shot learning should be employed. These learning&#xA;schemes are still in their developing phase but we expect deep&#xA;learning based NLP research to be driven in the direction of&#xA;making better use of unlabeled data. We expect such trend to&#xA;continue with more and better model designs. We expect to&#xA;see more NLP applications that employ reinforcement learning&#xA;methods, e.g., dialogue systems. We also expect to see more&#xA;research on multimodal learning [167] as, in the real world,&#xA;language is often grounded on (or correlated with) other&#xA;signals.&lt;/em&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;em&gt;Finally, we expect to see more deep learning models whose&#xA;internal memory (bottom-up knowledge learned from the data)&#xA;is enriched with an external memory (top-down knowledge&#xA;inherited from a KB). Coupling symbolic and sub-symbolic AI&#xA;will be key for stepping forward in the path from NLP to natural&#xA;language understanding. Relying on machine learning, in&#xA;fact, is good to make a ‘good guess’ based on past experience,&#xA;because sub-symbolic methods encode correlation and their&#xA;decision-making process is probabilistic.&lt;/em&gt;&lt;/p&gt;&#xA;" OwnerUserId="5763" LastEditorUserId="5763" LastEditDate="2018-02-24T22:58:21.840" LastActivityDate="2018-02-24T22:58:21.840" CommentCount="1" />
	<row Id="5658" PostTypeId="1" AcceptedAnswerId="5668" CreationDate="2018-03-13T10:04:26.173" Score="3" ViewCount="46" Body="&lt;p&gt;This is a theoretical question. I am newbie to artificial intelligence and machine learning, and the more I read the more I like this. So far, I have been reading about evaluation of language models (I am focused on ASR), but I still don't get the concept of development test. The clearest explanation I have come across is the following&lt;/p&gt;&#xA;&#xA;&lt;pre&gt;&lt;code&gt;&quot;Sometimes we use a particular test set so often that we implicitly tune to its &#xA;characteristics. We then need a fresh test set that is truly unseen. In such cases, &#xA;we call the initial test set the development test set or, devset&quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;Nevetheless I have not found sense as for why an additional test has to be used. In other words, why aren't training and test sets enough?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thanks in advance!&lt;/p&gt;&#xA;" OwnerUserId="13291" LastEditorUserId="4302" LastEditDate="2018-10-08T12:48:54.253" LastActivityDate="2018-10-08T12:48:54.253" Title="What are development tests used for?" Tags="&lt;natural-language-processing&gt;&lt;intelligence-testing&gt;&lt;voice-recognition&gt;" AnswerCount="1" CommentCount="1" />
	<row Id="6195" PostTypeId="1" CreationDate="2018-04-27T14:01:23.277" Score="1" ViewCount="30" Body="&lt;p&gt;Currently I am working with two large speech databases and I was asked to build one subset from each one in order to get two representative subsets with the same number of utterances. My question is: the number of utterances is the same as the number of audio files?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thank you so much!&lt;/p&gt;&#xA;" OwnerUserId="13291" LastEditorUserId="4302" LastEditDate="2018-10-08T12:47:35.603" LastActivityDate="2018-10-08T12:47:35.603" Title="Number of utterances" Tags="&lt;natural-language-processing&gt;&lt;voice-recognition&gt;&lt;lexical-recognition&gt;" AnswerCount="0" CommentCount="5" />
	<row Id="6464" PostTypeId="1" CreationDate="2018-05-19T06:46:02.830" Score="1" ViewCount="31" Body="&lt;p&gt;With all the Google I/O stuff coming out, how can I verify that I have an actual human on the phone using only voice? Are there still vocal things humans can, but robots can't do?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Conditions: the person on the phone is a stranger (so personal questions won't work), and the verification must be voice only.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;(Also, I understand Google Duplex may be just an overhyped demo that will turn out to flop like the Pixel Buds. But eventually such a bot would be created, right? If so, what's the best verification?)&lt;/p&gt;&#xA;" OwnerUserId="15743" LastActivityDate="2018-07-30T19:02:32.553" Title="&quot;Vocal captcha&quot; for robots on the phone?" Tags="&lt;human-like&gt;&lt;voice-recognition&gt;&lt;computational-linguistics&gt;" AnswerCount="1" CommentCount="0" FavoriteCount="1" />
	<row Id="6766" PostTypeId="1" CreationDate="2018-06-15T11:56:04.230" Score="2" ViewCount="495" Body="&lt;p&gt;As you know OpenCV is a big great open-source library for image recognition and machine vision(and may further purposes like computer graphics, etc).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Is there similar library in sound field(Voice recognition/ NLP(Natural Language Processing))? &lt;/p&gt;&#xA;&#xA;&lt;p&gt;I know espeak for TTS, also pocketsphinx for voice recognition. Also there is something like ChatScript that I don't know if I can consider as a NLP engine or not? But I like to know did I mentioned the Best libraries for each part of sound/voice field or there are better options to learn and work with them?&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Also will happy to hear some suggestions about best book(s) to read to learn the concepts/algorithms of ASR/NLP.&lt;/p&gt;&#xA;" OwnerUserId="9941" LastEditorUserId="9941" LastEditDate="2018-06-16T09:09:11.937" LastActivityDate="2018-10-10T05:21:59.100" Title="Is there something like OpenCV for voice recognition &amp; NLP?" Tags="&lt;natural-language-processing&gt;&lt;reference-request&gt;&lt;software-evaluation&gt;&lt;voice-recognition&gt;&lt;c++&gt;" AnswerCount="4" CommentCount="3" FavoriteCount="2" />
	<row Id="6767" PostTypeId="2" ParentId="6766" CreationDate="2018-06-15T13:14:29.763" Score="2" Body="&lt;p&gt;I don't know about voice recognition but for NLP i think that &lt;a href=&quot;https://radimrehurek.com/gensim/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Gensim&lt;/a&gt; could be what you are looking for!&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Gensim is a NLP package that contains efficient implementations of many well known functionalities for the tasks of topic modeling such as tf–idf, Latent Dirichlet allocation, Latent semantic analysis...&lt;/p&gt;&#xA;&#xA;&lt;p&gt;About the readings, maybe you can start with the original &lt;a href=&quot;https://arxiv.org/abs/1301.3781&quot; rel=&quot;nofollow noreferrer&quot;&gt;word2vec&lt;/a&gt; paper (“The meaning of a word can be inferred by the company it keeps”).&lt;/p&gt;&#xA;" OwnerUserId="16136" LastActivityDate="2018-06-15T13:14:29.763" CommentCount="0" />
	<row Id="6769" PostTypeId="2" ParentId="6766" CreationDate="2018-06-15T14:22:43.750" Score="2" Body="&lt;blockquote&gt;&#xA;  &lt;p&gt;According to what Josh Dotson posted via medium,gives a clear insightful knowledge concerning the following;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&#xA;&lt;p&gt;1.Speech data besides speech recognition.&lt;/p&gt;&#xA;&#xA;&lt;ol start=&quot;2&quot;&gt;&#xA;&lt;li&gt;&lt;p&gt;Language modelling.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Text to speech.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Machine translation.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;p&gt;Signal processing.&lt;/p&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&#xA;&lt;p&gt;&lt;strong&gt;And lastly, books and blogs for further research&lt;/strong&gt;&lt;/p&gt;&#xA;&#xA;&lt;blockquote&gt;&#xA;  &lt;p&gt;&lt;a href=&quot;https://medium.com/@joshdotai/a-curated-list-of-speech-and-natural-language-processing-resources-4d89f94c032a&quot; rel=&quot;nofollow noreferrer&quot;&gt;Resources for acknowledgement&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;" OwnerUserId="1581" LastEditorUserId="1671" LastEditDate="2018-06-15T21:09:51.520" LastActivityDate="2018-06-15T21:09:51.520" CommentCount="0" />
	<row Id="8337" PostTypeId="2" ParentId="6766" CreationDate="2018-10-10T05:21:59.100" Score="1" Body="&lt;p&gt;In the field of Automatic Speech Recognition (ASR) &lt;a href=&quot;https://github.com/kaldi-asr/kaldi&quot; rel=&quot;nofollow noreferrer&quot;&gt;Kaldi&lt;/a&gt; is the current leader. Before Deep Neural Network era there were &lt;a href=&quot;https://cmusphinx.github.io/wiki/about/&quot; rel=&quot;nofollow noreferrer&quot;&gt;Sphinx&lt;/a&gt; and &lt;a href=&quot;http://htk.eng.cam.ac.uk/&quot; rel=&quot;nofollow noreferrer&quot;&gt;HTK&lt;/a&gt;. &lt;/p&gt;&#xA;" OwnerUserId="18908" LastActivityDate="2018-10-10T05:21:59.100" CommentCount="0" />
	<row Id="7678" PostTypeId="1" CreationDate="2018-08-22T15:10:12.507" Score="1" ViewCount="27" Body="&lt;p&gt;The term paraphrasing is used for converting input text into output text with small modifications on the semantic level. Paraphrasing is used by managers to distribute work items to employees. It is a certain form of communication which is hard to formalize.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;From the management literature it is know that so called workflow management systems are implemented as groupware servers. They are storing and forward messages in the intranet of a company. The question is: is it possible to combine both? That means to paraphrase incoming messages of a company and distribute the messages to sub-departments? In theory, this would replace traditional managers, but I'm not sure. Perhaps it would make sense to test out the hypothesis first on the Enron dataset, which is a corpus of the e-mail fulltext of 158 employees in a large company.&lt;/p&gt;&#xA;" OwnerUserId="11571" LastActivityDate="2018-08-22T15:10:12.507" Title="Can semantic paraphrasing be used for a workflow management system?" Tags="&lt;machine-learning&gt;&lt;natural-language-processing&gt;&lt;voice-recognition&gt;" AnswerCount="0" CommentCount="0" />
	<row Id="7710" PostTypeId="1" CreationDate="2018-08-25T09:13:34.543" Score="0" ViewCount="42" Body="&lt;p&gt;I am planning to use Mozilla DeepSpeech for the project. For the use case at hand, I'm thinking if there's a possibility of using any NLP engine after the speech-to-text to improve its efficiency. If so, what and how could that be implemented.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;And regarding open-source S2T models, is there any model whose efficiency is better than Mozilla DeepSpeech?&lt;/p&gt;&#xA;" OwnerUserId="17714" LastEditorUserId="1671" LastEditDate="2018-08-27T19:50:49.820" LastActivityDate="2018-09-04T21:14:56.377" Title="Speech recognition/ Voice Recognition: How to use NLP after a speech-to-text to improve accuracy?" Tags="&lt;lstm&gt;&lt;software-evaluation&gt;&lt;voice-recognition&gt;" AnswerCount="0" CommentCount="3" />
	<row Id="8234" PostTypeId="2" ParentId="8223" CreationDate="2018-10-03T05:39:22.023" Score="3" Body="&lt;p&gt;Fourier transform is used to transform audio data to get more information (features).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;For example, raw audio data usually represented by a one-dimensional array, &lt;code&gt;x[n]&lt;/code&gt;, which has a length &lt;code&gt;n&lt;/code&gt; (number of samples). &lt;code&gt;x[i]&lt;/code&gt; is an amplitude value of the i-th sample point.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Using the Fourier transform, your audio data will be represented as a two-dimensional array. Now, &lt;code&gt;x[i]&lt;/code&gt; is a not a single value of amplitude, but a list of frequencies which compose original value at the i-th frame (a frame consists of a few samples).&lt;/p&gt;&#xA;&#xA;&lt;p&gt;See the image below (from wikipedia), the red graph is an original value of n samples before transformed, and the blue graph is a transformed value of one frame.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&quot;https://i.stack.imgur.com/1OWVu.png&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;img src=&quot;https://i.stack.imgur.com/1OWVu.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;" OwnerUserId="16565" LastActivityDate="2018-10-03T05:39:22.023" CommentCount="0" />
</test>